{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "8f74e1c4", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/node_postprocessor/PII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "c04ffe8e-6573-470f-aef5-348522a0de15", "metadata": {}, "source": ["PIIï¼ˆä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰è„±æ•\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "94cf2040", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "83660e9a", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-llms-huggingface"]}, {"cell_type": "code", "execution_count": null, "id": "254fff73", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "efa2a242-27bc-478f-8939-18a7f8153d4f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n", "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n", "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n", "NumExpr defaulting to 8 threads.\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/home/loganm/miniconda3/envs/llama-index/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n"]}], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n", "\n", "from llama_index.core.postprocessor import (\n", "    PIINodePostprocessor,\n", "    NERPIINodePostprocessor,\n", ")\n", "from llama_index.llms.huggingface import HuggingFaceLLM\n", "from llama_index.core import Document, VectorStoreIndex\n", "from llama_index.core.schema import TextNode"]}, {"cell_type": "code", "execution_count": null, "id": "216e951a-42c4-4e6b-b16d-6a6064829ebf", "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£\n", "text = \"\"\"\n", "ä½ å¥½ï¼ŒPaulo Santosã€‚æ‚¨ä¿¡ç”¨å¡è´¦æˆ·1111-0000-1111-0000çš„æœ€æ–°å¯¹è´¦å•å·²å¯„åˆ°Seattle, WA 98109çš„123 Any Streetã€‚\n", "\"\"\"\n", "node = TextNode(text=text)"]}, {"attachments": {}, "cell_type": "markdown", "id": "24495d69-d568-4cc7-9445-87692bf77863", "metadata": {}, "source": ["### é€‰é¡¹1ï¼šä½¿ç”¨NERæ¨¡å‹è¿›è¡ŒPIIå±è”½\n", "\n", "ä½¿ç”¨Hugging Faceçš„NERæ¨¡å‹è¿›è¡ŒPIIå±è”½\n"]}, {"cell_type": "code", "execution_count": null, "id": "003f66f0-f67f-47f2-88eb-b2bbb6d33791", "metadata": {}, "outputs": [], "source": ["processor = NERPIINodePostprocessor()"]}, {"cell_type": "code", "execution_count": null, "id": "e76c995c-57ee-4d1b-a771-6626ef93e8cd", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n", "Using a pipeline without specifying a model name and revision in production is not recommended.\n", "/home/loganm/miniconda3/envs/llama-index/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n", "  warnings.warn(\n"]}], "source": ["from llama_index.core.schema import NodeWithScore\n", "\n", "new_nodes = processor.postprocess_nodes([NodeWithScore(node=node)])"]}, {"cell_type": "code", "execution_count": null, "id": "d4783c27-9a55-44f1-be9e-a4fe1fc1e0fa", "metadata": {}, "outputs": [{"data": {"text/plain": ["'Hello [ORG_6]. The latest statement for your credit card account 1111-0000-1111-0000 was mailed to 123 [ORG_108] [LOC_112], [LOC_120], [LOC_129] 98109.'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# æŸ¥çœ‹å·²ç¼–è¾‘çš„æ–‡æœ¬\n", "new_nodes[0].node.get_text()"]}, {"cell_type": "code", "execution_count": null, "id": "075d45dc-a226-4ba7-8c8a-d9dd536f8560", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'[ORG_6]': 'Paulo Santos',\n", " '[ORG_108]': 'Any',\n", " '[LOC_112]': 'Street',\n", " '[LOC_120]': 'Seattle',\n", " '[LOC_129]': 'WA'}"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# è·å–å…ƒæ•°æ®ä¸­çš„æ˜ å°„\n", "# æ³¨æ„ï¼šè¿™ä¸ä¼šå‘é€åˆ°LLMï¼\n", "new_nodes[0].node.metadata[\"__pii_node_info__\"]"]}, {"attachments": {}, "cell_type": "markdown", "id": "06ca1e50-eeee-4079-bec6-3621cb760f98", "metadata": {}, "source": ["### é€‰é¡¹2ï¼šä½¿ç”¨LLMè¿›è¡ŒPIIæ•°æ®å±è”½\n", "\n", "æ³¨æ„ï¼šæ‚¨åº”è¯¥ä½¿ç”¨*æœ¬åœ°*LLMæ¨¡å‹è¿›è¡ŒPIIæ•°æ®å±è”½ã€‚ä¸‹é¢çš„ç¤ºä¾‹ä½¿ç”¨çš„æ˜¯OpenAIï¼Œä½†é€šå¸¸æƒ…å†µä¸‹æ‚¨ä¼šä½¿ç”¨åœ¨æœ¬åœ°è¿è¡Œçš„LLMï¼Œå¯èƒ½æ˜¯æ¥è‡ªhuggingfaceã€‚æœ¬åœ°LLMçš„ç¤ºä¾‹å¯ä»¥åœ¨[è¿™é‡Œ](https://gpt-index.readthedocs.io/en/latest/how_to/customization/custom_llms.html#example-using-a-huggingface-llm)æ‰¾åˆ°ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "5a2db8d3-6bb7-4855-852e-a4941abb03bf", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.openai import OpenAI\n", "\n", "processor = PIINodePostprocessor(llm=OpenAI())"]}, {"cell_type": "code", "execution_count": null, "id": "b834e7a3-8f90-45eb-841a-335b0d33dcab", "metadata": {}, "outputs": [], "source": ["from llama_index.core.schema import NodeWithScore\n", "\n", "new_nodes = processor.postprocess_nodes([NodeWithScore(node=node)])"]}, {"cell_type": "code", "execution_count": null, "id": "ca1498f3-34a1-4001-90f9-03feb5532d7d", "metadata": {}, "outputs": [{"data": {"text/plain": ["'Hello [NAME]. The latest statement for your credit card account [CREDIT_CARD_NUMBER] was mailed to [ADDRESS].'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# æŸ¥çœ‹å·²ç¼–è¾‘çš„æ–‡æœ¬\n", "new_nodes[0].node.get_text()"]}, {"cell_type": "code", "execution_count": null, "id": "d574d591-c1db-498b-ba32-9ed4190c6b4c", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'NAME': 'Paulo Santos',\n", " 'CREDIT_CARD_NUMBER': '1111-0000-1111-0000',\n", " 'ADDRESS': '123 Any Street, Seattle, WA 98109'}"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# è·å–å…ƒæ•°æ®ä¸­çš„æ˜ å°„\n", "# æ³¨æ„ï¼šè¿™ä¸ä¼šå‘é€åˆ°LLMï¼\n", "new_nodes[0].node.metadata[\"__pii_node_info__\"]"]}, {"cell_type": "markdown", "id": "6cc87ed4", "metadata": {}, "source": ["### é€‰é¡¹3ï¼šä½¿ç”¨Presidioè¿›è¡ŒPIIæ•°æ®è„±æ•\n", "\n", "ä½¿ç”¨Presidioæ¥è¯†åˆ«å’ŒåŒ¿ååŒ–PIIæ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "ac215117", "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£\n", "text = \"\"\"\n", "ä½ å¥½ï¼ŒPaulo Santosã€‚æ‚¨çš„ä¿¡ç”¨å¡è´¦æˆ·4095-2609-9393-4932çš„æœ€æ–°å¯¹è´¦å•å·²ç»å¯„åˆ°äº†åç››é¡¿å·è¥¿é›…å›¾å¸‚98109é‚®å¯„åœ°å€ã€‚\n", "IBAN GB90YNTU67299444055881å’Œç¤¾ä¼šå®‰å…¨å·ç 474-49-7577å·²åœ¨ç³»ç»Ÿä¸­éªŒè¯ã€‚\n", "è¿›ä¸€æ­¥çš„æ²Ÿé€šå°†å‘é€è‡³paulo@presidio.site\n", "\"\"\"\n", "presidio_node = TextNode(text=text)"]}, {"cell_type": "code", "execution_count": null, "id": "8a745520", "metadata": {}, "outputs": [], "source": ["from llama_index.postprocessor.presidio import PresidioPIINodePostprocessor\n", "\n", "processor = PresidioPIINodePostprocessor()"]}, {"cell_type": "code", "execution_count": null, "id": "89cb17ed", "metadata": {}, "outputs": [], "source": ["from llama_index.core.schema import NodeWithScore\n", "\n", "presidio_new_nodes = processor.postprocess_nodes(\n", "    [NodeWithScore(node=presidio_node)]\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "b8fe9cef", "metadata": {}, "outputs": [{"data": {"text/plain": ["'\\nHello <PERSON_1>. The latest statement for your credit card account <CREDIT_CARD_1> was mailed to <LOCATION_2>, <LOCATION_1>. IBAN <IBAN_CODE_1> and social security number is <US_SSN_1> were verified on the system. Further communications will be sent to <EMAIL_ADDRESS_1> \\n'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# æŸ¥çœ‹å·²ç¼–è¾‘çš„æ–‡æœ¬\n", "presidio_new_nodes[0].node.get_text()"]}, {"cell_type": "code", "execution_count": null, "id": "80203af0", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'<EMAIL_ADDRESS_1>': 'paulo@presidio.site',\n", " '<US_SSN_1>': '474-49-7577',\n", " '<IBAN_CODE_1>': 'GB90YNTU67299444055881',\n", " '<LOCATION_1>': 'WA 98109',\n", " '<LOCATION_2>': 'Seattle',\n", " '<CREDIT_CARD_1>': '4095-2609-9393-4932',\n", " '<PERSON_1>': 'Paulo Santos'}"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# è·å–å…ƒæ•°æ®ä¸­çš„æ˜ å°„\n", "# æ³¨æ„ï¼šè¿™ä¸ä¼šå‘é€åˆ°LLMï¼\n", "presidio_new_nodes[0].node.metadata[\"__pii_node_info__\"]"]}, {"attachments": {}, "cell_type": "markdown", "id": "3444d895-e2fd-4af9-834a-64acf49f74f8", "metadata": {}, "source": ["### å°†èŠ‚ç‚¹æä¾›ç»™ç´¢å¼•\n", "\n", "åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•å°†èŠ‚ç‚¹æ·»åŠ åˆ°ç´¢å¼•ä¸­ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "9d33a9c0-efcd-4e79-b1f5-05aca9fc109f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n", "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n", "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 30 tokens\n", "> [build_index_from_nodes] Total embedding token usage: 30 tokens\n"]}], "source": ["# è¾“å…¥åˆ°ç´¢å¼•ä¸­\n", "index = VectorStoreIndex([n.node for n in new_nodes])"]}, {"cell_type": "code", "execution_count": null, "id": "dc8b1993-d23b-4db1-8bb9-4f882bded66c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n", "> [retrieve] Total LLM token usage: 0 tokens\n", "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 8 tokens\n", "> [retrieve] Total embedding token usage: 8 tokens\n", "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 71 tokens\n", "> [get_response] Total LLM token usage: 71 tokens\n", "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n", "> [get_response] Total embedding token usage: 0 tokens\n", "\n", "[ADDRESS]\n"]}], "source": ["response = index.as_query_engine().query(\n", "    \"What address was the statement mailed to?\"\n", ")\n", "print(str(response))"]}], "metadata": {"kernelspec": {"display_name": "llama-index", "language": "python", "name": "llama-index"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}