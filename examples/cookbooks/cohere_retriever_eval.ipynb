{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "8a5706df", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/evaluation/cookbooks/cohere_retriever_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "36129c05-81f2-466c-a507-b62a577199d8", "metadata": {}, "source": ["# Cohere init8 和二进制嵌入检索评估\n", "\n", "Cohere Embed 是第一个原生支持浮点、int8、二进制和无符号二进制嵌入的嵌入模型。有关Cohere int8和二进制嵌入的更多详细信息，请参阅他们的[主要博客文章](https://txt.cohere.com/int8-binary-embeddings/)。\n", "\n", "这个笔记本帮助您评估这些不同的嵌入类型，并为您的RAG管道选择一个。它使用我们的`RetrieverEvaluator`来评估使用Retriever模块LlamaIndex的嵌入质量。\n", "\n", "观察到的指标：\n", "\n", "1. 命中率\n", "2. MRR（平均倒数排名）\n", "\n", "对于任何给定的问题，这些指标将比较从真实上下文中检索到的结果的质量。评估数据集是使用我们的合成数据集生成模块创建的。我们将使用GPT-4进行数据集生成，以避免偏见。\n", "\n", "# 注意：笔记本末尾显示的结果非常特定于数据集，以及考虑的各种其他参数。我们建议您将笔记本用作参考，在您的数据集上进行实验，并评估在RAG管道中使用不同嵌入类型的效果。\n"]}, {"cell_type": "markdown", "id": "27f54aff-edaf-4f99-9aa7-9c91a6cabaf8", "metadata": {}, "source": ["## 安装步骤\n"]}, {"cell_type": "code", "execution_count": null, "id": "9df86266", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-embeddings-cohere"]}, {"cell_type": "markdown", "id": "c6e98d46-1ac6-4fad-8004-64e4d4dcf47e", "metadata": {}, "source": ["```python\n", "# 设置API密钥\n", "\n", "# 在使用API之前，通常需要获取API密钥。\n", "# 以下是如何设置API密钥的示例代码。\n", "\n", "api_key = \"your_api_key_here\"\n", "```\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a7a03e7", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI KEY\"\n", "os.environ[\"COHERE_API_KEY\"] = \"YOUR COHEREAI API KEY\""]}, {"cell_type": "markdown", "id": "8659681a-7141-4f80-9bbe-8eddc061a134", "metadata": {}, "source": ["## 设置\n", "\n", "在这里，我们加载数据（PG文章），解析成节点。然后我们使用简单的向量索引对这些数据进行索引，并获得以下不同嵌入类型的检索器。\n", "\n", "1. `float`（浮点数）\n", "2. `int8`（8位整数）\n", "3. `binary`（二进制）\n", "4. `ubinary`（无符号二进制）\n"]}, {"cell_type": "code", "execution_count": null, "id": "bb6fecf4-7215-4ae9-b02b-3cb7c6000f2c", "metadata": {}, "outputs": [], "source": ["import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "4f63b16c-6a83-4ef0-a451-43c2c3d9c828", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import generate_question_context_pairs\n", "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "from llama_index.core.node_parser import SentenceSplitter\n", "from llama_index.llms.openai import OpenAI\n", "from llama_index.embeddings.cohere import CohereEmbedding"]}, {"attachments": {}, "cell_type": "markdown", "id": "4e3b3f28", "metadata": {}, "source": ["## 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "589c112d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2024-03-27 20:26:33--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 75042 (73K) [text/plain]\n", "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n", "\n", "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.03s   \n", "\n", "2024-03-27 20:26:34 (2.18 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n", "\n"]}], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "id": "af83cac0-2d08-467e-a88c-7370472eec87", "metadata": {}, "source": ["## 加载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "ab50ac91-e9d4-4fae-a519-db5711a13210", "metadata": {}, "outputs": [], "source": ["documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"]}, {"cell_type": "markdown", "id": "8d1beff2-c9e9-4b67-b5f8-4530df0d356f", "metadata": {}, "source": ["```python\n", "class Node:\n", "    def __init__(self, data):\n", "        self.data = data\n", "        self.next = None\n", "```\n", "\n", "这段代码创建了一个名为Node的类，该类具有一个构造函数`__init__`，用于初始化节点的数据和下一个节点的引用。\n"]}, {"cell_type": "code", "execution_count": null, "id": "66499039-d76d-4914-b03a-bcbd10c8c33b", "metadata": {}, "outputs": [], "source": ["node_parser = SentenceSplitter(chunk_size=512)\n", "nodes = node_parser.get_nodes_from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "id": "af31b424-02c4-4731-beca-e88ef4f202ca", "metadata": {}, "outputs": [], "source": ["# 默认情况下，节点的id被设置为随机的uuid。为了确保每次运行相同的id，我们手动设置它们。 ", "for idx, node in enumerate(nodes):", "    node.id_ = f\"node_{idx}\""]}, {"cell_type": "markdown", "id": "9ea4d0a3-7ab3-48a0-89c3-6e7abc6d82de", "metadata": {}, "source": ["## 为不同的嵌入类型创建检索器\n"]}, {"cell_type": "code", "execution_count": null, "id": "c1268ad2-3b29-49dc-92b3-6894900b4534", "metadata": {}, "outputs": [], "source": ["# llm 用于问题生成", "# 使用除cohereAI之外的任何其他llm以避免偏见。", "llm = OpenAI(model=\"gpt-4\")", "", "", "# 返回嵌入模型的函数", "def cohere_embedding(", "    model_name: str, input_type: str, embedding_type: str", ") -> CohereEmbedding:", "    return CohereEmbedding(", "        cohere_api_key=os.environ[\"COHERE_API_KEY\"],", "        model_name=model_name,", "        input_type=input_type,", "        embedding_type=embedding_type,", "    )", "", "", "# 返回不同嵌入类型嵌入模型的检索器函数", "def retriver(nodes, embedding_type=\"float\", model_name=\"embed-english-v3.0\"):", "    vector_index = VectorStoreIndex(", "        nodes,", "        embed_model=cohere_embedding(", "            model_name, \"search_document\", embedding_type", "        ),", "    )", "    retriever = vector_index.as_retriever(", "        similarity_top_k=2,", "        embed_model=cohere_embedding(", "            model_name, \"search_query\", embedding_type", "        ),", "    )", "    return retriever"]}, {"cell_type": "code", "execution_count": null, "id": "11836d3f-136d-45fe-bad8-f0480751ee67", "metadata": {}, "outputs": [], "source": ["# 为浮点嵌入类型构建检索器", "retriver_float = retriver(nodes)", "", "# 为int8嵌入类型构建检索器", "retriver_int8 = retriver(nodes, \"int8\")", "", "# 为二进制嵌入类型构建检索器", "retriver_binary = retriver(nodes, \"binary\")", "", "# 为无符号二进制嵌入类型构建检索器", "retriver_ubinary = retriver(nodes, \"ubinary\")"]}, {"cell_type": "markdown", "id": "baf75ec6-7419-4975-83df-6d6fa08adb77", "metadata": {}, "source": ["### 尝试检索\n", "\n", "我们将使用`float`检索器对一个示例查询进行检索。\n"]}, {"cell_type": "code", "execution_count": null, "id": "fd260990-0aea-490b-99e0-d7517f668020", "metadata": {}, "outputs": [], "source": ["retrieved_nodes = retriver_float.retrieve(\"What did the author do growing up?\")"]}, {"cell_type": "code", "execution_count": null, "id": "ce4b0823-8be4-4dd4-8486-8e73d79590fe", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**Node ID:** node_2<br>**Similarity:** 0.3641554823852197<br>**Text:** I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\n", "\n", "Computers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he'd write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\n", "\n", "Though I liked programming, I didn't plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledg...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** node_0<br>**Similarity:** 0.36283154406791923<br>**Text:** What I Worked On\n", "\n", "February 2021\n", "\n", "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n", "\n", "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n", "\n", "The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in ...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["from llama_index.core.response.notebook_utils import display_source_node\n", "\n", "for node in retrieved_nodes:\n", "    display_source_node(node, source_length=1000)"]}, {"cell_type": "markdown", "id": "5371db56-2b1c-497a-8fd0-a1a69b2ce773", "metadata": {}, "source": ["## 评估数据集 - (查询, 上下文) 对的合成数据集生成\n", "\n", "在这里，我们将在现有文本语料库上构建一个简单的评估数据集。\n", "\n", "我们使用我们的 `generate_question_context_pairs` 来在给定的非结构化文本语料库上生成一组 (查询, 上下文) 对。这使用LLM来自动从每个上下文块生成问题。\n", "\n", "我们得到一个 `EmbeddingQAFinetuneDataset` 对象。在高层次上，这包含了一组将查询和相关文档块映射到id的内容，以及语料库本身。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a25924cf-7eeb-4160-a035-4a69ee1e46de", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import (\n", "    generate_question_context_pairs,\n", "    EmbeddingQAFinetuneDataset,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "2d29a159-9a4f-4d44-9c0d-1cd683f8bb9b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 59/59 [04:10<00:00,  4.24s/it]\n"]}], "source": ["qa_dataset = generate_question_context_pairs(\n", "    nodes, llm=llm, num_questions_per_chunk=2\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "f32d458b-50ad-426c-a969-e9fe8fb5861a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\"Describe the author's initial experiences with programming on the IBM 1401. What were some of the challenges he faced and how did these experiences shape his understanding of programming?\"\n"]}], "source": ["queries = qa_dataset.queries.values()\n", "print(list(queries)[0])"]}, {"cell_type": "code", "execution_count": null, "id": "6a900650-38ed-405e-936c-08e48e0fb8ea", "metadata": {}, "outputs": [], "source": ["# [可选] 保存", "qa_dataset.save_json(\"pg_eval_dataset.json\")"]}, {"cell_type": "code", "execution_count": null, "id": "713c1b71-2ab6-42a0-bde3-ab3bfe880f97", "metadata": {}, "outputs": [], "source": ["", "# [可选] 加载", "qa_dataset = EmbeddingQAFinetuneDataset.from_json(\"pg_eval_dataset.json\")"]}, {"cell_type": "markdown", "id": "d3267fd6-187c-4e11-9f80-cfce08d98f1f", "metadata": {}, "source": ["## 使用`RetrieverEvaluator`进行检索评估\n", "\n", "现在我们已经准备好运行我们的检索评估。我们将在我们生成的评估数据集上运行我们的`RetrieverEvaluator`。\n"]}, {"cell_type": "markdown", "id": "c3d9ac28-672a-4a5b-be81-fb97e92a1e64", "metadata": {}, "source": ["### 为不同的嵌入类型定义`RetrieverEvaluator`\n"]}, {"cell_type": "code", "execution_count": null, "id": "42fa6f9c-a6da-43c4-b4c6-748ada393490", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import RetrieverEvaluator", "", "metrics = [\"mrr\", \"hit_rate\"]", "", "# 浮点型嵌入类型的检索评估器", "retriever_evaluator_float = RetrieverEvaluator.from_metric_names(", "    metrics, retriever=retriver_float", ")", "", "# int8型嵌入类型的检索评估器", "retriever_evaluator_int8 = RetrieverEvaluator.from_metric_names(", "    metrics, retriever=retriver_int8", ")", "", "# 二进制型嵌入类型的检索评估器", "retriever_evaluator_binary = RetrieverEvaluator.from_metric_names(", "    metrics, retriever=retriver_binary", ")", "", "# 无符号二进制型嵌入类型的检索评估器", "retriever_evaluator_ubinary = RetrieverEvaluator.from_metric_names(", "    metrics, retriever=retriver_ubinary", ")"]}, {"cell_type": "code", "execution_count": null, "id": "a16f3351-d745-46b3-b53b-916f7c244def", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Query: \"Describe the author's initial experiences with programming on the IBM 1401. What were some of the challenges he faced and how did these experiences shape his understanding of programming?\"\n", "Metrics: {'mrr': 0.5, 'hit_rate': 1.0}\n", "\n"]}], "source": ["# 在一个样本查询上尝试一下", "sample_id, sample_query = list(qa_dataset.queries.items())[0]", "sample_expected = qa_dataset.relevant_docs[sample_id]", "", "eval_result = retriever_evaluator_float.evaluate(sample_query, sample_expected)", "print(eval_result)"]}, {"cell_type": "code", "execution_count": null, "id": "3963d146-c4a3-4b00-8b53-52c6ec03d862", "metadata": {}, "outputs": [], "source": ["# 在整个数据集上的评估", "", "# 浮点嵌入类型", "eval_results_float = await retriever_evaluator_float.aevaluate_dataset(", "    qa_dataset", ")", "", "# int8嵌入类型", "eval_results_int8 = await retriever_evaluator_int8.aevaluate_dataset(", "    qa_dataset", ")", "", "# 二进制嵌入类型", "eval_results_binary = await retriever_evaluator_binary.aevaluate_dataset(", "    qa_dataset", ")", "", "# 无符号二进制嵌入类型", "eval_results_ubinary = await retriever_evaluator_ubinary.aevaluate_dataset(", "    qa_dataset", ")"]}, {"cell_type": "markdown", "id": "84bcf25d-f6ed-4e1d-b298-b7e318791865", "metadata": {}, "source": ["#### 定义`display_results`函数，用于在数据框中显示每个检索器的结果。\n"]}, {"cell_type": "code", "execution_count": null, "id": "ddbc38c7-660e-451b-8305-e8a7f23510a0", "metadata": {}, "outputs": [], "source": ["import pandas as pd", "", "", "def display_results(name, eval_results):", "    \"\"\"显示evaluate函数的结果。\"\"\"", "", "    metric_dicts = []", "    for eval_result in eval_results:", "        metric_dict = eval_result.metric_vals_dict", "        metric_dicts.append(metric_dict)", "", "    full_df = pd.DataFrame(metric_dicts)", "", "    hit_rate = full_df[\"hit_rate\"].mean()", "    mrr = full_df[\"mrr\"].mean()", "    columns = {\"Embedding Type\": [name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}", "", "    metric_df = pd.DataFrame(columns)", "", "    return metric_df"]}, {"cell_type": "markdown", "id": "b184508e-c57a-4f07-ab27-e51ff78ed8be", "metadata": {}, "source": ["## 评估结果\n"]}, {"cell_type": "code", "execution_count": null, "id": "d059d5ee-d2aa-4edf-8b9b-e09d29ff17b2", "metadata": {}, "outputs": [], "source": ["# 浮点嵌入类型的指标", "metrics_float = display_results(\"float\", eval_results_float)", "", "# int8嵌入类型的指标", "metrics_int8 = display_results(\"int8\", eval_results_int8)", "", "# 二进制嵌入类型的指标", "metrics_binary = display_results(\"binary\", eval_results_binary)", "", "# 无符号二进制嵌入类型的指标", "metrics_ubinary = display_results(\"ubinary\", eval_results_ubinary)"]}, {"cell_type": "code", "execution_count": null, "id": "6eb224e7", "metadata": {}, "outputs": [], "source": ["combined_metrics = pd.concat(\n", "    [metrics_float, metrics_int8, metrics_binary, metrics_ubinary]\n", ")\n", "combined_metrics.set_index([\"Embedding Type\"], append=True, inplace=True)"]}, {"cell_type": "code", "execution_count": null, "id": "7e4c0c85", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th></th>\n", "      <th>hit_rate</th>\n", "      <th>mrr</th>\n", "    </tr>\n", "    <tr>\n", "      <th></th>\n", "      <th>Embedding Type</th>\n", "      <th></th>\n", "      <th></th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th rowspan=\"4\" valign=\"top\">0</th>\n", "      <th>float</th>\n", "      <td>0.805085</td>\n", "      <td>0.665254</td>\n", "    </tr>\n", "    <tr>\n", "      <th>int8</th>\n", "      <td>0.813559</td>\n", "      <td>0.673729</td>\n", "    </tr>\n", "    <tr>\n", "      <th>binary</th>\n", "      <td>0.491525</td>\n", "      <td>0.394068</td>\n", "    </tr>\n", "    <tr>\n", "      <th>ubinary</th>\n", "      <td>0.449153</td>\n", "      <td>0.377119</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                  hit_rate       mrr\n", "  Embedding Type                    \n", "0 float           0.805085  0.665254\n", "  int8            0.813559  0.673729\n", "  binary          0.491525  0.394068\n", "  ubinary         0.449153  0.377119"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["combined_metrics"]}, {"cell_type": "markdown", "id": "658e5e99-921c-4c5b-9dd9-3c3439a88b2c", "metadata": {}, "source": ["注意：上面显示的结果非常特定于数据集和考虑的其他各种参数。我们建议您将笔记本用作参考，对您的数据集进行实验，并评估在您的RAG流程中使用不同嵌入类型的效果。\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "vscode": {"interpreter": {"hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}}, "nbformat": 4, "nbformat_minor": 5}