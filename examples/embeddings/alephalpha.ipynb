{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/ulan-yisaev/llama_index/blob/main/docs/docs/examples/embeddings/alephalpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# Aleph Alpha Embeddings\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-alephalpha"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä½¿ç”¨æ‚¨çš„AAä»¤ç‰Œè¿›è¡Œåˆå§‹åŒ–\n", "import os\n", "\n", "os.environ[\"AA_TOKEN\"] = \"your_token_here\""]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["#### ä½¿ç”¨`luminous-base`åµŒå…¥ã€‚\n", "\n", "- representation=\"Document\"ï¼šç”¨äºå­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­çš„æ–‡æœ¬ï¼ˆæ–‡æ¡£ï¼‰ã€‚\n", "- representation=\"Query\"ï¼šç”¨äºæœç´¢æŸ¥è¯¢ï¼Œä»¥æ‰¾åˆ°å‘é‡æ•°æ®åº“ä¸­æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚\n", "- representation=\"Symmetric\"ï¼šç”¨äºèšç±»ã€åˆ†ç±»ã€å¼‚å¸¸æ£€æµ‹æˆ–å¯è§†åŒ–ä»»åŠ¡ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "representation_enum: SemanticRepresentation.Query\n", "\n", "\n", "5120\n", "[0.14257812, 2.59375, 0.33203125, -0.33789062, -0.94140625]\n"]}], "source": ["æ¥è‡ªllama_index.embeddings.alephalphaçš„AlephAlphaEmbedding\n", "\n", "# è¦è‡ªå®šä¹‰æ‚¨çš„ä»¤ç‰Œï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ\n", "# å¦åˆ™ï¼Œå®ƒå°†æŸ¥æ‰¾æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­çš„AA_TOKEN\n", "# embed_model = AlephAlpha(token=\"<aa_token>\")\n", "\n", "# ä½¿ç”¨representation='query'\n", "embed_model = AlephAlphaEmbedding(\n", "    model=\"luminous-base\",\n", "    representation=\"Query\",\n", ")\n", "\n", "embeddings = embed_model.get_text_embedding(\"Hello Aleph Alpha!\")\n", "\n", "print(len(embeddings))\n", "print(embeddings[:5])\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "representation_enum: SemanticRepresentation.Document\n", "\n", "\n", "5120\n", "[0.14257812, 2.59375, 0.33203125, -0.33789062, -0.94140625]\n"]}], "source": ["# ä½¿ç”¨ representation='Document'\n", "embed_model = AlephAlphaEmbedding(\n", "    model=\"luminous-base\",\n", "    representation=\"Document\",\n", ")\n", "\n", "embeddings = embed_model.get_text_embedding(\"ä½ å¥½ Aleph Alpha!\")\n", "\n", "print(len(embeddings))\n", "print(embeddings[:5])\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "vscode": {"interpreter": {"hash": "64bcadabe4cd61f3d117ba0da9d14bf2f8e35582ff79e821f2e71056f2723d1e"}}}, "nbformat": 4, "nbformat_minor": 4}