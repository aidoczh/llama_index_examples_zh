{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n", "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/upstage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# UpstageåµŒå…¥\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-upstage==0.1.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"UPSTAGE_API_KEY\"] = \"YOUR_API_KEY\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.embeddings.upstage import UpstageEmbedding\n", "from llama_index.core import Settings\n", "\n", "embed_model = UpstageEmbedding()\n", "Settings.embed_model = embed_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ä½¿ç”¨ Upstage `solar-1-mini-embedding`\n", "\n", "æ³¨æ„ï¼Œæ‚¨å¯èƒ½éœ€è¦æ›´æ–°æ‚¨çš„ OpenAI å®¢æˆ·ç«¯ï¼š`pip install -U openai`\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è·å–APIå¯†é’¥å¹¶åˆ›å»ºåµŒå…¥\n", "from llama_index.embeddings.upstage import UpstageEmbedding\n", "\n", "embed_model = UpstageEmbedding()\n", "\n", "embeddings = embed_model.get_text_embedding(\n", "    \"Upstageæ–°çš„åµŒå…¥æ¨¡å‹å¾ˆæ£’ã€‚\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[0.02535058930516243, 0.007272760849446058, 0.015372460708022118, -0.007840132340788841, 0.0017625312320888042]\n"]}], "source": ["print(embeddings[:5])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["4096\n"]}], "source": ["print(len(embeddings))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["embeddings = embed_model.get_query_embedding(\n", "    \"What are some great Embeddings model?\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[0.03518765792250633, 0.01018011849373579, 0.013282101601362228, -0.008568626828491688, -0.005505830980837345]\n"]}], "source": ["print(embeddings[:5])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["4096\n"]}], "source": ["print(len(embeddings))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åµŒå…¥æ–‡æ¡£\n", "embeddings = embed_model.get_text_embedding_batch(\n", "    [\n", "        \"å‡çº§æ–°çš„åµŒå…¥æ¨¡å‹éå¸¸æ£’ã€‚\",\n", "        \"å‡çº§LLMä¹Ÿéå¸¸æ£’ã€‚\"\n", "    ]\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["2\n"]}], "source": ["print(len(embeddings))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[0.028246860951185226, 0.008945596404373646, 0.01719627156853676, -0.005711239762604237, 0.0016300849383696914]\n"]}], "source": ["print(embeddings[0][:5])"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}