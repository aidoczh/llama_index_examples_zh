{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 使用Intel® Extension for Transformers优化的BGE嵌入模型\n", "\n", "LlamaIndex支持加载由[Intel® Extension for Transformers](https://github.com/intel/intel-extension-for-transformers) (ITREX)生成的量化BGE嵌入模型，并使用ITREX [Neural Engine](https://github.com/intel/intel-extension-for-transformers/blob/main/intel_extension_for_transformers/llm/runtime/deprecated/docs/Installation.md)，这是一个高性能的NLP后端，可以加速模型的推断而不影响准确性。\n", "\n", "请参考我们的博客[使用Intel Extension for Transformers实现高效的自然语言嵌入模型](https://medium.com/intel-analytics-software/efficient-natural-language-embedding-models-with-intel-extension-for-transformers-2b6fcd0f8f34)和[BGE优化示例](https://github.com/intel/intel-extension-for-transformers/tree/main/examples/huggingface/pytorch/text-embedding/deployment/mteb/bge)以获取更多详细信息。\n", "\n", "为了能够加载和使用量化模型，请安装所需的依赖项`pip install intel-extension-for-transformers torch accelerate datasets onnx`。\n", "\n", "加载使用`ItrexQuantizedBgeEmbedding`类完成；使用方式类似于HuggingFace的本地嵌入模型；参见示例：\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-huggingface-itrex"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/yuwenzho/.conda/envs/yuwen/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n", "2024-03-29 15:40:42 [INFO] Start to extarct onnx model ops...\n", "2024-03-29 15:40:42 [INFO] Extract onnxruntime model done...\n", "2024-03-29 15:40:42 [INFO] Start to implement Sub-Graph matching and replacing...\n", "2024-03-29 15:40:43 [INFO] Sub-Graph match and replace done...\n"]}], "source": ["from llama_index.embeddings.huggingface_itrex import ItrexQuantizedBgeEmbedding\n", "\n", "embed_model = ItrexQuantizedBgeEmbedding(\n", "    \"Intel/bge-small-en-v1.5-sts-int8-static-inc\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["384\n", "[-0.005477035418152809, -0.000541043293196708, 0.036467909812927246, -0.04861024394631386, 0.0288068987429142]\n"]}], "source": ["embeddings = embed_model.get_text_embedding(\"Hello World!\")\n", "print(len(embeddings))\n", "print(embeddings[:5])"]}], "metadata": {"kernelspec": {"display_name": "yuwen", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}