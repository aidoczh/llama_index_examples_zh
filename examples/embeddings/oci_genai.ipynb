{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "6d1ca9ac", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/llm/bedrock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "9e3a8796-edc8-43f2-94ad-fe4fb20d70ed", "metadata": {}, "source": ["# Oracle云基础设施生成式人工智能\n", "\n", "Oracle云基础设施（OCI）生成式人工智能是一项完全托管的服务，提供一组最先进的、可定制的大型语言模型（LLMs），涵盖了广泛的用例，并可通过单个API访问。\n", "\n", "使用OCI生成式人工智能服务，您可以访问现成的预训练模型，或者基于自己的数据在专用AI集群上创建和托管自己微调的定制模型。该服务和API的详细文档可在__[这里](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__和__[这里](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__找到。\n", "\n", "本笔记本将解释如何使用OCI的生成式AI嵌入模型与LlamaIndex。\n"]}, {"cell_type": "markdown", "id": "3802e8c4", "metadata": {}, "source": ["## 设置\n", "\n", "如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "bb0dd8c9", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-oci-genai"]}, {"cell_type": "code", "execution_count": null, "id": "544d49f9", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "markdown", "id": "c2921307", "metadata": {}, "source": ["您还需要安装OCI sdk。\n"]}, {"cell_type": "code", "execution_count": null, "id": "378d5179", "metadata": {}, "outputs": [], "source": ["!pip install -U oci"]}, {"cell_type": "markdown", "id": "03d4024a", "metadata": {}, "source": ["## 基本用法\n"]}, {"cell_type": "code", "execution_count": null, "id": "60be18ae-c957-4ac2-a58a-0652e18ee6d6", "metadata": {}, "outputs": [], "source": ["from llama_index.embeddings.oci_genai import OCIGenAIEmbeddings\n", "\n", "embedding = OCIGenAIEmbeddings(\n", "    model_name=\"cohere.embed-english-light-v3.0\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "e1 = embedding.get_text_embedding(\"This is a test document\")\n", "print(e1[-5:])\n", "\n", "e2 = embedding.get_query_embedding(\"This is a test document\")\n", "print(e2[-5:])\n", "\n", "docs = [\"This is a test document\", \"This is another test document\"]\n", "e3 = embedding.get_text_embedding_batch(docs)\n", "print(e3)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}