{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/embeddings/OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨Colabä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# OpenAI Embeddingsï¼ˆOpenAIåµŒå…¥ï¼‰\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-openai"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.embeddings.openai import OpenAIEmbedding\n", "from llama_index.core import Settings\n", "\n", "embed_model = OpenAIEmbedding(embed_batch_size=10)\n", "Settings.embed_model = embed_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ä½¿ç”¨OpenAIçš„`text-embedding-3-large`å’Œ`text-embedding-3-small`\n", "\n", "æ³¨æ„ï¼Œä½ å¯èƒ½éœ€è¦æ›´æ–°ä½ çš„OpenAIå®¢æˆ·ç«¯ï¼š`pip install -U openai`\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è·å–APIå¯†é’¥å¹¶åˆ›å»ºåµŒå…¥\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "\n", "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n", "\n", "embeddings = embed_model.get_text_embedding(\n", "    \"Open AI new Embeddings models is great.\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[-0.011500772088766098, 0.02457442320883274, -0.01760469563305378, -0.017763426527380943, 0.029841400682926178]\n"]}], "source": ["print(embeddings[:5])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["3072\n"]}], "source": ["print(len(embeddings))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è·å–APIå¯†é’¥å¹¶åˆ›å»ºåµŒå…¥\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "\n", "embed_model = OpenAIEmbedding(\n", "    model=\"text-embedding-3-small\",\n", ")\n", "\n", "embeddings = embed_model.get_text_embedding(\n", "    \"Open AI new Embeddings models is awesome.\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["1536\n"]}], "source": ["print(len(embeddings))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## æ›´æ”¹è¾“å‡ºåµŒå…¥çš„ç»´åº¦\n", "æ³¨æ„ï¼šç¡®ä¿ä½ å®‰è£…äº†æœ€æ–°çš„OpenAIå®¢æˆ·ç«¯ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["512\n"]}], "source": ["# è·å–APIå¯†é’¥å¹¶åˆ›å»ºåµŒå…¥\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "\n", "\n", "embed_model = OpenAIEmbedding(\n", "    model=\"text-embedding-3-large\",\n", "    dimensions=512,\n", ")\n", "\n", "embeddings = embed_model.get_text_embedding(\n", "    \"Open AI new Embeddings models with different dimensions is awesome.\"\n", ")\n", "print(len(embeddings))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}