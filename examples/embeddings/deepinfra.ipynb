{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/ulan-yisaev/llama_index/blob/main/docs/docs/examples/embeddings/deepinfra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## DeepInfra\n", "\n", "通过这个集成，你可以使用DeepInfra嵌入模型为你的文本数据获取嵌入。这是[嵌入模型](https://deepinfra.com/models/embeddings)的链接。\n", "\n", "首先，你需要在[DeepInfra网站](https://deepinfra.com/)上注册并获取API令牌。你可以从模型卡中复制`model_ids`并开始在你的代码中使用它们。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 安装说明\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index llama-index-embeddings-deepinfra"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 初始化\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from dotenv import load_dotenv, find_dotenv\n", "from llama_index.embeddings.deepinfra import DeepInfraEmbeddingModel\n", "\n", "_ = load_dotenv(find_dotenv())\n", "\n", "model = DeepInfraEmbeddingModel(\n", "    model_id=\"BAAI/bge-large-en-v1.5\",  # 使用自定义模型ID\n", "    api_token=\"YOUR_API_TOKEN\",  # 可选择在此处提供令牌\n", "    normalize=True,  # 可选的规范化\n", "    text_prefix=\"text: \",  # 可选的文本前缀\n", "    query_prefix=\"query: \",  # 可选的查询前缀\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 同步请求\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["```python\n", "def get_text_embedding(text):\n", "    \"\"\"\n", "    Get the embedding for a given text.\n", "\n", "    Args:\n", "    text (str): The input text.\n", "\n", "    Returns:\n", "    embedding (np.array): The text embedding.\n", "    \"\"\"\n", "    # Implementation goes here\n", "    pass\n", "```\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["response = model.get_text_embedding(\"hello world\")\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["批量请求\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["texts = [\"hello world\", \"goodbye world\"]\n", "response_batch = model.get_text_embedding_batch(texts)\n", "print(response_batch)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 查询请求\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_response = model.get_query_embedding(\"hello world\")\n", "print(query_response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 异步请求\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 获取文本嵌入\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["async def main():\n", "    text = \"hello world\"\n", "    async_response = await model.aget_text_embedding(text)\n", "    print(async_response)\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    import asyncio\n", "\n", "    asyncio.run(main())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "如有任何问题或反馈，请通过feedback@deepinfra.com与我们联系。\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}