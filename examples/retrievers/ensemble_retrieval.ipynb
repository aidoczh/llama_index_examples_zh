{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "48518923", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/retrievers/ensemble_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "5bf1de44-4047-46cf-a04c-dbf910d9e179", "metadata": {}, "source": ["# é›†æˆæ£€ç´¢æŒ‡å—\n", "\n", "åœ¨æ„å»ºRAGåº”ç”¨ç¨‹åºæ—¶ï¼Œé€šå¸¸æœ‰è®¸å¤šæ£€ç´¢å‚æ•°/ç­–ç•¥å¯ä¾›é€‰æ‹©ï¼ˆä¾‹å¦‚ï¼Œä»å—å¤§å°åˆ°å‘é‡æ£€ç´¢ã€å…³é”®è¯æ£€ç´¢ã€æ··åˆæ£€ç´¢ç­‰ï¼‰ã€‚\n", "\n", "æƒ³æ³•æ˜¯ï¼šå¦‚æœæˆ‘ä»¬èƒ½å¤ŸåŒæ—¶å°è¯•å¤šç§ç­–ç•¥ï¼Œå¹¶è®©ä»»ä½•AI/é‡æ–°æ’åºå™¨/LLMä¿®å‰ªç»“æœï¼Œä¼šæ€ä¹ˆæ ·å‘¢ï¼Ÿ\n", "\n", "è¿™æ ·åšæœ‰ä¸¤ä¸ªç›®çš„ï¼š\n", "- é€šè¿‡æ±‡æ€»å¤šç§ç­–ç•¥çš„ç»“æœï¼Œå‡è®¾é‡æ–°æ’åºå™¨å¾ˆå¥½ï¼Œå¯ä»¥è·å¾—æ›´å¥½ï¼ˆå°½ç®¡æ›´æ˜‚è´µï¼‰çš„æ£€ç´¢ç»“æœ\n", "- ä¸€ç§å¯¹ä¸åŒæ£€ç´¢ç­–ç•¥è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„æ–¹æ³•ï¼ˆå…³äºé‡æ–°æ’åºå™¨ï¼‰\n", "\n", "æœ¬æŒ‡å—åœ¨Llama 2è®ºæ–‡ä¸­å±•ç¤ºäº†è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å¯¹ä¸åŒçš„å—å¤§å°å’Œä¸åŒçš„ç´¢å¼•è¿›è¡Œäº†é›†æˆæ£€ç´¢ã€‚\n", "\n", "**æ³¨æ„**ï¼šä¸€ä¸ªå¯†åˆ‡ç›¸å…³çš„æŒ‡å—æ˜¯æˆ‘ä»¬çš„[é›†æˆæŸ¥è¯¢å¼•æ“æŒ‡å—](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/ensemble_qury_engine.html) - ä¸€å®šè¦å»çœ‹çœ‹ï¼\n"]}, {"cell_type": "code", "execution_count": null, "id": "2d428f61", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-postprocessor-cohere-rerank\n", "%pip install llama-index-readers-file pymupdf"]}, {"cell_type": "code", "execution_count": null, "id": "aa2b0a5a-6449-4485-8217-b252fa47720e", "metadata": {}, "outputs": [], "source": ["%load_ext autoreload\n", "%autoreload 2"]}, {"cell_type": "markdown", "id": "6e73fead-ec2c-4346-bd08-e183c13c7e29", "metadata": {}, "source": ["## è®¾ç½®\n", "\n", "è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†å¿…è¦çš„å¯¼å…¥ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "0212306c", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨Colabä¸Šæ‰“å¼€æ­¤ç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "e8dd9c35", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "a2d59778-4cda-47b5-8cd0-b80fee91d1e4", "metadata": {}, "outputs": [], "source": ["# æ³¨æ„ï¼šè¿™ä»…åœ¨jupyterç¬”è®°æœ¬ä¸­æ˜¯å¿…éœ€çš„ã€‚\n", "# è¯¦æƒ…ï¼šJupyteråœ¨åå°è¿è¡Œä¸€ä¸ªäº‹ä»¶å¾ªç¯ã€‚\n", "#       å½“æˆ‘ä»¬å¯åŠ¨ä¸€ä¸ªäº‹ä»¶å¾ªç¯æ¥è¿›è¡Œå¼‚æ­¥æŸ¥è¯¢æ—¶ï¼Œä¼šå¯¼è‡´åµŒå¥—çš„äº‹ä»¶å¾ªç¯ã€‚\n", "#       é€šå¸¸æƒ…å†µä¸‹æ˜¯ä¸å…è®¸è¿™æ ·åšçš„ï¼Œæˆ‘ä»¬ä½¿ç”¨nest_asyncioæ¥å…è®¸è¿™æ ·åšä»¥æ–¹ä¾¿æ“ä½œã€‚\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "c628448c-573c-4eeb-a7e1-707fe8cc575c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n", "NumExpr defaulting to 8 threads.\n"]}], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().handlers = []\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n", "\n", "from llama_index.core import (\n", "    VectorStoreIndex,\n", "    SimpleDirectoryReader,\n", "    StorageContext,\n", ")\n", "from llama_index.core import SummaryIndex\n", "from llama_index.core.response.notebook_utils import display_response\n", "from llama_index.llms.openai import OpenAI"]}, {"cell_type": "markdown", "id": "787174ed-10ce-47d7-82fd-9ca7f891eea7", "metadata": {}, "source": ["## åŠ è½½æ•°æ®\n", "\n", "åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬é¦–å…ˆå°†Llama 2è®ºæ–‡ä½œä¸ºå•ä¸ªæ–‡æ¡£åŠ è½½è¿›æ¥ã€‚ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®ä¸åŒçš„å—å¤§å°å¯¹å…¶è¿›è¡Œå¤šæ¬¡åˆ†å—ã€‚æˆ‘ä»¬ä¸ºæ¯ä¸ªå—å¤§å°æ„å»ºä¸€ä¸ªå•ç‹¬çš„å‘é‡ç´¢å¼•ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "73a003b8-1d4a-4faf-9402-46d5977bb28d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2023-09-28 12:56:38--  https://arxiv.org/pdf/2307.09288.pdf\n", "Resolving arxiv.org (arxiv.org)... 128.84.21.199\n", "Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 13661300 (13M) [application/pdf]\n", "Saving to: â€˜data/llama2.pdfâ€™\n", "\n", "data/llama2.pdf     100%[===================>]  13.03M   521KB/s    in 42s     \n", "\n", "2023-09-28 12:57:20 (320 KB/s) - â€˜data/llama2.pdfâ€™ saved [13661300/13661300]\n"]}], "source": ["!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""]}, {"cell_type": "code", "execution_count": null, "id": "8dada361-4ac5-44a9-a29c-ae1aa8f5af78", "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "from llama_index.core import Document\n", "from llama_index.readers.file import PyMuPDFReader"]}, {"cell_type": "code", "execution_count": null, "id": "1ed22d71-2dfb-4c77-9511-57166a3de6d0", "metadata": {}, "outputs": [], "source": ["loader = PyMuPDFReader()\n", "docs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))\n", "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n", "docs = [Document(text=doc_text)]"]}, {"cell_type": "markdown", "id": "e63e6b28-22ae-4af7-9a1d-b2dcd7fafa8f", "metadata": {}, "source": ["åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°è¯•ä¸åŒçš„å—å¤§å°ï¼š128ã€256ã€512å’Œ1024ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "7081194a-ede7-478e-bff2-23e89e23ef16", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Chunk Size: 128\n", "Chunk Size: 256\n", "Chunk Size: 512\n", "Chunk Size: 1024\n"]}], "source": ["# åˆå§‹åŒ–æ¨¡å—\n", "llm = OpenAI(model=\"gpt-4\")\n", "chunk_sizes = [128, 256, 512, 1024]\n", "nodes_list = []\n", "vector_indices = []\n", "for chunk_size in chunk_sizes:\n", "    print(f\"å—å¤§å°: {chunk_size}\")\n", "    splitter = SentenceSplitter(chunk_size=chunk_size)\n", "    nodes = splitter.get_nodes_from_documents(docs)\n", "\n", "    # å°†å—å¤§å°æ·»åŠ åˆ°èŠ‚ç‚¹ä¸­ä»¥ä¾¿ä»¥åè·Ÿè¸ª\n", "    for node in nodes:\n", "        node.metadata[\"chunk_size\"] = chunk_size\n", "        node.excluded_embed_metadata_keys = [\"chunk_size\"]\n", "        node.excluded_llm_metadata_keys = [\"chunk_size\"]\n", "\n", "    nodes_list.append(nodes)\n", "\n", "    # æ„å»ºå‘é‡ç´¢å¼•\n", "    vector_index = VectorStoreIndex(nodes)\n", "    vector_indices.append(vector_index)"]}, {"cell_type": "markdown", "id": "50b9ac92-0ab2-4306-88ca-48f7e06ee763", "metadata": {}, "source": ["## å®šä¹‰é›†æˆæ£€ç´¢å™¨\n", "\n", "æˆ‘ä»¬ä½¿ç”¨é€’å½’æ£€ç´¢æŠ½è±¡æ¥è®¾ç½®ä¸€ä¸ªâ€œé›†æˆâ€æ£€ç´¢å™¨ï¼Œå…¶å·¥ä½œåŸç†å¦‚ä¸‹ï¼š\n", "- ä¸ºæ¯ä¸ªå—å¤§å°å®šä¹‰ä¸€ä¸ªå•ç‹¬çš„`IndexNode`ï¼Œå¯¹åº”äºå‘é‡æ£€ç´¢å™¨ï¼ˆç”¨äºå—å¤§å°128çš„æ£€ç´¢å™¨ï¼Œç”¨äºå—å¤§å°256çš„æ£€ç´¢å™¨ï¼Œä»¥æ­¤ç±»æ¨ï¼‰ã€‚\n", "- å°†æ‰€æœ‰çš„IndexNodesæ”¾å…¥å•ä¸ª`SummaryIndex`ä¸­ - å½“è°ƒç”¨ç›¸åº”çš„æ£€ç´¢å™¨æ—¶ï¼Œ*æ‰€æœ‰*èŠ‚ç‚¹éƒ½ä¼šè¢«è¿”å›ã€‚\n", "- å®šä¹‰ä¸€ä¸ªé€’å½’æ£€ç´¢å™¨ï¼Œå…¶æ ¹èŠ‚ç‚¹ä¸ºæ‘˜è¦ç´¢å¼•æ£€ç´¢å™¨ã€‚è¿™å°†é¦–å…ˆä»æ‘˜è¦ç´¢å¼•æ£€ç´¢å™¨ä¸­è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼Œç„¶åé€’å½’è°ƒç”¨æ¯ä¸ªå—å¤§å°çš„å‘é‡æ£€ç´¢å™¨ã€‚\n", "- å¯¹æœ€ç»ˆç»“æœè¿›è¡Œé‡æ–°æ’åºã€‚\n", "\n", "æœ€ç»ˆçš„ç»“æœæ˜¯åœ¨è¿è¡ŒæŸ¥è¯¢æ—¶ä¼šè°ƒç”¨æ‰€æœ‰çš„å‘é‡æ£€ç´¢å™¨ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "fbca69b4-d8d5-4dcb-af33-f9ed4a91ec05", "metadata": {}, "outputs": [], "source": ["# å°è¯•é›†æˆæ£€ç´¢\n", "\n", "from llama_index.core.tools import RetrieverTool\n", "from llama_index.core.schema import IndexNode\n", "\n", "# retriever_tools = []\n", "retriever_dict = {}\n", "retriever_nodes = []\n", "for chunk_size, vector_index in zip(chunk_sizes, vector_indices):\n", "    node_id = f\"chunk_{chunk_size}\"\n", "    node = IndexNode(\n", "        text=(\n", "            \"ä»Llama 2è®ºæ–‡ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ï¼ˆå—å¤§å°\"\n", "            f\" {chunk_size})\"\n", "        ),\n", "        index_id=node_id,\n", "    )\n", "    retriever_nodes.append(node)\n", "    retriever_dict[node_id] = vector_index.as_retriever()"]}, {"cell_type": "markdown", "id": "394c1883-4a85-4908-872f-d32072bfe63a", "metadata": {}, "source": ["å®šä¹‰é€’å½’æ£€ç´¢å™¨ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "5c9eaa6f-8f11-4380-b3c6-79092f17def3", "metadata": {}, "outputs": [], "source": ["from llama_index.core.selectors import PydanticMultiSelector\n", "\n", "from llama_index.core.retrievers import RouterRetriever\n", "from llama_index.core.retrievers import RecursiveRetriever\n", "from llama_index.core import SummaryIndex\n", "\n", "# æ´¾ç”Ÿçš„æ£€ç´¢å™¨å°†åªæ£€ç´¢æ‰€æœ‰èŠ‚ç‚¹\n", "summary_index = SummaryIndex(retriever_nodes)\n", "\n", "retriever = RecursiveRetriever(\n", "    root_id=\"root\",\n", "    retriever_dict={\"root\": summary_index.as_retriever(), **retriever_dict},\n", ")"]}, {"cell_type": "markdown", "id": "3b8317e0-2249-4d83-9ff0-dbd6701e25ec", "metadata": {}, "source": ["è®©æˆ‘ä»¬åœ¨ä¸€ä¸ªæ ·æœ¬æŸ¥è¯¢ä¸Šæµ‹è¯•æ£€ç´¢å™¨ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "7c72c61c-d4f7-4159-bb80-1989468ab61c", "metadata": {}, "outputs": [], "source": ["nodes = await retriever.aretrieve(\n", "    \"Tell me about the main aspects of safety fine-tuning\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "590ed8bc-83ad-4851-9ec6-bfbbdf3ff38d", "metadata": {}, "outputs": [], "source": ["print(f\"Number of nodes: {len(nodes)}\")\n", "for node in nodes:\n", "    print(node.node.metadata[\"chunk_size\"])\n", "    print(node.node.get_text())"]}, {"cell_type": "markdown", "id": "5b7e39a9-b031-46bb-b835-e09ed7bec3ee", "metadata": {}, "source": ["å®šä¹‰é‡æ–°æ’åºå™¨ä»¥å¤„ç†æœ€ç»ˆæ£€ç´¢åˆ°çš„èŠ‚ç‚¹é›†ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "1f26c527-17d2-4d4e-a6ee-8ea878ef8742", "metadata": {}, "outputs": [], "source": ["# å®šä¹‰é‡æ–°æ’åºå™¨\n", "from llama_index.core.postprocessor import LLMRerank,SentenceTransformerRerank\n", "from llama_index.postprocessor.cohere_rerank import CohereRerank\n", "\n", "# é‡æ–°æ’åºå™¨ = LLMRerank()\n", "# é‡æ–°æ’åºå™¨ = SentenceTransformerRerank(top_n=10)\n", "é‡æ–°æ’åºå™¨ = CohereRerank(top_n=10)"]}, {"cell_type": "markdown", "id": "9fcbee6b-aa93-4144-95b7-f5542c9c689e", "metadata": {}, "source": ["å®šä¹‰æ£€ç´¢æŸ¥è¯¢å¼•æ“ï¼Œå°†é€’å½’æ£€ç´¢å™¨å’Œé‡æ–°æ’åå™¨æ•´åˆåœ¨ä¸€èµ·ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "828589ef-d062-40dc-8a4b-245190769445", "metadata": {}, "outputs": [], "source": ["# å®šä¹‰RetrieverQueryEngine\n", "from llama_index.core.query_engine import RetrieverQueryEngine\n", "\n", "query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker])"]}, {"cell_type": "code", "execution_count": null, "id": "53e3c341-e66d-4950-88d5-6411699d064b", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\n", "    \"Tell me about the main aspects of safety fine-tuning\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "9aa680dd-03a0-4a76-b456-c4ef0136fdc2", "metadata": {}, "outputs": [], "source": ["display_response(\n", "    response, show_source=True, source_length=500, show_source_metadata=True\n", ")"]}, {"cell_type": "markdown", "id": "7850424f-84fc-4ea3-bb6a-18b4bc1d6dd5", "metadata": {}, "source": ["### åˆ†ææ¯ä¸ªå—çš„ç›¸å¯¹é‡è¦æ€§\n", "\n", "é›†æˆæ£€ç´¢çš„ä¸€ä¸ªæœ‰è¶£ç‰¹æ€§æ˜¯ï¼Œé€šè¿‡é‡æ–°æ’åºï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯ä»¥ä½¿ç”¨æœ€ç»ˆæ£€ç´¢é›†ä¸­å—çš„é¡ºåºæ¥ç¡®å®šæ¯ä¸ªå—å¤§å°çš„é‡è¦æ€§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæŸäº›å—å¤§å°æ€»æ˜¯æ’åœ¨å‰é¢ï¼Œé‚£ä¹ˆè¿™äº›å—å¯èƒ½ä¸æŸ¥è¯¢æ›´ç›¸å…³ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a7a8303-be94-45c5-8bc5-13ec8c7f1694", "metadata": {}, "outputs": [], "source": ["# æ ¹æ®åœ¨ç»„åˆæ’åä¸­çš„ä½ç½®è®¡ç®—æ¯ä¸ªå—å¤§å°çš„å¹³å‡ç²¾åº¦\n", "from collections import defaultdict\n", "import pandas as pd\n", "\n", "\n", "def mrr_all(metadata_values, metadata_key, source_nodes):\n", "    # æºèŠ‚ç‚¹æ˜¯ä¸€ä¸ªæ’ååˆ—è¡¨\n", "    # éå†æ¯ä¸ªå€¼ï¼Œæ‰¾å‡ºåœ¨source_nodesä¸­çš„ä½ç½®\n", "    value_to_mrr_dict = {}\n", "    for metadata_value in metadata_values:\n", "        mrr = 0\n", "        for idx, source_node in enumerate(source_nodes):\n", "            if source_node.node.metadata[metadata_key] == metadata_value:\n", "                mrr = 1 / (idx + 1)\n", "                break\n", "            else:\n", "                continue\n", "\n", "        # æ ‡å‡†åŒ–APï¼Œè®¾ç½®åœ¨å­—å…¸ä¸­\n", "        value_to_mrr_dict[metadata_value] = mrr\n", "\n", "    df = pd.DataFrame(value_to_mrr_dict, index=[\"MRR\"])\n", "    df.style.set_caption(\"å¹³å‡å€’æ•°æ’å\")\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "id": "adebbb82-764e-4b45-933e-84bf4ad64d40", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Mean Reciprocal Rank for each Chunk Size\n"]}, {"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>128</th>\n", "      <th>256</th>\n", "      <th>512</th>\n", "      <th>1024</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>MRR</th>\n", "      <td>0.333333</td>\n", "      <td>1.0</td>\n", "      <td>0.5</td>\n", "      <td>0.25</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["         128   256   512   1024\n", "MRR  0.333333   1.0   0.5  0.25"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# è®¡ç®—æ¯ä¸ªå—å¤§å°çš„å¹³å‡å€’æ•°æ’åï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰\n", "# æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å—å¤§å°ä¸º256å…·æœ‰æœ€é«˜çš„æ’åç»“æœã€‚\n", "print(\"æ¯ä¸ªå—å¤§å°çš„å¹³å‡å€’æ•°æ’å\")\n", "mrr_all(chunk_sizes, \"chunk_size\", response.source_nodes)"]}, {"cell_type": "markdown", "id": "b27a2f3c-55ce-4fa6-a15a-be539723a967", "metadata": {}, "source": ["## è¯„ä¼°\n", "\n", "æˆ‘ä»¬å°†æ›´ä¸¥æ ¼åœ°è¯„ä¼°é›†æˆæ£€ç´¢å™¨ç›¸å¯¹äºâ€œåŸºå‡†â€æ£€ç´¢å™¨çš„å·¥ä½œæ•ˆæœã€‚\n", "\n", "æˆ‘ä»¬å®šä¹‰/åŠ è½½ä¸€ä¸ªè¯„ä¼°åŸºå‡†æ•°æ®é›†ï¼Œç„¶åå¯¹å…¶è¿›è¡Œä¸åŒçš„è¯„ä¼°ã€‚\n", "\n", "**è­¦å‘Š**ï¼šè¿™å¯èƒ½ä¼šå¾ˆ*æ˜‚è´µ*ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨GPT-4ã€‚è¯·è°¨æ…ä½¿ç”¨ï¼Œå¹¶è°ƒæ•´æ ·æœ¬å¤§å°ä»¥é€‚åº”æ‚¨çš„é¢„ç®—ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "a4d66b14-4f38-4b61-809c-f603d7e09ef9", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset\n", "from llama_index.llms.openai import OpenAI\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "2b5a0d4e-7c0a-40f2-be5c-9dc1297483fc", "metadata": {}, "outputs": [], "source": ["# æ³¨æ„ï¼šå¦‚æœæ•°æ®é›†å°šæœªä¿å­˜ï¼Œè¯·è¿è¡Œæ­¤ä»£ç \n", "eval_llm = OpenAI(model=\"gpt-4\")\n", "# ä»æœ€å¤§çš„å—ï¼ˆ1024ï¼‰ç”Ÿæˆé—®é¢˜\n", "dataset_generator = DatasetGenerator(\n", "    nodes_list[-1],\n", "    llm=eval_llm,\n", "    show_progress=True,\n", "    num_questions_per_chunk=2,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "10b97355-de34-4840-a68f-4d137ab1b850", "metadata": {}, "outputs": [], "source": ["eval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=60)"]}, {"cell_type": "code", "execution_count": null, "id": "9ab72dc2-0d17-4925-83ca-a0630de28349", "metadata": {}, "outputs": [], "source": ["eval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")"]}, {"cell_type": "code", "execution_count": null, "id": "e7fd120e-36c2-4d20-8fca-d3e783756879", "metadata": {}, "outputs": [], "source": ["# å¯é€‰\n", "eval_dataset = QueryResponseDataset.from_json(\n", "    \"data/llama2_eval_qr_dataset.json\"\n", ")"]}, {"cell_type": "markdown", "id": "30f8b3a4-7824-4924-848f-fe8155291f80", "metadata": {}, "source": ["### æ¯”è¾ƒç»“æœ\n"]}, {"cell_type": "code", "execution_count": null, "id": "0d4e2e1a-a7cf-471a-b786-2645cfb327c7", "metadata": {}, "outputs": [], "source": ["import asyncio\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "c0cbc18a-9cec-4c29-a5e7-c0ba3752118e", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import (\n", "    CorrectnessEvaluator,\n", "    SemanticSimilarityEvaluator,\n", "    RelevancyEvaluator,\n", "    FaithfulnessEvaluator,\n", "    PairwiseComparisonEvaluator,\n", ")\n", "\n", "# æ³¨æ„ï¼šå¯ä»¥å–æ¶ˆå…¶ä»–è¯„ä¼°å™¨çš„æ³¨é‡Š\n", "evaluator_c = CorrectnessEvaluator(llm=eval_llm)  # æ­£ç¡®æ€§è¯„ä¼°å™¨\n", "evaluator_s = SemanticSimilarityEvaluator(llm=eval_llm)  # è¯­ä¹‰ç›¸ä¼¼æ€§è¯„ä¼°å™¨\n", "evaluator_r = RelevancyEvaluator(llm=eval_llm)  # ç›¸å…³æ€§è¯„ä¼°å™¨\n", "evaluator_f = FaithfulnessEvaluator(llm=eval_llm)  # å¿ å®åº¦è¯„ä¼°å™¨\n", "\n", "pairwise_evaluator = PairwiseComparisonEvaluator(llm=eval_llm)  # æˆå¯¹æ¯”è¾ƒè¯„ä¼°å™¨"]}, {"cell_type": "code", "execution_count": null, "id": "7a96ca32-9196-43e1-b82a-403becc2d56e", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation.eval_utils import (\n", "    get_responses,\n", "    get_results_df,\n", ")\n", "from llama_index.core.evaluation import BatchEvalRunner\n", "\n", "max_samples = 60\n", "\n", "eval_qs = eval_dataset.questions\n", "qr_pairs = eval_dataset.qr_pairs\n", "ref_response_strs = [r for (_, r) in qr_pairs]\n", "\n", "# é‡æ–°è®¾ç½®åŸºç¡€æŸ¥è¯¢å¼•æ“å’Œé›†æˆæŸ¥è¯¢å¼•æ“\n", "# åŸºç¡€æŸ¥è¯¢å¼•æ“\n", "base_query_engine = vector_indices[-1].as_query_engine(similarity_top_k=2)\n", "# é›†æˆæŸ¥è¯¢å¼•æ“\n", "reranker = CohereRerank(top_n=4)\n", "query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker])"]}, {"cell_type": "code", "execution_count": null, "id": "8bc3a77d-b513-4df8-a0eb-8543d86eb8ae", "metadata": {}, "outputs": [], "source": ["base_pred_responses = get_responses(\n", "    eval_qs[:max_samples], base_query_engine, show_progress=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "1401e805-97d3-447a-8460-d23c664bbcb5", "metadata": {}, "outputs": [], "source": ["pred_responses = get_responses(\n", "    eval_qs[:max_samples], query_engine, show_progress=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "023e8638-6d52-4d19-b0d8-99f43bfa5ef7", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "pred_response_strs = [str(p) for p in pred_responses]\n", "base_pred_response_strs = [str(p) for p in base_pred_responses]"]}, {"cell_type": "code", "execution_count": null, "id": "078f6459-c38d-4d3f-a53b-436b9d1d86b8", "metadata": {}, "outputs": [], "source": ["evaluator_dict = {\n", "    \"correctness\": evaluator_c,\n", "    \"faithfulness\": evaluator_f,\n", "    # \"relevancy\": evaluator_r,\n", "    \"semantic_similarity\": evaluator_s,\n", "}\n", "batch_runner = BatchEvalRunner(evaluator_dict, workers=1, show_progress=True)"]}, {"cell_type": "code", "execution_count": null, "id": "e88130b1-8938-4ba7-a91c-ee9c0e19a689", "metadata": {}, "outputs": [], "source": ["eval_results = await batch_runner.aevaluate_responses(\n", "    queries=eval_qs[:max_samples],\n", "    responses=pred_responses[:max_samples],\n", "    reference=ref_response_strs[:max_samples],\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8becc3de-2530-4e64-bafe-180fbd64a11a", "metadata": {}, "outputs": [], "source": ["base_eval_results = await batch_runner.aevaluate_responses(\n", "    queries=eval_qs[:max_samples],\n", "    responses=base_pred_responses[:max_samples],\n", "    reference=ref_response_strs[:max_samples],\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "a9153a9f-109c-437e-a860-9e2346859659", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>names</th>\n", "      <th>correctness</th>\n", "      <th>faithfulness</th>\n", "      <th>semantic_similarity</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Ensemble Retriever</td>\n", "      <td>4.375000</td>\n", "      <td>0.983333</td>\n", "      <td>0.964546</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Base Retriever</td>\n", "      <td>4.066667</td>\n", "      <td>0.983333</td>\n", "      <td>0.956692</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                names  correctness  faithfulness  semantic_similarity\n", "0  Ensemble Retriever     4.375000      0.983333             0.964546\n", "1      Base Retriever     4.066667      0.983333             0.956692"]}, "metadata": {}, "output_type": "display_data"}], "source": ["results_df = get_results_df(\n", "    [eval_results, base_eval_results],\n", "    [\"Ensemble Retriever\", \"Base Retriever\"],\n", "    [\"correctness\", \"faithfulness\", \"semantic_similarity\"],\n", ")\n", "display(results_df)"]}, {"cell_type": "code", "execution_count": null, "id": "33aa47ef-df96-4e58-8960-92d60091d6ad", "metadata": {}, "outputs": [], "source": ["batch_runner = BatchEvalRunner(\n", "    {\"pairwise\": pairwise_evaluator}, workers=3, show_progress=True\n", ")\n", "\n", "pairwise_eval_results = await batch_runner.aevaluate_response_strs(\n", "    queries=eval_qs[:max_samples],\n", "    response_strs=pred_response_strs[:max_samples],\n", "    reference=base_pred_response_strs[:max_samples],\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "f5f1c839-ac5e-4458-af05-c6ed4a2db7d7", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>names</th>\n", "      <th>pairwise</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Pairwise Comparison</td>\n", "      <td>0.5</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                 names  pairwise\n", "0  Pairwise Comparison       0.5"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["results_df = get_results_df(\n", "    [eval_results, base_eval_results],\n", "    [\"Ensemble Retriever\", \"Base Retriever\"],\n", "    [\"pairwise\"],\n", ")\n", "display(results_df)"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}