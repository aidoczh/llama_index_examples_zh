{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "48518923", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/retrievers/ensemble_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "5bf1de44-4047-46cf-a04c-dbf910d9e179", "metadata": {}, "source": ["# 集成检索指南\n", "\n", "在构建RAG应用程序时，通常有许多检索参数/策略可供选择（例如，从块大小到向量检索、关键词检索、混合检索等）。\n", "\n", "想法是：如果我们能够同时尝试多种策略，并让任何AI/重新排序器/LLM修剪结果，会怎么样呢？\n", "\n", "这样做有两个目的：\n", "- 通过汇总多种策略的结果，假设重新排序器很好，可以获得更好（尽管更昂贵）的检索结果\n", "- 一种对不同检索策略进行基准测试的方法（关于重新排序器）\n", "\n", "本指南在Llama 2论文中展示了这一点。我们对不同的块大小和不同的索引进行了集成检索。\n", "\n", "**注意**：一个密切相关的指南是我们的[集成查询引擎指南](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/ensemble_qury_engine.html) - 一定要去看看！\n"]}, {"cell_type": "code", "execution_count": null, "id": "2d428f61", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-postprocessor-cohere-rerank\n", "%pip install llama-index-readers-file pymupdf"]}, {"cell_type": "code", "execution_count": null, "id": "aa2b0a5a-6449-4485-8217-b252fa47720e", "metadata": {}, "outputs": [], "source": ["%load_ext autoreload\n", "%autoreload 2"]}, {"cell_type": "markdown", "id": "6e73fead-ec2c-4346-bd08-e183c13c7e29", "metadata": {}, "source": ["## 设置\n", "\n", "这里我们定义了必要的导入。\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "0212306c", "metadata": {}, "source": ["如果您在Colab上打开此笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "e8dd9c35", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "a2d59778-4cda-47b5-8cd0-b80fee91d1e4", "metadata": {}, "outputs": [], "source": ["# 注意：这仅在jupyter笔记本中是必需的。\n", "# 详情：Jupyter在后台运行一个事件循环。\n", "#       当我们启动一个事件循环来进行异步查询时，会导致嵌套的事件循环。\n", "#       通常情况下是不允许这样做的，我们使用nest_asyncio来允许这样做以方便操作。\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "c628448c-573c-4eeb-a7e1-707fe8cc575c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n", "NumExpr defaulting to 8 threads.\n"]}], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().handlers = []\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n", "\n", "from llama_index.core import (\n", "    VectorStoreIndex,\n", "    SimpleDirectoryReader,\n", "    StorageContext,\n", ")\n", "from llama_index.core import SummaryIndex\n", "from llama_index.core.response.notebook_utils import display_response\n", "from llama_index.llms.openai import OpenAI"]}, {"cell_type": "markdown", "id": "787174ed-10ce-47d7-82fd-9ca7f891eea7", "metadata": {}, "source": ["## 加载数据\n", "\n", "在这一部分，我们首先将Llama 2论文作为单个文档加载进来。然后，我们根据不同的块大小对其进行多次分块。我们为每个块大小构建一个单独的向量索引。\n"]}, {"cell_type": "code", "execution_count": null, "id": "73a003b8-1d4a-4faf-9402-46d5977bb28d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2023-09-28 12:56:38--  https://arxiv.org/pdf/2307.09288.pdf\n", "Resolving arxiv.org (arxiv.org)... 128.84.21.199\n", "Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 13661300 (13M) [application/pdf]\n", "Saving to: ‘data/llama2.pdf’\n", "\n", "data/llama2.pdf     100%[===================>]  13.03M   521KB/s    in 42s     \n", "\n", "2023-09-28 12:57:20 (320 KB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\n"]}], "source": ["!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""]}, {"cell_type": "code", "execution_count": null, "id": "8dada361-4ac5-44a9-a29c-ae1aa8f5af78", "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "from llama_index.core import Document\n", "from llama_index.readers.file import PyMuPDFReader"]}, {"cell_type": "code", "execution_count": null, "id": "1ed22d71-2dfb-4c77-9511-57166a3de6d0", "metadata": {}, "outputs": [], "source": ["loader = PyMuPDFReader()\n", "docs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))\n", "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n", "docs = [Document(text=doc_text)]"]}, {"cell_type": "markdown", "id": "e63e6b28-22ae-4af7-9a1d-b2dcd7fafa8f", "metadata": {}, "source": ["在这里，我们尝试不同的块大小：128、256、512和1024。\n"]}, {"cell_type": "code", "execution_count": null, "id": "7081194a-ede7-478e-bff2-23e89e23ef16", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Chunk Size: 128\n", "Chunk Size: 256\n", "Chunk Size: 512\n", "Chunk Size: 1024\n"]}], "source": ["# 初始化模块\n", "llm = OpenAI(model=\"gpt-4\")\n", "chunk_sizes = [128, 256, 512, 1024]\n", "nodes_list = []\n", "vector_indices = []\n", "for chunk_size in chunk_sizes:\n", "    print(f\"块大小: {chunk_size}\")\n", "    splitter = SentenceSplitter(chunk_size=chunk_size)\n", "    nodes = splitter.get_nodes_from_documents(docs)\n", "\n", "    # 将块大小添加到节点中以便以后跟踪\n", "    for node in nodes:\n", "        node.metadata[\"chunk_size\"] = chunk_size\n", "        node.excluded_embed_metadata_keys = [\"chunk_size\"]\n", "        node.excluded_llm_metadata_keys = [\"chunk_size\"]\n", "\n", "    nodes_list.append(nodes)\n", "\n", "    # 构建向量索引\n", "    vector_index = VectorStoreIndex(nodes)\n", "    vector_indices.append(vector_index)"]}, {"cell_type": "markdown", "id": "50b9ac92-0ab2-4306-88ca-48f7e06ee763", "metadata": {}, "source": ["## 定义集成检索器\n", "\n", "我们使用递归检索抽象来设置一个“集成”检索器，其工作原理如下：\n", "- 为每个块大小定义一个单独的`IndexNode`，对应于向量检索器（用于块大小128的检索器，用于块大小256的检索器，以此类推）。\n", "- 将所有的IndexNodes放入单个`SummaryIndex`中 - 当调用相应的检索器时，*所有*节点都会被返回。\n", "- 定义一个递归检索器，其根节点为摘要索引检索器。这将首先从摘要索引检索器中获取所有节点，然后递归调用每个块大小的向量检索器。\n", "- 对最终结果进行重新排序。\n", "\n", "最终的结果是在运行查询时会调用所有的向量检索器。\n"]}, {"cell_type": "code", "execution_count": null, "id": "fbca69b4-d8d5-4dcb-af33-f9ed4a91ec05", "metadata": {}, "outputs": [], "source": ["# 尝试集成检索\n", "\n", "from llama_index.core.tools import RetrieverTool\n", "from llama_index.core.schema import IndexNode\n", "\n", "# retriever_tools = []\n", "retriever_dict = {}\n", "retriever_nodes = []\n", "for chunk_size, vector_index in zip(chunk_sizes, vector_indices):\n", "    node_id = f\"chunk_{chunk_size}\"\n", "    node = IndexNode(\n", "        text=(\n", "            \"从Llama 2论文中检索相关内容（块大小\"\n", "            f\" {chunk_size})\"\n", "        ),\n", "        index_id=node_id,\n", "    )\n", "    retriever_nodes.append(node)\n", "    retriever_dict[node_id] = vector_index.as_retriever()"]}, {"cell_type": "markdown", "id": "394c1883-4a85-4908-872f-d32072bfe63a", "metadata": {}, "source": ["定义递归检索器。\n"]}, {"cell_type": "code", "execution_count": null, "id": "5c9eaa6f-8f11-4380-b3c6-79092f17def3", "metadata": {}, "outputs": [], "source": ["from llama_index.core.selectors import PydanticMultiSelector\n", "\n", "from llama_index.core.retrievers import RouterRetriever\n", "from llama_index.core.retrievers import RecursiveRetriever\n", "from llama_index.core import SummaryIndex\n", "\n", "# 派生的检索器将只检索所有节点\n", "summary_index = SummaryIndex(retriever_nodes)\n", "\n", "retriever = RecursiveRetriever(\n", "    root_id=\"root\",\n", "    retriever_dict={\"root\": summary_index.as_retriever(), **retriever_dict},\n", ")"]}, {"cell_type": "markdown", "id": "3b8317e0-2249-4d83-9ff0-dbd6701e25ec", "metadata": {}, "source": ["让我们在一个样本查询上测试检索器。\n"]}, {"cell_type": "code", "execution_count": null, "id": "7c72c61c-d4f7-4159-bb80-1989468ab61c", "metadata": {}, "outputs": [], "source": ["nodes = await retriever.aretrieve(\n", "    \"Tell me about the main aspects of safety fine-tuning\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "590ed8bc-83ad-4851-9ec6-bfbbdf3ff38d", "metadata": {}, "outputs": [], "source": ["print(f\"Number of nodes: {len(nodes)}\")\n", "for node in nodes:\n", "    print(node.node.metadata[\"chunk_size\"])\n", "    print(node.node.get_text())"]}, {"cell_type": "markdown", "id": "5b7e39a9-b031-46bb-b835-e09ed7bec3ee", "metadata": {}, "source": ["定义重新排序器以处理最终检索到的节点集。\n"]}, {"cell_type": "code", "execution_count": null, "id": "1f26c527-17d2-4d4e-a6ee-8ea878ef8742", "metadata": {}, "outputs": [], "source": ["# 定义重新排序器\n", "from llama_index.core.postprocessor import LLMRerank,SentenceTransformerRerank\n", "from llama_index.postprocessor.cohere_rerank import CohereRerank\n", "\n", "# 重新排序器 = LLMRerank()\n", "# 重新排序器 = SentenceTransformerRerank(top_n=10)\n", "重新排序器 = CohereRerank(top_n=10)"]}, {"cell_type": "markdown", "id": "9fcbee6b-aa93-4144-95b7-f5542c9c689e", "metadata": {}, "source": ["定义检索查询引擎，将递归检索器和重新排名器整合在一起。\n"]}, {"cell_type": "code", "execution_count": null, "id": "828589ef-d062-40dc-8a4b-245190769445", "metadata": {}, "outputs": [], "source": ["# 定义RetrieverQueryEngine\n", "from llama_index.core.query_engine import RetrieverQueryEngine\n", "\n", "query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker])"]}, {"cell_type": "code", "execution_count": null, "id": "53e3c341-e66d-4950-88d5-6411699d064b", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\n", "    \"Tell me about the main aspects of safety fine-tuning\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "9aa680dd-03a0-4a76-b456-c4ef0136fdc2", "metadata": {}, "outputs": [], "source": ["display_response(\n", "    response, show_source=True, source_length=500, show_source_metadata=True\n", ")"]}, {"cell_type": "markdown", "id": "7850424f-84fc-4ea3-bb6a-18b4bc1d6dd5", "metadata": {}, "source": ["### 分析每个块的相对重要性\n", "\n", "集成检索的一个有趣特性是，通过重新排序，我们实际上可以使用最终检索集中块的顺序来确定每个块大小的重要性。例如，如果某些块大小总是排在前面，那么这些块可能与查询更相关。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a7a8303-be94-45c5-8bc5-13ec8c7f1694", "metadata": {}, "outputs": [], "source": ["# 根据在组合排名中的位置计算每个块大小的平均精度\n", "from collections import defaultdict\n", "import pandas as pd\n", "\n", "\n", "def mrr_all(metadata_values, metadata_key, source_nodes):\n", "    # 源节点是一个排名列表\n", "    # 遍历每个值，找出在source_nodes中的位置\n", "    value_to_mrr_dict = {}\n", "    for metadata_value in metadata_values:\n", "        mrr = 0\n", "        for idx, source_node in enumerate(source_nodes):\n", "            if source_node.node.metadata[metadata_key] == metadata_value:\n", "                mrr = 1 / (idx + 1)\n", "                break\n", "            else:\n", "                continue\n", "\n", "        # 标准化AP，设置在字典中\n", "        value_to_mrr_dict[metadata_value] = mrr\n", "\n", "    df = pd.DataFrame(value_to_mrr_dict, index=[\"MRR\"])\n", "    df.style.set_caption(\"平均倒数排名\")\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "id": "adebbb82-764e-4b45-933e-84bf4ad64d40", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Mean Reciprocal Rank for each Chunk Size\n"]}, {"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>128</th>\n", "      <th>256</th>\n", "      <th>512</th>\n", "      <th>1024</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>MRR</th>\n", "      <td>0.333333</td>\n", "      <td>1.0</td>\n", "      <td>0.5</td>\n", "      <td>0.25</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["         128   256   512   1024\n", "MRR  0.333333   1.0   0.5  0.25"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# 计算每个块大小的平均倒数排名（越高越好）\n", "# 我们可以看到块大小为256具有最高的排名结果。\n", "print(\"每个块大小的平均倒数排名\")\n", "mrr_all(chunk_sizes, \"chunk_size\", response.source_nodes)"]}, {"cell_type": "markdown", "id": "b27a2f3c-55ce-4fa6-a15a-be539723a967", "metadata": {}, "source": ["## 评估\n", "\n", "我们将更严格地评估集成检索器相对于“基准”检索器的工作效果。\n", "\n", "我们定义/加载一个评估基准数据集，然后对其进行不同的评估。\n", "\n", "**警告**：这可能会很*昂贵*，特别是使用GPT-4。请谨慎使用，并调整样本大小以适应您的预算。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a4d66b14-4f38-4b61-809c-f603d7e09ef9", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset\n", "from llama_index.llms.openai import OpenAI\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "2b5a0d4e-7c0a-40f2-be5c-9dc1297483fc", "metadata": {}, "outputs": [], "source": ["# 注意：如果数据集尚未保存，请运行此代码\n", "eval_llm = OpenAI(model=\"gpt-4\")\n", "# 从最大的块（1024）生成问题\n", "dataset_generator = DatasetGenerator(\n", "    nodes_list[-1],\n", "    llm=eval_llm,\n", "    show_progress=True,\n", "    num_questions_per_chunk=2,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "10b97355-de34-4840-a68f-4d137ab1b850", "metadata": {}, "outputs": [], "source": ["eval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=60)"]}, {"cell_type": "code", "execution_count": null, "id": "9ab72dc2-0d17-4925-83ca-a0630de28349", "metadata": {}, "outputs": [], "source": ["eval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")"]}, {"cell_type": "code", "execution_count": null, "id": "e7fd120e-36c2-4d20-8fca-d3e783756879", "metadata": {}, "outputs": [], "source": ["# 可选\n", "eval_dataset = QueryResponseDataset.from_json(\n", "    \"data/llama2_eval_qr_dataset.json\"\n", ")"]}, {"cell_type": "markdown", "id": "30f8b3a4-7824-4924-848f-fe8155291f80", "metadata": {}, "source": ["### 比较结果\n"]}, {"cell_type": "code", "execution_count": null, "id": "0d4e2e1a-a7cf-471a-b786-2645cfb327c7", "metadata": {}, "outputs": [], "source": ["import asyncio\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "c0cbc18a-9cec-4c29-a5e7-c0ba3752118e", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import (\n", "    CorrectnessEvaluator,\n", "    SemanticSimilarityEvaluator,\n", "    RelevancyEvaluator,\n", "    FaithfulnessEvaluator,\n", "    PairwiseComparisonEvaluator,\n", ")\n", "\n", "# 注意：可以取消其他评估器的注释\n", "evaluator_c = CorrectnessEvaluator(llm=eval_llm)  # 正确性评估器\n", "evaluator_s = SemanticSimilarityEvaluator(llm=eval_llm)  # 语义相似性评估器\n", "evaluator_r = RelevancyEvaluator(llm=eval_llm)  # 相关性评估器\n", "evaluator_f = FaithfulnessEvaluator(llm=eval_llm)  # 忠实度评估器\n", "\n", "pairwise_evaluator = PairwiseComparisonEvaluator(llm=eval_llm)  # 成对比较评估器"]}, {"cell_type": "code", "execution_count": null, "id": "7a96ca32-9196-43e1-b82a-403becc2d56e", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation.eval_utils import (\n", "    get_responses,\n", "    get_results_df,\n", ")\n", "from llama_index.core.evaluation import BatchEvalRunner\n", "\n", "max_samples = 60\n", "\n", "eval_qs = eval_dataset.questions\n", "qr_pairs = eval_dataset.qr_pairs\n", "ref_response_strs = [r for (_, r) in qr_pairs]\n", "\n", "# 重新设置基础查询引擎和集成查询引擎\n", "# 基础查询引擎\n", "base_query_engine = vector_indices[-1].as_query_engine(similarity_top_k=2)\n", "# 集成查询引擎\n", "reranker = CohereRerank(top_n=4)\n", "query_engine = RetrieverQueryEngine(retriever, node_postprocessors=[reranker])"]}, {"cell_type": "code", "execution_count": null, "id": "8bc3a77d-b513-4df8-a0eb-8543d86eb8ae", "metadata": {}, "outputs": [], "source": ["base_pred_responses = get_responses(\n", "    eval_qs[:max_samples], base_query_engine, show_progress=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "1401e805-97d3-447a-8460-d23c664bbcb5", "metadata": {}, "outputs": [], "source": ["pred_responses = get_responses(\n", "    eval_qs[:max_samples], query_engine, show_progress=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "023e8638-6d52-4d19-b0d8-99f43bfa5ef7", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "pred_response_strs = [str(p) for p in pred_responses]\n", "base_pred_response_strs = [str(p) for p in base_pred_responses]"]}, {"cell_type": "code", "execution_count": null, "id": "078f6459-c38d-4d3f-a53b-436b9d1d86b8", "metadata": {}, "outputs": [], "source": ["evaluator_dict = {\n", "    \"correctness\": evaluator_c,\n", "    \"faithfulness\": evaluator_f,\n", "    # \"relevancy\": evaluator_r,\n", "    \"semantic_similarity\": evaluator_s,\n", "}\n", "batch_runner = BatchEvalRunner(evaluator_dict, workers=1, show_progress=True)"]}, {"cell_type": "code", "execution_count": null, "id": "e88130b1-8938-4ba7-a91c-ee9c0e19a689", "metadata": {}, "outputs": [], "source": ["eval_results = await batch_runner.aevaluate_responses(\n", "    queries=eval_qs[:max_samples],\n", "    responses=pred_responses[:max_samples],\n", "    reference=ref_response_strs[:max_samples],\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8becc3de-2530-4e64-bafe-180fbd64a11a", "metadata": {}, "outputs": [], "source": ["base_eval_results = await batch_runner.aevaluate_responses(\n", "    queries=eval_qs[:max_samples],\n", "    responses=base_pred_responses[:max_samples],\n", "    reference=ref_response_strs[:max_samples],\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "a9153a9f-109c-437e-a860-9e2346859659", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>names</th>\n", "      <th>correctness</th>\n", "      <th>faithfulness</th>\n", "      <th>semantic_similarity</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Ensemble Retriever</td>\n", "      <td>4.375000</td>\n", "      <td>0.983333</td>\n", "      <td>0.964546</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Base Retriever</td>\n", "      <td>4.066667</td>\n", "      <td>0.983333</td>\n", "      <td>0.956692</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                names  correctness  faithfulness  semantic_similarity\n", "0  Ensemble Retriever     4.375000      0.983333             0.964546\n", "1      Base Retriever     4.066667      0.983333             0.956692"]}, "metadata": {}, "output_type": "display_data"}], "source": ["results_df = get_results_df(\n", "    [eval_results, base_eval_results],\n", "    [\"Ensemble Retriever\", \"Base Retriever\"],\n", "    [\"correctness\", \"faithfulness\", \"semantic_similarity\"],\n", ")\n", "display(results_df)"]}, {"cell_type": "code", "execution_count": null, "id": "33aa47ef-df96-4e58-8960-92d60091d6ad", "metadata": {}, "outputs": [], "source": ["batch_runner = BatchEvalRunner(\n", "    {\"pairwise\": pairwise_evaluator}, workers=3, show_progress=True\n", ")\n", "\n", "pairwise_eval_results = await batch_runner.aevaluate_response_strs(\n", "    queries=eval_qs[:max_samples],\n", "    response_strs=pred_response_strs[:max_samples],\n", "    reference=base_pred_response_strs[:max_samples],\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "f5f1c839-ac5e-4458-af05-c6ed4a2db7d7", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>names</th>\n", "      <th>pairwise</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Pairwise Comparison</td>\n", "      <td>0.5</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                 names  pairwise\n", "0  Pairwise Comparison       0.5"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["results_df = get_results_df(\n", "    [eval_results, base_eval_results],\n", "    [\"Ensemble Retriever\", \"Base Retriever\"],\n", "    [\"pairwise\"],\n", ")\n", "display(results_df)"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}