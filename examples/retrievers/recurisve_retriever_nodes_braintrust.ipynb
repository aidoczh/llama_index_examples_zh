{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "30165d30", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/retrievers/recurisve_retriever_nodes_braintrust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "025f3e20-aec9-491c-8c90-234aed406a25", "metadata": {}, "source": ["# 递归检索器 + 节点引用 + Braintrust\n", "\n", "本指南展示了如何使用递归检索来遍历节点关系，并根据“引用”获取节点。\n", "\n", "节点引用是一个强大的概念。当您首次执行检索时，您可能希望检索引用而不是原始文本。您可以让多个引用指向同一个节点。\n", "\n", "在本指南中，我们探讨了节点引用的一些不同用法：\n", "- **块引用**：不同块大小指向更大的块\n", "- **元数据引用**：摘要 + 生成的问题指向更大的块\n", "\n", "我们通过[Braintrust](https://www.braintrustdata.com/)来评估我们的递归检索 + 节点引用方法的效果。Braintrust是构建人工智能产品的企业级堆栈。从评估到提示播放区，再到数据管理，我们消除了将人工智能整合到您的业务中的不确定性和烦琐。\n", "\n", "您可以在这里查看示例评估仪表板：\n", "- [基本检索器](https://www.braintrustdata.com/app/braintrustdata.com/p/llamaindex-recurisve-retrievers/baseRetriever)\n", "- [递归元数据检索器](https://www.braintrustdata.com/app/braintrustdata.com/p/llamaindex-recurisve-retrievers/recursiveMetadataRetriever)\n", "- [递归块检索器](https://www.braintrustdata.com/app/braintrustdata.com/p/llamaindex-recurisve-retrievers/recursiveChunkRetriever)\n"]}, {"cell_type": "code", "execution_count": null, "id": "c98b1160", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-readers-file"]}, {"cell_type": "code", "execution_count": null, "id": "ee583e89-a508-493e-b232-42e520ce19de", "metadata": {}, "outputs": [], "source": ["%load_ext autoreload", "%autoreload 2", "# 注意：将YOUR_OPENAI_API_KEY替换为您的OpenAI API密钥，将YOUR_BRAINTRUST_API_KEY替换为您的BrainTrust API密钥。不要用引号括起来。", "# 在https://braintrustdata.com/注册Braintrust，并在https://www.braintrustdata.com/app/braintrustdata.com/settings/api-keys获取您的API密钥", "# 注意：将YOUR_OPENAI_KEY替换为您的OpenAI API密钥，将YOUR_BRAINTRUST_API_KEY替换为您的BrainTrust API密钥。不要用引号括起来。", "%env OPENAI_API_KEY=", "%env BRAINTRUST_API_KEY=", "%env TOKENIZERS_PARALLELISM=true # 这是为了避免Chroma发出警告消息而需要的。"]}, {"cell_type": "code", "execution_count": null, "id": "98ed809c", "metadata": {}, "outputs": [], "source": ["%pip install -U llama_hub llama_index braintrust autoevals pypdf pillow transformers torch torchvision"]}, {"cell_type": "markdown", "id": "273f38de-e79a-4ce2-ad4e-2c70afc33f34", "metadata": {}, "source": ["## 加载数据 + 设置\n", "\n", "在这一部分，我们将下载 Llama 2 论文并创建一个初始节点集（块大小为 1024）。\n"]}, {"cell_type": "code", "execution_count": null, "id": "1eb829ef-b54b-4095-a832-6d1d115aa645", "metadata": {}, "outputs": [], "source": ["!mkdir data\n", "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""]}, {"cell_type": "code", "execution_count": null, "id": "6cd97455-5ff3-43ee-8222-f496ec234dc7", "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "from llama_index.readers.file import PDFReader\n", "from llama_index.core.response.notebook_utils import display_source_node\n", "from llama_index.core.retrievers import RecursiveRetriever\n", "from llama_index.core.query_engine import RetrieverQueryEngine\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.llms.openai import OpenAI\n", "import json"]}, {"cell_type": "code", "execution_count": null, "id": "a07c0e42-1ae8-4267-9355-6bb75323f82a", "metadata": {}, "outputs": [], "source": ["loader = PDFReader()\n", "docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))"]}, {"cell_type": "code", "execution_count": null, "id": "493e5492-a6ae-4e3e-aa23-274c0605b165", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Document\n", "\n", "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n", "docs = [Document(text=doc_text)]"]}, {"cell_type": "code", "execution_count": null, "id": "7c2abcd3-6cae-49dd-8719-9b738d000652", "metadata": {}, "outputs": [], "source": ["from llama_index.core.node_parser import SentenceSplitter\n", "from llama_index.core.schema import IndexNode"]}, {"cell_type": "code", "execution_count": null, "id": "91b997ae-9260-4ae7-af2f-0f8d38625d32", "metadata": {}, "outputs": [], "source": ["node_parser = SentenceSplitter(chunk_size=1024)"]}, {"cell_type": "code", "execution_count": null, "id": "0cda44b0-fd27-4255-9aa7-08d358635772", "metadata": {}, "outputs": [], "source": ["base_nodes = node_parser.get_nodes_from_documents(docs)", "# 将节点id设置为一个常量", "for idx, node in enumerate(base_nodes):", "    node.id_ = f\"node-{idx}\""]}, {"cell_type": "code", "execution_count": null, "id": "38e47623-b67d-45d6-9b24-33ba84719f1f", "metadata": {}, "outputs": [], "source": ["from llama_index.core.embeddings import resolve_embed_model\n", "\n", "embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n", "llm = OpenAI(model=\"gpt-3.5-turbo\")"]}, {"cell_type": "markdown", "id": "f43ebab2-fc46-41ea-8a92-9148994d793f", "metadata": {}, "source": ["## 基准检索器\n", "\n", "定义一个基准检索器，它简单地通过嵌入相似性来获取前k个原始文本节点。\n"]}, {"cell_type": "code", "execution_count": null, "id": "704fb3da-710e-4ad9-b630-565911917f0c", "metadata": {}, "outputs": [], "source": ["base_index = VectorStoreIndex(base_nodes, embed_model=embed_model)\n", "base_retriever = base_index.as_retriever(similarity_top_k=2)"]}, {"cell_type": "code", "execution_count": null, "id": "160c339b-601a-486b-9e17-dd6cc9f133ea", "metadata": {}, "outputs": [], "source": ["retrievals = base_retriever.retrieve(\n", "    \"Can you tell me about the key concepts for safety finetuning\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "632610f3-c8f2-440a-ab27-5ca7d65f882a", "metadata": {}, "outputs": [], "source": ["for n in retrievals:\n", "    display_source_node(n, source_length=1500)"]}, {"cell_type": "code", "execution_count": null, "id": "96dd8a01-1cae-4614-beab-5b5e0434fefe", "metadata": {}, "outputs": [], "source": ["query_engine_base = RetrieverQueryEngine.from_args(base_retriever, llm=llm)"]}, {"cell_type": "code", "execution_count": null, "id": "82ae66ff-7d12-45c8-9b1a-adb20bd3c7ea", "metadata": {}, "outputs": [], "source": ["response = query_engine_base.query(\n", "    \"Can you tell me about the key concepts for safety finetuning\"\n", ")\n", "print(str(response))"]}, {"cell_type": "markdown", "id": "d5431df3-d255-4492-bce4-bbebde6f2306", "metadata": {}, "source": ["## 分块引用：较小的子块引用较大的父块\n", "\n", "在这个用法示例中，我们展示了如何构建一个较小的子块指向较大父块的图。\n", "\n", "在查询时，我们检索较小的子块，但是我们跟随引用到较大的父块。这样可以让我们在合成时获得更多的上下文信息。\n"]}, {"cell_type": "code", "execution_count": null, "id": "49c784d8-71e6-42bc-84d9-a2aea4217b8b", "metadata": {}, "outputs": [], "source": ["sub_chunk_sizes = [128, 256, 512]", "sub_node_parsers = [SentenceSplitter(chunk_size=c) for c in sub_chunk_sizes]", "", "all_nodes = []", "", "for base_node in base_nodes:", "    for n in sub_node_parsers:", "        sub_nodes = n.get_nodes_from_documents([base_node])", "        sub_inodes = [", "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes", "        ]", "        all_nodes.extend(sub_inodes)", "", "    # also add original node to node", "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)", "    all_nodes.append(original_node)"]}, {"cell_type": "code", "execution_count": null, "id": "2d614088-b122-40ad-811a-29cc0c2a295e", "metadata": {}, "outputs": [], "source": ["all_nodes_dict = {n.node_id: n for n in all_nodes}"]}, {"cell_type": "code", "execution_count": null, "id": "a44ef2d5-0342-4073-831f-f35dd6f04dc0", "metadata": {}, "outputs": [], "source": ["vector_index_chunk = VectorStoreIndex(all_nodes, embed_model=embed_model)"]}, {"cell_type": "code", "execution_count": null, "id": "c06af99f-02be-4055-a6ea-3071ffe8fc8a", "metadata": {}, "outputs": [], "source": ["vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"]}, {"cell_type": "code", "execution_count": null, "id": "4c7c5e43-45b5-42d6-afc5-cb81ed3cb211", "metadata": {}, "outputs": [], "source": ["retriever_chunk = RecursiveRetriever(\n", "    \"vector\",\n", "    retriever_dict={\"vector\": vector_retriever_chunk},\n", "    node_dict=all_nodes_dict,\n", "    verbose=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "9e9f7bcb-5442-4d2d-a7eb-814b68ebb45c", "metadata": {}, "outputs": [], "source": ["nodes = retriever_chunk.retrieve(\n", "    \"Can you tell me about the key concepts for safety finetuning\"\n", ")\n", "for node in nodes:\n", "    display_source_node(node, source_length=2000)"]}, {"cell_type": "code", "execution_count": null, "id": "411f26ad-d13b-4858-938e-efcfa899e8cd", "metadata": {}, "outputs": [], "source": ["query_engine_chunk = RetrieverQueryEngine.from_args(retriever_chunk, llm=llm)"]}, {"cell_type": "code", "execution_count": null, "id": "4cd98366-0d5f-4d04-87cd-b811990b7485", "metadata": {}, "outputs": [], "source": ["response = query_engine_chunk.query(\n", "    \"Can you tell me about the key concepts for safety finetuning\"\n", ")\n", "print(str(response))"]}, {"cell_type": "markdown", "id": "3bcc7379-c077-40b7-ba4e-f47f80def0c7", "metadata": {}, "source": ["## 元数据引用：对更大块内容的摘要和生成的问题\n", "\n", "在这个用法示例中，我们展示了如何定义引用源节点的附加上下文。\n", "\n", "这个附加上下文包括摘要以及生成的问题。\n", "\n", "在查询时，我们检索较小的块，但是我们会跟随引用到更大的块。这样可以为综合提供更多的上下文。\n"]}, {"cell_type": "code", "execution_count": null, "id": "24e40c5e-4868-487f-aaf4-f333aa4bda66", "metadata": {}, "outputs": [], "source": ["from llama_index.core.node_parser import SentenceSplitter\n", "from llama_index.core.schema import IndexNode\n", "from llama_index.core.extractors import (\n", "    SummaryExtractor,\n", "    QuestionsAnsweredExtractor,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "5c5d6f87-790e-4b82-abb2-cc6944678b00", "metadata": {}, "outputs": [], "source": ["extractors = [\n", "    SummaryExtractor(summaries=[\"self\"], show_progress=True),\n", "    QuestionsAnsweredExtractor(questions=5, show_progress=True),\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "e47c706c-940e-499d-b742-eaf09a230b0d", "metadata": {}, "outputs": [], "source": ["# 在基本节点上运行元数据提取器，返回字典", "metadata_dicts = []", "for extractor in extractors:", "    metadata_dicts.extend(extractor.extract(base_nodes))"]}, {"cell_type": "code", "execution_count": null, "id": "2873327d-420a-4778-a83b-6fdf7aa21bcd", "metadata": {}, "outputs": [], "source": ["# 缓存元数据字典", "def save_metadata_dicts(path):", "    with open(path, \"w\") as fp:", "        for m in metadata_dicts:", "            fp.write(json.dumps(m) + \"\\n\")", "", "", "def load_metadata_dicts(path):", "    with open(path, \"r\") as fp:", "        metadata_dicts = [json.loads(l) for l in fp.readlines()]", "        return metadata_dicts"]}, {"cell_type": "code", "execution_count": null, "id": "e318efb2-9afa-4414-b37f-71738d73d01d", "metadata": {}, "outputs": [], "source": ["save_metadata_dicts(\"data/llama2_metadata_dicts.jsonl\")"]}, {"cell_type": "code", "execution_count": null, "id": "4edce99f-8a96-4539-95e7-62aeeabb2ce9", "metadata": {}, "outputs": [], "source": ["metadata_dicts = load_metadata_dicts(\"data/llama2_metadata_dicts.jsonl\")"]}, {"cell_type": "code", "execution_count": null, "id": "f18d2109-5fcb-4fd5-b147-23897fed8787", "metadata": {}, "outputs": [], "source": ["# 所有节点由源节点和元数据组成", "import copy", "", "all_nodes = copy.deepcopy(base_nodes)", "for idx, d in enumerate(metadata_dicts):", "    inode_q = IndexNode(", "        text=d[\"questions_this_excerpt_can_answer\"],", "        index_id=base_nodes[idx].node_id,", "    )", "    inode_s = IndexNode(", "        text=d[\"section_summary\"], index_id=base_nodes[idx].node_id", "    )", "    all_nodes.extend([inode_q, inode_s])"]}, {"cell_type": "code", "execution_count": null, "id": "8f90ada6-0969-40cc-a4ec-3579b4900cdd", "metadata": {}, "outputs": [], "source": ["all_nodes_dict = {n.node_id: n for n in all_nodes}"]}, {"cell_type": "code", "execution_count": null, "id": "22abc768-83d5-41d0-84f0-533899c76894", "metadata": {}, "outputs": [], "source": ["## 将索引加载到向量索引中", "from llama_index.core import VectorStoreIndex", "from llama_index.llms.openai import OpenAI", "", "llm = OpenAI(model=\"gpt-3.5-turbo\")", "", "vector_index_metadata = VectorStoreIndex(all_nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "0d53938a-1322-41b1-ad11-169b13b9805a", "metadata": {}, "outputs": [], "source": ["vector_retriever_metadata = vector_index_metadata.as_retriever(\n", "    similarity_top_k=2\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "37ae791f-c183-4ad4-9a3a-253288ded5a7", "metadata": {}, "outputs": [], "source": ["retriever_metadata = RecursiveRetriever(\n", "    \"vector\",\n", "    retriever_dict={\"vector\": vector_retriever_metadata},\n", "    node_dict=all_nodes_dict,\n", "    verbose=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "3cd85685-19eb-44cc-ad27-1d163eaddad6", "metadata": {}, "outputs": [], "source": ["nodes = retriever_metadata.retrieve(\n", "    \"Can you tell me about the key concepts for safety finetuning\"\n", ")\n", "for node in nodes:\n", "    display_source_node(node, source_length=2000)"]}, {"cell_type": "code", "execution_count": null, "id": "5285854a-69a6-4bc4-a2a5-1004cc790a63", "metadata": {}, "outputs": [], "source": ["query_engine_metadata = RetrieverQueryEngine.from_args(\n", "    retriever_metadata, llm=llm\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4e0ada5c-9a83-4517-bbb7-899d4415d68a", "metadata": {}, "outputs": [], "source": ["response = query_engine_metadata.query(\n", "    \"Can you tell me about the key concepts for safety finetuning\"\n", ")\n", "print(str(response))"]}, {"cell_type": "markdown", "id": "9973bdca-d179-47d6-bd96-2631b36e1d94", "metadata": {}, "source": ["## 评估\n", "\n", "我们使用[Braintrust](https://www.braintrustdata.com/)来评估我们的递归检索+节点引用方法的效果。Braintrust是构建人工智能产品的企业级堆栈。从评估到快速实验，再到数据管理，我们让将人工智能整合到您的业务中变得更加确定和轻松。\n", "\n", "我们评估块引用和元数据引用两种方法。我们使用嵌入相似度查找来检索引用节点。我们将这两种方法与直接获取原始节点的基准检索器进行比较。在指标方面，我们使用命中率和MRR进行评估。\n", "\n", "您可以在以下链接中查看示例评估仪表板：\n", "- [基准检索器](https://www.braintrustdata.com/app/braintrustdata.com/p/llamaindex-recurisve-retrievers/baseRetriever)\n", "- [递归元数据检索器](https://www.braintrustdata.com/app/braintrustdata.com/p/llamaindex-recurisve-retrievers/recursiveMetadataRetriever)\n", "- [递归块检索器](https://www.braintrustdata.com/app/braintrustdata.com/p/llamaindex-recurisve-retrievers/recursiveChunkRetriever)\n"]}, {"cell_type": "markdown", "id": "1b3a30b7-2eb2-4eae-b0b9-1d4ec26ac915", "metadata": {}, "source": ["### 数据集生成\n", "\n", "我们首先从文本块集合中生成一个问题数据集。\n"]}, {"cell_type": "code", "execution_count": null, "id": "3fe8ae8a-a2b2-4515-bcff-1145e14ede3d", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import (\n", "    generate_question_context_pairs,\n", "    EmbeddingQAFinetuneDataset,\n", ")\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "eef1b43d-996b-4b0a-becb-1cec08d9f8c3", "metadata": {}, "outputs": [], "source": ["eval_dataset = generate_question_context_pairs(base_nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "bd3e2507-9157-48a5-909b-18eeb9ec01d4", "metadata": {}, "outputs": [], "source": ["eval_dataset.save_json(\"data/llama2_eval_dataset.json\")"]}, {"cell_type": "code", "execution_count": null, "id": "611f07af-2006-4158-8dc6-59d11a269c8d", "metadata": {}, "outputs": [], "source": ["# 可选", "eval_dataset = EmbeddingQAFinetuneDataset.from_json(", "    \"data/llama2_eval_dataset.json\"", ")"]}, {"cell_type": "markdown", "id": "fb4782a6-f3da-453f-93be-7683ed15b508", "metadata": {}, "source": ["### 比较结果\n", "\n", "我们对每个检索器进行评估，以衡量命中率和MRR。\n", "\n", "我们发现具有节点引用（块或元数据）的检索器往往比检索原始块表现更好。\n"]}, {"cell_type": "code", "execution_count": null, "id": "87798866-11bc-4f7f-b8aa-0a023309492f", "metadata": {}, "outputs": [], "source": ["import pandas as pd", "", "# 将向量检索相似度的 top k 设置为更高", "top_k = 10", "", "", "def display_results(names, results_arr):", "    \"\"\"显示来自 evaluate 的结果。\"\"\"", "", "    hit_rates = []", "    mrrs = []", "    for name, eval_results in zip(names, results_arr):", "        metric_dicts = []", "        for eval_result in eval_results:", "            metric_dict = eval_result.metric_vals_dict", "            metric_dicts.append(metric_dict)", "        results_df = pd.DataFrame(metric_dicts)", "", "        hit_rate = results_df[\"hit_rate\"].mean()", "        mrr = results_df[\"mrr\"].mean()", "        hit_rates.append(hit_rate)", "        mrrs.append(mrr)", "", "    final_df = pd.DataFrame(", "        {\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs}", "    )", "    display(final_df)"]}, {"cell_type": "markdown", "id": "35a83d70", "metadata": {}, "source": ["让我们定义一些评分函数并定义我们的数据集数据变量。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a52e6b48", "metadata": {}, "outputs": [], "source": ["queries = eval_dataset.queries\n", "relevant_docs = eval_dataset.relevant_docs\n", "data = [\n", "    ({\"input\": queries[query], \"expected\": relevant_docs[query]})\n", "    for query in queries.keys()\n", "]\n", "\n", "\n", "def hitRateScorer(input, expected, output=None):\n", "    is_hit = any([id in expected for id in output])\n", "    return 1 if is_hit else 0\n", "\n", "\n", "def mrrScorer(input, expected, output=None):\n", "    for i, id in enumerate(output):\n", "        if id in expected:\n", "            return 1 / (i + 1)\n", "    return 0"]}, {"cell_type": "code", "execution_count": null, "id": "a6d142c6-0374-43ec-af31-e02d246bd815", "metadata": {}, "outputs": [], "source": ["import braintrust", "", "# 评估块检索器", "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=10)", "retriever_chunk = RecursiveRetriever(", "    \"vector\",", "    retriever_dict={\"vector\": vector_retriever_chunk},", "    node_dict=all_nodes_dict,", "    verbose=False,", ")", "", "", "def runChunkRetriever(input, hooks):", "    retrieved_nodes = retriever_chunk.retrieve(input)", "    retrieved_ids = [node.node.node_id for node in retrieved_nodes]", "    return retrieved_ids", "", "", "chunkEval = await braintrust.Eval(", "    name=\"llamaindex-recurisve-retrievers\",", "    data=data,", "    task=runChunkRetriever,", "    scores=[hitRateScorer, mrrScorer],", ")"]}, {"cell_type": "code", "execution_count": null, "id": "ae448fe7-3a66-45a6-8e8e-6ed3950e61b8", "metadata": {}, "outputs": [], "source": ["# 评估元数据检索器", "", "vector_retriever_metadata = vector_index_metadata.as_retriever(", "    similarity_top_k=10", ")", "retriever_metadata = RecursiveRetriever(", "    \"vector\",", "    retriever_dict={\"vector\": vector_retriever_metadata},", "    node_dict=all_nodes_dict,", "    verbose=False,", ")", "", "", "def runMetaDataRetriever(input, hooks):", "    retrieved_nodes = retriever_metadata.retrieve(input)", "    retrieved_ids = [node.node.node_id for node in retrieved_nodes]", "    return retrieved_ids", "", "", "metadataEval = await braintrust.Eval(", "    name=\"llamaindex-recurisve-retrievers\",", "    data=data,", "    task=runMetaDataRetriever,", "    scores=[hitRateScorer, mrrScorer],", ")"]}, {"cell_type": "code", "execution_count": null, "id": "3d3fc029-7ccc-4ec4-b391-b7b86744b5d8", "metadata": {}, "outputs": [], "source": ["# 评估基础检索器", "base_retriever = base_index.as_retriever(similarity_top_k=10)", "", "", "def runBaseRetriever(input, hooks):", "    retrieved_nodes = base_retriever.retrieve(input)", "    retrieved_ids = [node.node.node_id for node in retrieved_nodes]", "    return retrieved_ids", "", "", "baseEval = await braintrust.Eval(", "    name=\"llamaindex-recurisve-retrievers\",", "    data=data,", "    task=runBaseRetriever,", "    scores=[hitRateScorer, mrrScorer],", ")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}