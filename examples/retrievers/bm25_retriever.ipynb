{"cells": [{"cell_type": "markdown", "id": "723fcf40", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/retrievers/bm25_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "5bf1de44-4047-46cf-a04c-dbf910d9e179", "metadata": {}, "source": ["# BM25检索器\n", "在本指南中，我们定义了一个使用BM25方法搜索文档的BM25检索器。\n", "\n", "这个笔记本非常类似于RouterQueryEngine笔记本。\n"]}, {"cell_type": "markdown", "id": "6e73fead-ec2c-4346-bd08-e183c13c7e29", "metadata": {}, "source": ["## 设置\n"]}, {"cell_type": "markdown", "id": "9a2630bc", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a60fea8f", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-retrievers-bm25"]}, {"cell_type": "code", "execution_count": null, "id": "9bc13275", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "a2d59778-4cda-47b5-8cd0-b80fee91d1e4", "metadata": {}, "outputs": [], "source": ["# 注意：这仅在jupyter笔记本中是必要的。\n", "# 详情：Jupyter在后台运行一个事件循环。\n", "#       当我们启动一个事件循环来进行异步查询时，会导致嵌套的事件循环。\n", "#       通常情况下是不允许的，我们使用nest_asyncio来允许这种情况以方便操作。\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "04941476", "metadata": {}, "outputs": [], "source": ["import os\n", "import openai\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n", "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"]}, {"cell_type": "code", "execution_count": null, "id": "c628448c-573c-4eeb-a7e1-707fe8cc575c", "metadata": {}, "outputs": [], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().handlers = []\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n", "\n", "from llama_index.core import (\n", "    SimpleDirectoryReader,\n", "    StorageContext,\n", "    VectorStoreIndex,\n", ")\n", "from llama_index.retrievers.bm25 import BM25Retriever\n", "from llama_index.core.retrievers import VectorIndexRetriever\n", "from llama_index.core.node_parser import SentenceSplitter\n", "from llama_index.llms.openai import OpenAI"]}, {"cell_type": "markdown", "id": "8d87b60f", "metadata": {}, "source": ["## 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "4c9456c2", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "id": "787174ed-10ce-47d7-82fd-9ca7f891eea7", "metadata": {}, "source": ["## 加载数据\n", "\n", "我们首先展示如何将一个文档转换为一组节点，并插入到文档存储中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "1fc1b8ac-bf55-4d60-841c-61698663322f", "metadata": {}, "outputs": [], "source": ["# 加载文档\n", "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "7081194a-ede7-478e-bff2-23e89e23ef16", "metadata": {}, "outputs": [], "source": ["# 初始化LLM + 节点解析器\n", "llm = OpenAI(model=\"gpt-4\")\n", "splitter = SentenceSplitter(chunk_size=1024)\n", "\n", "nodes = splitter.get_nodes_from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "id": "8f61bca2-c3b4-4ef0-a8f1-367933aa6d05", "metadata": {}, "outputs": [], "source": ["# 初始化存储上下文（默认情况下是内存中的）\n", "storage_context = StorageContext.from_defaults()\n", "storage_context.docstore.add_documents(nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "0d6162df-9da7-4aad-a2ca-eb318f67daec", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]}], "source": ["index = VectorStoreIndex(\n", "    nodes=nodes,\n", "    storage_context=storage_context,\n", ")"]}, {"cell_type": "markdown", "id": "4fa4b18c-4f9b-4311-b1d9-9cbf24687e2c", "metadata": {}, "source": ["## BM25检索器\n", "\n", "我们将使用BM25检索器来搜索文档。\n"]}, {"cell_type": "code", "execution_count": null, "id": "ee3f7c3b-69b4-48d5-bf22-ac51a4e3179f", "metadata": {}, "outputs": [], "source": ["# 我们可以传入索引、doctore或节点列表来创建检索器\n", "retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=2)"]}, {"cell_type": "code", "execution_count": null, "id": "7b8c4c12-1a30-425e-8312-04be050b2101", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**Node ID:** 9afb8cb9-42f3-4160-807c-1cd6685fa774<br>**Similarity:** 1.6781810094192822<br>**Text:** Now that I could write essays again, I wrote a bunch about topics I'd had stacked up. I kept writ...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** 71de4371-10ff-4d3a-8a31-14b2d4ddec83<br>**Similarity:** 1.546534805781164<br>**Text:** I couldn't have put this into words when I was 18. All I knew at the time was that I kept taking ...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["from llama_index.core.response.notebook_utils import display_source_node\n", "\n", "# 将从特定公司检索上下文\n", "nodes = retriever.retrieve(\"Viaweb和Interleaf发生了什么？\")\n", "for node in nodes:\n", "    display_source_node(node)"]}, {"cell_type": "code", "execution_count": null, "id": "2749c34e-97c0-4bd5-8358-377a94b8b2d8", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**Node ID:** 42c88008-dd05-4590-8fd1-df85567579ea<br>**Similarity:** 5.389397745654172<br>**Text:** It was missing a lot of things you'd want in a programming language. So these had to be added, an...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** 4d98c2ad-60cc-4cc0-abe2-b95c0c4be87b<br>**Similarity:** 1.141523170922594<br>**Text:** Painting students were supposed to express themselves, which to the more worldly ones meant to tr...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["nodes = retriever.retrieve(\"What did Paul Graham do after RISD?\")\n", "for node in nodes:\n", "    display_source_node(node)"]}, {"cell_type": "markdown", "id": "73460e63-3c7a-49f4-80d2-ea9f4033848e", "metadata": {}, "source": ["## 使用BM25方法的路由器检索器\n", "\n", "现在我们将结合BM25检索器和向量索引检索器。\n"]}, {"cell_type": "code", "execution_count": null, "id": "5ceedab8-c9e8-4ec9-be91-cba27482a7e2", "metadata": {}, "outputs": [], "source": ["from llama_index.core.tools import RetrieverTool\n", "\n", "vector_retriever = VectorIndexRetriever(index)\n", "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=2)\n", "\n", "retriever_tools = [\n", "    RetrieverTool.from_defaults(\n", "        retriever=vector_retriever,\n", "        description=\"Useful in most cases\",\n", "    ),\n", "    RetrieverTool.from_defaults(\n", "        retriever=bm25_retriever,\n", "        description=\"Useful if searching about specific information\",\n", "    ),\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "dcb850f9-c8b4-4843-b66c-8cb2a977c0e8", "metadata": {}, "outputs": [], "source": ["from llama_index.core.retrievers import RouterRetriever\n", "\n", "retriever = RouterRetriever.from_defaults(\n", "    retriever_tools=retriever_tools,\n", "    llm=llm,\n", "    select_multi=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "f3e29b3e-38e3-4f0b-a263-d267ed003cc6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "Selecting retriever 0: The author's life context is a broad topic and can be useful in most cases..\n", "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]}, {"data": {"text/markdown": ["**Node ID:** 9afb8cb9-42f3-4160-807c-1cd6685fa774<br>**Similarity:** 0.7961776744788842<br>**Text:** Now that I could write essays again, I wrote a bunch about topics I'd had stacked up. I kept writ...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** b1ffb78d-dc4c-439b-906a-cca73b713940<br>**Similarity:** 0.7924813308773564<br>**Text:** We actually had one of those little stoves, fed with kindling, that you see in 19th century studi...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["# 将从作者的生活中检索所有上下文\n", "nodes = retriever.retrieve(\n", "    \"您能给我关于作者生活的所有上下文吗？\"\n", ")\n", "for node in nodes:\n", "    display_source_node(node)\n"]}, {"cell_type": "markdown", "id": "b1b4b717", "metadata": {}, "source": ["## 高级 - 混合检索器 + 重新排序\n", "\n", "在这里，我们扩展基本的检索器类，并创建一个自定义的检索器，它始终使用向量检索器和BM25检索器。\n", "\n", "然后，节点可以被重新排序和过滤。这样我们可以保持中间的top-k值很大，并让重新排序过滤掉不需要的节点。\n", "\n", "为了最好地演示这一点，我们将使用一个更大的源文档集合——来自2022年IPCC气候报告的第3章。\n"]}, {"cell_type": "markdown", "id": "a4be4ec7", "metadata": {}, "source": ["### 设置数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "5ebd3ddf", "metadata": {}, "outputs": [], "source": ["!curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"]}, {"cell_type": "code", "execution_count": null, "id": "3f7b5a97", "metadata": {}, "outputs": [], "source": ["# !pip install pypdf"]}, {"cell_type": "code", "execution_count": null, "id": "48bd32ac-6d99-4bb5-8559-45b61d528525", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex,StorageContext,SimpleDirectoryReader和Document\n", "from llama_index.core.node_parser import SentenceSplitter\n", "from llama_index.llms.openai import OpenAI\n", "\n", "# 加载文档\n", "documents = SimpleDirectoryReader(\n", "    input_files=[\"IPCC_AR6_WGII_Chapter03.pdf\"]\n", ").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "7c771a80-92e3-4178-b4a3-1f03c489b1a2", "metadata": {}, "outputs": [], "source": ["# 初始化llm + 节点解析器\n", "# -- 在这里，我们设置了一个较小的块大小，以便更有效地重新排名\n", "llm = OpenAI(model=\"gpt-3.5-turbo\")\n", "splitter = SentenceSplitter(chunk_size=256)\n", "# 限制到一个较小的部分\n", "nodes = splitter.get_nodes_from_documents(\n", "    [Document(text=documents[0].get_content()[:1000000])]\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "52f4243d-fd8f-4193-bf6a-73c07d661bcd", "metadata": {}, "outputs": [], "source": ["# 初始化存储上下文（默认情况下是内存中的）\n", "storage_context = StorageContext.from_defaults()\n", "storage_context.docstore.add_documents(nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "ccfc9879", "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "code", "execution_count": null, "id": "0474be06", "metadata": {}, "outputs": [], "source": ["from llama_index.retrievers.bm25 import BM25Retriever\n", "\n", "# 使用嵌入检索出前10个最相似的节点\n", "vector_retriever = index.as_retriever(similarity_top_k=10)\n", "\n", "# 使用bm25检索出前10个最相似的节点\n", "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=10)"]}, {"cell_type": "markdown", "id": "99e603a1", "metadata": {}, "source": ["```python\n", "class CustomRetriever:\n", "    def __init__(self, data):\n", "        self.data = data\n", "\n", "    def retrieve(self, key):\n", "        if key in self.data:\n", "            return self.data[key]\n", "        else:\n", "            return \"Key not found\"\n", "```\n", "\n", "自定义检索器实现\n"]}, {"cell_type": "code", "execution_count": null, "id": "917a3d85", "metadata": {}, "outputs": [], "source": ["from llama_index.core.retrievers import BaseRetriever\n", "\n", "\n", "class HybridRetriever(BaseRetriever):\n", "    def __init__(self, vector_retriever, bm25_retriever):\n", "        self.vector_retriever = vector_retriever\n", "        self.bm25_retriever = bm25_retriever\n", "        super().__init__()\n", "\n", "    def _retrieve(self, query, **kwargs):\n", "        bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\n", "        vector_nodes = self.vector_retriever.retrieve(query, **kwargs)\n", "\n", "        # 合并两个节点列表\n", "        all_nodes = []\n", "        node_ids = set()\n", "        for n in bm25_nodes + vector_nodes:\n", "            if n.node.node_id not in node_ids:\n", "                all_nodes.append(n)\n", "                node_ids.add(n.node.node_id)\n", "        return all_nodes"]}, {"cell_type": "code", "execution_count": null, "id": "9495e47c-2008-41ac-87e8-582d6d798190", "metadata": {}, "outputs": [], "source": ["index.as_retriever(similarity_top_k=5)\n", "\n", "hybrid_retriever = HybridRetriever(vector_retriever, bm25_retriever)"]}, {"cell_type": "markdown", "id": "bfd3b287", "metadata": {}, "source": ["### 重新排序器设置\n"]}, {"cell_type": "code", "execution_count": null, "id": "e1d910de", "metadata": {}, "outputs": [], "source": ["!pip install sentence-transformers"]}, {"cell_type": "code", "execution_count": null, "id": "638e7786", "metadata": {}, "outputs": [], "source": ["from llama_index.core.postprocessor import SentenceTransformerRerank\n", "\n", "reranker = SentenceTransformerRerank(top_n=4, model=\"BAAI/bge-reranker-base\")"]}, {"cell_type": "markdown", "id": "58a78eec", "metadata": {}, "source": ["### 检索\n"]}, {"cell_type": "code", "execution_count": null, "id": "9235f79d", "metadata": {}, "outputs": [], "source": ["from llama_index.core import QueryBundle\n", "from llama_index.core.schema import NodeWithScore\n", "\n", "retrieved_nodes = hybrid_retriever.retrieve(\n", "    \"What is the impact of climate change on the ocean?\"\n", ")\n", "reranked_nodes = reranker.postprocess_nodes(\n", "    retrieved_nodes,\n", "    query_bundle=QueryBundle(\n", "        \"What is the impact of climate change on the ocean?\"\n", "    ),\n", ")\n", "\n", "print(\"Initial retrieval: \", len(retrieved_nodes), \" nodes\")\n", "print(\"Re-ranked retrieval: \", len(reranked_nodes), \" nodes\")"]}, {"cell_type": "code", "execution_count": null, "id": "5674f1d6", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**Node ID:** 735c563d-e68c-42e7-bbeb-d360a2918d22<br>**Similarity:** 0.6910567283630371<br>**Text:** lb88\\8a|hiac2:,sg\u001c\n", "\n", "\u001a`HfvyȔs\u001fkz4\u000b\n", "\n", "4+)t$EAs9\b<\"L\u0013䴺-iai]\u000f}?R)J\u0003\u0002\u0018v8Q0V#9>f\u001b=3`߼\bב&WTFK\u001bNӅ9GN8v`4׏g\f\n", "\n", "tz...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** 07a796db-8307-47a0-83a0-9b5f953b86b0<br>**Similarity:** 0.609274685382843<br>**Text:** {_d3<,f\u0001CȀ\u001e\n", "\n", "0K0~n\u001e\n", "\n", "(\u0018A\t\b̙$saxt\f\n", "\n", " :\u001e\n", "\n", "xY3\u000fz/ߕXAW\u000fwpTeHY0\u0015\u0012H\u001bZHe\b̚kÇ>.\u001882%ϖ\u0017^.rCS.2^\u001a12C?<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** 0ee98fbd-d015-4cd4-aba0-812423880915<br>**Similarity:** 0.5765283107757568<br>**Text:** X+V/Z\u001d\n", "\n", "\u000b\n", "\n", "6\u000e;\u0005O8/%Z3EC\\a\u0010sU1f(\u0016xLͼ]X\\\u0014\u0018q\"1}.66OKGSi\u0001\u000f9ǧ\u0015'(?Iʲi=4ޮ^m,Mp1~\u0013lBxP\u00153]\u0011S<?C)3WM;\u0016WGQt@\bl...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** 2562bbfb-fda2-432d-9674-5ba77ff4b767<br>**Similarity:** 0.3882860541343689<br>**Text:** P\bxS0s\u0010.MAK|+MOUÊ\u0016^;tc0\n", "\u001a$\u0002XH\u0006mL\u0004<ҁ;Q@nUd&\u0013ի\n", "2`\u0018B0\u00041i^yOw:rsM冫S*wu4a{\u0001-.Խ=j鷩nQ\u0006D_A޾A%~T>~\u0018'OxU\tgk...<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["from llama_index.core.response.notebook_utils import display_source_node\n", "\n", "for node in reranked_nodes:\n", "    display_source_node(node)"]}, {"cell_type": "markdown", "id": "c24caa0d", "metadata": {}, "source": ["### 完整查询引擎\n"]}, {"cell_type": "code", "execution_count": null, "id": "549b9a96", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import RetrieverQueryEngine\n", "\n", "query_engine = RetrieverQueryEngine.from_args(\n", "    retriever=hybrid_retriever,\n", "    node_postprocessors=[reranker],\n", "    llm=llm,\n", ")\n", "\n", "response = query_engine.query(\n", "    \"What is the impact of climate change on the ocean?\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "171668b7", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**`Final Response:`** Climate change can have a significant impact on the ocean. Rising temperatures can lead to the melting of polar ice caps, resulting in sea-level rise and coastal flooding. It can also disrupt ocean currents and affect marine ecosystems, including coral reefs and fish populations. Additionally, climate change can lead to ocean acidification, which can harm marine life and impact the overall health of the ocean."], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["from llama_index.core.response.notebook_utils import display_response\n", "\n", "display_response(response)"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v3", "language": "python", "name": "llama_index_v3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}