{"cells": [{"cell_type": "markdown", "id": "b39acfe0", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/retrievers/auto_merging_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "5325ac27-38ea-47aa-afef-be4ec4f8f4b9", "metadata": {}, "source": ["# 自动合并检索器\n", "\n", "在这个笔记本中，我们展示了我们的`AutoMergingRetriever`，它查看一组叶节点，并递归地“合并”引用超过给定阈值的父节点的叶节点子集。这使我们能够将潜在不同的、较小的上下文合并成一个更大的上下文，这可能有助于综合。\n", "\n", "您可以自己在一组文档上定义这种层次结构，或者您可以使用我们全新的文本解析器：一个接受候选文档集并输出整个节点层次结构的HierarchicalNodeParser，从“粗到细”。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a15c0d4", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-readers-file pymupdf"]}, {"cell_type": "code", "execution_count": null, "id": "7ee0e185-408a-4c9c-a361-b6af96129b0d", "metadata": {}, "outputs": [], "source": ["%load_ext autoreload\n", "%autoreload 2"]}, {"cell_type": "markdown", "id": "b9fbdc26", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "06c89955", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "markdown", "id": "7e1316ac-84ca-41d0-80f9-d4ef758e653c", "metadata": {}, "source": ["## 加载数据\n", "\n", "让我们首先加载Llama 2论文：https://arxiv.org/pdf/2307.09288.pdf。这将成为我们的测试数据。\n"]}, {"cell_type": "code", "execution_count": null, "id": "80372299-ab32-4ddd-9b88-05c877120c17", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/'\n", "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""]}, {"cell_type": "code", "execution_count": null, "id": "5f9c5d99-bd0e-4b26-b816-9f5ad29df3c8", "metadata": {}, "outputs": [], "source": ["from pathlib import Path\n", "\n", "from llama_index.readers.file import PDFReader\n", "from llama_index.readers.file import PyMuPDFReader"]}, {"cell_type": "code", "execution_count": null, "id": "723f1f02-2157-4166-b013-90e627c76530", "metadata": {}, "outputs": [], "source": ["loader = PyMuPDFReader()", "# docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))", "docs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))"]}, {"cell_type": "markdown", "id": "ff7a8552-f347-45b0-b4a0-4f9b32be57ac", "metadata": {}, "source": ["默认情况下，PDF阅读器为每一页创建一个单独的文档。\n", "为了这个笔记本的目的，我们将这些文档拼接在一起成为一个文档。\n", "这将帮助我们更好地突出后面将“拼接”块合并在一起的自动合并功能。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a75c4217-ab50-417f-a8ed-3b746a9956c8", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Document\n", "\n", "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n", "docs = [Document(text=doc_text)]"]}, {"cell_type": "markdown", "id": "724fe6f1-80e1-4ac5-bd99-8b9b8d15bddd", "metadata": {}, "source": ["## 从文本中解析块层次结构，加载到存储中\n", "\n", "在本节中，我们将使用`HierarchicalNodeParser`。这将输出一个节点层次结构，从具有更大块大小的顶级节点到具有较小块大小的子节点，其中每个子节点都有一个具有更大块大小的父节点。\n", "\n", "默认情况下，层次结构如下：\n", "- 第1级：块大小为2048\n", "- 第2级：块大小为512\n", "- 第3级：块大小为128\n", "\n", "然后，我们将这些节点加载到存储中。叶节点被索引并通过向量存储检索 - 这些节点将首先通过相似性搜索直接检索。其他节点将从文档存储中检索。\n"]}, {"cell_type": "code", "execution_count": null, "id": "45e783f5-a323-4f51-ae9a-4b71b00e5e11", "metadata": {}, "outputs": [], "source": ["from llama_index.core.node_parser import (\n", "    HierarchicalNodeParser,\n", "    SentenceSplitter,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "2c3947df-25c2-4254-a3d4-381d136f3f77", "metadata": {}, "outputs": [], "source": ["node_parser = HierarchicalNodeParser.from_defaults()"]}, {"cell_type": "code", "execution_count": null, "id": "2162b309-dfc5-484b-a31c-24f705316f10", "metadata": {}, "outputs": [], "source": ["nodes = node_parser.get_nodes_from_documents(docs)"]}, {"cell_type": "code", "execution_count": null, "id": "a9b5bc9b-389d-47db-a41c-3eb5b3d38ac5", "metadata": {}, "outputs": [{"data": {"text/plain": ["1029"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["len(nodes)"]}, {"cell_type": "markdown", "id": "a7456b70-1803-4786-86d5-26e202e0f318", "metadata": {}, "source": ["这里我们导入一个简单的辅助函数，用于获取节点列表中的“叶子”节点。这些节点没有自己的子节点。\n"]}, {"cell_type": "code", "execution_count": null, "id": "7299ca7e-09b6-432f-a277-aae9eca0522a", "metadata": {}, "outputs": [], "source": ["from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes"]}, {"cell_type": "code", "execution_count": null, "id": "faeb37a8-aea9-4ee8-b6c0-3b2f188d244e", "metadata": {}, "outputs": [], "source": ["leaf_nodes = get_leaf_nodes(nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "7c33b5a8-4d9f-481e-8616-fc8717900159", "metadata": {}, "outputs": [{"data": {"text/plain": ["795"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["len(leaf_nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "b28b0aff-db6e-495e-8c58-36db29edb45b", "metadata": {}, "outputs": [], "source": ["root_nodes = get_root_nodes(nodes)"]}, {"cell_type": "markdown", "id": "c36ec940-8af7-45f5-9994-919d57583c24", "metadata": {}, "source": ["### 加载到存储\n", "\n", "我们定义了一个文档存储，将所有节点加载到其中。\n", "\n", "然后，我们定义一个 `VectorStoreIndex`，其中只包含叶子级节点。\n"]}, {"cell_type": "code", "execution_count": null, "id": "27c8f2cd-3e04-4feb-937b-b9ee33e1c2fd", "metadata": {}, "outputs": [], "source": ["# 定义存储上下文", "from llama_index.core.storage.docstore import SimpleDocumentStore", "from llama_index.core import StorageContext", "from llama_index.llms.openai import OpenAI", "", "docstore = SimpleDocumentStore()", "", "# 将节点插入到文档存储中", "docstore.add_documents(nodes)", "", "# 定义存储上下文（默认情况下也将包括向量存储）", "storage_context = StorageContext.from_defaults(docstore=docstore)", "", "llm = OpenAI(model=\"gpt-3.5-turbo\")"]}, {"cell_type": "code", "execution_count": null, "id": "827ece8e-7a4b-4ee1-8ee2-3433d7f2072a", "metadata": {}, "outputs": [], "source": ["## 将索引加载到向量索引中", "from llama_index.core import VectorStoreIndex", "", "base_index = VectorStoreIndex(", "    leaf_nodes,", "    storage_context=storage_context,", ")"]}, {"cell_type": "markdown", "id": "05d84c19-c9ac-4294-a000-264c3c02427b", "metadata": {}, "source": ["## 定义检索器\n"]}, {"cell_type": "code", "execution_count": null, "id": "e61682a0-dd3c-400b-8734-35d5d0a98252", "metadata": {}, "outputs": [], "source": ["from llama_index.core.retrievers import AutoMergingRetriever"]}, {"cell_type": "code", "execution_count": null, "id": "f96fd0bc-c6c0-4073-a692-d1803cf4289f", "metadata": {}, "outputs": [], "source": ["base_retriever = base_index.as_retriever(similarity_top_k=6)\n", "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"]}, {"cell_type": "code", "execution_count": null, "id": "62f655cd-4195-4398-80e5-5aa561982d25", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["> Merging 4 nodes into parent node.\n", "> Parent node id: caf5f81c-842f-46a4-b679-6be584bd6aff.\n", "> Parent node text: We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: an...\n"]}], "source": ["", "# 查询字符串 = \"从红队行动中学到了哪些教训？\"", "# 查询字符串 = \"您能告诉我有关安全微调的关键概念吗？\"", "查询字符串 = (", "    \"在RLHF阶段调整安全数据量可能会产生什么潜在结果？\"", ")", "", "节点 = retriever.retrieve(查询字符串)", "基础节点 = base_retriever.retrieve(查询字符串)"]}, {"cell_type": "code", "execution_count": null, "id": "77eabc56-2009-4504-8832-b6d857bd43a4", "metadata": {}, "outputs": [{"data": {"text/plain": ["3"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["len(nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "3a82690a-263a-4e48-ab27-b161e72cb983", "metadata": {}, "outputs": [{"data": {"text/plain": ["6"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["len(base_nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "0d482b22-fd38-476b-821f-0c77564815c3", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**Node ID:** d4d67180-71c8-4328-b3f1-1e98fa42ab69<br>**Similarity:** 0.8694979150607424<br>**Text:** We also list two\n", "qualitative examples where safety and helpfulness reward models don’t agree with each other in Table 35.\n", "A.4.2\n", "Qualitative Results on Safety Data Scaling\n", "In Section 4.2.3, we study the impact of adding more safety data into model RLHF in a quantitative manner.\n", "Here we showcase a few samples to qualitatively examine the evolution of model behavior when we scale\n", "safety data in Tables 36, 37, and 38. In general, we are observing that Llama 2-Chat becomes safer responding\n", "to unsafe prompts with more safety data used.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** caf5f81c-842f-46a4-b679-6be584bd6aff<br>**Similarity:** 0.86168727941324<br>**Text:** We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: annotators\n", "write a prompt that they believe can elicit unsafe behavior, and then compare multiple model responses to\n", "the prompts, selecting the response that is safest according to a set of guidelines. We then use the human\n", "preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\n", "sample from the model during the RLHF stage.\n", "Better Long-Tail Safety Robustness without Hurting Helpfulness\n", "Safety is inherently a long-tail problem,\n", "where the challenge comes from a small number of very specific cases. We investigate the impact of Safety\n", "RLHF by taking two intermediate Llama 2-Chat checkpoints—one without adversarial prompts in the RLHF\n", "stage and one with them—and score their responses on our test sets using our safety and helpfulness reward\n", "models. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\n", "of the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\n", "the distribution of safety RM scores on the safety set shifts to higher reward scores after safety tuning with\n", "RLHF, and that the long tail of the distribution near zero thins out. A clear cluster appears on the top-left\n", "corner suggesting the improvements of model safety. On the right side, we do not observe any gathering\n", "pattern below the y = x line on the right hand side of Figure 14, which indicates that the helpfulness score\n", "distribution is preserved after safety tuning with RLHF. Put another way, given sufficient helpfulness training\n", "data, the addition of an additional stage of safety mitigation does not negatively impact model performance\n", "on helpfulness to any notable degradation. A qualitative example is shown in Table 12.\n", "Impact of Safety Data Scaling.\n", "A tension between helpfulness and safety of LLMs has been observed in\n", "previous studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\n", "general model performance, especially helpfulness, we investigate the trends in safety data scaling by\n", "adjusting the amount of safety data used in the RLHF stage.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** d9893bef-a5a7-4248-a0a1-d7c28800ae59<br>**Similarity:** 0.8546977459150967<br>**Text:** 0\n", "0.2\n", "0.4\n", "0.6\n", "0.8\n", "1.0\n", "Helpfulness RM Score before Safety RLHF\n", "0.0\n", "0.2\n", "0.4\n", "0.6\n", "0.8\n", "1.0\n", "Helpfulness RM Score after Safety RLHF\n", "0\n", "1000\n", "0\n", "1000\n", "Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\n", "model scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\n", "suggests the improvements of model safety.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["from llama_index.core.response.notebook_utils import display_source_node\n", "\n", "for node in nodes:\n", "    display_source_node(node, source_length=10000)"]}, {"cell_type": "code", "execution_count": null, "id": "e4dd58db-4b12-49dc-b42f-8a0ee746f5c9", "metadata": {}, "outputs": [{"data": {"text/markdown": ["**Node ID:** 16328561-9ff7-4307-8d31-adf6bb74b71b<br>**Similarity:** 0.8770715326726375<br>**Text:** A qualitative example is shown in Table 12.\n", "Impact of Safety Data Scaling.\n", "A tension between helpfulness and safety of LLMs has been observed in\n", "previous studies (Bai et al., 2022a). To better understand how the addition of safety training data affects\n", "general model performance, especially helpfulness, we investigate the trends in safety data scaling by\n", "adjusting the amount of safety data used in the RLHF stage.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** e756d327-1a28-4228-ac38-f8a831b1bf77<br>**Similarity:** 0.8728111844788112<br>**Text:** A clear cluster appears on the top-left\n", "corner suggesting the improvements of model safety. On the right side, we do not observe any gathering\n", "pattern below the y = x line on the right hand side of Figure 14, which indicates that the helpfulness score\n", "distribution is preserved after safety tuning with RLHF. Put another way, given sufficient helpfulness training\n", "data, the addition of an additional stage of safety mitigation does not negatively impact model performance\n", "on helpfulness to any notable degradation. A qualitative example is shown in Table 12.\n", "Impact of Safety Data Scaling.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** d4d67180-71c8-4328-b3f1-1e98fa42ab69<br>**Similarity:** 0.8697379697028405<br>**Text:** We also list two\n", "qualitative examples where safety and helpfulness reward models don’t agree with each other in Table 35.\n", "A.4.2\n", "Qualitative Results on Safety Data Scaling\n", "In Section 4.2.3, we study the impact of adding more safety data into model RLHF in a quantitative manner.\n", "Here we showcase a few samples to qualitatively examine the evolution of model behavior when we scale\n", "safety data in Tables 36, 37, and 38. In general, we are observing that Llama 2-Chat becomes safer responding\n", "to unsafe prompts with more safety data used.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** d9893bef-a5a7-4248-a0a1-d7c28800ae59<br>**Similarity:** 0.855087365309258<br>**Text:** 0\n", "0.2\n", "0.4\n", "0.6\n", "0.8\n", "1.0\n", "Helpfulness RM Score before Safety RLHF\n", "0.0\n", "0.2\n", "0.4\n", "0.6\n", "0.8\n", "1.0\n", "Helpfulness RM Score after Safety RLHF\n", "0\n", "1000\n", "0\n", "1000\n", "Figure 14: Impact of safety RLHF measured by reward model score distributions. Left: safety reward\n", "model scores of generations on the Meta Safety test set. The clustering of samples in the top left corner\n", "suggests the improvements of model safety.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** d62ee107-9841-44b5-8b70-bc6487ad6315<br>**Similarity:** 0.8492541852986794<br>**Text:** Better Long-Tail Safety Robustness without Hurting Helpfulness\n", "Safety is inherently a long-tail problem,\n", "where the challenge comes from a small number of very specific cases. We investigate the impact of Safety\n", "RLHF by taking two intermediate Llama 2-Chat checkpoints—one without adversarial prompts in the RLHF\n", "stage and one with them—and score their responses on our test sets using our safety and helpfulness reward\n", "models.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/markdown": ["**Node ID:** 312a63b3-5e28-4fbf-a3e1-4e8dc0c026ea<br>**Similarity:** 0.8488371951811564<br>**Text:** We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: annotators\n", "write a prompt that they believe can elicit unsafe behavior, and then compare multiple model responses to\n", "the prompts, selecting the response that is safest according to a set of guidelines. We then use the human\n", "preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\n", "sample from the model during the RLHF stage.<br>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["for node in base_nodes:\n", "    display_source_node(node, source_length=10000)"]}, {"cell_type": "markdown", "id": "08f62e2c-4def-402e-8904-47f34d12c2fb", "metadata": {}, "source": ["## 将其连接到查询引擎\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "5d3ce9ec-f6cd-475b-94fa-3e8df81ab824", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import RetrieverQueryEngine"]}, {"cell_type": "code", "execution_count": null, "id": "f106e1bb-58bc-48bf-a46b-e527339f83c5", "metadata": {}, "outputs": [], "source": ["query_engine = RetrieverQueryEngine.from_args(retriever)\n", "base_query_engine = RetrieverQueryEngine.from_args(base_retriever)"]}, {"cell_type": "code", "execution_count": null, "id": "94a85854-ca04-41ed-9f44-b6dce1e513e1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["> Merging 4 nodes into parent node.\n", "> Parent node id: 3671b20d-ea5e-4afc-983e-02be6ee8302d.\n", "> Parent node text: We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: an...\n"]}], "source": ["response = query_engine.query(query_str)"]}, {"cell_type": "code", "execution_count": null, "id": "8b334b7b-fcb8-4057-a418-b8d8c425ad14", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Adjusting the amount of safety data used in the RLHF stage could potentially have the following outcomes:\n", "1. Improved model safety: Increasing the amount of safety data used in RLHF may lead to improvements in model safety. This means that the model becomes better at responding to unsafe prompts and avoids generating unsafe or harmful outputs.\n", "2. Thinning out of the long tail of safety RM scores: Increasing the amount of safety data may result in a shift in the distribution of safety reward model (RM) scores towards higher reward scores. This means that the model becomes more consistent in generating safe responses and reduces the occurrence of low safety scores.\n", "3. Preservation of helpfulness performance: Adjusting the amount of safety data used in RLHF is not expected to negatively impact model performance on helpfulness. This means that the model's ability to generate helpful responses is maintained even after incorporating additional safety training.\n", "4. Gathering pattern in helpfulness RM scores: There is no observed gathering pattern below the y = x line in the distribution of helpfulness RM scores after safety tuning with RLHF. This suggests that the helpfulness score distribution is preserved, indicating that the model's helpfulness performance is not significantly degraded by the addition of safety mitigation measures.\n", "Overall, adjusting the amount of safety data used in the RLHF stage aims to strike a balance between improving model safety without compromising its helpfulness performance.\n"]}], "source": ["print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "1c38a124-5279-4a43-a2fe-ed2cbce9bd66", "metadata": {}, "outputs": [], "source": ["base_response = base_query_engine.query(query_str)"]}, {"cell_type": "code", "execution_count": null, "id": "5c2910e5-1a45-4de5-8035-5b5a47125d81", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Adjusting the amount of safety data used in the RLHF stage could potentially lead to improvements in model safety. This can be observed by a clear cluster appearing on the top-left corner, suggesting enhanced model safety. Additionally, it is indicated that the helpfulness score distribution is preserved after safety tuning with RLHF, indicating that the addition of safety data does not negatively impact model performance on helpfulness.\n"]}], "source": ["print(str(base_response))"]}, {"cell_type": "markdown", "id": "f84be450-c036-4cca-bf94-ccfc18e5d52a", "metadata": {}, "source": ["## 评估\n", "\n", "我们以更加定量的方式评估分层检索器相对于基准检索器的工作效果。\n", "\n", "**警告**：这可能会*耗费*大量资源，特别是使用GPT-4。请谨慎使用，并调整样本大小以适应您的预算。\n"]}, {"cell_type": "code", "execution_count": null, "id": "cb5a6511-5756-4cdb-933e-f530f0c40bc3", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset\n", "from llama_index.llms.openai import OpenAI\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "914e3056-d9e3-42a0-9600-a66ae6a9f075", "metadata": {}, "outputs": [], "source": ["# 注意：如果数据集尚未保存，请运行此代码", "# 注意：我们只从前20个节点生成，因为其余的是引用", "eval_llm = OpenAI(model=\"gpt-4\")", "dataset_generator = DatasetGenerator(", "    root_nodes[:20],", "    llm=eval_llm,", "    show_progress=True,", "    num_questions_per_chunk=3,", ")"]}, {"cell_type": "code", "execution_count": null, "id": "d9569b69-d9bf-4b85-a1b3-3ff4ef6619b8", "metadata": {}, "outputs": [], "source": ["eval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=60)"]}, {"cell_type": "code", "execution_count": null, "id": "e5b3ba74-0092-4906-88cc-638fa304c97b", "metadata": {}, "outputs": [], "source": ["eval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")"]}, {"cell_type": "code", "execution_count": null, "id": "87f30894-ba65-4af7-9380-210f6a5b2de4", "metadata": {}, "outputs": [], "source": ["# 可选", "eval_dataset = QueryResponseDataset.from_json(", "    \"data/llama2_eval_qr_dataset.json\"", ")"]}, {"cell_type": "markdown", "id": "2d793ae5-80be-41ff-8b1f-e92ea27b2a8b", "metadata": {}, "source": ["### 比较结果\n", "\n", "我们对每个检索器进行了评估：正确性、语义相似性、相关性和忠实度。\n"]}, {"cell_type": "code", "execution_count": null, "id": "90ca35cf-e659-4a1e-8561-d07d50972b3a", "metadata": {}, "outputs": [], "source": ["import asyncio\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "f6814643-bdb2-47cd-a8a5-69a1bdfdda30", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import (", "    CorrectnessEvaluator,  # 正确性评估器", "    SemanticSimilarityEvaluator,  # 语义相似性评估器", "    RelevancyEvaluator,  # 相关性评估器", "    FaithfulnessEvaluator,  # 忠实度评估器", "    PairwiseComparisonEvaluator,  # 两两比较评估器", ")", "", "", "from collections import defaultdict", "import pandas as pd", "", "# 注意：可以取消其他评估器的注释", "evaluator_c = CorrectnessEvaluator(llm=eval_llm)  # 正确性评估器", "evaluator_s = SemanticSimilarityEvaluator(llm=eval_llm)  # 语义相似性评估器", "evaluator_r = RelevancyEvaluator(llm=eval_llm)  # 相关性评估器", "evaluator_f = FaithfulnessEvaluator(llm=eval_llm)  # 忠实度评估器", "# pairwise_evaluator = PairwiseComparisonEvaluator(llm=eval_llm)"]}, {"cell_type": "code", "execution_count": null, "id": "ae472816-5927-4f67-9105-fd0ba0c60f49", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation.eval_utils import (\n", "    get_responses,\n", "    get_results_df,\n", ")\n", "from llama_index.core.evaluation import BatchEvalRunner"]}, {"cell_type": "code", "execution_count": null, "id": "fdfd6d5b-7c73-40a5-9636-8db6a248ac00", "metadata": {}, "outputs": [], "source": ["eval_qs = eval_dataset.questions\n", "qr_pairs = eval_dataset.qr_pairs\n", "ref_response_strs = [r for (_, r) in qr_pairs]"]}, {"cell_type": "code", "execution_count": null, "id": "a7302e7b-6b3e-4d25-874b-94ffe944b527", "metadata": {}, "outputs": [], "source": ["pred_responses = get_responses(eval_qs, query_engine, show_progress=True)"]}, {"cell_type": "code", "execution_count": null, "id": "0bce562f-6c42-446a-b991-f208ca9f55cb", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:07<00:00,  8.17it/s]\n"]}], "source": ["base_pred_responses = get_responses(\n", "    eval_qs, base_query_engine, show_progress=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "3428afe0-b5e4-4604-b7ce-270f449766cb", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "pred_response_strs = [str(p) for p in pred_responses]\n", "base_pred_response_strs = [str(p) for p in base_pred_responses]"]}, {"cell_type": "code", "execution_count": null, "id": "b0a86029-bf5e-4f26-afdf-a9406bada315", "metadata": {}, "outputs": [], "source": ["evaluator_dict = {\n", "    \"correctness\": evaluator_c,\n", "    \"faithfulness\": evaluator_f,\n", "    \"relevancy\": evaluator_r,\n", "    \"semantic_similarity\": evaluator_s,\n", "}\n", "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)"]}, {"cell_type": "code", "execution_count": null, "id": "9abccb17-cf7d-4f59-b849-a4d5581df7a9", "metadata": {}, "outputs": [], "source": ["eval_results = await batch_runner.aevaluate_responses(\n", "    eval_qs, responses=pred_responses, reference=ref_response_strs\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "7c5df1ec-408a-4012-93c7-a0151fa92b9e", "metadata": {}, "outputs": [], "source": ["base_eval_results = await batch_runner.aevaluate_responses(\n", "    eval_qs, responses=base_pred_responses, reference=ref_response_strs\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "ea90f363-71d7-404c-9d4d-f6eea386e59f", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>names</th>\n", "      <th>correctness</th>\n", "      <th>relevancy</th>\n", "      <th>faithfulness</th>\n", "      <th>semantic_similarity</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Auto Merging Retriever</td>\n", "      <td>4.266667</td>\n", "      <td>0.916667</td>\n", "      <td>0.95</td>\n", "      <td>0.962196</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Base Retriever</td>\n", "      <td>4.208333</td>\n", "      <td>0.916667</td>\n", "      <td>0.95</td>\n", "      <td>0.960602</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                    names  correctness  relevancy  faithfulness  \\\n", "0  Auto Merging Retriever     4.266667   0.916667          0.95   \n", "1          Base Retriever     4.208333   0.916667          0.95   \n", "\n", "   semantic_similarity  \n", "0             0.962196  \n", "1             0.960602  "]}, "metadata": {}, "output_type": "display_data"}], "source": ["results_df = get_results_df(\n", "    [eval_results, base_eval_results],\n", "    [\"Auto Merging Retriever\", \"Base Retriever\"],\n", "    [\"correctness\", \"relevancy\", \"faithfulness\", \"semantic_similarity\"],\n", ")\n", "display(results_df)"]}, {"cell_type": "markdown", "id": "be393093-9a6d-46d1-9d18-d17e92523200", "metadata": {}, "source": ["**分析**：结果大致相同。\n", "\n", "让我们也尝试使用我们的成对评估来看看GPT-4更喜欢哪个答案。\n"]}, {"cell_type": "code", "execution_count": null, "id": "91126247-b68d-43a9-b64f-f6764b0c2357", "metadata": {}, "outputs": [], "source": ["batch_runner = BatchEvalRunner(\n", "    {\"pairwise\": pairwise_evaluator}, workers=10, show_progress=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4426a26a-c26e-4560-b176-f2a7894adda7", "metadata": {}, "outputs": [], "source": ["pairwise_eval_results = await batch_runner.aevaluate_response_strs(\n", "    eval_qs,\n", "    response_strs=pred_response_strs,\n", "    reference=base_pred_response_strs,\n", ")\n", "pairwise_score = np.array(\n", "    [r.score for r in pairwise_eval_results[\"pairwise\"]]\n", ").mean()"]}, {"cell_type": "code", "execution_count": null, "id": "0460557e-f80d-4dcb-a8ec-b08c61ed3129", "metadata": {}, "outputs": [{"data": {"text/plain": ["0.525"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["pairwise_score"]}, {"cell_type": "markdown", "id": "9ec2f94b-bbff-4fee-920a-bf4c872f23f2", "metadata": {}, "source": ["**分析**：成对比较分数是候选答案（使用自动合并检索器）被优先选择的百分比与基础答案（使用基础检索器）相比的度量。在这里，我们可以看到它大致是平衡的。\n"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}