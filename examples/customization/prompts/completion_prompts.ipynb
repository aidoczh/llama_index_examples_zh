{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/customization/prompts/completion_prompts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# 定制完成提示\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 设置提示\n", "\n", "下面，我们将使用默认提示并对其进行自定义，以便即使上下文不够有帮助，也能始终给出答案。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import PromptTemplate\n", "\n", "text_qa_template_str = (\n", "    \"Context information is\"\n", "    \" below.\\n---------------------\\n{context_str}\\n---------------------\\nUsing\"\n", "    \" both the context information and also using your own knowledge, answer\"\n", "    \" the question: {query_str}\\nIf the context isn't helpful, you can also\"\n", "    \" answer the question on your own.\\n\"\n", ")\n", "text_qa_template = PromptTemplate(text_qa_template_str)\n", "\n", "refine_template_str = (\n", "    \"The original question is as follows: {query_str}\\nWe have provided an\"\n", "    \" existing answer: {existing_answer}\\nWe have the opportunity to refine\"\n", "    \" the existing answer (only if needed) with some more context\"\n", "    \" below.\\n------------\\n{context_msg}\\n------------\\nUsing both the new\"\n", "    \" context and your own knowledge, update or repeat the existing answer.\\n\"\n", ")\n", "refine_template = PromptTemplate(refine_template_str)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 使用提示\n", "\n", "现在，我们在索引查询中使用提示！\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import openai\n", "import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n", "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "from llama_index.llms.openai import OpenAI\n", "\n", "llm = OpenAI(model=\"gpt-3.5-turbo\")\n", "\n", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n", "\n", "index = VectorStoreIndex.from_documents(documents)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 添加模板之前\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": [" Joe Biden is not mentioned in the context information.\n"]}], "source": ["print(index.as_query_engine(llm=llm).query(\"Who is Joe Biden?\"))"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 添加模板后\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Joe Biden is the 46th President of the United States. He was elected in 2020 and is the first Democratic president since Barack Obama. He previously served as Vice President under Obama from 2009 to 2017.\n"]}], "source": ["print(\n", "    index.as_query_engine(\n", "        text_qa_template=text_qa_template,\n", "        refine_template=refine_template,\n", "        llm=llm,\n", "    ).query(\"Who is Joe Biden?\")\n", ")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}