{"cells": [{"cell_type": "markdown", "id": "9af12a30", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/customization/llms/AzureOpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "ec51f656", "metadata": {}, "source": ["# Azure OpenAI\n"]}, {"cell_type": "markdown", "id": "ef3d26db", "metadata": {}, "source": ["Azure OpenAIèµ„æºä¸æ ‡å‡†OpenAIèµ„æºä¸åŒï¼Œå› ä¸ºæ‚¨æ— æ³•ç”ŸæˆåµŒå…¥ï¼Œé™¤éæ‚¨ä½¿ç”¨åµŒå…¥æ¨¡å‹ã€‚æ”¯æŒè¿™äº›æ¨¡å‹çš„åŒºåŸŸå¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ°ï¼šhttps://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models\n", "\n", "æ­¤å¤–ï¼Œæ”¯æŒåµŒå…¥æ¨¡å‹çš„åŒºåŸŸä¸å¹¸ä¸æ”¯æŒOpenAIæ¨¡å‹çš„æœ€æ–°ç‰ˆæœ¬ï¼ˆ<*>-003ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬è¢«è¿«åœ¨ä¸€ä¸ªåŒºåŸŸç”¨äºåµŒå…¥ï¼Œå¦ä¸€ä¸ªç”¨äºæ–‡æœ¬ç”Ÿæˆã€‚\n"]}, {"cell_type": "markdown", "id": "710d6708", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "94613811", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-azure-openai\n", "%pip install llama-index-llms-azure-openai"]}, {"cell_type": "code", "execution_count": null, "id": "de32bc14", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "b05e71d5", "metadata": {}, "outputs": [], "source": ["æ¥è‡ªllama_index.llms.azure_openaiçš„AzureOpenAI\n", "æ¥è‡ªllama_index.embeddings.azure_openaiçš„AzureOpenAIEmbedding\n", "æ¥è‡ªllama_index.coreçš„VectorStoreIndexå’ŒSimpleDirectoryReader\n", "import logging\n", "import sys\n", "\n", "logging.basicConfig(\n", "    stream=sys.stdout, level=logging.INFO\n", ")  # logging.DEBUGç”¨äºæ›´è¯¦ç»†çš„è¾“å‡º\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"cell_type": "markdown", "id": "fcaaafdf", "metadata": {}, "source": ["åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®¾ç½®åµŒå…¥æ¨¡å‹ï¼ˆç”¨äºæ£€ç´¢ï¼‰å’Œllmï¼ˆç”¨äºæ–‡æœ¬ç”Ÿæˆï¼‰ã€‚\n", "è¯·æ³¨æ„ï¼Œæ‚¨ä¸ä»…éœ€è¦æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚â€œtext-embedding-ada-002â€ï¼‰ï¼Œè¿˜éœ€è¦æ¨¡å‹éƒ¨ç½²åç§°ï¼ˆåœ¨Azureéƒ¨ç½²æ¨¡å‹æ—¶é€‰æ‹©çš„åç§°ï¼‰ã€‚\n", "åœ¨åˆå§‹åŒ–`AzureOpenAI`å’Œ`OpenAIEmbedding`æ—¶ï¼Œæ‚¨å¿…é¡»å°†éƒ¨ç½²åç§°ä½œä¸ºå‚æ•°ä¼ é€’ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "e2569cb0", "metadata": {}, "outputs": [], "source": ["api_key = \"<api-key>\"\n", "azure_endpoint = \"https://<your-resource-name>.openai.azure.com/\"\n", "api_version = \"2023-07-01-preview\"\n", "\n", "llm = AzureOpenAI(\n", "    model=\"gpt-35-turbo-16k\",\n", "    deployment_name=\"my-custom-llm\",\n", "    api_key=api_key,\n", "    azure_endpoint=azure_endpoint,\n", "    api_version=api_version,\n", ")\n", "\n", "# æ‚¨éœ€è¦éƒ¨ç½²è‡ªå·±çš„åµŒå…¥æ¨¡å‹ä»¥åŠè‡ªå·±çš„èŠå¤©å®Œæˆæ¨¡å‹\n", "embed_model = AzureOpenAIEmbedding(\n", "    model=\"text-embedding-ada-002\",\n", "    deployment_name=\"my-custom-embedding\",\n", "    api_key=api_key,\n", "    azure_endpoint=azure_endpoint,\n", "    api_version=api_version,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "72aac5a6-495e-40d2-82d3-bda8688ae919", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "Settings.llm = llm\n", "Settings.embed_model = embed_model"]}, {"cell_type": "code", "execution_count": null, "id": "1cf0e9c9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"]}], "source": ["documents = SimpleDirectoryReader(\n", "    input_files=[\"../../data/paul_graham/paul_graham_essay.txt\"]\n", ").load_data()\n", "index = VectorStoreIndex.from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "id": "98d9d3fd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-llm/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-llm/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-llm/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "> Source (Doc id: 3e0d1e3f-9099-483f-9abd-8f352c5e730f): A lot of Lisp hackers dream of building a new Lisp, partly because one of the distinctive feature...\n", "\n", "> Source (Doc id: 06c1d986-1856-44cd-980d-651252ad1caf): What I Worked On\n", "\n", "February 2021\n", "\n", "Before college the two main things I worked on, outside of schoo...\n", "query was: What is most interesting about this essay?\n", "answer was: The most interesting aspect of this essay is the author's exploration of the transformative power of publishing essays online. The author reflects on how the internet has democratized the publishing process, allowing anyone to publish their work and reach a wide audience. This realization led the author to start writing and publishing essays online, which eventually became a significant part of their work. The author also discusses the initial skepticism and lack of prestige associated with online essays, but they find encouragement in the potential for genuine discovery and the absence of the desire to impress others. Overall, the essay highlights the author's personal journey and the impact of online publishing on their career.\n"]}], "source": ["query = \"What is most interesting about this essay?\"\n", "query_engine = index.as_query_engine()\n", "answer = query_engine.query(query)\n", "\n", "print(answer.get_formatted_sources())\n", "print(\"query was:\", query)\n", "print(\"answer was:\", answer)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}