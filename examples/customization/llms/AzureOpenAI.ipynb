{"cells": [{"cell_type": "markdown", "id": "9af12a30", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/customization/llms/AzureOpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "ec51f656", "metadata": {}, "source": ["# Azure OpenAI\n"]}, {"cell_type": "markdown", "id": "ef3d26db", "metadata": {}, "source": ["Azure OpenAI资源与标准OpenAI资源不同，因为您无法生成嵌入，除非您使用嵌入模型。支持这些模型的区域可以在此处找到：https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models\n", "\n", "此外，支持嵌入模型的区域不幸不支持OpenAI模型的最新版本（<*>-003），因此我们被迫在一个区域用于嵌入，另一个用于文本生成。\n"]}, {"cell_type": "markdown", "id": "710d6708", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "94613811", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-azure-openai\n", "%pip install llama-index-llms-azure-openai"]}, {"cell_type": "code", "execution_count": null, "id": "de32bc14", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "b05e71d5", "metadata": {}, "outputs": [], "source": ["来自llama_index.llms.azure_openai的AzureOpenAI\n", "来自llama_index.embeddings.azure_openai的AzureOpenAIEmbedding\n", "来自llama_index.core的VectorStoreIndex和SimpleDirectoryReader\n", "import logging\n", "import sys\n", "\n", "logging.basicConfig(\n", "    stream=sys.stdout, level=logging.INFO\n", ")  # logging.DEBUG用于更详细的输出\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"cell_type": "markdown", "id": "fcaaafdf", "metadata": {}, "source": ["在这里，我们设置嵌入模型（用于检索）和llm（用于文本生成）。\n", "请注意，您不仅需要模型名称（例如“text-embedding-ada-002”），还需要模型部署名称（在Azure部署模型时选择的名称）。\n", "在初始化`AzureOpenAI`和`OpenAIEmbedding`时，您必须将部署名称作为参数传递。\n"]}, {"cell_type": "code", "execution_count": null, "id": "e2569cb0", "metadata": {}, "outputs": [], "source": ["api_key = \"<api-key>\"\n", "azure_endpoint = \"https://<your-resource-name>.openai.azure.com/\"\n", "api_version = \"2023-07-01-preview\"\n", "\n", "llm = AzureOpenAI(\n", "    model=\"gpt-35-turbo-16k\",\n", "    deployment_name=\"my-custom-llm\",\n", "    api_key=api_key,\n", "    azure_endpoint=azure_endpoint,\n", "    api_version=api_version,\n", ")\n", "\n", "# 您需要部署自己的嵌入模型以及自己的聊天完成模型\n", "embed_model = AzureOpenAIEmbedding(\n", "    model=\"text-embedding-ada-002\",\n", "    deployment_name=\"my-custom-embedding\",\n", "    api_key=api_key,\n", "    azure_endpoint=azure_endpoint,\n", "    api_version=api_version,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "72aac5a6-495e-40d2-82d3-bda8688ae919", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "Settings.llm = llm\n", "Settings.embed_model = embed_model"]}, {"cell_type": "code", "execution_count": null, "id": "1cf0e9c9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"]}], "source": ["documents = SimpleDirectoryReader(\n", "    input_files=[\"../../data/paul_graham/paul_graham_essay.txt\"]\n", ").load_data()\n", "index = VectorStoreIndex.from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "id": "98d9d3fd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-embedding/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "INFO:httpx:HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-llm/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-llm/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://test-simon.openai.azure.com//openai/deployments/my-custom-llm/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n", "> Source (Doc id: 3e0d1e3f-9099-483f-9abd-8f352c5e730f): A lot of Lisp hackers dream of building a new Lisp, partly because one of the distinctive feature...\n", "\n", "> Source (Doc id: 06c1d986-1856-44cd-980d-651252ad1caf): What I Worked On\n", "\n", "February 2021\n", "\n", "Before college the two main things I worked on, outside of schoo...\n", "query was: What is most interesting about this essay?\n", "answer was: The most interesting aspect of this essay is the author's exploration of the transformative power of publishing essays online. The author reflects on how the internet has democratized the publishing process, allowing anyone to publish their work and reach a wide audience. This realization led the author to start writing and publishing essays online, which eventually became a significant part of their work. The author also discusses the initial skepticism and lack of prestige associated with online essays, but they find encouragement in the potential for genuine discovery and the absence of the desire to impress others. Overall, the essay highlights the author's personal journey and the impact of online publishing on their career.\n"]}], "source": ["query = \"What is most interesting about this essay?\"\n", "query_engine = index.as_query_engine()\n", "answer = query_engine.query(query)\n", "\n", "print(answer.get_formatted_sources())\n", "print(\"query was:\", query)\n", "print(\"answer was:\", answer)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}