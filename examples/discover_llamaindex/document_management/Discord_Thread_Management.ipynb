{"cells": [{"cell_type": "markdown", "id": "518b983e", "metadata": {}, "source": ["# Discordçº¿ç¨‹ç®¡ç†\n", "\n", "è¿™ä¸ªç¬”è®°æœ¬ä»‹ç»äº†ç®¡ç†æ¥è‡ªä¸æ–­æ›´æ–°çš„æ•°æ®æºçš„æ–‡æ¡£çš„è¿‡ç¨‹ã€‚\n", "\n", "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªç›®å½•ï¼Œå®šæœŸå°†LlamaIndex Discordä¸Šçš„#issues-and-helpé¢‘é“ä¸­çš„å†…å®¹è½¬å‚¨åˆ°è¯¥ç›®å½•ä¸­ã€‚æˆ‘ä»¬å¸Œæœ›ç¡®ä¿æˆ‘ä»¬çš„ç´¢å¼•å§‹ç»ˆå…·æœ‰æœ€æ–°çš„æ•°æ®ï¼Œè€Œä¸ä¼šé‡å¤ä»»ä½•æ¶ˆæ¯ã€‚\n"]}, {"cell_type": "markdown", "id": "2a168a3c", "metadata": {}, "source": ["## ç´¢å¼•discordæ•°æ®\n", "\n", "Discordæ•°æ®è¢«è½¬å‚¨ä¸ºè¿ç»­çš„æ¶ˆæ¯ã€‚æ¯æ¡æ¶ˆæ¯éƒ½åŒ…å«æœ‰ç”¨çš„ä¿¡æ¯ï¼Œå¦‚æ—¶é—´æˆ³ã€ä½œè€…ä»¥åŠå¦‚æœæ¶ˆæ¯æ˜¯ä¸»é¢˜çš„ä¸€éƒ¨åˆ†ï¼Œåˆ™åŒ…å«åˆ°çˆ¶æ¶ˆæ¯çš„é“¾æ¥ã€‚\n", "\n", "æˆ‘ä»¬çš„Discordä¸Šçš„å¸®åŠ©é¢‘é“é€šå¸¸åœ¨è§£å†³é—®é¢˜æ—¶ä½¿ç”¨ä¸»é¢˜ï¼Œå› æ­¤æˆ‘ä»¬å°†æŠŠæ‰€æœ‰æ¶ˆæ¯åˆ†ç»„åˆ°ä¸»é¢˜ä¸­ï¼Œå¹¶å°†æ¯ä¸ªä¸»é¢˜ç´¢å¼•ä¸ºå•ç‹¬çš„æ–‡æ¡£ã€‚\n", "\n", "é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ¢ç´¢æˆ‘ä»¬è¦å¤„ç†çš„æ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "93b6022b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['help_channel_dump_06_02_23.json', 'help_channel_dump_05_25_23.json']\n"]}], "source": ["import os\n", "\n", "print(os.listdir(\"./discord_dumps\"))"]}, {"cell_type": "markdown", "id": "9c83dc57", "metadata": {}, "source": ["æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªæ¥è‡ªä¸åŒæ—¥æœŸçš„æ•°æ®è½¬å‚¨ã€‚å‡è®¾æˆ‘ä»¬åªæœ‰è¾ƒæ—§çš„æ•°æ®è½¬å‚¨ï¼Œæˆ‘ä»¬æƒ³è¦ä»è¿™äº›æ•°æ®ä¸­åˆ›å»ºä¸€ä¸ªç´¢å¼•ã€‚\n", "\n", "é¦–å…ˆï¼Œè®©æˆ‘ä»¬å…ˆå¯¹æ•°æ®è¿›è¡Œä¸€äº›æ¢ç´¢ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "ac1bcd6f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["JSON keys:  dict_keys(['guild', 'channel', 'dateRange', 'messages', 'messageCount']) \n", "\n", "Message Count:  5087 \n", "\n", "Sample Message Keys:  dict_keys(['id', 'type', 'timestamp', 'timestampEdited', 'callEndedTimestamp', 'isPinned', 'content', 'author', 'attachments', 'embeds', 'stickers', 'reactions', 'mentions']) \n", "\n", "First Message:  If you're running into any bugs, issues, or you have questions as to how to best use GPT Index, put those here! \n", "- If it's a bug, let's also track as a GH issue: https://github.com/jerryjliu/gpt_index/issues. \n", "\n", "Last Message:  Hello there! How can I use llama_index with GPU?\n"]}], "source": ["import json\n", "\n", "with open(\"./discord_dumps/help_channel_dump_05_25_23.json\", \"r\") as f:\n", "    data = json.load(f)\n", "print(\"JSON keys: \", data.keys(), \"\\n\")\n", "print(\"Message Count: \", len(data[\"messages\"]), \"\\n\")\n", "print(\"Sample Message Keys: \", data[\"messages\"][0].keys(), \"\\n\")\n", "print(\"First Message: \", data[\"messages\"][0][\"content\"], \"\\n\")\n", "print(\"Last Message: \", data[\"messages\"][-1][\"content\"])"]}, {"cell_type": "markdown", "id": "2ecd4bc3", "metadata": {}, "source": ["æ–¹ä¾¿èµ·è§ï¼Œæˆ‘å·²ç»æä¾›äº†ä¸€ä¸ªè„šæœ¬ï¼Œå¯ä»¥å°†è¿™äº›æ¶ˆæ¯åˆ†ç»„æˆçº¿ç¨‹ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹`group_conversations.py`è„šæœ¬ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚è¾“å‡ºæ–‡ä»¶å°†æ˜¯ä¸€ä¸ªjsonåˆ—è¡¨ï¼Œå…¶ä¸­åˆ—è¡¨ä¸­çš„æ¯ä¸ªé¡¹ç›®éƒ½æ˜¯ä¸€ä¸ªDiscordçº¿ç¨‹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "8d082c13", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Done! Written to conversation_docs.json\r\n"]}], "source": ["!python ./group_conversations.py ./discord_dumps/help_channel_dump_05_25_23.json"]}, {"cell_type": "code", "execution_count": null, "id": "f5c59130", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Thread keys:  dict_keys(['thread', 'metadata']) \n", "\n", "{'timestamp': '2023-01-02T03:36:04.191+00:00', 'id': '1059314106907242566'} \n", "\n", "arminta7:\n", "Hello all! Thanks to GPT_Index I've managed to put together a script that queries my extensive personal note collection which is a local directory of about 20k markdown files. Some of which are very long. I work in this folder all day everyday, so there are frequent changes. Currently I would need to rerun the entire indexing (is that the correct term?) when I want to incorporate edits I've made. \n", "\n", "So my question is... is there a way to schedule indexing to maybe once per day and only add information for files that have changed? Or even just manually run it but still only add edits? This would make a huge difference in saving time (I have to leave it running overnight for the entire directory) as well as cost ğŸ˜¬. \n", "\n", "Excuse me if this is a dumb question, I'm not a programmer and am sort of muddling around figuring this out ğŸ¤“ \n", "\n", "Thank you for making this sort of project accessible to someone like me!\n", "ragingWater_:\n", "I had a similar problem which I solved the following way in another world:\n", "- if you have a list of files, you want something which says that edits were made in the last day, possibly looking at the last_update_time of the file should help you.\n", "- for decreasing the cost, I would suggest maybe doing a keyword extraction or summarization of your notes and generating an embedding for it. Take your NLP query and get the most similar file (cosine similarity by pinecone db should help, GPTIndex also has a faiss) this should help with your cost needs\n", " \n", "\n"]}], "source": ["with open(\"conversation_docs.json\", \"r\") as f:\n", "    threads = json.load(f)\n", "print(\"Thread keys: \", threads[0].keys(), \"\\n\")\n", "print(threads[0][\"metadata\"], \"\\n\")\n", "print(threads[0][\"thread\"], \"\\n\")"]}, {"cell_type": "markdown", "id": "62ab605b", "metadata": {}, "source": ["ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªçº¿ç¨‹åˆ—è¡¨ï¼Œå¯ä»¥å°†å…¶è½¬æ¢ä¸ºæ–‡æ¡£å¹¶è¿›è¡Œç´¢å¼•ï¼\n"]}, {"cell_type": "markdown", "id": "ee3329af", "metadata": {}, "source": ["## åˆ›å»ºåˆå§‹ç´¢å¼•\n"]}, {"cell_type": "code", "execution_count": null, "id": "f05f0266", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Document\n", "\n", "# ä½¿ç”¨æ¯ä¸ªçº¿ç¨‹çš„doc_idå’Œæ—¥æœŸåˆ›å»ºæ–‡æ¡£å¯¹è±¡\n", "documents = []\n", "for thread in threads:\n", "    thread_text = thread[\"thread\"]\n", "    thread_id = thread[\"metadata\"][\"id\"]\n", "    timestamp = thread[\"metadata\"][\"timestamp\"]\n", "    documents.append(\n", "        Document(text=thread_text, id_=thread_id, metadata={\"date\": timestamp})\n", "    )"]}, {"cell_type": "code", "execution_count": null, "id": "41db23f7", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex\n", "\n", "index = VectorStoreIndex.from_documents(documents)"]}, {"cell_type": "markdown", "id": "45f98917", "metadata": {}, "source": ["è®©æˆ‘ä»¬å†æ¬¡æ£€æŸ¥ç´¢å¼•å®é™…æ‘„å–äº†å“ªäº›æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "e1e913fa", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ref_docs ingested:  767\n", "number of input documents:  767\n"]}], "source": ["print(\"ref_docs ingested: \", len(index.ref_doc_info))\n", "print(\"number of input documents: \", len(documents))"]}, {"cell_type": "markdown", "id": "b605d5d1", "metadata": {}, "source": ["å¥½çš„ï¼Œç›®å‰ä¸€åˆ‡é¡ºåˆ©ã€‚è®©æˆ‘ä»¬ä¹Ÿæ£€æŸ¥ä¸€ä¸‹ç‰¹å®šçš„çº¿ç¨‹ï¼Œä»¥ç¡®ä¿å…ƒæ•°æ®èµ·ä½œç”¨ï¼Œå¹¶æ£€æŸ¥å®ƒè¢«åˆ†æˆäº†å¤šå°‘ä¸ªèŠ‚ç‚¹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "31c36e9f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["RefDocInfo(node_ids=['0c530273-b6c3-4848-a760-fe73f5f8136e'], metadata={'date': '2023-01-02T03:36:04.191+00:00'})\n"]}], "source": ["thread_id = threads[0][\"metadata\"][\"id\"]\n", "print(index.ref_doc_info[thread_id])"]}, {"cell_type": "markdown", "id": "71689fcb", "metadata": {}, "source": ["å®Œç¾ï¼æˆ‘ä»¬çš„çº¿ç¨‹éå¸¸çŸ­ï¼Œå› æ­¤å®ƒç›´æ¥è¢«åˆ†æˆäº†ä¸€ä¸ªå•ç‹¬çš„èŠ‚ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ—¥æœŸå­—æ®µå·²ç»è¢«æ­£ç¡®è®¾ç½®ã€‚\n", "\n", "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å¤‡ä»½æˆ‘ä»¬çš„ç´¢å¼•ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¸å¿…æµªè´¹ä»¤ç‰Œå†æ¬¡è¿›è¡Œç´¢å¼•ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "cbe23135", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Double check ref_docs ingested:  767\n"]}], "source": ["# ä¿å­˜åˆå§‹ç´¢å¼•\n", "index.storage_context.persist(persist_dir=\"./storage\")\n", "\n", "# å†æ¬¡åŠ è½½ä»¥ç¡®è®¤å®ƒèµ·ä½œç”¨äº†\n", "from llama_index.core import StorageContext, load_index_from_storage\n", "\n", "index = load_index_from_storage(\n", "    StorageContext.from_defaults(persist_dir=\"./storage\")\n", ")\n", "\n", "print(\"å†æ¬¡ç¡®è®¤ ref_docs å·²è¢«æ‘„å–: \", len(index.ref_doc_info))"]}, {"cell_type": "markdown", "id": "55643a4c", "metadata": {}, "source": ["## åˆ·æ–°ç´¢å¼•ä»¥æ›´æ–°æ•°æ®ï¼\n", "\n", "ç°åœ¨ï¼Œçªç„¶é—´æˆ‘ä»¬æƒ³èµ·æˆ‘ä»¬æœ‰äº†æ–°çš„ Discord æ¶ˆæ¯è½¬å‚¨ï¼ä¸å…¶ä»å¤´å¼€å§‹é‡å»ºæ•´ä¸ªç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `refresh()` å‡½æ•°ä»…ç´¢å¼•æ–°æ–‡æ¡£ã€‚\n", "\n", "ç”±äºæˆ‘ä»¬æ‰‹åŠ¨è®¾ç½®äº†æ¯ä¸ªç´¢å¼•çš„ `doc_id`ï¼ŒLlamaIndex å¯ä»¥å°†ä¼ å…¥çš„æ–‡æ¡£ä¸ç›¸åŒ `doc_id` çš„æ–‡æ¡£è¿›è¡Œæ¯”è¾ƒï¼Œä»¥ç¡®è®¤ a) `doc_id` æ˜¯å¦å·²ç»è¢«æ‘„å–ï¼Œå¹¶ä¸” b) å†…å®¹æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ã€‚\n", "\n", "åˆ·æ–°å‡½æ•°å°†è¿”å›ä¸€ä¸ªå¸ƒå°”æ•°ç»„ï¼ŒæŒ‡ç¤ºè¾“å…¥ä¸­å“ªäº›æ–‡æ¡£å·²è¢«åˆ·æ–°æˆ–æ’å…¥ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªä¿¡æ¯æ¥ç¡®è®¤åªæœ‰æ–°çš„ Discord çº¿ç¨‹è¢«æ’å…¥ï¼\n", "\n", "å½“æ–‡æ¡£çš„å†…å®¹å‘ç”Ÿå˜åŒ–æ—¶ï¼Œå°†è°ƒç”¨ `update()` å‡½æ•°ï¼Œè¯¥å‡½æ•°ä¼šä»ç´¢å¼•ä¸­åˆ é™¤å¹¶é‡æ–°æ’å…¥æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "971357d5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["JSON keys:  dict_keys(['guild', 'channel', 'dateRange', 'messages', 'messageCount']) \n", "\n", "Message Count:  5286 \n", "\n", "Sample Message Keys:  dict_keys(['id', 'type', 'timestamp', 'timestampEdited', 'callEndedTimestamp', 'isPinned', 'content', 'author', 'attachments', 'embeds', 'stickers', 'reactions', 'mentions']) \n", "\n", "First Message:  If you're running into any bugs, issues, or you have questions as to how to best use GPT Index, put those here! \n", "- If it's a bug, let's also track as a GH issue: https://github.com/jerryjliu/gpt_index/issues. \n", "\n", "Last Message:  Started a thread.\n"]}], "source": ["import json\n", "\n", "with open(\"./discord_dumps/help_channel_dump_06_02_23.json\", \"r\") as f:\n", "    data = json.load(f)\n", "print(\"JSON keys: \", data.keys(), \"\\n\")\n", "print(\"Message Count: \", len(data[\"messages\"]), \"\\n\")\n", "print(\"Sample Message Keys: \", data[\"messages\"][0].keys(), \"\\n\")\n", "print(\"First Message: \", data[\"messages\"][0][\"content\"], \"\\n\")\n", "print(\"Last Message: \", data[\"messages\"][-1][\"content\"])"]}, {"cell_type": "markdown", "id": "931c9508", "metadata": {}, "source": ["æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œç¬¬ä¸€æ¡æ¶ˆæ¯ä¸åŸå§‹è½¬å‚¨çš„å†…å®¹ç›¸åŒã€‚ä½†ç°åœ¨æˆ‘ä»¬æœ‰å¤§çº¦200æ¡æ›´å¤šçš„æ¶ˆæ¯ï¼Œè€Œä¸”æœ€åä¸€æ¡æ¶ˆæ¯æ˜¾ç„¶æ˜¯æ–°çš„ï¼`refresh()`å°†ä½¿æ›´æ–°æˆ‘ä»¬çš„ç´¢å¼•å˜å¾—å®¹æ˜“ã€‚\n", "\n", "é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºæˆ‘ä»¬çš„æ–°çº¿ç¨‹/æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "fad09032", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Done! Written to conversation_docs.json\r\n"]}], "source": ["!python ./group_conversations.py ./discord_dumps/help_channel_dump_06_02_23.json"]}, {"cell_type": "code", "execution_count": null, "id": "f387c0dc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Thread keys:  dict_keys(['thread', 'metadata']) \n", "\n", "{'timestamp': '2023-01-02T03:36:04.191+00:00', 'id': '1059314106907242566'} \n", "\n", "arminta7:\n", "Hello all! Thanks to GPT_Index I've managed to put together a script that queries my extensive personal note collection which is a local directory of about 20k markdown files. Some of which are very long. I work in this folder all day everyday, so there are frequent changes. Currently I would need to rerun the entire indexing (is that the correct term?) when I want to incorporate edits I've made. \n", "\n", "So my question is... is there a way to schedule indexing to maybe once per day and only add information for files that have changed? Or even just manually run it but still only add edits? This would make a huge difference in saving time (I have to leave it running overnight for the entire directory) as well as cost ğŸ˜¬. \n", "\n", "Excuse me if this is a dumb question, I'm not a programmer and am sort of muddling around figuring this out ğŸ¤“ \n", "\n", "Thank you for making this sort of project accessible to someone like me!\n", "ragingWater_:\n", "I had a similar problem which I solved the following way in another world:\n", "- if you have a list of files, you want something which says that edits were made in the last day, possibly looking at the last_update_time of the file should help you.\n", "- for decreasing the cost, I would suggest maybe doing a keyword extraction or summarization of your notes and generating an embedding for it. Take your NLP query and get the most similar file (cosine similarity by pinecone db should help, GPTIndex also has a faiss) this should help with your cost needs\n", " \n", "\n"]}], "source": ["with open(\"conversation_docs.json\", \"r\") as f:\n", "    threads = json.load(f)\n", "print(\"Thread keys: \", threads[0].keys(), \"\\n\")\n", "print(threads[0][\"metadata\"], \"\\n\")\n", "print(threads[0][\"thread\"], \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "id": "2d737e98", "metadata": {}, "outputs": [], "source": ["# ä½¿ç”¨æ¯ä¸ªçº¿ç¨‹ä¸­çš„doc_idå’Œæ—¥æœŸåˆ›å»ºæ–‡æ¡£å¯¹è±¡\n", "new_documents = []\n", "for thread in threads:\n", "    thread_text = thread[\"thread\"]\n", "    thread_id = thread[\"metadata\"][\"id\"]\n", "    timestamp = thread[\"metadata\"][\"timestamp\"]\n", "    new_documents.append(\n", "        Document(text=thread_text, id_=thread_id, metadata={\"date\": timestamp})\n", "    )"]}, {"cell_type": "code", "execution_count": null, "id": "f3c97735", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Number of new documents:  13\n"]}], "source": ["print(\"Number of new documents: \", len(new_documents) - len(documents))"]}, {"cell_type": "code", "execution_count": null, "id": "87c4b886", "metadata": {}, "outputs": [], "source": ["# now, refresh!\n", "refreshed_docs = index.refresh(\n", "    new_documents,\n", "    update_kwargs={\"delete_kwargs\": {\"delete_from_docstore\": True}},\n", ")"]}, {"cell_type": "markdown", "id": "f85a4fec", "metadata": {}, "source": ["é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœæ–‡æ¡£çš„å†…å®¹å‘ç”Ÿäº†å˜åŒ–å¹¶è¿›è¡Œäº†æ›´æ–°ï¼Œæˆ‘ä»¬å¯ä»¥å‘ `delete_from_docstore` ä¼ é€’ä¸€ä¸ªé¢å¤–çš„æ ‡å¿—ã€‚è¿™ä¸ªæ ‡å¿—é»˜è®¤ä¸º `False`ï¼Œå› ä¸ºç´¢å¼•å¯ä»¥å…±äº«æ–‡æ¡£å­˜å‚¨ã€‚ä½†ç”±äºæˆ‘ä»¬åªæœ‰ä¸€ä¸ªç´¢å¼•ï¼Œåœ¨è¿™é‡Œä»æ–‡æ¡£å­˜å‚¨ä¸­åˆ é™¤æ˜¯å¯ä»¥çš„ã€‚\n", "\n", "å¦‚æœæˆ‘ä»¬ä¿æŒé€‰é¡¹ä¸º `False`ï¼Œé‚£ä¹ˆæ–‡æ¡£ä¿¡æ¯ä»ç„¶ä¼šä» `index_struct` ä¸­åˆ é™¤ï¼Œè¿™å®é™…ä¸Šä¼šä½¿è¯¥æ–‡æ¡£å¯¹ç´¢å¼•ä¸å¯è§ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "647025a9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Number of newly inserted/refreshed docs:  15\n"]}], "source": ["print(\"Number of newly inserted/refreshed docs: \", sum(refreshed_docs))"]}, {"cell_type": "markdown", "id": "0c72fa1f", "metadata": {}, "source": ["æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘ä»¬æœ‰13ä¸ªæ–°æ–‡æ¡£ï¼Œä½†æœ‰15ä¸ªæ–‡æ¡£è¢«åˆ·æ–°äº†ã€‚æ˜¯æœ‰äººç¼–è¾‘äº†ä»–ä»¬çš„æ¶ˆæ¯å—ï¼Ÿåœ¨ä¸»é¢˜ä¸­æ·»åŠ äº†æ›´å¤šæ–‡æœ¬ï¼Ÿè®©æˆ‘ä»¬æ‰¾å‡ºæ¥ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "a66882a6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[False, True, False, False, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True]\n"]}], "source": ["print(refreshed_docs[-25:])"]}, {"cell_type": "code", "execution_count": null, "id": "196aaa94", "metadata": {}, "outputs": [{"data": {"text/plain": ["Document(id_='1110938122902048809', embedding=None, weight=1.0, metadata={'date': '2023-05-24T14:31:28.732+00:00'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='36d308d1d2d1aa5cbfdb2f7d64709644a68805ec22a6053943f985084eec340e', text='Siddhant Saurabh:\\nhey facing error\\n```\\n*error_trace: Traceback (most recent call last):\\n File \"/app/src/chatbot/query_gpt.py\", line 248, in get_answer\\n   context_answer = self.call_pinecone_index(request)\\n File \"/app/src/chatbot/query_gpt.py\", line 229, in call_pinecone_index\\n   self.source.append(format_cited_source(source_node.doc_id))\\n File \"/usr/local/lib/python3.8/site-packages/llama_index/data_structs/node.py\", line 172, in doc_id\\n   return self.node.ref_doc_id\\n File \"/usr/local/lib/python3.8/site-packages/llama_index/data_structs/node.py\", line 87, in ref_doc_id\\n   return self.relationships.get(DocumentRelationship.SOURCE, None)\\nAttributeError: \\'Field\\' object has no attribute \\'get\\'\\n```\\nwith latest llama_index 0.6.9\\n@Logan M @jerryjliu98 @ravitheja\\nLogan M:\\nHow are you inserting nodes/documents? That attribute on the node should be set automatically usually\\nSiddhant Saurabh:\\nI think this happened because of the error mentioned by me here https://discord.com/channels/1059199217496772688/1106229492369850468/1108453477081948280\\nI think we need to re-preprocessing for such nodes, right?\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["new_documents[-21]"]}, {"cell_type": "code", "execution_count": null, "id": "d4f95b70", "metadata": {}, "outputs": [{"data": {"text/plain": ["Document(id_='1110938122902048809', embedding=None, weight=1.0, metadata={'date': '2023-05-24T14:31:28.732+00:00'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='c995c43873440a9d0263de70fff664269ec70d751c6e8245b290882ec5b656a1', text='Siddhant Saurabh:\\nhey facing error\\n```\\n*error_trace: Traceback (most recent call last):\\n File \"/app/src/chatbot/query_gpt.py\", line 248, in get_answer\\n   context_answer = self.call_pinecone_index(request)\\n File \"/app/src/chatbot/query_gpt.py\", line 229, in call_pinecone_index\\n   self.source.append(format_cited_source(source_node.doc_id))\\n File \"/usr/local/lib/python3.8/site-packages/llama_index/data_structs/node.py\", line 172, in doc_id\\n   return self.node.ref_doc_id\\n File \"/usr/local/lib/python3.8/site-packages/llama_index/data_structs/node.py\", line 87, in ref_doc_id\\n   return self.relationships.get(DocumentRelationship.SOURCE, None)\\nAttributeError: \\'Field\\' object has no attribute \\'get\\'\\n```\\nwith latest llama_index 0.6.9\\n@Logan M @jerryjliu98 @ravitheja\\nLogan M:\\nHow are you inserting nodes/documents? That attribute on the node should be set automatically usually\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["documents[-8]"]}, {"cell_type": "markdown", "id": "970427f1", "metadata": {}, "source": ["ä¸é”™ï¼è¾ƒæ–°çš„æ–‡æ¡£åŒ…å«äº†æ›´å¤šçš„æ¶ˆæ¯çº¿ç¨‹ã€‚æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œ`refresh()` èƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ä¸€ç‚¹ï¼Œå¹¶è‡ªåŠ¨ç”¨æ›´æ–°çš„æ–‡æœ¬æ›¿æ¢äº†æ—§çš„çº¿ç¨‹ã€‚\n"]}], "metadata": {"kernelspec": {"display_name": "llama-index", "language": "python", "name": "llama-index"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}