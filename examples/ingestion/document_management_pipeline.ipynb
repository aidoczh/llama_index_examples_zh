{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 数据摄取管道 + 文档管理\n", "\n", "将`docstore`连接到数据摄取管道将启用文档管理。\n", "\n", "使用`document.doc_id`或`node.ref_doc_id`作为基准点，数据摄取管道将积极查找重复文档。\n", "\n", "它的工作方式是：\n", "- 存储一个`doc_id` -> `document_hash`的映射\n", "- 如果检测到重复的`doc_id`，并且哈希值已更改，则文档将被重新处理\n", "- 如果哈希值未更改，则文档将在管道中被跳过\n", "\n", "如果我们不连接向量存储，我们只能检查和删除重复的输入。\n", "\n", "如果连接了向量存储，我们还可以处理更新！我们有另一个指南用于更新和向量存储。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["```python\n", "# 创建种子数据\n", "\n", "在开始使用模型之前，通常需要一些种子数据来测试和验证模型的功能。这些种子数据可以是模拟的数据，也可以是真实数据的子集。\n", "\n", "在这个示例中，我们将创建一些模拟的种子数据来演示如何使用模型。\n", "\n", "```\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-storage-docstore-redis\n", "%pip install llama-index-storage-docstore-mongodb\n", "%pip install llama-index-embeddings-huggingface"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 生成一些测试数据", "!mkdir -p data", "!echo \"这是一个测试文件：第一个！\" > data/test1.txt", "!echo \"这是一个测试文件：第二个！\" > data/test2.txt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/loganm/.cache/pypoetry/virtualenvs/llama-index-4a-wkI5X-py3.11/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.9) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n", "  warnings.warn(\n"]}], "source": ["from llama_index.core import SimpleDirectoryReader", "", "# 使用确定性ID加载文档", "documents = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 使用文档存储创建流水线\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n", "from llama_index.core.ingestion import IngestionPipeline\n", "from llama_index.core.storage.docstore import SimpleDocumentStore\n", "from llama_index.storage.docstore.redis import RedisDocumentStore\n", "from llama_index.storage.docstore.mongodb import MongoDocumentStore\n", "from llama_index.core.node_parser import SentenceSplitter\n", "\n", "\n", "pipeline = IngestionPipeline(\n", "    transformations=[\n", "        SentenceSplitter(),\n", "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n", "    ],\n", "    docstore=SimpleDocumentStore(),\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Docstore strategy set to upserts, but no vector store. Switching to duplicates_only strategy.\n"]}], "source": ["nodes = pipeline.run(documents=documents)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Ingested 2 Nodes\n"]}], "source": ["print(f\"Ingested {len(nodes)} Nodes\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### [可选] 保存/加载管道\n", "\n", "保存管道将同时保存内部缓存和文档存储。\n", "\n", "**注意：** 如果您正在使用远程缓存/文档存储，则不需要此步骤。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline.persist(\"./pipeline_storage\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipeline = IngestionPipeline(", "    transformations=[", "        SentenceSplitter(),  # 句子拆分器", "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),  # Hugging Face嵌入模型", "    ]", ")", "", "# 恢复管道", "pipeline.load(\"./pipeline_storage\")", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 测试文档管理\n", "\n", "在这里，我们可以创建一个新文档，也可以编辑一个现有的文档，以测试文档管理功能。\n", "\n", "新文档和编辑后的文档都将被纳入管理，而未更改的文档将被跳过。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!echo \"This is a test file: three!\" > data/test3.txt\n", "!echo \"This is a NEW test file: one!\" > data/test1.txt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["documents = SimpleDirectoryReader(\"./data\", filename_as_id=True).load_data()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Docstore strategy set to upserts, but no vector store. Switching to duplicates_only strategy.\n"]}], "source": ["nodes = pipeline.run(documents=documents)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Ingested 2 Nodes\n"]}], "source": ["print(f\"Ingested {len(nodes)} Nodes\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["让我们确认已经摄入了哪些节点：\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Node: This is a NEW test file: one!\n", "Node: This is a test file: three!\n"]}], "source": ["for node in nodes:\n", "    print(f\"Node: {node.text}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们还可以验证文档存储只跟踪了三个文档\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["3\n"]}], "source": ["print(len(pipeline.docstore.docs))"]}], "metadata": {"kernelspec": {"display_name": "llama-index-4a-wkI5X-py3.11", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}