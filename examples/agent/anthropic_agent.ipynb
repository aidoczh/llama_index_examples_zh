{"cells": [{"cell_type": "markdown", "id": "24103c51", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/mistral_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Âú® Colab ‰∏≠ÊâìÂºÄ\"/></a>\n"]}, {"cell_type": "markdown", "id": "99cea58c-48bc-4af6-8358-df9695659983", "metadata": {}, "source": ["# Ë∞ÉÁî®ÂáΩÊï∞ÁöÑ‰∫∫Á±ªÊô∫ËÉΩ‰Ωì\n"]}, {"cell_type": "markdown", "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e", "metadata": {}, "source": ["Ëøô‰∏™Á¨îËÆ∞Êú¨ÂêëÊÇ®Â±ïÁ§∫‰∫ÜÂ¶Ç‰Ωï‰ΩøÁî®Êàë‰ª¨ÁöÑAnthropic‰ª£ÁêÜÔºåËØ•‰ª£ÁêÜÁî±ÂáΩÊï∞Ë∞ÉÁî®ÂäüËÉΩÊèê‰æõÊîØÊåÅ„ÄÇ\n", "\n", "**Ê≥®ÊÑèÔºö** Âè™Êúâclaude-3Ê®°ÂûãÊîØÊåÅ‰ΩøÁî®AnthropicÁöÑAPIËøõË°åÂáΩÊï∞Ë∞ÉÁî®„ÄÇ\n"]}, {"cell_type": "markdown", "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc", "metadata": {}, "source": ["## ÂàùÂßãËÆæÁΩÆ\n"]}, {"cell_type": "markdown", "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f", "metadata": {}, "source": ["ËÆ©Êàë‰ª¨‰ªéÂØºÂÖ•‰∏Ä‰∫õÁÆÄÂçïÁöÑÊûÑÂª∫Ê®°ÂùóÂºÄÂßã„ÄÇ\n", "\n", "Êàë‰ª¨‰∏ªË¶ÅÈúÄË¶ÅÁöÑÊòØÔºö\n", "1. ‰∫∫Á±ª APIÔºà‰ΩøÁî®Êàë‰ª¨Ëá™Â∑±ÁöÑ `llama_index` LLM Á±ªÔºâ\n", "2. ‰∏Ä‰∏™Áî®‰∫é‰øùÂ≠òÂØπËØùÂéÜÂè≤ÁöÑÂú∞Êñπ\n", "3. Êàë‰ª¨ÁöÑ‰ª£ÁêÜÂèØ‰ª•‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑ÂÆö‰πâ„ÄÇ\n"]}, {"cell_type": "markdown", "id": "41101795", "metadata": {}, "source": ["Â¶ÇÊûúÊÇ®Âú®colab‰∏äÊâìÂºÄËøô‰∏™Á¨îËÆ∞Êú¨ÔºåÊÇ®ÂèØËÉΩÈúÄË¶ÅÂÆâË£ÖLlamaIndex ü¶ô„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "4985c578", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-anthropic\n", "%pip install llama-index-embeddings-openai"]}, {"cell_type": "code", "execution_count": null, "id": "c61c873d", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "9d47283b-025e-4874-88ed-76245b22f82e", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.anthropic import Anthropic\n", "from llama_index.core.tools import FunctionTool\n", "\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf", "metadata": {}, "source": ["ËÆ©Êàë‰ª¨‰∏∫Êàë‰ª¨ÁöÑ‰ª£ÁêÜÂÆö‰πâ‰∏Ä‰∫õÈùûÂ∏∏ÁÆÄÂçïÁöÑËÆ°ÁÆóÂô®Â∑•ÂÖ∑„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992", "metadata": {}, "outputs": [], "source": ["def multiply(a: int, b: int) -> int:", "    \"\"\"Â∞Ü‰∏§‰∏™Êï¥Êï∞Áõ∏‰πòÔºåÂπ∂ËøîÂõûÁªìÊûúÊï¥Êï∞\"\"\"", "    return a * b", "", "", "multiply_tool = FunctionTool.from_defaults(fn=multiply)"]}, {"cell_type": "code", "execution_count": null, "id": "bfcfb78b-7d4f-48d9-8d4c-ffcded23e7ac", "metadata": {}, "outputs": [], "source": ["def add(a: int, b: int) -> int:", "    \"\"\"ÂØπ‰∏§‰∏™Êï¥Êï∞ËøõË°åÁõ∏Âä†ÔºåÂπ∂ËøîÂõûÁªìÊûúÊï¥Êï∞\"\"\"", "    return a + b", "", "", "add_tool = FunctionTool.from_defaults(fn=add)"]}, {"cell_type": "markdown", "id": "eeac7d4c-58fd-42a5-9da9-c258375c61a0", "metadata": {}, "source": ["Á°Æ‰øù‰Ω†ÁöÑANTHROPIC_API_KEYÂ∑≤ËÆæÁΩÆ„ÄÇÂê¶ÂàôÔºåËØ∑ÊòéÁ°ÆÊåáÂÆö`api_key`ÂèÇÊï∞„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "4becf171-6632-42e5-bdec-918a00934696", "metadata": {}, "outputs": [], "source": ["llm = Anthropic(model=\"claude-3-opus-20240229\", api_key=\"sk-ant-...\")"]}, {"cell_type": "markdown", "id": "707d30b8-6405-4187-a9ed-6146dcc42167", "metadata": {}, "source": ["## ÂàùÂßãÂåñ‰∫∫Á±ªÊô∫ËÉΩ‰Ωì\n"]}, {"cell_type": "markdown", "id": "798ca3fd-6711-4c0c-a853-d868dd14b484", "metadata": {}, "source": ["Âú®ËøôÈáåÔºåÊàë‰ª¨‰ΩøÁî®ËÆ°ÁÆóÂô®ÂáΩÊï∞ÂàùÂßãÂåñ‰∫Ü‰∏Ä‰∏™ÁÆÄÂçïÁöÑMistral‰ª£ÁêÜ„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "38ab3938-1138-43ea-b085-f430b42f5377", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import FunctionCallingAgentWorker\n", "\n", "agent_worker = FunctionCallingAgentWorker.from_tools(\n", "    [multiply_tool, add_tool],\n", "    llm=llm,\n", "    verbose=True,\n", "    allow_parallel_tool_calls=False,\n", ")\n", "agent = agent_worker.as_agent()"]}, {"cell_type": "markdown", "id": "500cbee4", "metadata": {}, "source": ["ËøôÊòØ‰∏Ä‰∏™Áî®PythonÁºñÂÜôÁöÑÁÆÄÂçïËÅäÂ§©Á®ãÂ∫è„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "9450401d-769f-46e8-8bab-0f27f7362f5d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What is (121 + 2) * 5?\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\": 121, \"b\": 2}\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 123, \"b\": 5}\n", "assistant: Therefore, (121 + 2) * 5 = 615\n"]}], "source": ["response = agent.chat(\"What is (121 + 2) * 5?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "538bf32f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[ToolOutput(content='123', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 121, 'b': 2}}, raw_output=123), ToolOutput(content='615', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 123, 'b': 5}}, raw_output=615)]\n"]}], "source": ["# Ê£ÄÊü•Êï∞ÊçÆÊ∫ê", "print(response.sources)"]}, {"cell_type": "markdown", "id": "fb33983c", "metadata": {}, "source": ["### ÂºÇÊ≠•ËÅäÂ§©\n", "\n", "ÂêåÊó∂ÔºåËÆ©Êàë‰ª¨ÈáçÊñ∞ÂêØÁî®Âπ∂Ë°åÂáΩÊï∞Ë∞ÉÁî®ÔºåËøôÊ†∑Êàë‰ª¨Â∞±ÂèØ‰ª•ÂêåÊó∂Ë∞ÉÁî®‰∏§‰∏™`multiply`Êìç‰Ωú„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "1d1fc974", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What is (121 * 3) + (5 * 8)?\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 121, \"b\": 3}\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 5, \"b\": 8}\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\": 363, \"b\": 40}\n", "assistant: Therefore, the result of (121 * 3) + (5 * 8) is 403.\n"]}], "source": ["# ÂêØÁî®Âπ∂Ë°åÂáΩÊï∞Ë∞ÉÁî®", "agent_worker = FunctionCallingAgentWorker.from_tools(", "    [multiply_tool, add_tool],", "    llm=llm,", "    verbose=True,", "    allow_parallel_tool_calls=True,", ")", "agent = agent_worker.as_agent()", "response = await agent.achat(\"What is (121 * 3) + (5 * 8)?\")", "print(str(response))"]}, {"cell_type": "markdown", "id": "cabfdf01-8d63-43ff-b06e-a3059ede2ddf", "metadata": {}, "source": ["## Âü∫‰∫éRAGÁÆ°ÈÅìÁöÑAnthropic‰ª£ÁêÜ\n", "\n", "Âú®‰∏Ä‰∏™ÁÆÄÂçïÁöÑ10KÊñáÊ°£‰∏äÊûÑÂª∫‰∏Ä‰∏™Anthropic‰ª£ÁêÜ„ÄÇÊàë‰ª¨‰ΩøÁî®OpenAIÂµåÂÖ•Âíåclaude-3-haiku-20240307Êù•ÊûÑÂª∫RAGÁÆ°ÈÅìÔºåÂπ∂Â∞ÜÂÖ∂‰º†ÈÄíÁªôAnthropic Opus‰ª£ÁêÜ‰Ωú‰∏∫Â∑•ÂÖ∑„ÄÇ\n"]}, {"cell_type": "code", "execution_count": null, "id": "48120dd4-7f50-426f-bc7e-a903e090d32e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2024-04-04 18:12:42--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 1880483 (1.8M) [application/octet-stream]\n", "Saving to: ‚Äòdata/10k/uber_2021.pdf‚Äô\n", "\n", "data/10k/uber_2021. 100%[===================>]   1.79M  6.09MB/s    in 0.3s    \n", "\n", "2024-04-04 18:12:43 (6.09 MB/s) - ‚Äòdata/10k/uber_2021.pdf‚Äô saved [1880483/1880483]\n", "\n"]}], "source": ["!mkdir -p 'data/10k/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'"]}, {"cell_type": "code", "execution_count": null, "id": "48c0cf98-3f10-4599-8437-d88dc89cefad", "metadata": {}, "outputs": [], "source": ["from llama_index.core.tools import QueryEngineTool, ToolMetadata", "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex", "from llama_index.embeddings.openai import OpenAIEmbedding", "from llama_index.llms.anthropic import Anthropic", "", "embed_model = OpenAIEmbedding(api_key=\"sk-...\")", "query_llm = Anthropic(model=\"claude-3-haiku-20240307\", api_key=\"sk-ant-...\")", "", "# Âä†ËΩΩÊï∞ÊçÆ", "uber_docs = SimpleDirectoryReader(", "    input_files=[\"./data/10k/uber_2021.pdf\"]", ").load_data()", "# ÊûÑÂª∫Á¥¢Âºï", "uber_index = VectorStoreIndex.from_documents(", "    uber_docs, embed_model=embed_model", ")", "uber_engine = uber_index.as_query_engine(similarity_top_k=3, llm=query_llm)", "query_engine_tool = QueryEngineTool(", "    query_engine=uber_engine,", "    metadata=ToolMetadata(", "        name=\"uber_10k\",", "        description=(", "            \"Êèê‰æõ2021Âπ¥UberË¥¢Âä°‰ø°ÊÅØ„ÄÇ\"", "            \"‰ΩøÁî®ËØ¶ÁªÜÁöÑÁ∫ØÊñáÊú¨ÈóÆÈ¢ò‰Ωú‰∏∫Â∑•ÂÖ∑ÁöÑËæìÂÖ•„ÄÇ\"", "        ),", "    ),", ")"]}, {"cell_type": "code", "execution_count": null, "id": "ebfdaf80-e5e1-4c60-b556-20558da3d5e3", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import FunctionCallingAgentWorker\n", "\n", "agent_worker = FunctionCallingAgentWorker.from_tools(\n", "    [query_engine_tool], llm=llm, verbose=True\n", ")\n", "agent = agent_worker.as_agent()"]}, {"cell_type": "code", "execution_count": null, "id": "58c53f2a-0a3f-4abe-b8b6-97a974ec7546", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: Tell me both the risk factors and tailwinds for Uber?\n", "=== Calling Function ===\n", "Calling function: uber_10k with args: {\"input\": \"What were some of the key risk factors and tailwinds mentioned for Uber's business in 2021?\"}\n", "assistant: In summary, some of the key risk factors Uber faced in 2021 included regulatory challenges, IP protection, staying competitive with new technologies, seasonality and forecasting challenges due to COVID-19, and risks of international expansion. However, Uber also benefited from tailwinds like accelerated growth in food delivery due to the pandemic and adapting well to new remote work arrangements.\n"]}], "source": ["response = agent.chat(\"Tell me both the risk factors and tailwinds for Uber?\")\n", "print(str(response))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}