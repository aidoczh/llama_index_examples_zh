{"cells": [{"cell_type": "markdown", "id": "791115e1", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/memory/vector_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "d9cfc1b0-f28a-43ee-8242-90cfdb49fec2", "metadata": {}, "source": ["# 向量记忆\n", "\n", "向量记忆模块使用向量搜索（由向量数据库支持）来检索与用户输入相关的对话内容。\n", "\n", "本笔记本向您展示如何使用`VectorMemory`类。我们将向您展示如何使用它的各个函数。向量记忆的典型用例是作为聊天消息的长期存储。您可以\n"]}, {"cell_type": "markdown", "id": "8cc3cc2c-96e2-49ff-a029-0ce4ff314538", "metadata": {}, "source": ["![VectorMemoryIllustration](https://d3ddy8balm3goa.cloudfront.net/llamaindex/vector-memory.excalidraw.svg)\n"]}, {"cell_type": "markdown", "id": "3d29a822-727d-4a87-aa7f-e3091a311d5f", "metadata": {}, "source": ["### 初始化并尝试内存模块\n", "\n", "在这里，我们初始化一个原始的内存模块，并演示其功能 - 将ChatMessage对象放入内存并检索出来。\n", "\n", "- 请注意，`retriever_kwargs` 是您在 `VectorIndexRetriever` 或 `index.as_retriever(..)` 中指定的相同参数。\n"]}, {"cell_type": "code", "execution_count": null, "id": "54fefa31-4c6c-4ae4-9957-ea73781ecc21", "metadata": {}, "outputs": [], "source": ["", "# from llama_index.core.memory import VectorMemory", "# from llama_index.embeddings.openai import OpenAIEmbedding", "", "vector_memory = VectorMemory.from_defaults(", "    vector_store=None,  # 将其保留为None以使用默认的内存向量存储", "    embed_model=OpenAIEmbedding(),", "    retriever_kwargs={\"similarity_top_k\": 1},", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8073c255-a35e-432d-a917-12dafaf377e4", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llms import ChatMessage\n", "\n", "msgs = [\n", "    ChatMessage.from_str(\"Jerry likes juice.\", \"user\"),\n", "    ChatMessage.from_str(\"Bob likes burgers.\", \"user\"),\n", "    ChatMessage.from_str(\"Alice likes apples.\", \"user\"),\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "e44017c1-129a-4864-a070-c00ca6d6cf0e", "metadata": {}, "outputs": [], "source": ["# 加载到内存中", "对于 m 在 msgs 中:", "    vector_memory.put(m)"]}, {"cell_type": "code", "execution_count": null, "id": "aa077b6e-6477-406a-8d52-d8e375daae6c", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.USER: 'user'>, content='Jerry likes juice.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# 从内存中检索", "msgs = vector_memory.get(\"Jerry喜欢什么？\")", "msgs"]}, {"cell_type": "code", "execution_count": null, "id": "aa4baa16-55d1-418c-ac7f-a8f30252e6c7", "metadata": {}, "outputs": [], "source": ["vector_memory.reset()"]}, {"cell_type": "markdown", "id": "e5f17529-bd4a-4edb-8176-7332e48016ea", "metadata": {}, "source": ["现在让我们尝试重置并再试一次。这次，我们将添加一个助手消息。请注意，默认情况下，用户/助手消息会被捆绑在一起。\n"]}, {"cell_type": "code", "execution_count": null, "id": "f5c427d1-c157-4916-a9c2-17b3fede4f18", "metadata": {}, "outputs": [], "source": ["msgs = [\n", "    ChatMessage.from_str(\"Jerry likes burgers.\", \"user\"),\n", "    ChatMessage.from_str(\"Bob likes apples.\", \"user\"),\n", "    ChatMessage.from_str(\"Indeed, Bob likes apples.\", \"assistant\"),\n", "    ChatMessage.from_str(\"Alice likes juice.\", \"user\"),\n", "]\n", "vector_memory.set(msgs)"]}, {"cell_type": "code", "execution_count": null, "id": "fd4402fe-f140-415b-9e07-accbde8ae2c8", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.USER: 'user'>, content='Bob likes apples.', additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Indeed, Bob likes apples.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["msgs = vector_memory.get(\"What does Bob like?\")\n", "msgs"]}], "metadata": {"kernelspec": {"display_name": "llama-index-core", "language": "python", "name": "llama-index-core"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}