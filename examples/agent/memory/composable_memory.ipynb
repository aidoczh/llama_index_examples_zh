{"cells": [{"cell_type": "markdown", "id": "3902b09d", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/memory/composable_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "3869de9c-846a-4295-ab6d-1b3fcfc4aa6f", "metadata": {}, "source": ["# 简单可组合的内存\n", "\n", "这是一个简单的内存类，它可以用于创建具有不同存储和检索功能的内存对象。内存对象可以被组合在一起，以创建更复杂的存储结构。\n"]}, {"cell_type": "markdown", "id": "330ee9d2-263a-4ec6-93e6-3fb62562a286", "metadata": {}, "source": ["在这个笔记本中，我们演示了如何将多个记忆源注入到一个agent中。具体来说，我们使用了`SimpleComposableMemory`，它由一个`primary_memory`和可能有几个次要记忆源（存储在`secondary_memory_sources`中）组成。主要区别在于`primary_memory`将被用作agent的主要聊天缓冲区，而从`secondary_memory_sources`中检索到的任何消息将只被注入到系统提示消息中。\n", "\n", "多个记忆源可能在以下情况下很有用，例如在您有一个长期记忆（如`VectorMemory`），您希望将其与默认的`ChatMemoryBuffer`一起使用。在这个笔记本中，您将看到使用`SimpleComposableMemory`，您将能够有效地将来自长期记忆的所需消息“加载”到主要记忆中（即`ChatMemoryBuffer`）。\n"]}, {"cell_type": "markdown", "id": "6531f04b-9016-4046-989a-9957a49af944", "metadata": {}, "source": ["## `SimpleComposableMemory`是如何工作的？\n"]}, {"cell_type": "markdown", "id": "16e6ff6f-eeee-44fa-b85c-862f08366b74", "metadata": {}, "source": ["我们从`SimpleComposableMemory`的基本用法开始。在这里，我们构建了一个`VectorMemory`以及一个默认的`ChatMemoryBuffer`。`VectorMemory`将是我们的次要内存源，而`ChatMemoryBuffer`将是主要的内存源。要实例化一个`SimpleComposableMemory`对象，我们需要提供一个`primary_memory`，以及（可选地）一个`secondary_memory_sources`列表。\n"]}, {"cell_type": "markdown", "id": "ab4609da-ac1d-405e-98d7-8a228f4577d3", "metadata": {}, "source": ["![SimpleComposableMemoryIllustration](https://d3ddy8balm3goa.cloudfront.net/llamaindex/simple-composable-memory.excalidraw.svg)\n"]}, {"cell_type": "code", "execution_count": null, "id": "e51784f0-98a9-497a-8e35-257a62c55141", "metadata": {}, "outputs": [], "source": ["from llama_index.core.memory import (", "    VectorMemory,  # 向量内存", "    SimpleComposableMemory,  # 简单可组合内存", "    ChatMemoryBuffer,  # 聊天内存缓存", ")", "from llama_index.core.llms import ChatMessage  # 聊天消息", "from llama_index.embeddings.openai import OpenAIEmbedding  # OpenAI嵌入", "", "vector_memory = VectorMemory.from_defaults(", "    vector_store=None,  # 将其保留为None以使用默认的内存向量存储", "    embed_model=OpenAIEmbedding(),  # 嵌入模型", "    retriever_kwargs={\"similarity_top_k\": 1},  # 检索器参数", ")", "", "# 让我们在我们的次要向量内存中设置一些初始消息", "msgs = [", "    ChatMessage.from_str(\"You are a SOMEWHAT helpful assistant.\", \"system\"),  # 你是一个有点有帮助的助手", "    ChatMessage.from_str(\"Bob likes burgers.\", \"user\"),  # Bob喜欢汉堡", "    ChatMessage.from_str(\"Indeed, Bob likes apples.\", \"assistant\"),  # 的确，Bob喜欢苹果", "    ChatMessage.from_str(\"Alice likes apples.\", \"user\"),  # Alice喜欢苹果", "]", "vector_memory.set(msgs)", "", "chat_memory_buffer = ChatMemoryBuffer.from_defaults()", "", "composable_memory = SimpleComposableMemory.from_defaults(", "    primary_memory=chat_memory_buffer,  # 主要内存", "    secondary_memory_sources=[vector_memory],  # 次要内存来源", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8d9c6ee0-969a-4346-9a5d-a21de36dc383", "metadata": {}, "outputs": [{"data": {"text/plain": ["ChatMemoryBuffer(chat_store=SimpleChatStore(store={}), chat_store_key='chat_history', token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'))"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["composable_memory.primary_memory"]}, {"cell_type": "code", "execution_count": null, "id": "9cb7cbe1-0793-48c7-9643-a324b569b96a", "metadata": {}, "outputs": [{"data": {"text/plain": ["[VectorMemory(vector_index=<llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x137b912a0>, retriever_kwargs={'similarity_top_k': 1}, batch_by_user_message=True, cur_batch_textnode=TextNode(id_='288b0ef3-570e-4698-a1ae-b3531df66361', embedding=None, metadata={'sub_dicts': [{'role': <MessageRole.USER: 'user'>, 'content': 'Alice likes apples.', 'additional_kwargs': {}}]}, excluded_embed_metadata_keys=['sub_dicts'], excluded_llm_metadata_keys=['sub_dicts'], relationships={}, text='Alice likes apples.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'))]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["composable_memory.secondary_memory_sources"]}, {"cell_type": "markdown", "id": "0aa65eb4-7c00-4d25-bbc7-5e7d8d5794e2", "metadata": {}, "source": ["### 将消息放入内存中\n"]}, {"cell_type": "markdown", "id": "61c1c752-07b5-42b9-9393-3623841b860d", "metadata": {}, "source": ["由于`SimpleComposableMemory`本身是`BaseMemory`的子类，因此我们可以像对待其他内存模块一样向其中添加消息。需要注意的是，对于`SimpleComposableMemory`，调用`.put()`实际上会在所有内存源上调用`.put()`。换句话说，消息会被添加到`primary`和`secondary`源中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "6fd78f09-1bbb-4e5c-9535-a222cce9190e", "metadata": {}, "outputs": [], "source": ["msgs = [\n", "    ChatMessage.from_str(\"You are a REALLY helpful assistant.\", \"system\"),\n", "    ChatMessage.from_str(\"Jerry likes juice.\", \"user\"),\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "1b0a9b2d-64f0-4d24-a980-94157d906043", "metadata": {}, "outputs": [], "source": ["# 将所有内存源模块加载", "for m in msgs:", "    composable_memory.put(m)"]}, {"cell_type": "markdown", "id": "049e59b8-2df7-411f-9529-58c1bc77cfd8", "metadata": {}, "source": ["### 从内存中获取`get()`消息\n"]}, {"cell_type": "markdown", "id": "f987d6b7-6651-4d57-a290-7ed2deaed9da", "metadata": {}, "source": ["当调用`.get()`时，我们类似地执行`primary`内存的所有`.get()`方法以及所有`secondary`来源的方法。这给我们留下了一系列消息列表，我们必须将其“组合”成一个合理的消息集（以传递到下游代理）。一般情况下，必须特别小心，以确保最终的消息序列既合理又符合LLM提供程序的聊天API。\n", "\n", "对于`SimpleComposableMemory`，我们**将系统消息中的`secondary`来源的消息注入到`primary`内存的消息中**。`primary`来源的其余消息历史保持不变，最终返回的就是这种组合。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a74fc439-9f5b-4560-b06d-e9cb3c078cac", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are a REALLY helpful assistant.\\n\\nBelow are a set of relevant dialogues retrieved from potentially several memory sources:\\n\\n=====Relevant messages from memory source 1=====\\n\\n\\tUSER: Bob likes burgers.\\n\\tASSISTANT: Indeed, Bob likes apples.\\n\\n=====End of relevant messages from memory source 1======\\n\\nThis is the end of the retrieved message dialogues.', additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.USER: 'user'>, content='Jerry likes juice.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["msgs = composable_memory.get(\"What does Bob like?\")\n", "msgs"]}, {"cell_type": "code", "execution_count": null, "id": "9ae49db4-15ef-4532-b84d-ee9a6fed1337", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["system: You are a REALLY helpful assistant.\n", "\n", "Below are a set of relevant dialogues retrieved from potentially several memory sources:\n", "\n", "=====Relevant messages from memory source 1=====\n", "\n", "\tUSER: Bob likes burgers.\n", "\tASSISTANT: Indeed, Bob likes apples.\n", "\n", "=====End of relevant messages from memory source 1======\n", "\n", "This is the end of the retrieved message dialogues.\n"]}], "source": ["# 查看注入到主内存系统消息中的内存", "print(msgs[0])"]}, {"cell_type": "markdown", "id": "3cb966da-b5cb-4744-b189-ef139e0972cf", "metadata": {}, "source": ["### 连续调用 `get()`\n"]}, {"cell_type": "markdown", "id": "15531d59-acf8-4a5a-b6ad-57a787f4e804", "metadata": {}, "source": ["连续调用`get()`将简单地替换系统提示中加载的`secondary`内存消息。\n"]}, {"cell_type": "code", "execution_count": null, "id": "ca764fb4-5597-4e4c-9ab4-8ec1a3bafb4f", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are a REALLY helpful assistant.\\n\\nBelow are a set of relevant dialogues retrieved from potentially several memory sources:\\n\\n=====Relevant messages from memory source 1=====\\n\\n\\tUSER: Alice likes apples.\\n\\n=====End of relevant messages from memory source 1======\\n\\nThis is the end of the retrieved message dialogues.', additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.USER: 'user'>, content='Jerry likes juice.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["msgs = composable_memory.get(\"What does Alice like?\")\n", "msgs"]}, {"cell_type": "code", "execution_count": null, "id": "ef7ff24f-7dc1-4027-b078-13e818fe05be", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["system: You are a REALLY helpful assistant.\n", "\n", "Below are a set of relevant dialogues retrieved from potentially several memory sources:\n", "\n", "=====Relevant messages from memory source 1=====\n", "\n", "\tUSER: Alice likes apples.\n", "\n", "=====End of relevant messages from memory source 1======\n", "\n", "This is the end of the retrieved message dialogues.\n"]}], "source": ["# 查看注入到主内存系统消息中的内存", "print(msgs[0])"]}, {"cell_type": "markdown", "id": "cfce6b59-21ba-4e6f-b9bf-1a19dbacfe21", "metadata": {}, "source": ["### 如果`get()`方法检索到已经存在于`primary`内存中的`secondary`消息会怎么样？\n"]}, {"cell_type": "markdown", "id": "9b2839b2-40da-4714-92ee-eb6c795d92bb", "metadata": {}, "source": ["如果从`secondary`内存中检索到的消息已经存在于`primary`内存中，那么这些多余的`secondary`消息将不会被添加到系统消息中。在下面的例子中，消息\"Jerry likes juice.\"被`put`到了所有内存源中，因此系统消息没有发生改变。\n"]}, {"cell_type": "code", "execution_count": null, "id": "c96604e4-3b4e-490f-a196-f046d28c13f8", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are a REALLY helpful assistant.', additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.USER: 'user'>, content='Jerry likes juice.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["msgs = composable_memory.get(\"What does Jerry like?\")\n", "msgs"]}, {"cell_type": "markdown", "id": "81b3a61e-9704-4547-825c-e73f09116684", "metadata": {}, "source": ["### 如何“重置”内存\n"]}, {"cell_type": "markdown", "id": "0948e792-b5c0-4f53-a2ca-b71210e9e445", "metadata": {}, "source": ["与其他方法`put()`和`get()`类似，调用`reset()`将在`primary`和`secondary`内存源上执行`reset()`。如果您只想重置`primary`，那么应该只从它调用`reset()`方法。\n"]}, {"cell_type": "markdown", "id": "2b008b6a-160e-41a8-b1fb-32edc5fd3cc3", "metadata": {}, "source": ["#### `reset()` 仅重置主存储器\n"]}, {"cell_type": "code", "execution_count": null, "id": "f77e557e-c6b2-4c80-80e4-b30398aa0f9a", "metadata": {}, "outputs": [], "source": ["composable_memory.primary_memory.reset()"]}, {"cell_type": "code", "execution_count": null, "id": "46cf6aa5-65cf-488d-841c-bcda29db0613", "metadata": {}, "outputs": [{"data": {"text/plain": ["[]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["composable_memory.primary_memory.get()"]}, {"cell_type": "code", "execution_count": null, "id": "527fbdba-d0d4-47a2-b05c-bcd05c7b3764", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.USER: 'user'>, content='Alice likes apples.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["composable_memory.secondary_memory_sources[0].get(\"What does Alice like?\")"]}, {"cell_type": "markdown", "id": "d1b2eba6-2c74-419d-9d8e-f0e4a5f3250b", "metadata": {}, "source": ["#### `reset()` 重置所有内存资源\n"]}, {"cell_type": "code", "execution_count": null, "id": "ba3e0989-8873-437d-9f5a-508a757745bb", "metadata": {}, "outputs": [], "source": ["composable_memory.reset()"]}, {"cell_type": "code", "execution_count": null, "id": "907779e6-1e6c-4494-b60c-85e1a3b18c4f", "metadata": {}, "outputs": [{"data": {"text/plain": ["[]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["composable_memory.primary_memory.get()"]}, {"cell_type": "code", "execution_count": null, "id": "e5546827-39d1-41b9-96e3-fc67c34722ca", "metadata": {}, "outputs": [{"data": {"text/plain": ["[]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["composable_memory.secondary_memory_sources[0].get(\"What does Alice like?\")"]}, {"cell_type": "markdown", "id": "5a79882a-ccc1-4336-87e0-fbcd789cf991", "metadata": {}, "source": ["## 使用`SimpleComposableMemory`与代理程序\n"]}, {"cell_type": "markdown", "id": "2898764d-245c-4ceb-a748-fef14212d24d", "metadata": {}, "source": ["在这里，我们将使用一个带有代理的`SimpleComposableMemory`，并演示如何使用来自一个代理对话的消息作为另一个代理会话中的一部分的次要、长期记忆来源。\n"]}, {"cell_type": "code", "execution_count": null, "id": "22d37976-bdb0-45c8-94b8-94df62a0853f", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.openai import OpenAI\n", "from llama_index.core.tools import FunctionTool\n", "from llama_index.core.agent import FunctionCallingAgentWorker\n", "\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "id": "41a04de0-b0f6-4f83-b09c-7a83f94a4112", "metadata": {}, "source": ["### 定义我们的内存模块\n"]}, {"cell_type": "code", "execution_count": null, "id": "15ca5351-91b8-4c7d-a4e7-f2d068a87688", "metadata": {}, "outputs": [], "source": ["vector_memory = VectorMemory.from_defaults(", "    vector_store=None,  # 将其保留为None以使用默认的内存向量存储", "    embed_model=OpenAIEmbedding(),  # 嵌入模型", "    retriever_kwargs={\"similarity_top_k\": 2},  # 检索器参数", ")", "", "chat_memory_buffer = ChatMemoryBuffer.from_defaults()  # 从默认值创建聊天记忆缓冲区", "", "composable_memory = SimpleComposableMemory.from_defaults(", "    primary_memory=chat_memory_buffer,  # 主要记忆", "    secondary_memory_sources=[vector_memory],  # 次要记忆来源", ")"]}, {"cell_type": "markdown", "id": "67958c2b-267e-4c77-a4ee-20b7d5ef3d93", "metadata": {}, "source": ["### 定义我们的Agent\n"]}, {"cell_type": "code", "execution_count": null, "id": "812f7258-1bd4-4a75-a3cd-85e913919e39", "metadata": {}, "outputs": [], "source": ["def multiply(a: int, b: int) -> int:", "    \"\"\"将两个整数相乘并返回结果整数\"\"\"", "    return a * b", "", "", "def mystery(a: int, b: int) -> int:", "    \"\"\"对两个数字进行神秘操作\"\"\"", "    return a**2 - b**2", "", "", "multiply_tool = FunctionTool.from_defaults(fn=multiply)", "mystery_tool = FunctionTool.from_defaults(fn=mystery)"]}, {"cell_type": "code", "execution_count": null, "id": "b50f611c-9c0f-4be0-952a-7580ce14b6c3", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n", "agent_worker = FunctionCallingAgentWorker.from_tools(\n", "    [multiply_tool, mystery_tool], llm=llm, verbose=True\n", ")\n", "agent = agent_worker.as_agent(memory=composable_memory)"]}, {"cell_type": "markdown", "id": "91d7bd71-76a9-4034-8126-22329168860a", "metadata": {}, "source": ["### 执行一些函数调用\n"]}, {"cell_type": "markdown", "id": "8ad0a320-9f41-4249-bfa4-2366f87c49f4", "metadata": {}, "source": ["当调用`.chat()`时，消息被放入可组合的内存中，我们从前面的部分了解到，这意味着所有消息都被放入`primary`和`secondary`两个源中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "bbc6fc63-7330-4e2e-b8a4-25e87c2325b8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What is the mystery function on 5 and 6?\n", "=== Calling Function ===\n", "Calling function: mystery with args: {\"a\": 5, \"b\": 6}\n", "=== Function Output ===\n", "-11\n", "=== LLM Response ===\n", "The mystery function on 5 and 6 returns -11.\n"]}], "source": ["response = agent.chat(\"What is the mystery function on 5 and 6?\")"]}, {"cell_type": "code", "execution_count": null, "id": "8f79abef-dd0f-4a0a-b9ca-cd5d0d2e7d02", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What happens if you multiply 2 and 3?\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 2, \"b\": 3}\n", "=== Function Output ===\n", "6\n", "=== LLM Response ===\n", "If you multiply 2 and 3, the result is 6.\n"]}], "source": ["response = agent.chat(\"What happens if you multiply 2 and 3?\")"]}, {"cell_type": "markdown", "id": "596e684f-d5d0-44b4-8b0f-1e107c43ca28", "metadata": {}, "source": ["### 新代理会话\n"]}, {"cell_type": "markdown", "id": "e7a2a4f7-322e-46d4-92ca-ce140951faf0", "metadata": {}, "source": ["现在我们已经将消息添加到我们的`vector_memory`中，我们可以看到将这个内存与新的agent会话一起使用时的效果。具体来说，我们要求新的agents“回忆”函数调用的输出，而不是重新计算。\n"]}, {"cell_type": "markdown", "id": "c8c1312e-91eb-4167-9a07-8042c4a6846f", "metadata": {}, "source": ["#### 一个没有过去记忆的代理\n", "\n", "在深度强化学习中，有时我们会遇到一种情况，即代理在执行任务时没有过去的记忆。这意味着代理只能根据当前的状态和奖励来做决策，而无法依靠之前的经验或记忆。这种情况可能会对代理的学习和决策产生影响，因此需要特殊的算法和技术来处理。\n"]}, {"cell_type": "code", "execution_count": null, "id": "728c1124-f9a2-4b8c-ab94-c65e63f9314d", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n", "agent_worker = FunctionCallingAgentWorker.from_tools(\n", "    [multiply_tool, mystery_tool], llm=llm, verbose=True\n", ")\n", "agent_without_memory = agent_worker.as_agent()"]}, {"cell_type": "code", "execution_count": null, "id": "b67a73b5-13e5-4927-a1a4-18fbaa843e6c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What was the output of the mystery function on 5 and 6 again? Don't recompute.\n", "=== LLM Response ===\n", "I'm sorry, but I don't have access to the previous output of the mystery function on 5 and 6.\n"]}], "source": ["response = agent_without_memory.chat(\n", "    \"What was the output of the mystery function on 5 and 6 again? Don't recompute.\"\n", ")"]}, {"cell_type": "markdown", "id": "ef3ca898-e799-45a2-87f9-9747ba673692", "metadata": {}, "source": ["#### 一个带有我们过去记忆的代理\n", "\n", "在这个示例中，我们将创建一个带有记忆的代理，使其能够记住先前的状态并在需要时使用这些信息。\n"]}, {"cell_type": "markdown", "id": "5a806952-abff-497a-b829-baed461efc4b", "metadata": {}, "source": ["我们发现，没有访问我们过去记忆的代理无法完成任务。对于接下来的代理，我们将确实传入我们先前的长期记忆（即`vector_memory`）。请注意，我们甚至使用了一个全新的`ChatMemoryBuffer`，这意味着这个代理没有`chat_history`。尽管如此，它仍然能够从我们的长期记忆中检索以获取所需的过去对话。\n"]}, {"cell_type": "code", "execution_count": null, "id": "9fe7f702-79b1-4203-8394-8afe1a0d0f08", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-0613\")", "agent_worker = FunctionCallingAgentWorker.from_tools(", "    [multiply_tool, mystery_tool], llm=llm, verbose=True", ")", "composable_memory = SimpleComposableMemory.from_defaults(", "    primary_memory=ChatMemoryBuffer.from_defaults(),", "    secondary_memory_sources=[", "        vector_memory.copy(", "            deep=True", "        )  # using a copy here for illustration purposes", "        # later will use original vector_memory again", "    ],", ")", "agent_with_memory = agent_worker.as_agent(memory=composable_memory)"]}, {"cell_type": "code", "execution_count": null, "id": "cc205eb5-b5c7-4f60-9e39-92a91149dcf8", "metadata": {}, "outputs": [{"data": {"text/plain": ["[]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["agent_with_memory.chat_history  # 一个空的聊天记录"]}, {"cell_type": "code", "execution_count": null, "id": "538cd6ec-b9dd-4622-9690-665b7eb578a2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What was the output of the mystery function on 5 and 6 again? Don't recompute.\n", "=== LLM Response ===\n", "The output of the mystery function on 5 and 6 is -11.\n"]}], "source": ["response = agent_with_memory.chat(\n", "    \"What was the output of the mystery function on 5 and 6 again? Don't recompute.\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "ec4ec6a0-8a78-46eb-b727-26eb4817cdd0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What was the output of the multiply function on 2 and 3 again? Don't recompute.\n", "=== LLM Response ===\n", "The output of the multiply function on 2 and 3 is 6.\n"]}], "source": ["response = agent_with_memory.chat(\n", "    \"What was the output of the multiply function on 2 and 3 again? Don't recompute.\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "5187ead5-8388-4305-9918-0b61d9874ee2", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.USER: 'user'>, content=\"What was the output of the mystery function on 5 and 6 again? Don't recompute.\", additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The output of the mystery function on 5 and 6 is -11.', additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.USER: 'user'>, content=\"What was the output of the multiply function on 2 and 3 again? Don't recompute.\", additional_kwargs={}),\n", " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='The output of the multiply function on 2 and 3 is 6.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["agent_with_memory.chat_history"]}, {"cell_type": "markdown", "id": "82c4fb96-6bae-48a7-a43b-4a99a1989e90", "metadata": {}, "source": ["### `.chat(user_input)` 在幕后发生了什么\n", "\n", "当调用`.chat(user_input)`时，Rasa会执行以下步骤：\n", "\n", "1. Rasa将用户输入传递给当前活动的对话模型。\n", "2. 对话模型将用户输入转换为对应的意图（intent）和实体（entities）。\n", "3. Rasa使用对话策略（policy）来预测下一个动作，例如回复用户的消息或者请求更多信息。\n", "4. Rasa执行预测的动作，并将响应返回给用户。\n", "\n", "这些步骤使Rasa能够理解用户输入并做出相应的响应。\n"]}, {"cell_type": "markdown", "id": "e20ed139-c7a9-44ac-a455-d2f1c96122eb", "metadata": {}, "source": ["在内部，`.chat(user_input)`调用实际上会调用内存的`.get()`方法，并将`user_input`作为参数传递。正如我们在前面的部分学到的那样，这最终将返回`primary`和所有`secondary`内存源的组合。这些组合的消息将作为聊天历史传递给LLM的聊天API。\n"]}, {"cell_type": "code", "execution_count": null, "id": "96f42289-e7cb-463a-b10b-44696bf3dc9b", "metadata": {}, "outputs": [], "source": ["composable_memory = SimpleComposableMemory.from_defaults(", "    primary_memory=ChatMemoryBuffer.from_defaults(),", "    secondary_memory_sources=[", "        vector_memory.copy(", "            deep=True", "        )  # 为了说明在前一小节中发生了什么，进行了复制", "    ],", ")", "agent_with_memory = agent_worker.as_agent(memory=composable_memory)"]}, {"cell_type": "code", "execution_count": null, "id": "b3040fea-ba11-4703-a47b-395c3fd68d2e", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='You are a helpful assistant.\\n\\nBelow are a set of relevant dialogues retrieved from potentially several memory sources:\\n\\n=====Relevant messages from memory source 1=====\\n\\n\\tUSER: What is the mystery function on 5 and 6?\\n\\tASSISTANT: None\\n\\tTOOL: -11\\n\\tASSISTANT: The mystery function on 5 and 6 returns -11.\\n\\n=====End of relevant messages from memory source 1======\\n\\nThis is the end of the retrieved message dialogues.', additional_kwargs={})]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["agent_with_memory.memory.get(\n", "    \"What was the output of the mystery function on 5 and 6 again? Don't recompute.\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "06f363dc-957f-43d2-83ea-6e03b89f348c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["system: You are a helpful assistant.\n", "\n", "Below are a set of relevant dialogues retrieved from potentially several memory sources:\n", "\n", "=====Relevant messages from memory source 1=====\n", "\n", "\tUSER: What is the mystery function on 5 and 6?\n", "\tASSISTANT: None\n", "\tTOOL: -11\n", "\tASSISTANT: The mystery function on 5 and 6 returns -11.\n", "\n", "=====End of relevant messages from memory source 1======\n", "\n", "This is the end of the retrieved message dialogues.\n"]}], "source": ["print(\n", "    agent_with_memory.memory.get(\n", "        \"What was the output of the mystery function on 5 and 6 again? Don't recompute.\"\n", "    )[0]\n", ")"]}], "metadata": {"kernelspec": {"display_name": "llama-index-core", "language": "python", "name": "llama-index-core"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}