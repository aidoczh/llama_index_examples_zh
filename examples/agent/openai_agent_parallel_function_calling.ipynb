{"cells": [{"cell_type": "markdown", "id": "81206313-0516-4c5c-a294-f1a4825fabe1", "metadata": {}, "source": ["# 单轮多功能调用的OpenAI代理\n", "\n", "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/openai_agent_parallel_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在Colab中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "d2ce8589-7b10-40be-807b-b39e66317649", "metadata": {}, "source": ["使用最新的OpenAI API（版本1.1.0+），用户现在可以在“用户”和“代理”对话的单个轮次中执行多个函数调用。我们已经更新了我们的库以启用这个新功能，并在本笔记本中将向您展示它是如何工作的！\n", "\n", "注意：OpenAI将此称为“并行”函数调用，但当前的实现并不会调用多个函数调用的并行计算。因此，在我们当前的实现中，这是“可并行化”的函数调用。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d094a0d1", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-agent-openai\n", "%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "d53b839f-da37-401a-9815-53d791dce805", "metadata": {}, "outputs": [], "source": ["from llama_index.agent.openai import OpenAIAgent\n", "from llama_index.llms.openai import OpenAI\n", "from llama_index.core.tools import BaseTool, FunctionTool"]}, {"cell_type": "markdown", "id": "57e7ad14-a1a9-4e7a-91ca-85351398084a", "metadata": {}, "source": ["### 设置\n", "\n", "如果您之前看过我们关于OpenAI Agents的任何笔记本，那么您已经熟悉我们在这里需要遵循的配方。但如果没有，或者如果您想要复习一下，那么我们需要做的（在高层次上）是以下步骤：\n", "\n", "1. 定义一组工具（我们将使用`FunctionTool`），因为Agents与工具一起工作\n", "2. 为Agent定义`LLM`\n", "3. 定义一个`OpenAIAgent`\n"]}, {"cell_type": "code", "execution_count": null, "id": "a905b412-8d9b-4187-8fba-6a9a64374ca8", "metadata": {}, "outputs": [], "source": ["def multiply(a: int, b: int) -> int:", "    \"\"\"将两个整数相乘，并返回结果整数\"\"\"", "    return a * b", "", "", "multiply_tool = FunctionTool.from_defaults(fn=multiply)"]}, {"cell_type": "code", "execution_count": null, "id": "6cc05ce0-e520-427a-9fcc-6eb3aefd300f", "metadata": {}, "outputs": [], "source": ["def add(a: int, b: int) -> int:", "    \"\"\"对两个整数进行相加，并返回结果整数\"\"\"", "    return a + b", "", "", "add_tool = FunctionTool.from_defaults(fn=add)"]}, {"cell_type": "code", "execution_count": null, "id": "560776f1-d48b-4b1b-b98a-16f3e3c1d15c", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-1106\")\n", "agent = OpenAIAgent.from_tools(\n", "    [multiply_tool, add_tool], llm=llm, verbose=True\n", ")"]}, {"cell_type": "markdown", "id": "6c1757ca-92f9-4a95-aa78-6f6910de75d7", "metadata": {}, "source": ["### 同步模式\n"]}, {"cell_type": "code", "execution_count": null, "id": "f3aaf5cc-1482-4377-a88d-e10fbf521c75", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["STARTING TURN 1\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 121, \"b\": 3}\n", "Got output: 363\n", "========================\n", "\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\": 363, \"b\": 42}\n", "Got output: 405\n", "========================\n", "\n", "STARTING TURN 2\n", "---------------\n", "\n", "The result of (121 * 3) + 42 is 405.\n"]}], "source": ["response = agent.chat(\"What is (121 * 3) + 42?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "b8b1fcee-9f4c-4d2b-82b6-aa41388de062", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["STARTING TURN 1\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\":363,\"b\":42}\n", "Got output: 405\n", "========================\n", "\n", "STARTING TURN 2\n", "---------------\n", "\n"]}], "source": ["response = agent.stream_chat(\"What is (121 * 3) + 42?\")"]}, {"cell_type": "markdown", "id": "0471ad80-0f9c-4be0-87a7-65eff1293d30", "metadata": {}, "source": ["### 异步模式\n"]}, {"cell_type": "code", "execution_count": null, "id": "0ee3ead7-4507-4886-81b5-4924bb422690", "metadata": {}, "outputs": [], "source": ["import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "01344bdb-c06b-4f56-ab75-6b06eb7e7af8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["STARTING TURN 1\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\":363,\"b\":42}\n", "Got output: 405\n", "========================\n", "\n", "STARTING TURN 2\n", "---------------\n", "\n", "The result of (121 * 3) + 42 is 405.\n"]}], "source": ["response = await agent.achat(\"What is (121 * 3) + 42?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "dfe479ae-21fc-4e7b-95af-204985730d25", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["STARTING TURN 1\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 121, \"b\": 3}\n", "Got output: 363\n", "========================\n", "\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\": 363, \"b\": 42}\n", "Got output: 405\n", "========================\n", "\n", "STARTING TURN 2\n", "---------------\n", "\n", "The result of (121 * 3) + 42 is 405."]}], "source": ["response = await agent.astream_chat(\"What is (121 * 3) + 42?\")\n", "\n", "response_gen = response.response_gen\n", "\n", "async for token in response.async_response_gen():\n", "    print(token, end=\"\")"]}, {"cell_type": "markdown", "id": "2172bcb4-08b6-4cfc-b208-e38ce3a588bf", "metadata": {}, "source": ["### OpenAI文档中的示例\n", "\n", "这里是直接从OpenAI的[文档](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)中关于并行函数调用的示例。（他们的示例需要76行代码，而使用`llama_index`库可以将其减少到大约18行。）\n"]}, {"cell_type": "code", "execution_count": null, "id": "7ab6853d-8638-4a62-9dec-4f32fa22e434", "metadata": {}, "outputs": [], "source": ["import json", "", "", "# 示例虚拟函数，硬编码为返回相同的天气", "# 在生产中，这可以是您的后端API或外部API", "def get_current_weather(location, unit=\"fahrenheit\"):", "    \"\"\"获取给定位置的当前天气\"\"\"", "    if \"tokyo\" in location.lower():", "        return json.dumps(", "            {\"location\": location, \"temperature\": \"10\", \"unit\": \"celsius\"}", "        )", "    elif \"san francisco\" in location.lower():", "        return json.dumps(", "            {\"location\": location, \"temperature\": \"72\", \"unit\": \"fahrenheit\"}", "        )", "    else:", "        return json.dumps(", "            {\"location\": location, \"temperature\": \"22\", \"unit\": \"celsius\"}", "        )", "", "", "weather_tool = FunctionTool.from_defaults(fn=get_current_weather)"]}, {"cell_type": "code", "execution_count": null, "id": "a529de65-6360-444c-8f43-d9ebbb71b184", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["STARTING TURN 1\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: get_current_weather with args: {\"location\": \"San Francisco\", \"unit\": \"fahrenheit\"}\n", "Got output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\n", "========================\n", "\n", "=== Calling Function ===\n", "Calling function: get_current_weather with args: {\"location\": \"Tokyo\", \"unit\": \"fahrenheit\"}\n", "Got output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\n", "========================\n", "\n", "=== Calling Function ===\n", "Calling function: get_current_weather with args: {\"location\": \"Paris\", \"unit\": \"fahrenheit\"}\n", "Got output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\n", "========================\n", "\n", "STARTING TURN 2\n", "---------------\n", "\n"]}], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-1106\")\n", "agent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\n", "response = agent.chat(\n", "    \"What's the weather like in San Francisco, Tokyo, and Paris?\"\n", ")"]}, {"cell_type": "markdown", "id": "549701a6-ed24-4aa1-b339-5ac7acc2b8a4", "metadata": {}, "source": ["上述所有的函数调用都是在“助手”和“用户”之间的单个对话回合中完成的。有趣的是，GPT-3.5的旧版本并不像它的后继者那样先进 — 它会在3个单独的回合中完成上述任务。为了演示，以下是它的执行过程。\n"]}, {"cell_type": "code", "execution_count": null, "id": "3de05a75-93fd-42c9-b197-f31821aec121", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["STARTING TURN 1\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: get_current_weather with args: {\n", "  \"location\": \"San Francisco\"\n", "}\n", "Got output: {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}\n", "========================\n", "\n", "STARTING TURN 2\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: get_current_weather with args: {\n", "  \"location\": \"Tokyo\"\n", "}\n", "Got output: {\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\n", "========================\n", "\n", "STARTING TURN 3\n", "---------------\n", "\n", "=== Calling Function ===\n", "Calling function: get_current_weather with args: {\n", "  \"location\": \"Paris\"\n", "}\n", "Got output: {\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}\n", "========================\n", "\n", "STARTING TURN 4\n", "---------------\n", "\n"]}], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n", "agent = OpenAIAgent.from_tools([weather_tool], llm=llm, verbose=True)\n", "response = agent.chat(\n", "    \"What's the weather like in San Francisco, Tokyo, and Paris?\"\n", ")"]}, {"cell_type": "markdown", "id": "0e2b59b5-a21b-4197-a241-83e87415a25a", "metadata": {}, "source": ["## 结论\n", "\n", "因此，正如你所看到的，`llama_index` 库可以在用户和OpenAI代理之间的单个对话回合中处理多个函数调用（以及单个函数调用）！\n"]}], "metadata": {"kernelspec": {"display_name": "llama_index_3.10", "language": "python", "name": "llama_index_3.10"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}