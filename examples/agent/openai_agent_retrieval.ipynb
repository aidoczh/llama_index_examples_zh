{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "88216e84", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/openai_agent_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "99cea58c-48bc-4af6-8358-df9695659983", "metadata": {}, "source": ["# æ£€ç´¢å¢å¼ºå‹ OpenAI ä»£ç†\n", "\n", "è¿™æ˜¯ä¸€ä¸ªç”¨äºæ¼”ç¤º OpenAI GPT-3 æ¨¡å‹çš„ç¤ºä¾‹ï¼Œè¯¥æ¨¡å‹å·²ç»é€šè¿‡æ£€ç´¢å¢å¼ºæŠ€æœ¯è¿›è¡Œäº†å¢å¼ºã€‚åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ£€ç´¢å¢å¼ºæŠ€æœ¯æ¥æ”¹è¿›å¯¹è¯ç³»ç»Ÿçš„æ€§èƒ½ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e", "metadata": {}, "source": ["åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„`OpenAIAgent`å®ç°ä¸å·¥å…·æ£€ç´¢å™¨ï¼Œä»¥æ„å»ºä¸€ä¸ªåŸºäºOpenAIçš„å‡½æ•°APIçš„ä»£ç†ï¼Œå¹¶å­˜å‚¨/ç´¢å¼•ä»»æ„æ•°é‡çš„å·¥å…·ã€‚æˆ‘ä»¬çš„ç´¢å¼•/æ£€ç´¢æ¨¡å—æœ‰åŠ©äºæ¶ˆé™¤ç”±äºå‡½æ•°è¿‡å¤šè€Œæ— æ³•é€‚åº”æç¤ºçš„å¤æ‚æ€§ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc", "metadata": {}, "source": ["## åˆå§‹è®¾ç½®\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f", "metadata": {}, "source": ["è®©æˆ‘ä»¬ä»å¯¼å…¥ä¸€äº›ç®€å•çš„åŸºæœ¬æ¨¡å—å¼€å§‹ã€‚\n", "\n", "æˆ‘ä»¬ä¸»è¦éœ€è¦çš„æ˜¯ï¼š\n", "1. OpenAI API\n", "2. ä¸€ä¸ªç”¨äºä¿å­˜å¯¹è¯å†å²è®°å½•çš„åœ°æ–¹\n", "3. ä»£ç†ç¨‹åºå¯ä»¥ä½¿ç”¨çš„å·¥å…·å®šä¹‰ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "4ce34f4d", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨Colabä¸Šæ‰“å¼€æ­¤ç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "51441848", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-agent-openai-legacy"]}, {"cell_type": "code", "execution_count": null, "id": "346fb488", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "9d47283b-025e-4874-88ed-76245b22f82e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.7) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n", "  warnings.warn(\n"]}], "source": ["import json\n", "from typing import Sequence\n", "\n", "from llama_index.core.tools import BaseTool, FunctionTool"]}, {"attachments": {}, "cell_type": "markdown", "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf", "metadata": {}, "source": ["è®©æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„ä»£ç†äººå®šä¹‰ä¸€äº›éå¸¸ç®€å•çš„è®¡ç®—å™¨å·¥å…·ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992", "metadata": {}, "outputs": [], "source": ["def multiply(a: int, b: int) -> int:", "    \"\"\"å°†ä¸¤ä¸ªæ•´æ•°ç›¸ä¹˜ï¼Œå¹¶è¿”å›ç»“æœæ•´æ•°\"\"\"", "    return a * b", "", "", "def add(a: int, b: int) -> int:", "    \"\"\"å°†ä¸¤ä¸ªæ•´æ•°ç›¸åŠ ï¼Œå¹¶è¿”å›ç»“æœæ•´æ•°\"\"\"", "    return a + b", "", "", "def useless(a: int, b: int) -> int:", "    \"\"\"æ— ç”¨çš„ç©å…·å‡½æ•°ã€‚\"\"\"", "    pass", "", "", "multiply_tool = FunctionTool.from_defaults(fn=multiply, name=\"multiply\")", "useless_tools = [", "    FunctionTool.from_defaults(fn=useless, name=f\"useless_{str(idx)}\")", "    for idx in range(28)", "]", "add_tool = FunctionTool.from_defaults(fn=add, name=\"add\")", "", "all_tools = [multiply_tool] + [add_tool] + useless_tools", "all_tools_map = {t.metadata.name: t for t in all_tools}"]}, {"attachments": {}, "cell_type": "markdown", "id": "8170dd32-fa00-458c-aeb5-37292d0773c0", "metadata": {}, "source": ["## æ„å»ºå¯¹è±¡ç´¢å¼•\n", "\n", "åœ¨LlamaIndexä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸º`ObjectIndex`çš„æ„é€ ï¼Œå…è®¸ç”¨æˆ·åœ¨ä»»æ„å¯¹è±¡ä¸Šä½¿ç”¨æˆ‘ä»¬çš„ç´¢å¼•æ•°æ®ç»“æ„ã€‚\n", "ObjectIndexå°†å¤„ç†å¯¹è±¡çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–ï¼Œå¹¶ä½¿ç”¨åº•å±‚ç´¢å¼•ï¼ˆä¾‹å¦‚VectorStoreIndexã€SummaryIndexã€KeywordTableIndexï¼‰ä½œä¸ºå­˜å‚¨æœºåˆ¶ã€‚\n", "\n", "åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå¤§å‹çš„Toolå¯¹è±¡é›†åˆï¼Œå¹¶ä¸”å¸Œæœ›åœ¨è¿™äº›Toolä¸Šå®šä¹‰ä¸€ä¸ªObjectIndexã€‚\n", "\n", "è¯¥ç´¢å¼•æ†ç»‘äº†ä¸€ä¸ªæ£€ç´¢æœºåˆ¶ï¼Œå³`ObjectRetriever`ã€‚\n", "\n", "è¿™å¯ä»¥ä¼ é€’ç»™æˆ‘ä»¬çš„ä»£ç†ï¼Œä»¥ä¾¿åœ¨æŸ¥è¯¢æ—¶æ‰§è¡ŒToolæ£€ç´¢ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "6704a755-7f05-43a3-8a56-f5f587ae4c40", "metadata": {}, "outputs": [], "source": ["# åœ¨è¿™äº›å·¥å…·ä¸Šå®šä¹‰ä¸€ä¸ªâ€œå¯¹è±¡â€ç´¢å¼•", "from llama_index.core import VectorStoreIndex", "from llama_index.core.objects import ObjectIndex", "", "obj_index = ObjectIndex.from_objects(", "    all_tools,", "    index_cls=VectorStoreIndex,", ")"]}, {"attachments": {}, "cell_type": "markdown", "id": "707d30b8-6405-4187-a9ed-6146dcc42167", "metadata": {}, "source": ["## ä½¿ç”¨å·¥å…·æ£€ç´¢çš„OpenAIAgent\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "798ca3fd-6711-4c0c-a853-d868dd14b484", "metadata": {}, "source": ["æˆ‘ä»¬åœ¨LlamaIndexä¸­æä¾›äº†ä¸€ä¸ª`OpenAIAgent`å®ç°ï¼Œå®ƒå¯ä»¥æ¥å—ä¸€ç»„`BaseTool`å¯¹è±¡ä¸Šçš„`ObjectRetriever`ã€‚\n", "\n", "åœ¨æŸ¥è¯¢æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆä¼šä½¿ç”¨`ObjectRetriever`æ¥æ£€ç´¢ä¸€ç»„ç›¸å…³çš„å·¥å…·ã€‚ç„¶åè¿™äº›å·¥å…·å°†è¢«ä¼ é€’ç»™agentï¼›æ›´å…·ä½“åœ°è¯´ï¼Œå®ƒä»¬çš„å‡½æ•°ç­¾åå°†è¢«ä¼ é€’ç»™OpenAIå‡½æ•°è°ƒç”¨APIã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "38ab3938-1138-43ea-b085-f430b42f5377", "metadata": {}, "outputs": [], "source": ["from llama_index.agent.openai import OpenAIAgent"]}, {"cell_type": "code", "execution_count": null, "id": "d852ece7-e5a1-4368-9d59-c7014e0b5b4d", "metadata": {}, "outputs": [], "source": ["agent = OpenAIAgent.from_tools(\n", "    tool_retriever=obj_index.as_retriever(similarity_top_k=2), verbose=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "33ea069f-819b-4ec1-a93c-fcbaacb362a1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["=== Calling Function ===\n", "Calling function: multiply with args: {\n", "  \"a\": 212,\n", "  \"b\": 122\n", "}\n", "Got output: 25864\n", "========================\n"]}, {"data": {"text/plain": ["Response(response='212 multiplied by 122 is 25,864.', source_nodes=[], metadata=None)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["agent.chat(\"What's 212 multiplied by 122? Make sure to use Tools\")"]}, {"cell_type": "code", "execution_count": null, "id": "ec423b90-59cd-40ef-b497-a3842b3e7b58", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["=== Calling Function ===\n", "Calling function: add with args: {\n", "  \"a\": 212,\n", "  \"b\": 122\n", "}\n", "Got output: 334\n", "========================\n"]}, {"data": {"text/plain": ["Response(response='212 added to 122 is 334.', source_nodes=[], metadata=None)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["agent.chat(\"What's 212 added to 122 ? Make sure to use Tools\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}