{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "24103c51", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/agent/openai_agent_tool_call_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "99cea58c-48bc-4af6-8358-df9695659983", "metadata": {}, "source": ["# ä½¿ç”¨å·¥å…·è°ƒç”¨è§£æå™¨çš„OpenAIä»£ç†\n"]}, {"cell_type": "markdown", "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e", "metadata": {}, "source": ["å¾ˆé—æ†¾ï¼ŒOpenAIå·¥å…·è°ƒç”¨å¹¶ä¸æ€»æ˜¯æœ‰æ•ˆçš„jsonï¼Œç‰¹åˆ«æ˜¯æ¥è‡ªè¾ƒæ—§ç‰ˆæœ¬çš„APIã€‚åœ¨åŒ…æ‹¬OpenAI APIç‰ˆæœ¬1106åœ¨å†…çš„ç‰ˆæœ¬ä¸­ï¼Œå¦‚æœå‚æ•°æ˜¯ä¸€ä¸ªé•¿å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚Pythonè„šæœ¬ï¼‰ï¼Œè¿™ä¸ªé—®é¢˜å°±ç›¸å¯¹é¢‘ç¹ï¼Œä¾‹å¦‚å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://community.openai.com/t/malformed-json-in-gpt4-1106-function-arguments/685884)ã€‚\n", "\n", "ä½¿ç”¨é»˜è®¤çš„å·¥å…·è°ƒç”¨è§£æå™¨ï¼ŒOpenAIä»£ç†å°†æ— æ³•è§£æè¿™äº›å·¥å…·è°ƒç”¨ï¼Œå¹¶å°è¯•åœ¨ä¸‹ä¸€æ­¥ä¸­ä¿®å¤å·¥å…·è°ƒç”¨ã€‚è¿™éœ€è¦å¦ä¸€ä¸ªllmè°ƒç”¨ï¼Œè¿™æ˜¯ç¼“æ…¢ä¸”æ˜‚è´µçš„ã€‚\n", "\n", "æœ¬ç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„å·¥å…·è°ƒç”¨è§£æå™¨ï¼Œå¯ä»¥å¤„ç†æŸäº›ç±»å‹çš„æ ¼å¼ä¸æ­£ç¡®çš„å‡½æ•°è°ƒç”¨ã€‚\n", "ä»¥ä¸‹æ­¥éª¤æ˜¯ä»OpenAIä»£ç†ç¬”è®°æœ¬ä¸­å¤åˆ¶çš„ï¼ŒåŒæ—¶æ·»åŠ äº†è‡ªå®šä¹‰çš„å·¥å…·è°ƒç”¨è§£æå™¨ã€‚\n"]}, {"cell_type": "markdown", "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc", "metadata": {}, "source": ["## åˆå§‹è®¾ç½®\n"]}, {"cell_type": "markdown", "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f", "metadata": {}, "source": ["è®©æˆ‘ä»¬ä»å¯¼å…¥ä¸€äº›ç®€å•çš„æ„å»ºæ¨¡å—å¼€å§‹ã€‚\n", "\n", "æˆ‘ä»¬ä¸»è¦éœ€è¦ä»¥ä¸‹å†…å®¹ï¼š\n", "1. OpenAI APIï¼ˆä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„ `llama_index` LLM ç±»ï¼‰\n", "2. ä¸€ä¸ªç”¨äºä¿å­˜å¯¹è¯å†å²è®°å½•çš„åœ°æ–¹\n", "3. ä¸€ä¸ªå®šä¹‰æˆ‘ä»¬çš„ä»£ç†å¯ä»¥ä½¿ç”¨çš„å·¥å…·çš„å®šä¹‰ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "41101795", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "4985c578", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-agent-openai\n", "%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "c61c873d", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "9d47283b-025e-4874-88ed-76245b22f82e", "metadata": {}, "outputs": [], "source": ["import json\n", "from llama_index.core.tools import FunctionTool\n", "\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "id": "6fe08eb1-e638-4c00-9103-5c305bfacccf", "metadata": {}, "source": ["è®©æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„ä»£ç†å®šä¹‰ä¸€äº›éå¸¸ç®€å•çš„è®¡ç®—å™¨å·¥å…·ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "3dd3c4a6-f3e0-46f9-ad3b-7ba57d1bc992", "metadata": {}, "outputs": [], "source": ["def multiply(a: int, b: int) -> int:\n", "    \"\"\"å°†ä¸¤ä¸ªæ•´æ•°ç›¸ä¹˜å¹¶è¿”å›ç»“æœæ•´æ•°\"\"\"\n", "    return a * b\n", "\n", "\n", "multiply_tool = FunctionTool.from_defaults(fn=multiply)"]}, {"cell_type": "code", "execution_count": null, "id": "bfcfb78b-7d4f-48d9-8d4c-ffcded23e7ac", "metadata": {}, "outputs": [], "source": ["def add(a: int, b: int) -> int:\n", "    \"\"\"å°†ä¸¤ä¸ªæ•´æ•°ç›¸åŠ å¹¶è¿”å›ç»“æœæ•´æ•°\"\"\"\n", "    return a + b\n", "\n", "add_tool = FunctionTool.from_defaults(fn=add)"]}, {"cell_type": "markdown", "id": "30016529", "metadata": {}, "source": ["## å·¥å…·è°ƒç”¨è§£æå™¨çš„å®šä¹‰\n", "\n", "æœ‰æ—¶ï¼ŒOpenAIå·¥å…·è°ƒç”¨å¹¶ä¸æ˜¯æœ‰æ•ˆçš„jsonæ ¼å¼ã€‚\n", "\n", "åœ¨å®šä¹‰è‡ªå·±çš„å·¥å…·è°ƒç”¨è§£æå™¨æ—¶ï¼Œæ‚¨éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸€ä¸ªOpenAIToolCallå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ã€‚è¯¥å­—å…¸å°†ä½œä¸º**kwargsä¼ é€’ç»™å·¥å…·å‡½æ•°ã€‚\n", "\n", "å¦‚æœè§£æå™¨æ— æ³•è§£æå·¥å…·è°ƒç”¨ï¼Œåˆ™åº”å¼•å‘ValueErrorã€‚è¿™å°†è¿”å›ç»™ä»£ç†ç¨‹åºï¼Œä»£ç†ç¨‹åºå°†åœ¨ä¸‹ä¸€æ­¥å°è¯•ä¿®å¤è°ƒç”¨ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "ffe547b6", "metadata": {}, "outputs": [], "source": ["from typing import Dict\n", "from llama_index.llms.openai.utils import OpenAIToolCall\n", "import re\n", "\n", "# ç›¸åŒçš„è§£æå™¨ä¹Ÿå¯ä»¥ä»llama_index.agent.openaiå¯¼å…¥advanced_tool_call_parser\n", "\n", "def custom_tool_call_parser(tool_call: OpenAIToolCall) -> Dict:\n", "    r\"\"\"è§£æä¸æ˜¯æ ‡å‡†jsonçš„å·¥å…·è°ƒç”¨ã€‚\n", "    è¿˜è§£æä»¥ä¸‹å½¢å¼çš„å·¥å…·è°ƒç”¨ï¼š\n", "    variable = \\\"\\\"\\\"Some long text\\\"\\\"\\\"\n", "    variable = \"Some long text\"'\n", "    variable = '''Some long text'''\n", "    variable = 'Some long text'\n", "    \"\"\"\n", "    arguments_str = tool_call.function.arguments\n", "    if len(arguments_str.strip()) == 0:\n", "        # å¯¹äºä¸åŒ…å«å‚æ•°çš„å‡½æ•°ï¼ŒOpenAIè¿”å›ç©ºå­—ç¬¦ä¸²\n", "        return {}\n", "    try:\n", "        tool_call = json.loads(arguments_str)\n", "        if not isinstance(tool_call, dict):\n", "            raise ValueError(\"å·¥å…·è°ƒç”¨å¿…é¡»æ˜¯å­—å…¸\")\n", "        return tool_call\n", "    except json.JSONDecodeError as e:\n", "        # åŒ¹é…å˜é‡åå’Œå¼•å·å†…çš„å†…å®¹çš„æ¨¡å¼\n", "        pattern = r'([a-zA-Z_][a-zA-Z_0-9]*)\\s*=\\s*[\"\\']+(.*?)[\"\\']+'\n", "        match = re.search(pattern, arguments_str)\n", "\n", "        if match:\n", "            variable_name = match.group(1)  # è¿™æ˜¯å˜é‡å\n", "            content = match.group(2)  # è¿™æ˜¯å¼•å·å†…çš„å†…å®¹\n", "            return {variable_name: content}\n", "        raise ValueError(f\"æ— æ•ˆçš„å·¥å…·è°ƒç”¨: {e!s}\")"]}, {"cell_type": "markdown", "id": "707d30b8-6405-4187-a9ed-6146dcc42167", "metadata": {}, "source": ["## ä½¿ç”¨å·¥å…·è°ƒç”¨è§£æå™¨å®šä¹‰OpenAIä»£ç†\n", "\n", "åœ¨è¿™ä¸ªnotebookä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨OpenAI Gymç¯å¢ƒå’Œä¸€ä¸ªå·¥å…·è°ƒç”¨è§£æå™¨æ¥å®šä¹‰ä¸€ä¸ªç®€å•çš„OpenAIä»£ç†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„Q-learningç®—æ³•æ¥è®­ç»ƒä»£ç†ï¼Œä»¥ä¾¿å®ƒèƒ½å¤Ÿåœ¨ç»™å®šç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "38ab3938-1138-43ea-b085-f430b42f5377", "metadata": {}, "outputs": [], "source": ["from llama_index.agent.openai import OpenAIAgent\n", "from llama_index.llms.openai import OpenAI"]}, {"cell_type": "code", "execution_count": null, "id": "d852ece7-e5a1-4368-9d59-c7014e0b5b4d", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n", "agent = OpenAIAgent.from_tools(\n", "    [multiply_tool, add_tool],\n", "    llm=llm,\n", "    verbose=True,\n", "    tool_call_parser=custom_tool_call_parser,\n", ")"]}, {"cell_type": "markdown", "id": "500cbee4", "metadata": {}, "source": ["### èŠå¤©\n"]}, {"cell_type": "code", "execution_count": null, "id": "9fd1cad5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What is (121 * 3) + 42?\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\n", "  \"a\": 121,\n", "  \"b\": 3\n", "}\n", "Got output: 363\n", "========================\n", "\n", "=== Calling Function ===\n", "Calling function: add with args: {\n", "  \"a\": 363,\n", "  \"b\": 42\n", "}\n", "Got output: 405\n", "========================\n", "\n", "(121 * 3) + 42 is equal to 405.\n"]}], "source": ["response = agent.chat(\"What is (121 * 3) + 42?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "538bf32f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[ToolOutput(content='363', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 121, 'b': 3}}, raw_output=363), ToolOutput(content='405', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 363, 'b': 42}}, raw_output=405)]\n"]}], "source": ["# æ£€æŸ¥æ•°æ®æº\n", "print(response.sources)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}