{"cells": [{"cell_type": "markdown", "id": "b7973eef-7e5e-4ca4-844a-1d016f5a638b", "metadata": {}, "source": ["# 在查询管道周围构建代理\n", "\n", "在本手册中，我们将向您展示如何在查询管道周围构建代理。\n", "\n", "代理提供了在您设置的任何查询DAG之上进行复杂的顺序推理的能力。从概念上讲，这也是您可以向图形添加“循环”的一种方式之一。\n", "\n", "我们将向您展示两个您可以实现的代理示例：\n", "- 一个完整的 ReAct 代理，可以进行工具选择\n", "- 一个“简单”的代理，可以在文本到SQL查询引擎周围添加重试层。\n", "\n", "**注意：** 任何文本到SQL应用程序都应该意识到，执行任意SQL查询可能存在安全风险。建议采取必要的预防措施，例如使用受限角色、只读数据库、沙箱等。\n"]}, {"cell_type": "code", "execution_count": null, "id": "763a442a-cfcd-4e63-9121-e3a45dc3acff", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SQLDatabase\n", "from sqlalchemy import (\n", "    create_engine,\n", "    MetaData,\n", "    Table,\n", "    Column,\n", "    String,\n", "    Integer,\n", "    select,\n", "    column,\n", ")\n", "\n", "engine = create_engine(\"sqlite:///chinook.db\")\n", "sql_database = SQLDatabase(engine)"]}, {"cell_type": "code", "execution_count": null, "id": "0aacdcad-f0c1-40f4-b319-6c4cf3b309c7", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_pipeline import QueryPipeline"]}, {"cell_type": "markdown", "id": "122dce22-6d3a-4d4a-a265-a6a3d3f90d26", "metadata": {}, "source": ["## 设置\n", "\n", "### 设置数据\n", "\n", "我们使用chinook数据库作为示例数据。[来源](https://www.sqlitetutorial.net/sqlite-sample-database/)。\n"]}, {"cell_type": "code", "execution_count": null, "id": "cce0a58f", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "926b79ba-1868-46ca-bb7e-2bd3c907773c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n", "                                 Dload  Upload   Total   Spent    Left  Speed\n", "100  298k  100  298k    0     0  2327k      0 --:--:-- --:--:-- --:--:-- 2387k\n", "curl: (6) Could not resolve host: .\n", "Archive:  ./chinook.zip\n", "  inflating: chinook.db              \n"]}], "source": ["!curl \"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\" -O ./chinook.zip\n", "!unzip ./chinook.zip"]}, {"cell_type": "markdown", "id": "419f97cf-63c1-456b-babd-b07d9ce4b937", "metadata": {}, "source": ["### 设置可观测性\n", "\n", "我们设置 Arize Phoenix 以实现可观测性。\n"]}, {"cell_type": "code", "execution_count": null, "id": "5fb303b7-2fb1-496b-aff8-57844cdc519b", "metadata": {}, "outputs": [], "source": ["# 定义全局回调设置\n", "from llama_index.core.settings import Settings\n", "from llama_index.core.callbacks import CallbackManager\n", "\n", "callback_manager = CallbackManager()\n", "Settings.callback_manager = callback_manager"]}, {"cell_type": "code", "execution_count": null, "id": "754f11d3-f053-46f7-acb4-ae8ee7d3fe07", "metadata": {}, "outputs": [], "source": ["# 设置 Arize Phoenix 用于日志记录/可观测性\n", "import phoenix as px\n", "import llama_index.core\n", "\n", "px.launch_app()\n", "llama_index.core.set_global_handler(\"arize_phoenix\")"]}, {"cell_type": "markdown", "id": "fbbc38d8-2a78-4457-888d-cfe8960a9c6b", "metadata": {}, "source": ["## 设置文本到SQL查询引擎/工具\n", "\n", "现在我们设置一个简单的文本到SQL工具：给定一个查询，将文本翻译成SQL，执行在数据库中，并得到结果。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d72eb79e-05b4-4260-b086-e837b01cce77", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import NLSQLTableQueryEngine\n", "from llama_index.core.tools import QueryEngineTool\n", "\n", "sql_query_engine = NLSQLTableQueryEngine(\n", "    sql_database=sql_database,\n", "    tables=[\"albums\", \"tracks\", \"artists\"],\n", "    verbose=True,\n", ")\n", "sql_tool = QueryEngineTool.from_defaults(\n", "    query_engine=sql_query_engine,\n", "    name=\"sql_tool\",\n", "    description=(\n", "        \"Useful for translating a natural language query into a SQL query\"\n", "    ),\n", ")"]}, {"cell_type": "markdown", "id": "af9d8d26-65c8-4788-a0ad-8d2448b23254", "metadata": {}, "source": ["## 设置ReAct Agent Pipeline\n", "\n", "现在，我们将使用我们的查询管道语法为单个步骤设置一个ReAct管道。这是一个多部分的过程，包括以下内容：\n", "1. 接收agent输入\n", "2. 使用LLM调用ReAct提示生成下一个动作/工具（或返回一个响应）。\n", "3. 如果选择工具/动作，则调用工具管道来执行工具+收集响应。\n", "4. 如果生成响应，则获取响应。\n", "\n", "在整个过程中，我们将使用各种特定于agent的查询组件。与普通的查询管道不同，这些组件专门设计用于在`QueryPipelineAgentWorker`中使用的查询管道：\n", "- 一个`AgentInputComponent`，允许您将agent输入（任务、状态字典）转换为查询管道的一组输入。\n", "- 一个`AgentFnComponent`：一个通用处理器，允许您接收当前任务、状态以及任意输入，并返回一个输出。在本手册中，我们定义了一个函数组件来格式化ReAct提示。但是，您可以将其放在任何地方。\n", "- [本笔记本中未使用] 一个`CustomAgentComponent`：类似于`AgentFnComponent`，您可以实现`_run_component`来定义自己的逻辑，同时可以访问任务和状态。它比`AgentFnComponent`更冗长，但比`AgentFnComponent`更灵活（例如，您可以定义初始化变量，并且回调在基类中）。\n", "\n", "请注意，传递给`AgentFnComponent`和`AgentInputComponent`的任何函数都必须包括`task`和`state`作为输入变量，因为这些是从agent传递的输入。\n", "\n", "请注意，agentic查询管道的输出必须是`Tuple[AgentChatResponse, bool]`。您将在下面看到这一点。\n"]}, {"cell_type": "code", "execution_count": null, "id": "9884b8c0-0ec3-4b14-9538-db9f5be63466", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_pipeline import QueryPipeline as QP\n", "\n", "qp = QP(verbose=True)"]}, {"cell_type": "markdown", "id": "a024201f-a39b-4e23-a567-9737026dd771", "metadata": {}, "source": ["### 定义Agent输入组件\n", "\n", "在这里，我们定义了Agent输入组件，它在每个Agent步骤的开始时被调用。除了传递输入之外，我们还进行初始化和状态修改。\n"]}, {"cell_type": "code", "execution_count": null, "id": "9b1a9252-57df-47cc-9fcf-84d87b1e0102", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent.react.types import (\n", "    ActionReasoningStep,  # 行动推理步骤\n", "    ObservationReasoningStep,  # 观察推理步骤\n", "    ResponseReasoningStep,  # 响应推理步骤\n", ")\n", "from llama_index.core.agent import Task, AgentChatResponse  # 任务，代理聊天响应\n", "from llama_index.core.query_pipeline import (\n", "    AgentInputComponent,  # 代理输入组件\n", "    AgentFnComponent,  # 代理函数组件\n", "    CustomAgentComponent,  # 自定义代理组件\n", "    QueryComponent,  # 查询组件\n", "    ToolRunnerComponent,  # 工具运行组件\n", ")\n", "from llama_index.core.llms import MessageRole  # 消息角色\n", "from typing import Dict, Any, Optional, Tuple, List, cast  # 导入类型提示\n", "\n", "\n", "## 代理输入组件\n", "## 这是产生代理输入的组件，供其他组件使用\n", "## 也可以在这里放置初始化逻辑。\n", "def agent_input_fn(task: Task, state: Dict[str, Any]) -> Dict[str, Any]:\n", "    \"\"\"代理输入函数。\n", "\n", "    返回:\n", "        一个包含输出键和值的字典。如果在定义该组件与其他组件之间的链接时指定了src_key，\n", "        请确保src_key与指定的output_key匹配。\n", "\n", "    \"\"\"\n", "    # 初始化当前推理\n", "    if \"current_reasoning\" not in state:\n", "        state[\"current_reasoning\"] = []\n", "    reasoning_step = ObservationReasoningStep(observation=task.input)\n", "    state[\"current_reasoning\"].append(reasoning_step)\n", "    return {\"input\": task.input}\n", "\n", "\n", "agent_input_component = AgentInputComponent(fn=agent_input_fn)"]}, {"cell_type": "markdown", "id": "dd914690-ee4d-4b3b-bb95-9cce0994b9c1", "metadata": {}, "source": ["### 定义代理提示\n", "\n", "在这里，我们定义了生成 ReAct 提示的代理组件，并且在从LLM生成输出之后，将其解析为一个结构化对象。\n"]}, {"cell_type": "code", "execution_count": null, "id": "8a1957da-bc2b-4186-abf0-11148a23dba7", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import ReActChatFormatter\n", "from llama_index.core.query_pipeline import InputComponent, Link\n", "from llama_index.core.llms import ChatMessage\n", "from llama_index.core.tools import BaseTool\n", "\n", "\n", "## 定义提示函数\n", "def react_prompt_fn(\n", "    task: Task, state: Dict[str, Any], input: str, tools: List[BaseTool]\n", ") -> List[ChatMessage]:\n", "    # 将输入添加到推理中\n", "    chat_formatter = ReActChatFormatter()\n", "    return chat_formatter.format(\n", "        tools,\n", "        chat_history=task.memory.get() + state[\"memory\"].get_all(),\n", "        current_reasoning=state[\"current_reasoning\"],\n", "    )\n", "\n", "\n", "react_prompt_component = AgentFnComponent(\n", "    fn=react_prompt_fn, partial_dict={\"tools\": [sql_tool]}\n", ")"]}, {"cell_type": "markdown", "id": "7acd7088-7804-48c5-8c7f-0c5c112d27f0", "metadata": {}, "source": ["### 定义代理输出解析器 + 工具流水线\n", "\n", "一旦LLM给出一个输出，我们就有一个决策树：\n", "1. 如果给出了一个答案，那么我们就完成了。处理输出。\n", "2. 如果给出了一个动作，我们需要使用指定的工具和参数执行指定的工具，然后处理输出。\n", "\n", "工具调用可以通过`ToolRunnerComponent`模块来实现。这是一个简单的包装模块，它接受一个工具列表，并可以使用指定的工具名称（每个工具都有一个名称）和工具动作来“执行”。\n", "\n", "我们实现这个整体模块`OutputAgentComponent`，它是`CustomAgentComponent`的子类。\n", "\n", "注意：我们还实现了`sub_query_components`来将高级回调管理器传递到工具运行子模块。\n"]}, {"cell_type": "code", "execution_count": null, "id": "702e3070-40df-491b-b468-d19ba98edc6b", "metadata": {}, "outputs": [], "source": ["from typing import Set, Optional\n", "from llama_index.core.agent.react.output_parser import ReActOutputParser\n", "from llama_index.core.llms import ChatResponse\n", "from llama_index.core.agent.types import Task\n", "\n", "\n", "def parse_react_output_fn(\n", "    task: Task, state: Dict[str, Any], chat_response: ChatResponse\n", "):\n", "    \"\"\"将ReAct输出解析为推理步骤。\"\"\"\n", "    output_parser = ReActOutputParser()\n", "    reasoning_step = output_parser.parse(chat_response.message.content)\n", "    return {\"done\": reasoning_step.is_done, \"reasoning_step\": reasoning_step}\n", "\n", "\n", "parse_react_output = AgentFnComponent(fn=parse_react_output_fn)\n", "\n", "\n", "def run_tool_fn(\n", "    task: Task, state: Dict[str, Any], reasoning_step: ActionReasoningStep\n", "):\n", "    \"\"\"运行工具并处理工具输出。\"\"\"\n", "    tool_runner_component = ToolRunnerComponent(\n", "        [sql_tool], callback_manager=task.callback_manager\n", "    )\n", "    tool_output = tool_runner_component.run_component(\n", "        tool_name=reasoning_step.action,\n", "        tool_input=reasoning_step.action_input,\n", "    )\n", "    observation_step = ObservationReasoningStep(observation=str(tool_output))\n", "    state[\"current_reasoning\"].append(observation_step)\n", "    # TODO: 获取输出\n", "\n", "    return {\"response_str\": observation_step.get_content(), \"is_done\": False}\n", "\n", "\n", "run_tool = AgentFnComponent(fn=run_tool_fn)\n", "\n", "\n", "def process_response_fn(\n", "    task: Task, state: Dict[str, Any], response_step: ResponseReasoningStep\n", "):\n", "    \"\"\"处理响应。\"\"\"\n", "    state[\"current_reasoning\"].append(response_step)\n", "    response_str = response_step.response\n", "    # 现在我们完成了这一步，将其放入内存\n", "    state[\"memory\"].put(ChatMessage(content=task.input, role=MessageRole.USER))\n", "    state[\"memory\"].put(\n", "        ChatMessage(content=response_str, role=MessageRole.ASSISTANT)\n", "    )\n", "\n", "    return {\"response_str\": response_str, \"is_done\": True}\n", "\n", "\n", "process_response = AgentFnComponent(fn=process_response_fn)\n", "\n", "\n", "def process_agent_response_fn(\n", "    task: Task, state: Dict[str, Any], response_dict: dict\n", "):\n", "    \"\"\"处理代理响应。\"\"\"\n", "    return (\n", "        AgentChatResponse(response_dict[\"response_str\"]),\n", "        response_dict[\"is_done\"],\n", "    )\n", "\n", "\n", "process_agent_response = AgentFnComponent(fn=process_agent_response_fn)"]}, {"cell_type": "markdown", "id": "03c1382b-f9ef-42a6-b117-91d7b2a14921", "metadata": {}, "source": ["### 组合代理查询管道\n", "\n", "现在我们可以将顶层代理管道组合在一起：agent_input -> react_prompt -> llm -> react_output。\n", "\n", "最后一个组件是调用子组件的if-else组件。\n"]}, {"cell_type": "code", "execution_count": null, "id": "219ec2ed-474e-450e-866c-15772055b8b1", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_pipeline import QueryPipeline as QP\n", "from llama_index.llms.openai import OpenAI\n", "\n", "qp.add_modules(\n", "    {\n", "        \"agent_input\": agent_input_component,\n", "        \"react_prompt\": react_prompt_component,\n", "        \"llm\": OpenAI(model=\"gpt-4-1106-preview\"),\n", "        \"react_output_parser\": parse_react_output,\n", "        \"run_tool\": run_tool,\n", "        \"process_response\": process_response,\n", "        \"process_agent_response\": process_agent_response,\n", "    }\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "be90408b-0893-4cab-a7c7-32206979eecd", "metadata": {}, "outputs": [], "source": ["# 将输入链接到反应提示以解析出响应（工具操作/输入或观察）\n", "qp.add_chain([\"agent_input\", \"react_prompt\", \"llm\", \"react_output_parser\"])\n", "\n", "# 从反应输出到工具调用添加条件链接（如果尚未完成）\n", "qp.add_link(\n", "    \"react_output_parser\",\n", "    \"run_tool\",\n", "    condition_fn=lambda x: not x[\"done\"],\n", "    input_fn=lambda x: x[\"reasoning_step\"],\n", ")\n", "# 从反应输出到最终响应处理添加条件链接（如果已完成）\n", "qp.add_link(\n", "    \"react_output_parser\",\n", "    \"process_response\",\n", "    condition_fn=lambda x: x[\"done\"],\n", "    input_fn=lambda x: x[\"reasoning_step\"],\n", ")\n", "\n", "# 无论是响应处理还是工具输出处理，都添加链接到最终代理响应\n", "qp.add_link(\"process_response\", \"process_agent_response\")\n", "qp.add_link(\"run_tool\", \"process_agent_response\")"]}, {"cell_type": "markdown", "id": "207ff8b0-efc3-482d-8224-f3b82c9a1c2c", "metadata": {}, "source": ["### 可视化查询管道\n"]}, {"cell_type": "code", "execution_count": null, "id": "cd5e739b-ef99-44dd-91a3-a495fa11e4f7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["agent_dag.html\n"]}, {"data": {"text/html": ["\n", "        <iframe\n", "            width=\"100%\"\n", "            height=\"600px\"\n", "            src=\"agent_dag.html\"\n", "            frameborder=\"0\"\n", "            allowfullscreen\n", "            \n", "        ></iframe>\n", "        "], "text/plain": ["<IPython.lib.display.IFrame at 0x297838880>"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["from pyvis.network import Network\n", "\n", "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n", "net.from_nx(qp.clean_dag)\n", "net.show(\"agent_dag.html\")"]}, {"cell_type": "markdown", "id": "f7785354-1fe0-49b4-8b48-08ce51853a4e", "metadata": {}, "source": ["### 在文本到SQL查询管道周围设置代理工作程序\n", "\n", "这是我们设置代理工作程序以围绕文本到SQL查询管道的方式。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d01ea94b-3d3f-4b26-b71a-eea3d1d1ec0d", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import QueryPipelineAgentWorker\n", "from llama_index.core.callbacks import CallbackManager\n", "\n", "agent_worker = QueryPipelineAgentWorker(qp)\n", "agent = agent_worker.as_agent(\n", "    callback_manager=CallbackManager([]), verbose=True\n", ")"]}, {"cell_type": "markdown", "id": "373bd661-4a6b-4c5b-b35b-0082921cc3b9", "metadata": {}, "source": ["### 运行代理程序\n", "\n", "让我们尝试在一些示例查询上运行代理程序。\n"]}, {"cell_type": "code", "execution_count": null, "id": "6ea55110-98fb-4acf-b2f8-eee2b15c087b", "metadata": {}, "outputs": [], "source": ["# 开始任务\n", "task = agent.create_task(\n", "    \"AC/DC乐队有哪些歌曲？限制在3首内\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "7f35e816-e76b-43ba-8eb4-ddda8ee97a0b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["> Running step edb9926c-7290-4b8d-ac80-1421432a0ea6. Step input: What are some tracks from the artist AC/DC? Limit it to 3\n", "\u001b[1;3;38;2;155;135;227m> Running module agent_input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='b9b747a7-880f-4e91-9eed-b64574cbb6d0' input='What are some tracks from the artist AC/DC? Limit it to 3' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method ...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_prompt with input: \n", "input: What are some tracks from the artist AC/DC? Limit it to 3\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='\\nYou are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.\\n\\n## Too...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n", "chat_response: assistant: Thought: I need to use a tool to help me answer the question.\n", "Action: sql_tool\n", "Action Input: {\"input\": \"Select track_name from tracks where artist_name = 'AC/DC' limit 3\"}\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module run_tool with input: \n", "reasoning_step: thought='I need to use a tool to help me answer the question.' action='sql_tool' action_input={'input': \"Select track_name from tracks where artist_name = 'AC/DC' limit 3\"}\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n", "response_dict: {'response_str': 'Observation: {\\'output\\': ToolOutput(content=\\'The top 3 tracks by AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\\\\\'s Get It Up\".\\', tool_nam...\n", "\n", "\u001b[0m"]}], "source": ["step_output = agent.run_step(task.task_id)"]}, {"cell_type": "code", "execution_count": null, "id": "2a13e449-db6c-43a3-99b7-70d23687e8b8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["> Running step 37e2312b-540b-4c79-9261-15318d4796d9. Step input: None\n", "\u001b[1;3;38;2;155;135;227m> Running module agent_input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='b9b747a7-880f-4e91-9eed-b64574cbb6d0' input='What are some tracks from the artist AC/DC? Limit it to 3' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method ...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_prompt with input: \n", "input: What are some tracks from the artist AC/DC? Limit it to 3\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='\\nYou are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.\\n\\n## Too...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n", "chat_response: assistant: Thought: The user has repeated the request, possibly due to not noticing the previous response. I will provide the information again.\n", "\n", "Answer: The top 3 tracks by AC/DC are \"For Those About...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_response with input: \n", "response_step: thought='The user has repeated the request, possibly due to not noticing the previous response. I will provide the information again.' response='The top 3 tracks by AC/DC are \"For Those About To Rock ...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n", "response_dict: {'response_str': 'The top 3 tracks by AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\'s Get It Up\".', 'is_done': True}\n", "\n", "\u001b[0m"]}], "source": ["step_output = agent.run_step(task.task_id)"]}, {"cell_type": "code", "execution_count": null, "id": "22dffeec-651e-43e7-8929-827566c8f6da", "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["step_output.is_last"]}, {"cell_type": "code", "execution_count": null, "id": "44372a37-0b1e-4d90-8f42-9816546cc66e", "metadata": {}, "outputs": [], "source": ["response = agent.finalize_response(task.task_id)"]}, {"cell_type": "code", "execution_count": null, "id": "7ba842bd-cc86-422b-8c17-2ff87c1962b6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The top 3 tracks by AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let's Get It Up\".\n"]}], "source": ["print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "c6ef125b-ccd7-4937-820a-e3b0a8b1f825", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["> Running step 781d6e78-5bfe-4330-b8fc-3242deb6f64a. Step input: What are some tracks from the artist AC/DC? Limit it to 3\n", "\u001b[1;3;38;2;155;135;227m> Running module agent_input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='c09dd358-19e8-4fcc-8b82-326783ba4af2' input='What are some tracks from the artist AC/DC? Limit it to 3' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method ...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_prompt with input: \n", "input: What are some tracks from the artist AC/DC? Limit it to 3\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='\\nYou are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.\\n\\n## Too...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n", "chat_response: assistant: Thought: I need to use a tool to help me answer the question.\n", "Action: sql_tool\n", "Action Input: {\"input\": \"SELECT track_name FROM tracks WHERE artist_name = 'AC/DC' LIMIT 3\"}\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module run_tool with input: \n", "reasoning_step: thought='I need to use a tool to help me answer the question.' action='sql_tool' action_input={'input': \"SELECT track_name FROM tracks WHERE artist_name = 'AC/DC' LIMIT 3\"}\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n", "response_dict: {'response_str': 'Observation: {\\'output\\': ToolOutput(content=\\'The top three tracks by AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\\\\\'s Get It Up\".\\', tool...\n", "\n", "\u001b[0m> Running step a65d44a6-7a98-49ec-86ce-eb4b3bcd6a48. Step input: None\n", "\u001b[1;3;38;2;155;135;227m> Running module agent_input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='c09dd358-19e8-4fcc-8b82-326783ba4af2' input='What are some tracks from the artist AC/DC? Limit it to 3' memory=ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method ...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_prompt with input: \n", "input: What are some tracks from the artist AC/DC? Limit it to 3\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: [ChatMessage(role=<MessageRole.SYSTEM: 'system'>, content='\\nYou are designed to help with a variety of tasks, from answering questions     to providing summaries to other types of analyses.\\n\\n## Too...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module react_output_parser with input: \n", "chat_response: assistant: Thought: The user has repeated the request for tracks from the artist AC/DC, limited to 3, despite having already received an answer. It's possible that the user did not see the previous re...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_response with input: \n", "response_step: thought=\"The user has repeated the request for tracks from the artist AC/DC, limited to 3, despite having already received an answer. It's possible that the user did not see the previous response, or ...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module process_agent_response with input: \n", "response_dict: {'response_str': 'The top three tracks by AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let\\'s Get It Up\".', 'is_done': True}\n", "\n", "\u001b[0m"]}], "source": ["# 运行这个端到端测试\n", "agent.reset()\n", "response = agent.chat(\n", "    \"AC/DC这个艺术家有哪些歌曲？限制在3首内\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "de05be63-319f-48e3-bc16-6155b23b13a0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The top three tracks by AC/DC are \"For Those About To Rock (We Salute You)\", \"Put The Finger On You\", and \"Let's Get It Up\".\n"]}], "source": ["print(str(response))"]}, {"cell_type": "markdown", "id": "e8f8458f-4fab-420f-bb80-214e1f11c0a8", "metadata": {}, "source": ["## 设置简单的文本到SQL重试代理管道\n", "\n", "与进行工具选择的完整ReAct管道不同，让我们尝试一个更简单的代理管道，只进行文本到SQL的转换，并带有重试逻辑。\n", "\n", "我们尝试一个简单的基于文本的“重试”提示，根据用户输入和先前的对话历史，可以生成一个修改后的查询，以输出正确的结果。\n"]}, {"cell_type": "markdown", "id": "7adc8aa9-5b72-4525-8bad-052c5df28d6a", "metadata": {}, "source": ["### 定义核心模块\n", "\n", "- 代理输入\n", "- 重试提示\n", "- 输出处理器（包括验证提示）\n"]}, {"cell_type": "code", "execution_count": null, "id": "5b62f3c5-6c4d-4532-ab34-fafe9abb77a1", "metadata": {}, "outputs": [], "source": ["\n", "来自llama_index.llms.openai的OpenAI\n", "\n", "# llm = OpenAI(model=\"gpt-3.5-turbo\")\n", "llm = OpenAI(model=\"gpt-4-1106-preview\")"]}, {"cell_type": "code", "execution_count": null, "id": "06dd3c71-66d3-4a7d-ba03-abecd61268d0", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import Task, AgentChatResponse\n", "from typing import Dict, Any\n", "from llama_index.core.query_pipeline import (\n", "    AgentInputComponent,\n", "    AgentFnComponent,\n", ")\n", "\n", "\n", "def agent_input_fn(task: Task, state: Dict[str, Any]) -> Dict:\n", "    \"\"\"代理输入函数。\"\"\"\n", "    # 初始化当前推理\n", "    if \"convo_history\" not in state:\n", "        state[\"convo_history\"] = []\n", "        state[\"count\"] = 0\n", "    state[\"convo_history\"].append(f\"用户: {task.input}\")\n", "    convo_history_str = \"\\n\".join(state[\"convo_history\"]) or \"无\"\n", "    return {\"input\": task.input, \"convo_history\": convo_history_str}\n", "\n", "\n", "agent_input_component = AgentInputComponent(fn=agent_input_fn)"]}, {"cell_type": "code", "execution_count": null, "id": "f18356fa-df3b-4fbf-ab5b-c2708b0bfaa4", "metadata": {}, "outputs": [], "source": ["from llama_index.core import PromptTemplate\n", "\n", "retry_prompt_str = \"\"\"\\\n", "您正在尝试根据用户输入生成一个合适的自然语言查询。\n", "\n", "然后，这个查询将被下游的文本到SQL代理解释，该代理将把查询转换为SQL语句。如果代理触发错误，那么这将反映在当前的对话历史中（见下文）。\n", "\n", "如果对话历史为None，请使用用户输入。如果不为None，则生成一个新的SQL查询，避免前一个SQL查询的问题。\n", "\n", "输入：{input}\n", "对话历史（失败的尝试）：\n", "{convo_history}\n", "\n", "新输入：\"\"\"\n", "retry_prompt = PromptTemplate(retry_prompt_str)"]}, {"cell_type": "code", "execution_count": null, "id": "f14e034c-b5b3-4f7d-b840-b7f2f4926d79", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Response\n", "from typing import Tuple\n", "\n", "validate_prompt_str = \"\"\"\\\n", "给定用户查询，验证推断的SQL查询和执行查询后的响应是否正确并回答了查询。\n", "\n", "用YES或NO回答。\n", "\n", "查询: {input}\n", "推断的SQL查询: {sql_query}\n", "SQL响应: {sql_response}\n", "\n", "结果: \"\"\"\n", "validate_prompt = PromptTemplate(validate_prompt_str)\n", "\n", "MAX_ITER = 3\n", "\n", "\n", "def agent_output_fn(\n", "    task: Task, state: Dict[str, Any], output: Response\n", ") -> Tuple[AgentChatResponse, bool]:\n", "    \"\"\"代理输出组件。\"\"\"\n", "    print(f\"> 推断的SQL查询: {output.metadata['sql_query']}\")\n", "    print(f\"> SQL响应: {str(output)}\")\n", "    state[\"convo_history\"].append(\n", "        f\"助手（推断的SQL查询）: {output.metadata['sql_query']}\"\n", "    )\n", "    state[\"convo_history\"].append(f\"助手（响应）: {str(output)}\")\n", "\n", "    # 运行一个小型链来获取响应\n", "    validate_prompt_partial = validate_prompt.as_query_component(\n", "        partial={\n", "            \"sql_query\": output.metadata[\"sql_query\"],\n", "            \"sql_response\": str(output),\n", "        }\n", "    )\n", "    qp = QP(chain=[validate_prompt_partial, llm])\n", "    validate_output = qp.run(input=task.input)\n", "\n", "    state[\"count\"] += 1\n", "    is_done = False\n", "    if state[\"count\"] >= MAX_ITER:\n", "        is_done = True\n", "    if \"YES\" in validate_output.message.content:\n", "        is_done = True\n", "\n", "    return AgentChatResponse(response=str(output)), is_done\n", "\n", "\n", "agent_output_component = AgentFnComponent(fn=agent_output_fn)"]}, {"cell_type": "code", "execution_count": null, "id": "44015fad-a37d-48e7-90d0-77d62ff4ab83", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_pipeline import (\n", "    QueryPipeline as QP,\n", "    Link,\n", "    InputComponent,\n", ")\n", "\n", "qp = QP(\n", "    modules={\n", "        \"input\": agent_input_component,\n", "        \"retry_prompt\": retry_prompt,\n", "        \"llm\": llm,\n", "        \"sql_query_engine\": sql_query_engine,\n", "        \"output_component\": agent_output_component,\n", "    },\n", "    verbose=True,\n", ")\n", "qp.add_link(\"input\", \"retry_prompt\", src_key=\"input\", dest_key=\"input\")\n", "qp.add_link(\n", "    \"input\", \"retry_prompt\", src_key=\"convo_history\", dest_key=\"convo_history\"\n", ")\n", "qp.add_chain([\"retry_prompt\", \"llm\", \"sql_query_engine\", \"output_component\"])"]}, {"cell_type": "markdown", "id": "64185c9e-b90f-4acb-b498-64a1bb4f8751", "metadata": {}, "source": ["### 可视化查询管道\n"]}, {"cell_type": "code", "execution_count": null, "id": "142dd638-578c-42c0-aa06-395052ca210a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["agent_dag.html\n"]}, {"data": {"text/html": ["\n", "        <iframe\n", "            width=\"100%\"\n", "            height=\"600px\"\n", "            src=\"agent_dag.html\"\n", "            frameborder=\"0\"\n", "            allowfullscreen\n", "            \n", "        ></iframe>\n", "        "], "text/plain": ["<IPython.lib.display.IFrame at 0x2b28a9780>"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["from pyvis.network import Network\n", "\n", "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n", "net.from_nx(qp.dag)\n", "net.show(\"agent_dag.html\")"]}, {"cell_type": "markdown", "id": "ab09a855-ef74-457c-8aa6-2292adf12278", "metadata": {}, "source": ["### 定义代理工作者\n"]}, {"cell_type": "code", "execution_count": null, "id": "f3764e8c-78a3-41cd-97f4-8c6c1642ff1e", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import QueryPipelineAgentWorker\n", "from llama_index.core.callbacks import CallbackManager\n", "\n", "# 回调管理器从查询管道传递给代理工作器/代理\n", "agent_worker = QueryPipelineAgentWorker(qp)\n", "agent = agent_worker.as_agent(\n", "    callback_manager=CallbackManager(), verbose=False\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "0d9a327a-e9ee-481e-b427-701245cdd2f1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[1;3;38;2;155;135;227m> Running module input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='2d8a63de-7410-4422-98f3-f0ca41884f58' input=\"How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\" memory=ChatMemoryBuffer(token_limit=3000, toke...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n", "input: How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\n", "convo_history: User: How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: You are trying to generate a proper natural language query given a user input.\n", "\n", "This query will then be interpreted by a downstream text-to-SQL agent which\n", "will convert the query to a SQL statement. I...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n", "input: assistant: Given the conversation history, it seems that the previous attempt to generate a SQL query from the user's question may have resulted in an error. To avoid the same problem, we need to reph...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n", "output: I'm sorry, but there seems to be an error in the SQL query. The query you provided is invalid SQL. Please double-check the syntax and try again.\n", "\n", "\u001b[0m> Inferred SQL Query: SELECT COUNT(albums.AlbumId) \n", "FROM albums \n", "JOIN tracks ON albums.AlbumId = tracks.AlbumId \n", "WHERE tracks.Name = 'Restless and Wild' \n", "AND albums.ArtistId = tracks.Composer \n", "AND COUNT(albums.AlbumId) > 0\n", "> SQL Response: I'm sorry, but there seems to be an error in the SQL query. The query you provided is invalid SQL. Please double-check the syntax and try again.\n", "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='2d8a63de-7410-4422-98f3-f0ca41884f58' input=\"How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\" memory=ChatMemoryBuffer(token_limit=3000, toke...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n", "input: How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\n", "convo_history: User: How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\n", "Assistant (inferred SQL query): SELECT COUNT(albums.AlbumId) \n", "FROM albums \n", "JOIN tracks ON album...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: You are trying to generate a proper natural language query given a user input.\n", "\n", "This query will then be interpreted by a downstream text-to-SQL agent which\n", "will convert the query to a SQL statement. I...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n", "input: assistant: Given the previous error, it seems that the SQL query was incorrect because it attempted to use an aggregate function (`COUNT`) in the `WHERE` clause, which is not allowed. Additionally, th...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n", "output: The number of albums released by the artist who composed the track 'Restless and Wild' is 1.\n", "\n", "\u001b[0m> Inferred SQL Query: SELECT COUNT(DISTINCT albums.AlbumId) AS NumAlbums\n", "FROM tracks\n", "JOIN albums ON tracks.AlbumId = albums.AlbumId\n", "JOIN artists ON albums.ArtistId = artists.ArtistId\n", "WHERE tracks.Name = 'Restless and Wild'\n", "GROUP BY artists.ArtistId\n", "HAVING NumAlbums > 0;\n", "> SQL Response: The number of albums released by the artist who composed the track 'Restless and Wild' is 1.\n", "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n", "state: {'sources': [], 'memory': ChatMemoryBuffer(token_limit=3000, tokenizer_fn=functools.partial(<bound method Encoding.encode of <Encoding 'cl100k_base'>>, allowed_special='all'), chat_store=SimpleChatSto...\n", "task: task_id='2d8a63de-7410-4422-98f3-f0ca41884f58' input=\"How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\" memory=ChatMemoryBuffer(token_limit=3000, toke...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module retry_prompt with input: \n", "input: How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\n", "convo_history: User: How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\n", "Assistant (inferred SQL query): SELECT COUNT(albums.AlbumId) \n", "FROM albums \n", "JOIN tracks ON album...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm with input: \n", "messages: You are trying to generate a proper natural language query given a user input.\n", "\n", "This query will then be interpreted by a downstream text-to-SQL agent which\n", "will convert the query to a SQL statement. I...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_query_engine with input: \n", "input: assistant: Given the conversation history, it seems that the previous SQL query was successful in retrieving the number of albums released by the artist who composed the track 'Restless and Wild'. How...\n", "\n", "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module output_component with input: \n", "output: I apologize, but there seems to be an error in the SQL query provided. Please double-check the syntax and try again.\n", "\n", "\u001b[0m> Inferred SQL Query: SELECT COUNT(DISTINCT albums.AlbumId) AS TotalAlbums\n", "FROM albums\n", "JOIN artists ON albums.ArtistId = artists.ArtistId\n", "WHERE artists.ArtistId = (\n", "    SELECT artists.ArtistId\n", "    FROM tracks\n", "    JOIN albums ON tracks.AlbumId = albums.AlbumId\n", "    JOIN artists ON albums.ArtistId = artists.ArtistId\n", "    WHERE tracks.Name = 'Restless and Wild'\n", "    LIMIT 1\n", ")\n", "AND TotalAlbums > 0;\n", "> SQL Response: I apologize, but there seems to be an error in the SQL query provided. Please double-check the syntax and try again.\n", "I apologize, but there seems to be an error in the SQL query provided. Please double-check the syntax and try again.\n"]}], "source": ["response = agent.chat(\n", "    \"How many albums did the artist who wrote 'Restless and Wild' release? (answer should be non-zero)?\"\n", ")\n", "print(str(response))"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v3", "language": "python", "name": "llama_index_v3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}