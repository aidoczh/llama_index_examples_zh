{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/metadata_extraction/EntityExtractionClimate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# å®ä½“å…ƒæ•°æ®æå–\n", "\n", "åœ¨è¿™ä¸ªæ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–°çš„ `EntityExtractor` æ¥ä»æ¯ä¸ªèŠ‚ç‚¹ä¸­æå–å­˜å‚¨åœ¨å…ƒæ•°æ®ä¸­çš„å®ä½“ã€‚é»˜è®¤æ¨¡å‹æ˜¯ `tomaarsen/span-marker-mbert-base-multinerd`ï¼Œå¯ä»¥ä»[HuggingFace](https://huggingface.co/tomaarsen/span-marker-mbert-base-multinerd)ä¸‹è½½å¹¶åœ¨æœ¬åœ°è¿è¡Œã€‚\n", "\n", "æœ‰å…³LlamaIndexä¸­å…ƒæ•°æ®æå–çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„[æ–‡æ¡£](https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_metadata_extractor.html)ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-extractors-entity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è¿è¡Œå®ä½“æå–å™¨æ‰€éœ€", "# !pip install span_marker", "", "import os", "", "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## è®¾ç½®æå–å™¨å’Œè§£æå™¨\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/Users/loganmarkewich/llama_index/llama-index/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n", "/Users/loganmarkewich/llama_index/llama-index/lib/python3.9/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n", "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"]}, {"name": "stdout", "output_type": "stream", "text": ["'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"]}], "source": ["from llama_index.extractors.entity import EntityExtractor", "from llama_index.core.node_parser import SentenceSplitter", "", "entity_extractor = EntityExtractor(", "    prediction_threshold=0.5,", "    label_entities=False,  # åœ¨å…ƒæ•°æ®ä¸­åŒ…å«å®ä½“æ ‡ç­¾ï¼ˆå¯èƒ½æ˜¯é”™è¯¯çš„ï¼‰", "    device=\"cpu\",  # å¦‚æœæœ‰GPUï¼Œåˆ™è®¾ç½®ä¸º\"cuda\"", ")", "", "node_parser = SentenceSplitter()", "", "transformations = [node_parser, entity_extractor]"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## åŠ è½½æ•°æ®\n", "\n", "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä¸‹è½½2023å¹´IPCCæ°”å€™æŠ¥å‘Š-ç¬¬3ç« å…³äºæµ·æ´‹å’Œæ²¿æµ·ç”Ÿæ€ç³»ç»Ÿï¼ˆ172é¡µï¼‰ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n", "                                 Dload  Upload   Total   Spent    Left  Speed\n", "100 20.7M  100 20.7M    0     0  22.1M      0 --:--:-- --:--:-- --:--:-- 22.1M\n"]}], "source": ["!curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["æ¥ä¸‹æ¥ï¼ŒåŠ è½½æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "\n", "documents = SimpleDirectoryReader(\n", "    input_files=[\"./IPCC_AR6_WGII_Chapter03.pdf\"]\n", ").load_data()"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## æå–å…ƒæ•°æ®\n", "\n", "ç°åœ¨ï¼Œè¿™æ˜¯ä¸€ä¸ªç›¸å½“é•¿çš„æ–‡æ¡£ã€‚ç”±äºæˆ‘ä»¬ç›®å‰ä¸æ˜¯åœ¨CPUä¸Šè¿è¡Œï¼Œæ‰€ä»¥æˆ‘ä»¬åªä¼šåœ¨æ–‡æ¡£çš„å­é›†ä¸Šè¿è¡Œã€‚ä¸è¿‡ï¼Œä½ å¯ä»¥éšæ—¶è‡ªè¡Œåœ¨æ‰€æœ‰æ–‡æ¡£ä¸Šè¿è¡Œå®ƒï¼\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n", "To disable this warning, you can either:\n", "\t- Avoid using `tokenizers` before the fork if possible\n", "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}], "source": ["from llama_index.core.ingestion import IngestionPipeline", "", "import random", "", "random.seed(42)", "# æ³¨é‡Šæ‰ä»¥åœ¨æ‰€æœ‰æ–‡æ¡£ä¸Šè¿è¡Œ", "# åœ¨CPUä¸Šå¤„ç†100ä¸ªæ–‡æ¡£å¤§çº¦éœ€è¦5åˆ†é’Ÿ", "documents = random.sample(documents, 100)", "", "pipeline = IngestionPipeline(transformations=transformations)", "", "nodes = pipeline.run(documents=documents)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### æ£€æŸ¥è¾“å‡ºç»“æœ\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'page_label': '387', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}\n", "{'page_label': '410', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf', 'entities': {'Parmesan', 'Boyd', 'Riebesell', 'Gattuso'}}\n", "{'page_label': '391', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf', 'entities': {'Gulev', 'Fox-Kemper'}}\n", "{'page_label': '430', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf', 'entities': {'Kessouri', 'van der Sleen', 'Brodeur', 'Siedlecki', 'Fiechter', 'Ramajo', 'Carozza'}}\n", "{'page_label': '388', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}\n"]}], "source": ["samples = random.sample(nodes, 5)\n", "for node in samples:\n", "    print(node.metadata)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## å°è¯•ä¸€ä¸ªæŸ¥è¯¢ï¼\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex\n", "from llama_index.llms.openai import OpenAI\n", "from llama_index.core import Settings\n", "\n", "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.2)\n", "\n", "index = VectorStoreIndex(nodes=nodes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["According to the provided context information, Fox-Kemper is mentioned in relation to the observed and projected trends of ocean warming and marine heatwaves. It is stated that Fox-Kemper et al. (2021) reported that ocean warming has increased on average by 0.88Â°C from 1850-1900 to 2011-2020. Additionally, it is mentioned that Fox-Kemper et al. (2021) projected that ocean warming will continue throughout the 21st century, with the rate of global ocean warming becoming scenario-dependent from the mid-21st century. Fox-Kemper is also cited as a source for the information on the increasing frequency, intensity, and duration of marine heatwaves over the 20th and early 21st centuries, as well as the projected increase in frequency of marine heatwaves in the future.\n"]}], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"What is said by Fox-Kemper?\")\n", "print(response)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### æ²¡æœ‰å…ƒæ•°æ®çš„å¯¹æ¯”\n", "\n", "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é‡æ–°æ„å»ºç´¢å¼•ï¼Œä½†æ²¡æœ‰å…ƒæ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'page_label': '542', 'file_name': 'IPCC_AR6_WGII_Chapter03.pdf'}\n"]}], "source": ["for node in nodes:\n", "    node.metadata.pop(\"entities\", None)\n", "\n", "print(nodes[0].metadata)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex(nodes=nodes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["According to the provided context information, Fox-Kemper is mentioned in relation to the decline of the AMOC (Atlantic Meridional Overturning Circulation) over the 21st century. The statement mentions that there is high confidence in the decline of the AMOC, but low confidence for quantitative projections.\n"]}], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"What is said by Fox-Kemper?\")\n", "print(response)"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬çš„å…ƒæ•°æ®ä¸°å¯Œçš„ç´¢å¼•èƒ½å¤Ÿè·å–æ›´å¤šç›¸å…³çš„ä¿¡æ¯ã€‚\n"]}], "metadata": {"kernelspec": {"display_name": "llama-index", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}