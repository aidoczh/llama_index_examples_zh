{"cells": [{"cell_type": "markdown", "id": "4bc26779", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/evaluation/mt_bench_human_judgement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "1c44792f-924f-4aaf-b414-30e23f491454", "metadata": {}, "source": ["# 在MT-Bench人工判断的`LabelledPairwiseEvaluatorDataset`上对LLM评估器进行基准测试\n"]}, {"cell_type": "markdown", "id": "1bfad227-fe26-4cdb-b181-2384e8d1bba0", "metadata": {}, "source": ["在这个笔记本指南中，我们使用稍微调整过的MT-Bench人类评判数据集对Gemini和GPT模型进行基准测试，作为LLM评估器。对于这个数据集，人类评估者会比较两个LLM模型对于给定查询的响应，并根据自己的偏好对它们进行排名。在原始版本中，对于给定的示例（查询，两个模型的响应），可能会有多个人类评估者。然而，在我们考虑的调整版本中，我们会聚合这些“重复”的条目，并将原始模式的“获胜者”列转换为代表“model_a”在所有人类评估者中获胜比例的形式。为了适应llama数据集，并更好地考虑平局（尽管样本较小），我们为这个比例设定了一个不确定性阈值，即如果它在[0.4, 0.6]之间，我们认为两个模型之间没有获胜者。我们从[llama-hub](https://llamahub.ai)下载这个数据集。最后，我们要对以下LLM进行基准测试：\n", "\n", "1. GPT-3.5（OpenAI）\n", "2. GPT-4（OpenAI）\n", "3. Gemini-Pro（Google）\n"]}, {"cell_type": "code", "execution_count": null, "id": "74a734fa", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai\n", "%pip install llama-index-llms-cohere\n", "%pip install llama-index-llms-gemini"]}, {"cell_type": "code", "execution_count": null, "id": "95120632-50cf-4844-bedd-7d31567a0d42", "metadata": {}, "outputs": [], "source": ["!pip install \"google-generativeai\" -q"]}, {"cell_type": "code", "execution_count": null, "id": "b1e0eaca-4eeb-408d-ac89-5eb6338c7694", "metadata": {}, "outputs": [], "source": ["import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "id": "4d117804-1c19-48ca-b995-7e6fbadbb10c", "metadata": {}, "source": ["### 加载数据集\n", "\n", "让我们从llama-hub加载llama数据集。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a168fe64-dd85-4113-8f04-95a221696ed7", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llama_dataset import download_llama_dataset", "", "# 下载数据集", "pairwise_evaluator_dataset, _ = download_llama_dataset(", "    \"MtBenchHumanJudgementDataset\", \"./mt_bench_data\"", ")"]}, {"cell_type": "code", "execution_count": null, "id": "941607dd-99ec-443a-9b46-5e8842a20828", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>query</th>\n", "      <th>answer</th>\n", "      <th>second_answer</th>\n", "      <th>contexts</th>\n", "      <th>ground_truth_answer</th>\n", "      <th>query_by</th>\n", "      <th>answer_by</th>\n", "      <th>second_answer_by</th>\n", "      <th>ground_truth_answer_by</th>\n", "      <th>reference_feedback</th>\n", "      <th>reference_score</th>\n", "      <th>reference_evaluation_by</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Compose an engaging travel blog post about a r...</td>\n", "      <td>I recently had the pleasure of visiting Hawaii...</td>\n", "      <td>Aloha! I recently had the pleasure of embarkin...</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>human</td>\n", "      <td>ai (alpaca-13b)</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>0.0</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Compose an engaging travel blog post about a r...</td>\n", "      <td>I recently had the pleasure of visiting Hawaii...</td>\n", "      <td>Aloha and welcome to my travel blog post about...</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>human</td>\n", "      <td>ai (alpaca-13b)</td>\n", "      <td>ai (vicuna-13b-v1.2)</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>0.0</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Compose an engaging travel blog post about a r...</td>\n", "      <td>Here is a draft travel blog post about a recen...</td>\n", "      <td>I recently had the pleasure of visiting Hawaii...</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>human</td>\n", "      <td>ai (claude-v1)</td>\n", "      <td>ai (alpaca-13b)</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>1.0</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Compose an engaging travel blog post about a r...</td>\n", "      <td>Here is a draft travel blog post about a recen...</td>\n", "      <td>Here is a travel blog post about a recent trip...</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>human</td>\n", "      <td>ai (claude-v1)</td>\n", "      <td>ai (llama-13b)</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>1.0</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Compose an engaging travel blog post about a r...</td>\n", "      <td>Aloha! I recently had the pleasure of embarkin...</td>\n", "      <td>I recently had the pleasure of visiting Hawaii...</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>human</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>ai (alpaca-13b)</td>\n", "      <td>None</td>\n", "      <td>None</td>\n", "      <td>1.0</td>\n", "      <td>human</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                                               query  \\\n", "0  Compose an engaging travel blog post about a r...   \n", "1  Compose an engaging travel blog post about a r...   \n", "2  Compose an engaging travel blog post about a r...   \n", "3  Compose an engaging travel blog post about a r...   \n", "4  Compose an engaging travel blog post about a r...   \n", "\n", "                                              answer  \\\n", "0  I recently had the pleasure of visiting Hawaii...   \n", "1  I recently had the pleasure of visiting Hawaii...   \n", "2  Here is a draft travel blog post about a recen...   \n", "3  Here is a draft travel blog post about a recen...   \n", "4  Aloha! I recently had the pleasure of embarkin...   \n", "\n", "                                       second_answer contexts  \\\n", "0  Aloha! I recently had the pleasure of embarkin...     None   \n", "1  Aloha and welcome to my travel blog post about...     None   \n", "2  I recently had the pleasure of visiting Hawaii...     None   \n", "3  Here is a travel blog post about a recent trip...     None   \n", "4  I recently had the pleasure of visiting Hawaii...     None   \n", "\n", "  ground_truth_answer query_by           answer_by      second_answer_by  \\\n", "0                None    human     ai (alpaca-13b)    ai (gpt-3.5-turbo)   \n", "1                None    human     ai (alpaca-13b)  ai (vicuna-13b-v1.2)   \n", "2                None    human      ai (claude-v1)       ai (alpaca-13b)   \n", "3                None    human      ai (claude-v1)        ai (llama-13b)   \n", "4                None    human  ai (gpt-3.5-turbo)       ai (alpaca-13b)   \n", "\n", "  ground_truth_answer_by reference_feedback  reference_score  \\\n", "0                   None               None              0.0   \n", "1                   None               None              0.0   \n", "2                   None               None              1.0   \n", "3                   None               None              1.0   \n", "4                   None               None              1.0   \n", "\n", "  reference_evaluation_by  \n", "0                   human  \n", "1                   human  \n", "2                   human  \n", "3                   human  \n", "4                   human  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["pairwise_evaluator_dataset.to_pandas()[:5]"]}, {"cell_type": "markdown", "id": "f234425b-1e8d-44e9-ab57-5678df1a112d", "metadata": {}, "source": ["### 定义我们的评估器\n"]}, {"cell_type": "code", "execution_count": null, "id": "92aa0a9d-6005-49fa-9854-e093935657a6", "metadata": {}, "outputs": [], "source": ["from llama_index.core.evaluation import PairwiseComparisonEvaluator\n", "from llama_index.llms.openai import OpenAI\n", "from llama_index.llms.gemini import Gemini\n", "from llama_index.llms.cohere import Cohere\n", "\n", "\n", "llm_gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n", "llm_gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n", "llm_gemini = Gemini(model=\"models/gemini-pro\", temperature=0)\n", "\n", "evaluators = {\n", "    \"gpt-4\": PairwiseComparisonEvaluator(llm=llm_gpt4),\n", "    \"gpt-3.5\": PairwiseComparisonEvaluator(llm=llm_gpt35),\n", "    \"gemini-pro\": PairwiseComparisonEvaluator(llm=llm_gemini),\n", "}"]}, {"cell_type": "markdown", "id": "8be1af05-113f-4886-aa0e-8664f271d8fa", "metadata": {}, "source": ["### 使用`EvaluatorBenchmarkerPack`（llama-pack）进行基准测试\n", "\n", "为了比较我们的四个评估器，我们将它们与`MTBenchHumanJudgementDataset`进行基准测试，其中参考由人类评估者提供。基准测试将返回以下数量：\n", "\n", "- `number_examples`：数据集包含的示例数量。\n", "- `invalid_predictions`：无法产生最终评估的评估数量（例如，由于无法解析评估输出或LLM评估器抛出异常）。\n", "- `inconclusives`：由于这是一种成对比较，为了减少“位置偏见”的风险，我们进行两次评估 —— 一次是按照呈现两个模型答案的原始顺序进行，另一次是按照呈现给评估器LLM的顺序进行翻转。如果LLM评估器在第二个顺序中翻转其投票以与第一次投票相比，则结果是无法确定的。\n", "- `ties`：`PairwiseComparisonEvaluator`也可以返回“平局”结果。这是给出平局结果的示例数量。\n", "- `agreement_rate_with_ties`：LLM评估器在包括平局时与参考（在本例中是人类）评估者达成一致的比率。用于计算此指标的分母为：`number_examples - invalid_predictions - inconclusives`。\n", "- `agreement_rate_without_ties`：LLM评估器在不包括平局时与参考（在本例中是人类）评估者达成一致的比率。用于计算此指标的分母为：`number_examples - invalid_predictions - inconclusives - ties`。\n", "\n", "为了计算这些指标，我们将使用`EvaluatorBenchmarkerPack`。\n"]}, {"cell_type": "code", "execution_count": null, "id": "8296a18a-5119-4271-a74e-4e17c03355fa", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llama_pack import download_llama_pack\n", "\n", "EvaluatorBenchmarkerPack = download_llama_pack(\n", "    \"EvaluatorBenchmarkerPack\", \"./pack\"\n", ")"]}, {"cell_type": "markdown", "id": "592153a3-a082-4391-b071-6402b9ee797a", "metadata": {}, "source": ["GPT-3.5 是 OpenAI 推出的一种自然语言处理模型，它是 GPT-3 的改进版本。这个模型具有更强大的语言理解和生成能力，可以用于各种文本生成任务，如对话系统、文章写作和翻译等。 GPT-3.5 使用了大量的预训练数据和深度学习技术，使其在处理自然语言任务时表现出色。\n"]}, {"cell_type": "code", "execution_count": null, "id": "57cde4d3-aeb1-4d60-88bd-9f058283551d", "metadata": {}, "outputs": [], "source": ["evaluator_benchmarker = EvaluatorBenchmarkerPack(\n", "    evaluator=evaluators[\"gpt-3.5\"],\n", "    eval_dataset=pairwise_evaluator_dataset,\n", "    show_progress=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "0c98d4cd-353f-4753-b520-c4a9f6df9350", "metadata": {}, "outputs": [], "source": ["gpt_3p5_benchmark_df = await evaluator_benchmarker.arun(\n", "    batch_size=100, sleep_time_in_seconds=0\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "e3a5acd5-bd8b-409e-94b0-7a3e6a8bc5df", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>number_examples</th>\n", "      <th>invalid_predictions</th>\n", "      <th>inconclusives</th>\n", "      <th>ties</th>\n", "      <th>agreement_rate_with_ties</th>\n", "      <th>agreement_rate_without_ties</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>gpt-3.5</th>\n", "      <td>1204</td>\n", "      <td>82</td>\n", "      <td>393</td>\n", "      <td>56</td>\n", "      <td>0.736626</td>\n", "      <td>0.793462</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["         number_examples  invalid_predictions  inconclusives  ties  \\\n", "gpt-3.5             1204                   82            393    56   \n", "\n", "         agreement_rate_with_ties  agreement_rate_without_ties  \n", "gpt-3.5                  0.736626                     0.793462  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["gpt_3p5_benchmark_df.index = [\"gpt-3.5\"]\n", "gpt_3p5_benchmark_df"]}, {"cell_type": "markdown", "id": "42c3b1f3-50db-419c-987e-6f74a9e93b46", "metadata": {}, "source": ["GPT-4\n", "\n", "GPT-4是OpenAI公司开发的第四代通用预训练模型。它是一种基于人工智能的语言模型，可以用于生成文本、回答问题和执行其他自然语言处理任务。GPT-4相较于之前的版本在语言理解和生成方面有了显著的改进，能够更准确地理解和生成自然语言。\n"]}, {"cell_type": "code", "execution_count": null, "id": "4122606e-6490-4d65-aaab-a55d4702f604", "metadata": {}, "outputs": [], "source": ["evaluator_benchmarker = EvaluatorBenchmarkerPack(\n", "    evaluator=evaluators[\"gpt-4\"],\n", "    eval_dataset=pairwise_evaluator_dataset,\n", "    show_progress=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "b7381359-ce0b-4a1a-941d-829ce1151e03", "metadata": {}, "outputs": [], "source": ["gpt_4_benchmark_df = await evaluator_benchmarker.arun(\n", "    batch_size=100, sleep_time_in_seconds=0\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "d858adbe-1140-4da9-85fc-5c6f009cb733", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>number_examples</th>\n", "      <th>invalid_predictions</th>\n", "      <th>inconclusives</th>\n", "      <th>ties</th>\n", "      <th>agreement_rate_with_ties</th>\n", "      <th>agreement_rate_without_ties</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>gpt-4</th>\n", "      <td>1204</td>\n", "      <td>0</td>\n", "      <td>100</td>\n", "      <td>103</td>\n", "      <td>0.701087</td>\n", "      <td>0.77023</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["       number_examples  invalid_predictions  inconclusives  ties  \\\n", "gpt-4             1204                    0            100   103   \n", "\n", "       agreement_rate_with_ties  agreement_rate_without_ties  \n", "gpt-4                  0.701087                      0.77023  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["gpt_4_benchmark_df.index = [\"gpt-4\"]\n", "gpt_4_benchmark_df"]}, {"cell_type": "markdown", "id": "b145b017-ebc8-4bf9-8e39-5e6b5b0de8d4", "metadata": {}, "source": ["### Gemini Pro\n", "\n", "注意：Gemini模型的速率限制仍然非常严格，这是可以理解的，因为在撰写本笔记时它们刚刚发布。因此，我们使用非常小的`batch_size`和适度高的`sleep_time_in_seconds`来降低被限制速率的风险。\n"]}, {"cell_type": "code", "execution_count": null, "id": "7af501e5-9c83-4bc2-91c0-85f1f9561506", "metadata": {}, "outputs": [], "source": ["evaluator_benchmarker = EvaluatorBenchmarkerPack(\n", "    evaluator=evaluators[\"gemini-pro\"],\n", "    eval_dataset=pairwise_evaluator_dataset,\n", "    show_progress=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8730b655-917a-4b31-be57-e2397d811567", "metadata": {}, "outputs": [], "source": ["gemini_pro_benchmark_df = await evaluator_benchmarker.arun(\n", "    batch_size=5, sleep_time_in_seconds=0.5\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4853944a-4d88-44cb-8bab-91dcfd99d900", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>number_examples</th>\n", "      <th>invalid_predictions</th>\n", "      <th>inconclusives</th>\n", "      <th>ties</th>\n", "      <th>agreement_rate_with_ties</th>\n", "      <th>agreement_rate_without_ties</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>gemini-pro</th>\n", "      <td>1204</td>\n", "      <td>2</td>\n", "      <td>295</td>\n", "      <td>60</td>\n", "      <td>0.742007</td>\n", "      <td>0.793388</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["            number_examples  invalid_predictions  inconclusives  ties  \\\n", "gemini-pro             1204                    2            295    60   \n", "\n", "            agreement_rate_with_ties  agreement_rate_without_ties  \n", "gemini-pro                  0.742007                     0.793388  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["gemini_pro_benchmark_df.index = [\"gemini-pro\"]\n", "gemini_pro_benchmark_df"]}, {"cell_type": "code", "execution_count": null, "id": "b38099fe-27c6-4f69-b0ce-8f5a853a7679", "metadata": {}, "outputs": [], "source": ["evaluator_benchmarker.prediction_dataset.save_json(\"gemini_predictions.json\")"]}, {"cell_type": "markdown", "id": "1ef51ad4-2f63-4b04-aba3-05676b49d6af", "metadata": {}, "source": ["### 概要\n", "\n", "为了方便起见，让我们将所有的结果放在一个单独的DataFrame中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0f52b919-739f-46b9-812d-715b86f08656", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>number_examples</th>\n", "      <th>invalid_predictions</th>\n", "      <th>inconclusives</th>\n", "      <th>ties</th>\n", "      <th>agreement_rate_with_ties</th>\n", "      <th>agreement_rate_without_ties</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>gpt-3.5</th>\n", "      <td>1204</td>\n", "      <td>82</td>\n", "      <td>393</td>\n", "      <td>56</td>\n", "      <td>0.736626</td>\n", "      <td>0.793462</td>\n", "    </tr>\n", "    <tr>\n", "      <th>gpt-4</th>\n", "      <td>1204</td>\n", "      <td>0</td>\n", "      <td>100</td>\n", "      <td>103</td>\n", "      <td>0.701087</td>\n", "      <td>0.770230</td>\n", "    </tr>\n", "    <tr>\n", "      <th>gemini-pro</th>\n", "      <td>1204</td>\n", "      <td>2</td>\n", "      <td>295</td>\n", "      <td>60</td>\n", "      <td>0.742007</td>\n", "      <td>0.793388</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["            number_examples  invalid_predictions  inconclusives  ties  \\\n", "gpt-3.5                1204                   82            393    56   \n", "gpt-4                  1204                    0            100   103   \n", "gemini-pro             1204                    2            295    60   \n", "\n", "            agreement_rate_with_ties  agreement_rate_without_ties  \n", "gpt-3.5                     0.736626                     0.793462  \n", "gpt-4                       0.701087                     0.770230  \n", "gemini-pro                  0.742007                     0.793388  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "\n", "final_benchmark = pd.concat(\n", "    [\n", "        gpt_3p5_benchmark_df,\n", "        gpt_4_benchmark_df,\n", "        gemini_pro_benchmark_df,\n", "    ],\n", "    axis=0,\n", ")\n", "final_benchmark"]}, {"cell_type": "markdown", "id": "f54852ee-204d-4395-b193-6002a185daf4", "metadata": {}, "source": ["从上面的结果中，我们得出以下观察结果：\n", "- 就一致性率而言，三个模型似乎非常接近，或许Gemini模型稍微领先一些\n", "- Gemini Pro和GPT-3.5似乎比GPT-4更加肯定，导致只有50-60次与GPT-4的100次并列。\n", "- 然而，也许与前一点有关，GPT-4产生的无法确定的情况最少，这意味着它在位置偏见方面受到的影响最小。\n", "- 总的来说，看起来Gemini Pro与GPT模型不相上下，并且可以说它的表现优于GPT-3.5 — 看起来Gemini可以成为评估任务中GPT模型的合法替代品。\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}