{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/evaluation/BeirEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# BEIRé¢†åŸŸå¤–åŸºå‡†æµ‹è¯•\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å…³äº[BEIR](https://github.com/beir-cellar/beir)ï¼š\n", "\n", "BEIRæ˜¯ä¸€ä¸ªåŒ…å«å¤šæ ·åŒ–IRä»»åŠ¡çš„å¼‚æ„åŸºå‡†æµ‹è¯•ã€‚å®ƒè¿˜ä¸ºåœ¨åŸºå‡†æµ‹è¯•ä¸­è¯„ä¼°æ£€ç´¢æ–¹æ³•æä¾›äº†ä¸€ä¸ªé€šç”¨ä¸”ç®€å•çš„æ¡†æ¶ã€‚\n", "\n", "è¯·é€šè¿‡é“¾æ¥å‚è€ƒå­˜å‚¨åº“ä»¥è·å–æ”¯æŒçš„æ•°æ®é›†çš„å®Œæ•´åˆ—è¡¨ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æµ‹è¯•äº†`all-MiniLM-L6-v2`å¥å­è½¬æ¢å™¨åµŒå…¥ï¼Œè¿™æ˜¯åœ¨ç»™å®šå‡†ç¡®æ€§èŒƒå›´å†…é€Ÿåº¦æœ€å¿«çš„ä¹‹ä¸€ã€‚æˆ‘ä»¬å°†æ£€ç´¢å™¨çš„top_kå€¼è®¾ç½®ä¸º30ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨äº†nfcorpusæ•°æ®é›†ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-huggingface"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/jonch/.pyenv/versions/3.10.6/lib/python3.10/site-packages/beir/datasets/data_loader.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from tqdm.autonotebook import tqdm\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Dataset: nfcorpus downloaded at: /home/jonch/.cache/llama_index/datasets/BeIR__nfcorpus\n", "Evaluating on dataset: nfcorpus\n", "-------------------------------------\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3633/3633 [00:00<00:00, 141316.79it/s]\n", "Parsing documents into nodes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3633/3633 [00:06<00:00, 569.35it/s]\n", "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3649/3649 [04:22<00:00, 13.92it/s]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Retriever created for:  nfcorpus\n", "Evaluating retriever on questions against qrels\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 323/323 [01:26<00:00,  3.74it/s]"]}, {"name": "stdout", "output_type": "stream", "text": ["Results for: nfcorpus\n", "{'NDCG@3': 0.35476, 'MAP@3': 0.07489, 'Recall@3': 0.08583, 'precision@3': 0.33746}\n", "{'NDCG@10': 0.31403, 'MAP@10': 0.11003, 'Recall@10': 0.15885, 'precision@10': 0.23994}\n", "{'NDCG@30': 0.28636, 'MAP@30': 0.12794, 'Recall@30': 0.21653, 'precision@30': 0.14716}\n", "-------------------------------------\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n", "from llama_index.core.evaluation.benchmarks import BeirEvaluator\n", "from llama_index.core import VectorStoreIndex\n", "\n", "\n", "def create_retriever(documents):\n", "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n", "    index = VectorStoreIndex.from_documents(\n", "        documents, embed_model=embed_model, show_progress=True\n", "    )\n", "    return index.as_retriever(similarity_top_k=30)\n", "\n", "\n", "BeirEvaluator().run(\n", "    create_retriever, datasets=[\"nfcorpus\"], metrics_k_values=[3, 10, 30]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡éƒ½æ˜¯è¶Šé«˜è¶Šå¥½ã€‚\n", "\n", "è¿™ç¯‡[towardsdatascienceæ–‡ç« ](https://towardsdatascience.com/ranking-evaluation-metrics-for-recommender-systems-263d0a66ef54)æ›´æ·±å…¥åœ°ä»‹ç»äº†NDCGã€MAPå’ŒMRRã€‚\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}