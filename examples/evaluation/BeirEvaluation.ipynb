{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/evaluation/BeirEvaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# BEIR领域外基准测试\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["关于[BEIR](https://github.com/beir-cellar/beir)：\n", "\n", "BEIR是一个包含多样化IR任务的异构基准测试。它还为在基准测试中评估检索方法提供了一个通用且简单的框架。\n", "\n", "请通过链接参考存储库以获取支持的数据集的完整列表。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["在这里，我们测试了`all-MiniLM-L6-v2`句子转换器嵌入，这是在给定准确性范围内速度最快的之一。我们将检索器的top_k值设置为30。我们还使用了nfcorpus数据集。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-huggingface"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/home/jonch/.pyenv/versions/3.10.6/lib/python3.10/site-packages/beir/datasets/data_loader.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from tqdm.autonotebook import tqdm\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Dataset: nfcorpus downloaded at: /home/jonch/.cache/llama_index/datasets/BeIR__nfcorpus\n", "Evaluating on dataset: nfcorpus\n", "-------------------------------------\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|███████████████████████████████████| 3633/3633 [00:00<00:00, 141316.79it/s]\n", "Parsing documents into nodes: 100%|████████| 3633/3633 [00:06<00:00, 569.35it/s]\n", "Generating embeddings: 100%|████████████████| 3649/3649 [04:22<00:00, 13.92it/s]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Retriever created for:  nfcorpus\n", "Evaluating retriever on questions against qrels\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|█████████████████████████████████████████| 323/323 [01:26<00:00,  3.74it/s]"]}, {"name": "stdout", "output_type": "stream", "text": ["Results for: nfcorpus\n", "{'NDCG@3': 0.35476, 'MAP@3': 0.07489, 'Recall@3': 0.08583, 'precision@3': 0.33746}\n", "{'NDCG@10': 0.31403, 'MAP@10': 0.11003, 'Recall@10': 0.15885, 'precision@10': 0.23994}\n", "{'NDCG@30': 0.28636, 'MAP@30': 0.12794, 'Recall@30': 0.21653, 'precision@30': 0.14716}\n", "-------------------------------------\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n", "from llama_index.core.evaluation.benchmarks import BeirEvaluator\n", "from llama_index.core import VectorStoreIndex\n", "\n", "\n", "def create_retriever(documents):\n", "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n", "    index = VectorStoreIndex.from_documents(\n", "        documents, embed_model=embed_model, show_progress=True\n", "    )\n", "    return index.as_retriever(similarity_top_k=30)\n", "\n", "\n", "BeirEvaluator().run(\n", "    create_retriever, datasets=[\"nfcorpus\"], metrics_k_values=[3, 10, 30]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["所有评估指标都是越高越好。\n", "\n", "这篇[towardsdatascience文章](https://towardsdatascience.com/ranking-evaluation-metrics-for-recommender-systems-263d0a66ef54)更深入地介绍了NDCG、MAP和MRR。\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}