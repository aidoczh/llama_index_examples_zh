{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# ä½¿ç”¨NVIDIAçš„LLM APIç›®å½•è¿æ¥å™¨\n", "\n", "æœ¬ç¬”è®°æœ¬å°†æŒ‡å¯¼æ‚¨äº†è§£`NVIDIA`è¿æ¥å™¨çš„åŸºæœ¬ç”¨æ³•ã€‚\n", "\n", "é€šè¿‡è¿™ä¸ªè¿æ¥å™¨ï¼Œæ‚¨å°†èƒ½å¤Ÿè¿æ¥åˆ°NVIDIAçš„[APIç›®å½•](https://build.nvidia.com/explore/discover)ä¸­å¯ç”¨çš„å…¼å®¹æ¨¡å‹ï¼Œå¹¶ç”Ÿæˆæ¨¡å‹ï¼Œä¾‹å¦‚ï¼š\n", "\n", "- Googleçš„[gemma-7b](https://build.nvidia.com/google/gemma-7b)\n", "- Mistal AIçš„[mistral-7b-instruct-v0.2](https://build.nvidia.com/mistralai/mistral-7b-instruct-v2)\n", "- ç­‰ç­‰ï¼\n", "\n", "æˆ‘ä»¬å°†é¦–å…ˆç¡®ä¿å®‰è£…äº†`llama-index`å’Œç›¸å…³è½¯ä»¶åŒ…ã€‚\n", "\n", "> æ³¨æ„ï¼šç›®å‰ï¼Œåªæœ‰åŸºæœ¬URLä¸º`https://integrate.api.nvidia.com/v1`çš„æ¨¡å‹ä¸æ­¤è¿æ¥å™¨å…¼å®¹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Collecting llama-index-embeddings-openai\n", "  Using cached llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n", "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-embeddings-openai) (0.10.30)\n", "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n", "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.29)\n", "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.5)\n", "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.4)\n", "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n", "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n", "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.3.1)\n", "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n", "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.1.18)\n", "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n", "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.1)\n", "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n", "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.24.4)\n", "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.22.0)\n", "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.3)\n", "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (10.3.0)\n", "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.31.0)\n", "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.2.3)\n", "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n", "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.2)\n", "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.11.0)\n", "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n", "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n", "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n", "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2.0)\n", "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n", "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n", "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n", "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.7.0)\n", "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.3.0)\n", "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.2.2)\n", "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n", "Requirement already satisfied: idna in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7)\n", "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n", "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n", "Requirement already satisfied: click in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n", "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.0)\n", "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.4.16)\n", "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.0)\n", "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n", "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.2.1)\n", "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n", "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n", "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.1)\n", "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.9.0.post0)\n", "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n", "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n", "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.0)\n", "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n", "Requirement already satisfied: pydantic-core==2.18.1 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.18.1)\n", "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/nvidia-llama-index-api/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n", "Using cached llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n", "Installing collected packages: llama-index-embeddings-openai\n", "Successfully installed llama-index-embeddings-openai-0.1.7\n"]}], "source": ["!pip install llama-index-embeddings-openai llama-index-readers-file"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## APIå¯†é’¥å’Œæ ·æ¿æ–‡ä»¶\n", "\n", "åœ¨ä¸‹ä¸€ä¸ªå•å…ƒæ ¼ä¸­ï¼Œæˆ‘ä»¬å°†è¿è¡Œä¸€äº›æ ·æ¿æ–‡ä»¶ï¼Œä»¥ä¾¿åœ¨ç¬”è®°æœ¬ç¯å¢ƒä¸­é¡ºåˆ©æ‰§è¡Œç¤ºä¾‹ã€‚\n", "\n", "æˆ‘ä»¬è¿˜å°†æä¾›æˆ‘ä»¬çš„APIå¯†é’¥ã€‚\n", "\n", "> æ³¨æ„ï¼šæ‚¨å¯ä»¥ä½¿ç”¨ä»£ç ç¤ºä¾‹çª—å£ä¸­çš„â€œè·å–APIå¯†é’¥â€æŒ‰é’®åˆ›å»ºæ‚¨è‡ªå·±çš„NVIDIA APIå¯†é’¥ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# llama-parseæ˜¯å¼‚æ­¥ä¼˜å…ˆçš„ï¼Œè¿è¡Œç¬”è®°æœ¬ä¸­çš„å¼‚æ­¥ä»£ç éœ€è¦ä½¿ç”¨nest_asyncio", "import nest_asyncio", "", "nest_asyncio.apply()", "", "import os", "", "# ä½¿ç”¨OpenAI APIè¿›è¡ŒåµŒå…¥", "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"", "", "# ä½¿ç”¨NVIDIA API Playground APIå¯†é’¥è¿›è¡ŒLLM", "os.environ[\"NVIDIA_API_KEY\"] = \"nvapi-\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## åŠ è½½NVIDIA LLM\n", "\n", "ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¼ å…¥æ¨¡å‹åç§°æ¥åŠ è½½æˆ‘ä»¬çš„`NVIDIA` LLMï¼Œæ¨¡å‹åç§°å¯ä»¥åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ° - ä½äº[è¿™é‡Œ](https://docs.api.nvidia.com/nim/reference/)\n", "\n", "> æ³¨æ„ï¼šé»˜è®¤æ¨¡å‹æ˜¯`mistralai/mistral-7b-instruct-v0.2`ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.llms.nvidia import NVIDIA\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.core import Settings\n", "\n", "llm = NVIDIA(model=\"mistralai/mistral-7b-instruct-v0.2\")\n", "\n", "Settings.llm = llm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿæˆ‘ä»¬çš„ `llm` å¯¹è±¡å½“å‰å…³è”çš„æ¨¡å‹æ˜¯å“ªä¸ªï¼Œé€šè¿‡æŸ¥çœ‹ `.model` å±æ€§ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["'mistralai/mistral-7b-instruct-v0.2'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["llm.model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## åŠ è½½APIç›®å½• LLM\n", "\n", "æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨å®ƒä»¬çš„APIç›®å½•åœ°å€æ¥åŠ è½½æ¨¡å‹ã€‚\n", "\n", "è®©æˆ‘ä»¬ä»¥`gemma-7b`ä¸ºä¾‹ï¼\n", "\n", "1. è½¬åˆ°[modelé¡µé¢](https://build.nvidia.com/google/gemma-7b)\n", "2. åœ¨`model`å‚æ•°ä¸­æ‰¾åˆ°åœ°å€ï¼ˆä¾‹å¦‚`\"google/gemma-7b\"`ï¼‰\n", "3. éªŒè¯å®ƒå…·æœ‰`base_url`ä¸º`\"https://integrate.api.nvidia.com/v1\"`\n", "4. ä½¿ç”¨`NVIDIA(model=\"model_name_here\")`æ¥æŒ‡å‘è¯¥æ¨¡å‹çš„è¿æ¥å™¨ï¼ˆä¾‹å¦‚`NVIDIA(model=\"google/gemma-7b\"`ï¼‰\n", "\n", "è®©æˆ‘ä»¬åœ¨ä»£ç ä¸­çœ‹çœ‹è¿™ä¸ªã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["llm = NVIDIA(model=\"google/gemma-7b\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["è®©æˆ‘ä»¬ç¡®è®¤ä¸€ä¸‹æˆ‘ä»¬æ˜¯å¦å°† `NvidiaAIPlayground` LLM ä¸æ­£ç¡®çš„æ¨¡å‹å…³è”èµ·æ¥äº†ï¼\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["'google/gemma-7b'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["llm.model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## åŸºæœ¬åŠŸèƒ½\n", "\n", "ç°åœ¨æˆ‘ä»¬å¯ä»¥æ¢ç´¢åœ¨LlamaIndexç”Ÿæ€ç³»ç»Ÿä¸­å¯ä»¥ä½¿ç”¨è¿æ¥å™¨çš„ä¸åŒæ–¹å¼ï¼\n", "\n", "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬è®¾ç½®ä¸€ä¸ª`ChatMessage`å¯¹è±¡çš„åˆ—è¡¨ - è¿™æ˜¯ä¸€äº›æ–¹æ³•çš„é¢„æœŸè¾“å…¥ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.llms import ChatMessage, MessageRole\n", "\n", "chat_messages = [\n", "    ChatMessage(\n", "        role=MessageRole.SYSTEM, content=(\"You are a helpful assistant.\")\n", "    ),\n", "    ChatMessage(\n", "        role=MessageRole.USER,\n", "        content=(\"What are the most popular house pets in North America?\"),\n", "    ),\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æˆ‘ä»¬å°†æŒ‰ç…§æ¯ä¸ªç¤ºä¾‹ç›¸åŒçš„åŸºæœ¬æ¨¡å¼è¿›è¡Œæ“ä½œï¼š\n", "\n", "1. æˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„ `NVIDIA` LLM æŒ‡å‘æˆ‘ä»¬æƒ³è¦çš„æ¨¡å‹\n", "2. æˆ‘ä»¬å°†æ£€æŸ¥å¦‚ä½•ä½¿ç”¨ç«¯ç‚¹æ¥å®ç°æœŸæœ›çš„ä»»åŠ¡ï¼\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### å®Œæˆï¼š`.complete()`\n", "\n", "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`.complete()`/`.acomplete()`ï¼ˆæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ï¼‰æ¥ä»æ‰€é€‰æ¨¡å‹ä¸­è·å–å“åº”ã€‚\n", "\n", "è®©æˆ‘ä»¬ä¸ºè¿™ä¸ªä»»åŠ¡ä½¿ç”¨æˆ‘ä»¬çš„é»˜è®¤æ¨¡å‹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["completion_llm = NVIDIA()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æˆ‘ä»¬å¯ä»¥é€šè¿‡æ£€æŸ¥`.model`å±æ€§æ¥éªŒè¯è¿™æ˜¯å¦æ˜¯é¢„æœŸçš„é»˜è®¤å€¼ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["'mistralai/mistral-7b-instruct-v0.2'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["completion_llm.model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["è®©æˆ‘ä»¬åœ¨æ¨¡å‹ä¸Šè°ƒç”¨`.complete()`æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨å­—ç¬¦ä¸²`\"Hello!\"`ä½œä¸ºè¾“å…¥ï¼Œè§‚å¯Ÿå“åº”ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["CompletionResponse(text=\" Hello there! How can I help you today? I'm here to answer any questions you might have or provide information on a wide range of topics. So, feel free to ask me anything!\\n\\nIf you're looking for some general information, I can help you with that too. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some general information, I can provide you with that as well. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some general information, I can provide you with that as well. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some general information, I can provide you with that as well. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some\", additional_kwargs={}, raw={'id': 'chatcmpl-f6906079-51e7-44bf-aaea-a9478397dfbf', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=\" Hello there! How can I help you today? I'm here to answer any questions you might have or provide information on a wide range of topics. So, feel free to ask me anything!\\n\\nIf you're looking for some general information, I can help you with that too. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some general information, I can provide you with that as well. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some general information, I can provide you with that as well. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some general information, I can provide you with that as well. For example, I can tell you about the weather, current events, or provide definitions for various words and concepts. I can also help you with math problems, translate words and phrases, and even tell you a joke or two!\\n\\nSo, what would you like to know? Let me know and I'll do my best to help you out!\\n\\nIf you have any specific question or topic in mind, please let me know and I'll be glad to help you out. If you want some\", role='assistant', function_call=None, tool_calls=None))], 'created': 1713474670, 'model': 'mistralai/mistral-7b-instruct-v0.2', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=512, prompt_tokens=11, total_tokens=523)}, logprobs=None, delta=None)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["completion_llm.complete(\"Hello!\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æ­£å¦‚LlamaIndexæ‰€æœŸæœ›çš„é‚£æ · - æˆ‘ä»¬ä¼šæ”¶åˆ°ä¸€ä¸ª`CompletionResponse`ä½œä¸ºå“åº”ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### å¼‚æ­¥å®Œæˆï¼š`.acomplete()`\n", "\n", "è¿˜æœ‰ä¸€ä¸ªå¯ä»¥ä»¥ç›¸åŒæ–¹å¼åˆ©ç”¨çš„å¼‚æ­¥å®ç°ï¼\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["CompletionResponse(text=\" Hello there! How can I help you today? I'm here to answer any questions you might have or provide information on a wide range of topics. So feel free to ask me anything!\\n\\nIf you're looking for a specific topic, just let me know and I'll do my best to provide you with accurate and up-to-date information. And if you have any requests for fun facts or trivia, I'm happy to oblige!\\n\\nSo, what would you like to know today? Let me help make your day a little brighter! ğŸ˜Š\", additional_kwargs={}, raw={'id': 'chatcmpl-8ce881c1-a47b-43aa-afd8-9e9addf26ce9', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=\" Hello there! How can I help you today? I'm here to answer any questions you might have or provide information on a wide range of topics. So feel free to ask me anything!\\n\\nIf you're looking for a specific topic, just let me know and I'll do my best to provide you with accurate and up-to-date information. And if you have any requests for fun facts or trivia, I'm happy to oblige!\\n\\nSo, what would you like to know today? Let me help make your day a little brighter! ğŸ˜Š\", role='assistant', function_call=None, tool_calls=None))], 'created': 1712175910, 'model': 'mistralai/mistral-7b-instruct-v0.2', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=123, prompt_tokens=11, total_tokens=134)}, logprobs=None, delta=None)"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["await completion_llm.acomplete(\"Hello!\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### èŠå¤©ï¼š`.chat()`\n", "\n", "ç°åœ¨æˆ‘ä»¬å¯ä»¥å°è¯•ä½¿ç”¨`.chat()`æ–¹æ³•æ¥åšåŒæ ·çš„äº‹æƒ…ã€‚è¿™ä¸ªæ–¹æ³•éœ€è¦ä¸€ä¸ªèŠå¤©æ¶ˆæ¯çš„åˆ—è¡¨ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„é‚£ä¸ªåˆ—è¡¨ã€‚\n", "\n", "æˆ‘ä»¬å°†ä½¿ç”¨`mistralai/mixtral-8x7b-instruct-v0.1`æ¨¡å‹ä½œä¸ºç¤ºä¾‹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["chat_llm = NVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ç°åœ¨æˆ‘ä»¬åªéœ€è¦åœ¨æˆ‘ä»¬çš„`ChatMessages`åˆ—è¡¨ä¸Šè°ƒç”¨`.chat()`ï¼Œç„¶åè§‚å¯Ÿæˆ‘ä»¬çš„å“åº”ã€‚\n", "\n", "æ‚¨è¿˜ä¼šæ³¨æ„åˆ°ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥ä¸€äº›é¢å¤–çš„å…³é”®å­—å‚æ•°æ¥å½±å“ç”Ÿæˆè¿‡ç¨‹ - åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†`seed`å‚æ•°æ¥å½±å“æˆ‘ä»¬çš„ç”Ÿæˆï¼Œä»¥åŠ`stop`å‚æ•°æ¥æŒ‡ç¤ºæˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨è¾¾åˆ°ç‰¹å®šæ ‡è®°æ—¶åœæ­¢ç”Ÿæˆï¼\n", "\n", "> æ³¨æ„ï¼šæ‚¨å¯ä»¥åœ¨æ‰€é€‰æ¨¡å‹çš„APIæ–‡æ¡£ä¸­æ‰¾åˆ°æœ‰å…³æ¨¡å‹ç«¯ç‚¹æ”¯æŒçš„å…¶ä»–kwargsçš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼ŒMixtralçš„APIæ–‡æ¡£ä½äº[æ­¤å¤„](https://docs.api.nvidia.com/nim/reference/mistralai-mixtral-8x7b-instruct-infer)ï¼\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\" In North America, the most popular types of house pets are:\\n\\n1. Dogs: Man's best friend is the most popular pet in North America. They are known for their loyalty, companionship, and the variety of breeds that cater to different lifestyles and preferences.\\n\\n2. Cats\", additional_kwargs={}), raw={'id': 'chatcmpl-b6ef95ca-e023-4dc8-8ee9-843f214169e9', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=\" In North America, the most popular types of house pets are:\\n\\n1. Dogs: Man's best friend is the most popular pet in North America. They are known for their loyalty, companionship, and the variety of breeds that cater to different lifestyles and preferences.\\n\\n2. Cats\", role='assistant', function_call=None, tool_calls=None))], 'created': 1713474655, 'model': 'mistralai/mixtral-8x7b-instruct-v0.1', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=66, prompt_tokens=26, total_tokens=92)}, delta=None, logprobs=None, additional_kwargs={})"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["chat_llm.chat(chat_messages, seed=4, stop=[\"cat\", \"cats\", \"Cat\", \"Cats\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["å¦‚é¢„æœŸï¼Œæˆ‘ä»¬æ”¶åˆ°äº†ä¸€ä¸ª`ChatResponse`ä½œä¸ºå“åº”ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### å¼‚æ­¥èŠå¤©ï¼š(`achat`)\n", "\n", "æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªå¼‚æ­¥å®ç°çš„`.chat()`æ–¹æ³•ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼è°ƒç”¨ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=' The most popular house pets in North America are dogs and cats. According to the American Pet Products Association (APPA), as of 2021, approximately 69 million homes in the United States own a pet, and 63.4 million of those households have a dog, while 42.7 million have a cat. Birds, small mammals, reptiles, and fish are also popular pets, but to a lesser extent.', additional_kwargs={}), raw={'id': 'chatcmpl-373a1d42-4dc1-4ef9-aaf3-5fea137e8e1e', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=' The most popular house pets in North America are dogs and cats. According to the American Pet Products Association (APPA), as of 2021, approximately 69 million homes in the United States own a pet, and 63.4 million of those households have a dog, while 42.7 million have a cat. Birds, small mammals, reptiles, and fish are also popular pets, but to a lesser extent.', role='assistant', function_call=None, tool_calls=None))], 'created': 1712177472, 'model': 'mistralai/mixtral-8x7b-instruct-v0.1', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=95, prompt_tokens=59, total_tokens=154)}, delta=None, logprobs=None, additional_kwargs={})"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["await chat_llm.achat(chat_messages)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### æµï¼š`.stream_chat()`\n", "\n", "æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨åœ¨`build.nvidia.com`ä¸Šæ‰¾åˆ°çš„æ¨¡å‹æ¥è¿›è¡Œæµå¼ä½¿ç”¨æ¡ˆä¾‹ï¼\n", "\n", "è®©æˆ‘ä»¬é€‰æ‹©å¦ä¸€ä¸ªæ¨¡å‹å¹¶è§‚å¯Ÿå…¶è¡Œä¸ºã€‚æˆ‘ä»¬å°†ä½¿ç”¨è°·æ­Œçš„`gemma-7b`æ¨¡å‹æ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stream_llm = NVIDIA(model=\"google/gemma-7b\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["è®©æˆ‘ä»¬ä½¿ç”¨`.stream_chat()`æ¥è°ƒç”¨æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå®ƒå†æ¬¡æœŸæœ›ä¸€ä¸ª`ChatMessage`å¯¹è±¡çš„åˆ—è¡¨ï¼Œå¹¶æ•è·å“åº”ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["streamed_response = stream_llm.stream_chat(chat_messages)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["<generator object llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat.<locals>.wrapped_gen at 0x7dd89853e320>"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["streamed_response"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œå“åº”æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œå…¶ä¸­åŒ…å«æµå¼å“åº”ã€‚\n", "\n", "è®©æˆ‘ä»¬åœ¨ç”Ÿæˆå®ŒæˆåæŸ¥çœ‹æœ€ç»ˆçš„å“åº”ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["assistant: **Top Popular House Pets in North America:**\n", "\n", "**1. Dogs:**\n", "* Estimated 63.4 million pet dogs in households (2023)\n", "* Known for their loyalty, companionship, and trainability\n", "\n", "**2. Cats:**\n", "* Estimated 38.4 million pet cats in households (2023)\n", "* Known for their independence, affection, and low-maintenance nature\n", "\n", "**3. Fish:**\n", "* Estimated 14.5 million pet fish in households (2023)\n", "* Popular for their tranquility, beauty, and variety of species\n", "\n", "**4. Small mammals (guinea pigs, hamsters, rabbits):**\n", "* Estimated 14.4 million pet small mammals in households (2023)\n", "* Known for their playful and affectionate nature\n", "\n", "**5. Birds:**\n", "* Estimated 13.3 million pet birds in households (2023)\n", "* Known for their beauty, song, and intelligence\n", "\n", "**Other popular pets:**\n", "\n", "* Tortoises and reptiles\n", "* Hamsters and rodents\n", "* Invertebrates (such as spiders and hermit crabs)\n", "\n", "**Factors influencing pet popularity:**\n", "\n", "* **Lifestyle and living situation:** Urban dwellers are more likely to have cats, while suburban and rural residents are more likely to have dogs.\n", "* **Cost:** Dogs tend to be more expensive to own than cats.\n", "* **Personality and preferences:** Some people prefer the companionship of dogs, while others prefer the independence of cats.\n", "* **Availability:** Certain pets are easier to find or adopt than others.\n", "* **Trend and cultural influences:** Some pets become more popular than others due to trends or cultural preferences.\n"]}], "source": ["last_element = None\n", "for last_element in streamed_response:\n", "    pass\n", "\n", "print(last_element)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### å¼‚æ­¥æµï¼š`.astream_chat()`\n", "\n", "æˆ‘ä»¬ä¹Ÿæœ‰ä¸æµå¼å¤„ç†ç­‰æ•ˆçš„å¼‚æ­¥æ–¹æ³•ï¼Œå¯ä»¥ä»¥ç±»ä¼¼çš„æ–¹å¼ç”¨äºåŒæ­¥å®ç°ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["streamed_response = await stream_llm.astream_chat(chat_messages)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["<async_generator object llm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat.<locals>.wrapped_gen at 0x787709eea460>"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["streamed_response"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["assistant: Sure, here are the most popular house pets in North America:\n", "\n", "1. Dogs\n", "2. Cats\n", "3. Fish\n", "4. Small Mammals\n", "5. Birds\n"]}], "source": ["last_element = None\n", "async for last_element in streamed_response:\n", "    pass\n", "\n", "print(last_element)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## æµå¼æŸ¥è¯¢å¼•æ“å“åº”\n", "\n", "è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„ä¾‹å­ï¼Œä½¿ç”¨ä¸€ä¸ªæŸ¥è¯¢å¼•æ“ï¼\n", "\n", "æˆ‘ä»¬å°†ä»åŠ è½½ä¸€äº›æ•°æ®å¼€å§‹ï¼ˆæˆ‘ä»¬å°†ä½¿ç”¨[ã€Šé“¶æ²³ç³»æ¼«æ¸¸æŒ‡å—ã€‹](https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt)ï¼‰ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### åŠ è½½æ•°æ®\n", "\n", "è®©æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªç›®å½•ï¼Œç”¨æ¥å­˜æ”¾æˆ‘ä»¬çš„æ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/hhgttg'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æˆ‘ä»¬å°†ä»ä¸Šè¿°æ¥æºä¸‹è½½æˆ‘ä»¬çš„æ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2024-04-01 14:39:38--  https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt\n", "Resolving web.eecs.utk.edu (web.eecs.utk.edu)... 160.36.127.165\n", "Connecting to web.eecs.utk.edu (web.eecs.utk.edu)|160.36.127.165|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 1534289 (1.5M) [text/plain]\n", "Saving to: â€˜data/hhgttg/hhgttg.txtâ€™\n", "\n", "data/hhgttg/hhgttg. 100%[===================>]   1.46M  6.75MB/s    in 0.2s    \n", "\n", "2024-04-01 14:39:39 (6.75 MB/s) - â€˜data/hhgttg/hhgttg.txtâ€™ saved [1534289/1534289]\n", "\n"]}], "source": ["!wget 'https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt' -O 'data/hhgttg/hhgttg.txt'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["æˆ‘ä»¬éœ€è¦ä¸ºè¿™ä¸€æ­¥å‡†å¤‡ä¸€ä¸ªåµŒå…¥æ¨¡å‹ï¼æˆ‘ä»¬å°†ä½¿ç”¨OpenAIçš„`text-embedding-03-small`æ¨¡å‹æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå¹¶å°†å…¶ä¿å­˜åœ¨æˆ‘ä»¬çš„`Settings`ä¸­ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.embeddings.openai import OpenAIEmbedding\n", "\n", "openai_embedding = OpenAIEmbedding(model=\"text-embedding-3-small\")\n", "\n", "Settings.embed_model = openai_embedding"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ç°åœ¨æˆ‘ä»¬å¯ä»¥åŠ è½½æˆ‘ä»¬çš„æ–‡æ¡£ï¼Œå¹¶åˆ©ç”¨ä¸Šé¢åˆ›å»ºçš„ `OpenAIEmbedding()` åˆ›å»ºä¸€ä¸ªç´¢å¼•ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "\n", "documents = SimpleDirectoryReader(\"data/hhgttg\").load_data()\n", "index = VectorStoreIndex.from_documents(documents)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ç°åœ¨æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç®€å•çš„æŸ¥è¯¢å¼•æ“ï¼Œå¹¶å°†æˆ‘ä»¬çš„ `streaming` å‚æ•°è®¾ç½®ä¸º `True`ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["streaming_qe = index.as_query_engine(streaming=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["è®©æˆ‘ä»¬å‘æŸ¥è¯¢å¼•æ“å‘é€ä¸€ä¸ªæŸ¥è¯¢ï¼Œç„¶åæµå¼ä¼ è¾“å“åº”ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["streaming_response = streaming_qe.query(\n", "    \"What is the significance of the number 42?\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The significance of the number 42 is a central theme in \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams. The book is a comedic science fiction satire that follows the adventures of two intergalactic travelers, Arthur Dent and Ford Prefect, as they try to escape the destruction of Earth and uncover the true meaning of the number 42.\n", "\n", "Throughout the book, the number 42 is presented as the ultimate answer to the ultimate question of life, the universe, and everything. The question itself is never explicitly stated, but it is implied to be a deeply profound and existential one that has been sought after by philosophers, scientists, and thinkers throughout history.\n", "\n", "The idea of the number 42 as the ultimate answer is a playful jab at the idea of seeking ultimate knowledge and understanding, which is often seen as an impossible task. The number 42 is also a reference to the famous \"42\" answer in the \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, which is a comedic science fiction satire that follows the adventures of two intergalactic travelers, Arthur Dent and Ford Prefect, as they try to escape the destruction of Earth and uncover the true meaning of the number 42.\n", "\n", "In the book, the supercomputer Deep Thought is asked to find the answer to the ultimate question, and after billions of years of computation, it determines that the answer is 42. The answer is so profound that it causes Deep Thought to become obsolete, as it is no longer needed to answer questions.\n", "\n", "The significance of the number 42 in \"The Hitchhiker's Guide to the Galaxy\" is a commentary on the nature of knowledge and the quest for ultimate understanding. It is a reminder that there are limits to what can be known and that the pursuit of knowledge should be done with a sense of humor and a willingness to accept the unknown."]}], "source": ["streaming_response.print_response_stream()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## è¿æ¥æœ¬åœ°NIMs\n", "\n", "é™¤äº†è¿æ¥åˆ°æ‰˜ç®¡çš„[NVIDIA NIMs](https://ai.nvidia.com)ä¹‹å¤–ï¼Œæ­¤è¿æ¥å™¨è¿˜å¯ä»¥ç”¨äºè¿æ¥åˆ°æœ¬åœ°å¾®æœåŠ¡å®ä¾‹ã€‚è¿™æœ‰åŠ©äºåœ¨å¿…è¦æ—¶å°†æ‚¨çš„åº”ç”¨ç¨‹åºéƒ¨ç½²åˆ°æœ¬åœ°ã€‚\n", "\n", "æœ‰å…³è®¾ç½®æœ¬åœ°å¾®æœåŠ¡å®ä¾‹çš„è¯´æ˜ï¼Œè¯·å‚é˜…https://developer.nvidia.com/blog/nvidia-nim-offers-optimized-inference-microservices-for-deploying-ai-models-at-scale/\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.llms.nvidia import NVIDIA\n", "\n", "llm = NVIDIA(model=\"...\").mode(\"nim\", base_url=\"https://localhost.../v1\")\n", "llm.available_models"]}], "metadata": {"kernelspec": {"display_name": "nvidia-llama-index-playground-connector", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}