{"cells": [{"cell_type": "markdown", "id": "9fd54a32", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/llm/fireworks_cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "9e3a8796-edc8-43f2-94ad-fe4fb20d70ed", "metadata": {}, "source": ["# Fireworks函数调用手册\n", "\n", "Fireworks.ai支持对其LLMs进行函数调用，类似于OpenAI。这使用户可以直接描述可用的工具/函数集，并使模型动态选择正确的函数调用来调用，而无需用户复杂的提示。\n", "\n", "由于我们的Fireworks LLM直接是OpenAI的子类，因此我们可以在Fireworks中使用现有的抽象。\n", "\n", "我们将在三个层面上展示这一点：直接在模型API上，作为Pydantic程序的一部分（结构化输出提取），以及作为代理的一部分。\n"]}, {"cell_type": "code", "execution_count": null, "id": "3f6f8702", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-fireworks"]}, {"cell_type": "code", "execution_count": null, "id": "83ea30ee", "metadata": {}, "outputs": [], "source": ["%pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "b070abb8-fa3f-4892-b23e-3ae91d0bf340", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"FIREWORKS_API_KEY\"] = \"\""]}, {"cell_type": "code", "execution_count": null, "id": "5497a17f-1099-4baf-884a-3620705be350", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/Users/jerryliu/Programming/gpt_index/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n"]}], "source": ["from llama_index.llms.fireworks import Fireworks\n", "\n", "## 定义fireworks模型\n", "llm = Fireworks(\n", "    model=\"accounts/fireworks/models/firefunction-v1\", temperature=0\n", ")"]}, {"cell_type": "markdown", "id": "b007403c-6b7a-420c-92f1-4171d05ed9bb", "metadata": {}, "source": ["## 在LLM模块上调用函数\n", "\n", "您可以直接在LLM模块上输入函数调用。\n"]}, {"cell_type": "code", "execution_count": null, "id": "015c2d39", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[ChatCompletionMessageToolCall(id='call_34ZaM0xPl1cveODjVUpO78ra', function=Function(arguments='{\"name\": \"Crazy in Love\", \"artist\": \"Beyonce\"}', name='Song'), type='function', index=0)]\n"]}], "source": ["from pydantic import BaseModel\n", "from llama_index.llms.openai.utils import to_openai_tool\n", "\n", "\n", "class Song(BaseModel):\n", "    \"\"\"具有名称和艺术家的歌曲\"\"\"\n", "\n", "    name: str\n", "    artist: str\n", "\n", "\n", "# 这将pydantic模型转换为函数，以提取结构化输出\n", "song_fn = to_openai_tool(Song)\n", "\n", "\n", "response = llm.complete(\"从Beyonce生成一首歌曲\", tools=[song_fn])\n", "tool_calls = response.additional_kwargs[\"tool_calls\"]\n", "print(tool_calls)"]}, {"cell_type": "markdown", "id": "1f3e9bbe-e1ee-4396-8e03-0bb6455761fa", "metadata": {}, "source": ["## 使用Pydantic程序\n", "\n", "我们的Pydantic程序允许将结构化输出提取到Pydantic对象中。`OpenAIPydanticProgram`利用函数调用来进行结构化输出提取。\n"]}, {"cell_type": "code", "execution_count": null, "id": "b1332454-6aff-464b-a428-e4c94bd24fb9", "metadata": {}, "outputs": [], "source": ["from llama_index.program.openai import OpenAIPydanticProgram"]}, {"cell_type": "code", "execution_count": null, "id": "40de5e32-e015-419a-8faf-01ffd0e45222", "metadata": {}, "outputs": [], "source": ["prompt_template_str = \"Generate a song about {artist_name}\"\n", "program = OpenAIPydanticProgram.from_defaults(\n", "    output_cls=Song, prompt_template_str=prompt_template_str, llm=llm\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "247c9c74-86c3-41a6-9579-93db817557c6", "metadata": {}, "outputs": [], "source": ["output = program(artist_name=\"Eminem\")"]}, {"cell_type": "code", "execution_count": null, "id": "c1ebc517-469e-49b0-9197-708cf34b8454", "metadata": {}, "outputs": [{"data": {"text/plain": ["Song(name='Rap God', artist='Eminem')"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["output"]}, {"cell_type": "markdown", "id": "af7d9e57-5fa6-43ed-93f1-36841b688289", "metadata": {}, "source": ["在本示例中，我们将使用OpenAI的GPT-3代理来生成文本。我们将演示如何设置代理并使用它来生成文本。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a8347ca9-98fb-4f65-a644-dc50abeb39fb", "metadata": {}, "outputs": [], "source": ["from llama_index.agent.openai import OpenAIAgent"]}, {"cell_type": "code", "execution_count": null, "id": "8340c355-5e05-4c90-a1f7-719111ad4cd1", "metadata": {}, "outputs": [], "source": ["\n", "# from llama_index.core.tools import BaseTool,FunctionTool\n", "\n", "def multiply(a: int, b: int) -> int:\n", "    \"\"\"将两个整数相乘，并返回结果整数\"\"\"\n", "    return a * b\n", "\n", "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n", "\n", "def add(a: int, b: int) -> int:\n", "    \"\"\"将两个整数相加，并返回结果整数\"\"\"\n", "    return a + b\n", "\n", "add_tool = FunctionTool.from_defaults(fn=add)"]}, {"cell_type": "code", "execution_count": null, "id": "1f96ada4-f117-4dd4-b726-6c02a6093eae", "metadata": {}, "outputs": [], "source": ["agent = OpenAIAgent.from_tools(\n", "    [multiply_tool, add_tool], llm=llm, verbose=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "29df7ebd-74e4-4cd9-aedf-a4e63bd28857", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Added user message to memory: What is (121 * 3) + 42?\n", "=== Calling Function ===\n", "Calling function: multiply with args: {\"a\": 121, \"b\": 3}\n", "Got output: 363\n", "========================\n", "\n", "=== Calling Function ===\n", "Calling function: add with args: {\"a\": 363, \"b\": 42}\n", "Got output: 405\n", "========================\n", "\n", "The result of (121 * 3) + 42 is 405.\n"]}], "source": ["response = agent.chat(\"What is (121 * 3) + 42?\")\n", "print(str(response))"]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "llama_index_v3", "language": "python", "name": "llama_index_v3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}