{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# MistralRS LLM\n", "\n", "**注意：** MistralRS需要安装一个名为`cargo`的Rust包管理器。请访问 https://rustup.rs/ 获取安装详情。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-core\n", "%pip install llama-index-readers-file\n", "%pip install llama-index-llms-mistral-rs\n", "%pip install llama-index-llms-huggingface"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 从llama_index.core导入VectorStoreIndex、SimpleDirectoryReader、Settings", "# 从llama_index.core.embeddings导入resolve_embed_model", "# 从llama_index.llms.mistral_rs导入MistralRS", "# 从mistralrs导入Which、Architecture", "", "# 使用SimpleDirectoryReader从\"data\"目录加载数据", "", "# bge嵌入模型", "# 设置Settings.embed_model为resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["MistralRS 使用来自 Hugging Face Hub 的模型 ID。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 完整模型", "Settings.llm = MistralRS(", "    which=Which.Plain(", "        model_id=\"mistralai/Mistral-7B-Instruct-v0.1\",", "        arch=Architecture.Mistral,", "        tokenizer_json=None,", "        repeat_last_n=64,", "    ),", "    max_new_tokens=4096,", "    context_window=1024 * 5,", ")", "", "# GGUF模型，量化", "Settings.llm = MistralRS(", "    which=Which.GGUF(", "        tok_model_id=\"mistralai/Mistral-7B-Instruct-v0.1\",", "        quantized_model_id=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",", "        quantized_filename=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",", "        tokenizer_json=None,", "        repeat_last_n=64,", "    ),", "    max_new_tokens=4096,", "    context_window=1024 * 5,", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex.from_documents(\n", "    documents,\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"How do I pronounce graphene?\")\n", "print(response)"]}], "metadata": {"language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 2}