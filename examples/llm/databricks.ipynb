{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "2e33dced-e587-4397-81b3-d6606aa1738a", "metadata": {}, "source": ["# DataBricks\n", "\n", "é›†æˆDataBricks LLMs APIã€‚\n"]}, {"cell_type": "markdown", "id": "0c4105d3", "metadata": {}, "source": ["## å…ˆå†³æ¡ä»¶\n", "\n", "- [Databricksä¸ªäººè®¿é—®ä»¤ç‰Œ](https://docs.databricks.com/en/dev-tools/auth/pat.html)ç”¨äºæŸ¥è¯¢å’Œè®¿é—®Databricksæ¨¡å‹æœåŠ¡ç«¯ç‚¹ã€‚\n", "\n", "- åœ¨[æ”¯æŒçš„åŒºåŸŸ](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-limits.html#regions)ä¸­æ‹¥æœ‰[Databrickså·¥ä½œåŒº](https://docs.databricks.com/en/workspace/index.html)ï¼Œä»¥ä¾¿ä½¿ç”¨Foundation Model APIsæŒ‰ä»¤ç‰Œä»˜è´¹ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "5863dde9-84a0-4c33-ad52-cc767442f63f", "metadata": {}, "source": ["## è®¾ç½®\n"]}, {"cell_type": "markdown", "id": "833bdb2b", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "4aff387e", "metadata": {}, "outputs": [], "source": ["% pip install llama-index-llms-databricks"]}, {"cell_type": "code", "execution_count": null, "id": "9bbbc106", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "ad297f19-998f-4485-aa2f-d67020058b7d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"]}], "source": ["from llama_index.llms.databricks import DataBricks"]}, {"cell_type": "markdown", "id": "4eefec25", "metadata": {}, "source": ["```bash\n", "export DATABRICKS_API_KEY=<ä½ çš„APIå¯†é’¥>\n", "export DATABRICKS_API_BASE=<ä½ çš„APIæœåŠ¡ç«¯ç‚¹>\n", "```\n", "\n", "æˆ–è€…ï¼Œä½ å¯ä»¥åœ¨åˆå§‹åŒ–æ—¶å°†ä½ çš„APIå¯†é’¥å’ŒæœåŠ¡ç«¯ç‚¹ä¼ é€’ç»™LLMï¼š\n"]}, {"cell_type": "code", "execution_count": null, "id": "152ced37-9a42-47be-9a39-4218521f5e72", "metadata": {}, "outputs": [], "source": ["llm = DataBricks(\n", "    model=\"databricks-dbrx-instruct\",\n", "    api_key=\"your_api_key\",\n", "    api_base=\"https://[your-work-space].cloud.databricks.com/serving-endpoints/[your-serving-endpoint]\",\n", ")"]}, {"cell_type": "markdown", "id": "562455fe", "metadata": {}, "source": ["å¯ä»¥åœ¨[è¿™é‡Œ](https://console.groq.com/docs/models)æ‰¾åˆ°å¯ç”¨çš„LLMæ¨¡å‹åˆ—è¡¨ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "d61b10bb-e911-47fb-8e84-19828cf224be", "metadata": {}, "outputs": [], "source": ["response = llm.complete(\"Explain the importance of open source LLMs\")"]}, {"cell_type": "code", "execution_count": null, "id": "3bd14f4e-c245-4384-a471-97e4ddfcb40e", "metadata": {}, "outputs": [], "source": ["print(response)"]}, {"attachments": {}, "cell_type": "markdown", "id": "3ba9503c-b440-43c6-a50c-676c79993813", "metadata": {}, "source": ["#### ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨è°ƒç”¨ `chat`\n"]}, {"cell_type": "code", "execution_count": null, "id": "ee8a4a55-5680-4dc6-a44c-fc8ad7892f80", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"What is your name\"),\n", "]\n", "resp = llm.chat(messages)"]}, {"cell_type": "code", "execution_count": null, "id": "2a9bfe53-d15b-4e75-9d91-8c5d024f4eda", "metadata": {}, "outputs": [], "source": ["print(resp)"]}, {"attachments": {}, "cell_type": "markdown", "id": "25ad1b00-28fc-4bcd-96c4-d5b35605721a", "metadata": {}, "source": ["### Streaming\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "13c641fa-345a-4dce-87c5-ab1f6dcf4757", "metadata": {}, "source": ["ä½¿ç”¨ `stream_complete` ç»ˆç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "id": "06da1ef1-2f6b-497c-847b-62dd2df11491", "metadata": {}, "outputs": [], "source": ["response = llm.stream_complete(\"Explain the importance of open source LLMs\")"]}, {"cell_type": "code", "execution_count": null, "id": "1b851def-5160-46e5-a30c-5a3ef2356b79", "metadata": {}, "outputs": [], "source": ["for r in response:\n", "    print(r.delta, end=\"\")"]}, {"attachments": {}, "cell_type": "markdown", "id": "ca52051d-6b28-49d7-98f5-82e266a1c7a6", "metadata": {}, "source": ["ä½¿ç”¨ `stream_chat` ç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "id": "fe553190-52a9-436d-84ae-4dd99a1808f4", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"What is your name\"),\n", "]\n", "resp = llm.stream_chat(messages)"]}, {"cell_type": "code", "execution_count": null, "id": "154c503c-f893-4b6b-8a65-a9a27b636046", "metadata": {}, "outputs": [], "source": ["for r in resp:\n", "    print(r.delta, end=\"\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}