{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "6d1ca9ac", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/llm/bedrock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "9e3a8796-edc8-43f2-94ad-fe4fb20d70ed", "metadata": {}, "source": ["# Oracle云基础设施生成式人工智能\n", "\n", "Oracle云基础设施（OCI）生成式人工智能是一个完全托管的服务，提供一组最先进的可定制大型语言模型（LLMs），涵盖广泛的用例，并通过单个API提供。\n", "使用OCI生成式人工智能服务，您可以访问现成的预训练模型，或者基于专用AI集群上的自有数据创建和托管自定义微调模型。服务和API的详细文档可在__[此处](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__和__[此处](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__找到。\n", "\n", "本笔记本解释了如何使用OCI的生成式人工智能模型与LlamaIndex。\n"]}, {"cell_type": "markdown", "id": "3802e8c4", "metadata": {}, "source": ["## 设置\n", "\n", "如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "bb0dd8c9", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-oci-genai"]}, {"cell_type": "code", "execution_count": null, "id": "544d49f9", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "markdown", "id": "c2921307", "metadata": {}, "source": ["您还需要安装OCI SDK。\n"]}, {"cell_type": "code", "execution_count": null, "id": "378d5179", "metadata": {}, "outputs": [], "source": ["!pip install -U oci"]}, {"cell_type": "markdown", "id": "03d4024a", "metadata": {}, "source": ["## 基本用法\n", "\n", "使用OCI Generative AI提供的LLMs与LlamaIndex只需要您使用您的OCI端点、模型ID、OCID和认证方法初始化OCIGenAI接口。\n"]}, {"cell_type": "markdown", "id": "8ead155e-b8bd-46f9-ab9b-28fc009361dd", "metadata": {}, "source": ["#### 使用提示调用`complete`\n"]}, {"cell_type": "code", "execution_count": null, "id": "60be18ae-c957-4ac2-a58a-0652e18ee6d6", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.complete(\"Paul Graham is \")\n", "print(resp)"]}, {"cell_type": "markdown", "id": "14831268-f90f-499d-9d86-925dbc88292b", "metadata": {}, "source": ["#### 使用消息列表调用`chat`\n"]}, {"cell_type": "code", "execution_count": null, "id": "bbe29574-4af1-48d5-9739-f60652b6ce6c", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.chat(messages)\n", "print(resp)"]}, {"cell_type": "markdown", "id": "2ed5e894-4597-4911-a623-591560f72b82", "metadata": {}, "source": ["## 流式处理\n"]}, {"cell_type": "markdown", "id": "4cb7986f-aaed-42e2-abdd-f274f6d4fc59", "metadata": {}, "source": ["使用 `stream_complete` 终端点\n"]}, {"cell_type": "code", "execution_count": null, "id": "d43f17a2-0aeb-464b-a7a7-732ba5e8ef24", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.stream_complete(\"Paul Graham is \")\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "40350dd8-3f50-4a2f-8545-5723942039bb", "metadata": {}, "source": ["使用 `stream_chat` 端点\n"]}, {"cell_type": "code", "execution_count": null, "id": "bc636e65-a67b-4dcd-ac60-b25abc9d8dbd", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.stream_chat(messages)\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "dc2414f5", "metadata": {}, "source": ["## 异步\n"]}, {"cell_type": "markdown", "id": "f82bc4d7", "metadata": {}, "source": ["本地异步目前不受支持。异步调用将回退为同步。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0d3e1b75", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.achat(messages)\n", "print(resp)\n", "\n", "resp = llm.astream_chat(messages)\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "009d3f1c-ef35-4126-ae82-0b97adb746e3", "metadata": {}, "source": ["## 配置模型\n"]}, {"cell_type": "code", "execution_count": null, "id": "e973e3d1-a3c9-43b9-bee1-af3e57946ac3", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"cohere.command\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.complete(\"Paul Graham is \")\n", "print(resp)"]}, {"cell_type": "markdown", "id": "1bdd4602-e37c-4230-af82-35af5292f9a0", "metadata": {}, "source": ["## 认证\n", "LlamaIndex支持的认证方法与其他OCI服务使用的方法相同，并遵循__[标准SDK认证](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm)__方法，具体包括API密钥、会话令牌、实例主体和资源主体。\n", "\n", "API密钥是默认的认证方法。以下示例演示了如何使用不同的认证方法（会话令牌）。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a9c80814-6d59-4782-a4bb-cbfcdba6a072", "metadata": {}, "outputs": [], "source": ["# 从llama_index.llms.oci_genai导入OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", "    auth_type=\"SECURITY_TOKEN\",\n", "    auth_profile=\"MY_PROFILE\",  # 用你的配置文件名称替换\n", ")\n", "\n", "resp = llm.complete(\"Paul Graham is \")\n", "print(resp)"]}, {"cell_type": "markdown", "id": "9845613a", "metadata": {}, "source": ["## 专用AI集群\n", "要访问托管在专用AI集群中的模型，需要 __[创建一个端点](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai-inference/20231130/)__，其分配的OCID（当前以'ocid1.generativeaiendpoint.oc1.us-chicago-1'为前缀）将被用作您的模型ID。\n", "\n", "当访问托管在专用AI集群中的模型时，您需要使用两个额外的必需参数（\"provider\"和\"context_size\"）初始化OCIGenAI接口。\n"]}, {"cell_type": "code", "execution_count": null, "id": "c5c153ed", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "llm = OCIGenAI(\n", "    model=\"ocid1.generativeaiendpoint.oc1.us-chicago-1....\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"DEDICATED_COMPARTMENT_OCID\",\n", "    auth_profile=\"MY_PROFILE\",  # 替换为您的配置文件名称,\n", "    provider=\"MODEL_PROVIDER\",  # 例如，\"cohere\"或\"meta\"\n", "    context_size=\"MODEL_CONTEXT_SIZE\",  # 例如，128000\n", ")\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "resp = llm.chat(messages)\n", "print(resp)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}