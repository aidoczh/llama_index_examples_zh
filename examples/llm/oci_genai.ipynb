{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "6d1ca9ac", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/llm/bedrock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "9e3a8796-edc8-43f2-94ad-fe4fb20d70ed", "metadata": {}, "source": ["# Oracleäº‘åŸºç¡€è®¾æ–½ç”Ÿæˆå¼äººå·¥æ™ºèƒ½\n", "\n", "Oracleäº‘åŸºç¡€è®¾æ–½ï¼ˆOCIï¼‰ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ˜¯ä¸€ä¸ªå®Œå…¨æ‰˜ç®¡çš„æœåŠ¡ï¼Œæä¾›ä¸€ç»„æœ€å…ˆè¿›çš„å¯å®šåˆ¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œæ¶µç›–å¹¿æ³›çš„ç”¨ä¾‹ï¼Œå¹¶é€šè¿‡å•ä¸ªAPIæä¾›ã€‚\n", "ä½¿ç”¨OCIç”Ÿæˆå¼äººå·¥æ™ºèƒ½æœåŠ¡ï¼Œæ‚¨å¯ä»¥è®¿é—®ç°æˆçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ–è€…åŸºäºä¸“ç”¨AIé›†ç¾¤ä¸Šçš„è‡ªæœ‰æ•°æ®åˆ›å»ºå’Œæ‰˜ç®¡è‡ªå®šä¹‰å¾®è°ƒæ¨¡å‹ã€‚æœåŠ¡å’ŒAPIçš„è¯¦ç»†æ–‡æ¡£å¯åœ¨__[æ­¤å¤„](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__å’Œ__[æ­¤å¤„](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__æ‰¾åˆ°ã€‚\n", "\n", "æœ¬ç¬”è®°æœ¬è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨OCIçš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹ä¸LlamaIndexã€‚\n"]}, {"cell_type": "markdown", "id": "3802e8c4", "metadata": {}, "source": ["## è®¾ç½®\n", "\n", "å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "bb0dd8c9", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-oci-genai"]}, {"cell_type": "code", "execution_count": null, "id": "544d49f9", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "markdown", "id": "c2921307", "metadata": {}, "source": ["æ‚¨è¿˜éœ€è¦å®‰è£…OCI SDKã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "378d5179", "metadata": {}, "outputs": [], "source": ["!pip install -U oci"]}, {"cell_type": "markdown", "id": "03d4024a", "metadata": {}, "source": ["## åŸºæœ¬ç”¨æ³•\n", "\n", "ä½¿ç”¨OCI Generative AIæä¾›çš„LLMsä¸LlamaIndexåªéœ€è¦æ‚¨ä½¿ç”¨æ‚¨çš„OCIç«¯ç‚¹ã€æ¨¡å‹IDã€OCIDå’Œè®¤è¯æ–¹æ³•åˆå§‹åŒ–OCIGenAIæ¥å£ã€‚\n"]}, {"cell_type": "markdown", "id": "8ead155e-b8bd-46f9-ab9b-28fc009361dd", "metadata": {}, "source": ["#### ä½¿ç”¨æç¤ºè°ƒç”¨`complete`\n"]}, {"cell_type": "code", "execution_count": null, "id": "60be18ae-c957-4ac2-a58a-0652e18ee6d6", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.complete(\"Paul Graham is \")\n", "print(resp)"]}, {"cell_type": "markdown", "id": "14831268-f90f-499d-9d86-925dbc88292b", "metadata": {}, "source": ["#### ä½¿ç”¨æ¶ˆæ¯åˆ—è¡¨è°ƒç”¨`chat`\n"]}, {"cell_type": "code", "execution_count": null, "id": "bbe29574-4af1-48d5-9739-f60652b6ce6c", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.chat(messages)\n", "print(resp)"]}, {"cell_type": "markdown", "id": "2ed5e894-4597-4911-a623-591560f72b82", "metadata": {}, "source": ["## æµå¼å¤„ç†\n"]}, {"cell_type": "markdown", "id": "4cb7986f-aaed-42e2-abdd-f274f6d4fc59", "metadata": {}, "source": ["ä½¿ç”¨ `stream_complete` ç»ˆç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "id": "d43f17a2-0aeb-464b-a7a7-732ba5e8ef24", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.stream_complete(\"Paul Graham is \")\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "40350dd8-3f50-4a2f-8545-5723942039bb", "metadata": {}, "source": ["ä½¿ç”¨ `stream_chat` ç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "id": "bc636e65-a67b-4dcd-ac60-b25abc9d8dbd", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.stream_chat(messages)\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "dc2414f5", "metadata": {}, "source": ["## å¼‚æ­¥\n"]}, {"cell_type": "markdown", "id": "f82bc4d7", "metadata": {}, "source": ["æœ¬åœ°å¼‚æ­¥ç›®å‰ä¸å—æ”¯æŒã€‚å¼‚æ­¥è°ƒç”¨å°†å›é€€ä¸ºåŒæ­¥ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "0d3e1b75", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.achat(messages)\n", "print(resp)\n", "\n", "resp = llm.astream_chat(messages)\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "009d3f1c-ef35-4126-ae82-0b97adb746e3", "metadata": {}, "source": ["## é…ç½®æ¨¡å‹\n"]}, {"cell_type": "code", "execution_count": null, "id": "e973e3d1-a3c9-43b9-bee1-af3e57946ac3", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"cohere.command\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", ")\n", "\n", "resp = llm.complete(\"Paul Graham is \")\n", "print(resp)"]}, {"cell_type": "markdown", "id": "1bdd4602-e37c-4230-af82-35af5292f9a0", "metadata": {}, "source": ["## è®¤è¯\n", "LlamaIndexæ”¯æŒçš„è®¤è¯æ–¹æ³•ä¸å…¶ä»–OCIæœåŠ¡ä½¿ç”¨çš„æ–¹æ³•ç›¸åŒï¼Œå¹¶éµå¾ª__[æ ‡å‡†SDKè®¤è¯](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm)__æ–¹æ³•ï¼Œå…·ä½“åŒ…æ‹¬APIå¯†é’¥ã€ä¼šè¯ä»¤ç‰Œã€å®ä¾‹ä¸»ä½“å’Œèµ„æºä¸»ä½“ã€‚\n", "\n", "APIå¯†é’¥æ˜¯é»˜è®¤çš„è®¤è¯æ–¹æ³•ã€‚ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¸åŒçš„è®¤è¯æ–¹æ³•ï¼ˆä¼šè¯ä»¤ç‰Œï¼‰ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "a9c80814-6d59-4782-a4bb-cbfcdba6a072", "metadata": {}, "outputs": [], "source": ["# ä»llama_index.llms.oci_genaiå¯¼å…¥OCIGenAI\n", "\n", "llm = OCIGenAI(\n", "    model=\"MY_MODEL\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"MY_OCID\",\n", "    auth_type=\"SECURITY_TOKEN\",\n", "    auth_profile=\"MY_PROFILE\",  # ç”¨ä½ çš„é…ç½®æ–‡ä»¶åç§°æ›¿æ¢\n", ")\n", "\n", "resp = llm.complete(\"Paul Graham is \")\n", "print(resp)"]}, {"cell_type": "markdown", "id": "9845613a", "metadata": {}, "source": ["## ä¸“ç”¨AIé›†ç¾¤\n", "è¦è®¿é—®æ‰˜ç®¡åœ¨ä¸“ç”¨AIé›†ç¾¤ä¸­çš„æ¨¡å‹ï¼Œéœ€è¦ __[åˆ›å»ºä¸€ä¸ªç«¯ç‚¹](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai-inference/20231130/)__ï¼Œå…¶åˆ†é…çš„OCIDï¼ˆå½“å‰ä»¥'ocid1.generativeaiendpoint.oc1.us-chicago-1'ä¸ºå‰ç¼€ï¼‰å°†è¢«ç”¨ä½œæ‚¨çš„æ¨¡å‹IDã€‚\n", "\n", "å½“è®¿é—®æ‰˜ç®¡åœ¨ä¸“ç”¨AIé›†ç¾¤ä¸­çš„æ¨¡å‹æ—¶ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ä¸¤ä¸ªé¢å¤–çš„å¿…éœ€å‚æ•°ï¼ˆ\"provider\"å’Œ\"context_size\"ï¼‰åˆå§‹åŒ–OCIGenAIæ¥å£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "c5c153ed", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.oci_genai import OCIGenAI\n", "from llama_index.core.llms import ChatMessage\n", "\n", "llm = OCIGenAI(\n", "    model=\"ocid1.generativeaiendpoint.oc1.us-chicago-1....\",\n", "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n", "    compartment_id=\"DEDICATED_COMPARTMENT_OCID\",\n", "    auth_profile=\"MY_PROFILE\",  # æ›¿æ¢ä¸ºæ‚¨çš„é…ç½®æ–‡ä»¶åç§°,\n", "    provider=\"MODEL_PROVIDER\",  # ä¾‹å¦‚ï¼Œ\"cohere\"æˆ–\"meta\"\n", "    context_size=\"MODEL_CONTEXT_SIZE\",  # ä¾‹å¦‚ï¼Œ128000\n", ")\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n", "]\n", "\n", "resp = llm.chat(messages)\n", "print(resp)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}