{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/drive/1F0V_eClPOpS_2HIW-F2mCivgqBfFo2TR?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# PremAI LlamaIndex\n", "\n", "[PremAI](https://premai.io/)是一个一体化平台，简化了由生成式人工智能驱动的稳健、生产就绪应用程序的创建过程。通过简化开发流程，PremAI让您可以集中精力提升用户体验，并推动应用程序的整体增长。您可以在[这里](https://docs.premai.io/quick-start)快速开始使用我们的平台。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 安装和设置\n", "\n", "我们首先安装 `llama-index` 和 `premai-sdk`。您可以输入以下命令进行安装：\n", "\n", "```bash\n", "pip install premai llama-index\n", "```\n", "\n", "在继续之前，请确保您已在 PremAI 上创建了账户并已经创建了一个项目。如果没有，请参考 [快速入门](https://docs.premai.io/introduction) 指南开始使用 PremAI 平台。创建您的第一个项目并获取您的 API 密钥。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-premai"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.llms.premai import PremAI\n", "from llama_index.core.llms import ChatMessage"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 使用LlamaIndex设置PremAI客户端\n", "\n", "在导入所需的模块之后，让我们设置我们的客户端。现在假设我们的`project_id`是`8`。但请确保您使用您自己的项目ID，否则会抛出错误。\n", "\n", "要在PremAI中使用llama-index，您无需传递任何模型名称或设置任何参数给我们的聊天客户端。默认情况下，它将使用在[LaunchPad](https://docs.premai.io/get-started/launchpad)中使用的模型名称和参数。\n", "\n", "> 如果您在设置客户端时更改了`model`或任何其他参数，如`temperature`或`max_tokens`，它将覆盖在LaunchPad中使用的现有默认配置。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import getpass\n", "\n", "if os.environ.get(\"PREMAI_API_KEY\") is None:\n", "    os.environ[\"PREMAI_API_KEY\"] = getpass.getpass(\"PremAI API Key:\")\n", "\n", "prem_chat = PremAI(project_id=8)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 聊天完成\n", "\n", "现在你已经准备就绪。我们现在可以开始与我们的应用程序进行交互了。让我们从使用llama-index构建简单的聊天请求和响应开始。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["messages = [\n", "    ChatMessage(role=\"user\", content=\"What is your name\"),\n", "    ChatMessage(\n", "        role=\"user\", content=\"Write an essay about your school in 500 words\"\n", "    ),\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["请注意：您可以在`ChatMessage`中提供系统提示，就像这样：\n", "\n", "```python\n", "messages = [\n", "    ChatMessage(role=\"system\", content=\"Act like a pirate\"),\n", "    ChatMessage(role=\"user\", content=\"What is your name\"),\n", "    ChatMessage(role=\"user\", content=\"Where do you live, write an essay in 500 words\"),\n", "]\n", "```\n", "此外，您还可以像这样使用系统提示实例化您的客户端：\n", "\n", "```python\n", "chat = PremAI(project_id=8, system_prompt=\"Act like nemo fish\")\n", "```\n", "\n", "\n", "> 在这两种情况下，您将覆盖在部署应用程序时从平台上固定的系统提示。特别是在这种情况下，如果在实例化**PremAI**类时覆盖系统提示，那么`ChatMessage`中的系统消息将不会产生任何影响。\n", "\n", "> 因此，如果您想要为任何实验情况覆盖系统提示，您需要在实例化客户端时提供该提示，或者在`ChatMessage`中以`system`角色编写该提示。\n", "\n", "现在让我们调用模型。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"I'm here to assist you with any questions or tasks you have, but I'm not able to write essays. However, if you need help brainstorming ideas or organizing your thoughts for your essay about your school, I'd be happy to help with that. Just let me know how I can assist you further!\", additional_kwargs={}), raw={'role': <RoleEnum.ASSISTANT: 'assistant'>, 'content': \"I'm here to assist you with any questions or tasks you have, but I'm not able to write essays. However, if you need help brainstorming ideas or organizing your thoughts for your essay about your school, I'd be happy to help with that. Just let me know how I can assist you further!\"}, delta=None, additional_kwargs={})]\n"]}], "source": ["response = prem_chat.chat(messages)\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["您还可以将聊天功能转换为完成功能。以下是它的工作原理。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["completion = prem_chat.complete(\"Paul Graham is \")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 流式处理\n", "\n", "在本节中，让我们看看如何使用llama-index和PremAI来流式处理标记。这与上述方法非常相似。以下是操作步骤。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["I'm here to assist you with writing tasks, but I don't have personal experiences or attend school. However, I can help you brainstorm ideas, outline your essay, or provide information on various school-related topics. Just let me know how I can assist you further!"]}], "source": ["streamed_response = prem_chat.stream_chat(messages)\n", "\n", "for response_delta in streamed_response:\n", "    print(response_delta.delta, end=\"\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["这将一个接一个地流式传输标记。与`complete`方法类似，我们有`stream_complete`方法，用于完成时的标记流式传输。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Hello! I'm here and ready to assist you. How can I help you today?"]}], "source": ["# 这将逐个流式传输标记", "streamed_response = prem_chat.stream_complete(\"你好，你好吗\")", "", "for response_delta in streamed_response:", "    print(response_delta.delta, end=\"\")"]}], "metadata": {"kernelspec": {"display_name": "venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}