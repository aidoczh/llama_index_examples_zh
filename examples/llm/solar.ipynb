{"cells": [{"cell_type": "markdown", "id": "cae1b4a8", "metadata": {}, "source": ["# Solar LLM\n", "\n", "警告：Solar LLM 已被弃用，请使用 Upstage LLM。请参阅 [Upstage LLM](https://docs.llamaindex.ai/en/stable/examples/llm/upstage/)。\n"]}, {"cell_type": "code", "execution_count": null, "id": "715d392e", "metadata": {}, "outputs": [], "source": ["!pip install llama-index-llms-solar"]}, {"cell_type": "code", "execution_count": null, "id": "1fdc2dc3-1454-41e9-8862-9dfd75b5b61f", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"SOLAR_API_KEY\"] = \"SOLAR_API_KEY\""]}, {"cell_type": "code", "execution_count": null, "id": "26b168b8-9ebf-479d-ac53-28bc952da354", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["assistant: Mother also went into the room.\n"]}], "source": ["# from llama_index.llms import ", "from llama_index.llms.solar import Solar", "from llama_index.core.base.llms.types import ChatMessage, MessageRole", "", "llm = Solar(model=\"solar-1-mini-chat\", is_chat_model=True)", "response = llm.chat(", "    messages=[", "        ChatMessage(role=\"user\", content=\"아버지가방에들어가셨다\"),", "        ChatMessage(role=\"assistant\", content=\"Father went into his room\"),", "        ChatMessage(role=\"user\", content=\"엄마도들어가셨다\"),", "    ]", ")", "", "print(response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}