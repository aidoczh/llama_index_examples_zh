{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "9f2acbee", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/gradient_base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "bf9f19f3", "metadata": {}, "source": ["# 梯度基础模型\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "9ea1fcaa", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "5ad7f620", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-langchain\n", "%pip install llama-index-llms-gradient"]}, {"cell_type": "code", "execution_count": null, "id": "7294e8a2", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "79a726c5", "metadata": {}, "outputs": [], "source": ["%pip install llama-index --quiet\n", "%pip install gradientai --quiet"]}, {"cell_type": "code", "execution_count": null, "id": "1c2b0d5d", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"GRADIENT_ACCESS_TOKEN\"] = \"{GRADIENT_ACCESS_TOKEN}\"\n", "os.environ[\"GRADIENT_WORKSPACE_ID\"] = \"{GRADIENT_WORKSPACE_ID}\""]}, {"cell_type": "markdown", "id": "9a602a2a", "metadata": {}, "source": ["## 流程 1：直接查询Gradient LLM\n"]}, {"cell_type": "code", "execution_count": null, "id": "4baffaa2", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.gradient import GradientBaseModelLLM\n", "\n", "llm = GradientBaseModelLLM(\n", "    base_model_slug=\"llama2-7b-chat\",\n", "    max_tokens=400,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "e7039a65", "metadata": {}, "outputs": [], "source": ["result = llm.complete(\"Can you tell me about large language models?\")\n", "print(result)"]}, {"cell_type": "markdown", "id": "1112e828", "metadata": {}, "source": ["## 流程2：梯度LLM辅助的检索增强生成（RAG）\n"]}, {"cell_type": "code", "execution_count": null, "id": "cacff36a", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "from llama_index.embeddings.langchain import LangchainEmbedding\n", "from langchain.embeddings import HuggingFaceEmbeddings\n", "from llama_index.core.node_parser import SentenceSplitter"]}, {"attachments": {}, "cell_type": "markdown", "id": "f0afcf64", "metadata": {}, "source": ["#### 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "41e45271", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "id": "1edd41d1", "metadata": {}, "source": ["### 加载文档\n"]}, {"cell_type": "code", "execution_count": null, "id": "c5941151", "metadata": {}, "outputs": [], "source": ["documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"]}, {"cell_type": "markdown", "id": "7df4407f", "metadata": {}, "source": ["### 配置Gradient LLM\n", "\n", "在这个notebook中，我们将学习如何配置Gradient Language Model (LLM)。 Gradient LLM 是一个基于transformer的语言模型，可以用于各种自然语言处理任务。我们将学习如何配置模型的参数，以便在特定任务中进行微调和训练。\n"]}, {"cell_type": "code", "execution_count": null, "id": "dec73a6b", "metadata": {}, "outputs": [], "source": ["embed_model = LangchainEmbedding(HuggingFaceEmbeddings())\n", "splitter = SentenceSplitter(chunk_size=1024)"]}, {"cell_type": "markdown", "id": "7a131a8e", "metadata": {}, "source": ["### 设置和查询索引\n"]}, {"cell_type": "code", "execution_count": null, "id": "c9b10269", "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex.from_documents(\n", "    documents, transformations=[splitter], embed_model=embed_model\n", ")\n", "query_engine = index.as_query_engine(llm=llm)"]}, {"cell_type": "code", "execution_count": null, "id": "ac73eb65", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\n", "    \"What did the author do after his time at Y Combinator?\"\n", ")\n", "print(response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "vscode": {"interpreter": {"hash": "5ae9fa2777630f93d325d67fd0c37f7375ed1afcb20dd85f425eb8692a47ff3f"}}}, "nbformat": 4, "nbformat_minor": 5}