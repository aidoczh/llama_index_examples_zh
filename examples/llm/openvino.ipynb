{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "978146e2", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/openvino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "f717d3d4-942b-4d86-9435-fc44b3ac6d39", "metadata": {}, "source": ["# OpenVINO è¯­è¨€æ¨¡å‹\n", "\n", "[OpenVINOâ„¢](https://github.com/openvinotoolkit/openvino) æ˜¯ä¸€ä¸ªç”¨äºä¼˜åŒ–å’Œéƒ¨ç½²AIæ¨æ–­çš„å¼€æºå·¥å…·åŒ…ã€‚OpenVINOâ„¢ Runtime å¯ä»¥åœ¨å„ç§ç¡¬ä»¶[è®¾å¤‡](https://github.com/openvinotoolkit/openvino?tab=readme-ov-file#supported-hardware-matrix)ä¸Šè¿è¡Œç»è¿‡ä¼˜åŒ–çš„ç›¸åŒæ¨¡å‹ã€‚åŠ é€Ÿæ‚¨åœ¨è¯­è¨€æ¨¡å‹ + LLMsã€è®¡ç®—æœºè§†è§‰ã€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç­‰ç”¨ä¾‹ä¸­çš„æ·±åº¦å­¦ä¹ æ€§èƒ½ã€‚\n", "\n", "é€šè¿‡ `OpenVINOLLM` å®ä½“å°è£…çš„ LlamaIndexï¼Œå¯ä»¥åœ¨æœ¬åœ°è¿è¡Œ OpenVINO æ¨¡å‹ï¼š\n"]}, {"cell_type": "markdown", "id": "90cf0f2e-8d8d-4e42-81bf-866c759221e1", "metadata": {}, "source": ["åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬å®‰è£…äº†è¿™ä¸ªæ¼”ç¤ºæ‰€éœ€çš„åŒ…ï¼š\n"]}, {"cell_type": "code", "execution_count": null, "id": "f413f179", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openvino transformers huggingface_hub"]}, {"cell_type": "markdown", "id": "3dac8f9f-7136-43f7-9e9f-de679e74d66e", "metadata": {}, "source": ["ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†ï¼Œè®©æˆ‘ä»¬å¼€å§‹ç©ä¸€ä¸‹å§ï¼š\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "2c577674", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨Colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "86028752", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "0465029c-fe69-454a-9561-55f7a382b2e2", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.openvino import OpenVINOLLM"]}, {"cell_type": "code", "execution_count": null, "id": "49122583", "metadata": {}, "outputs": [], "source": ["def messages_to_prompt(messages):", "    prompt = \"\"", "    for message in messages:", "        if message.role == \"system\":", "            prompt += f\"<|system|>\\n{message.content}</s>\\n\"", "        elif message.role == \"user\":", "            prompt += f\"<|user|>\\n{message.content}</s>\\n\"", "        elif message.role == \"assistant\":", "            prompt += f\"<|assistant|>\\n{message.content}</s>\\n\"", "", "    # ç¡®ä¿æˆ‘ä»¬ä»¥ç³»ç»Ÿæç¤ºå¼€å§‹ï¼Œå¦‚æœéœ€è¦åˆ™æ’å…¥ç©ºç™½", "    if not prompt.startswith(\"<|system|>\\n\"):", "        prompt = \"<|system|>\\n</s>\\n\" + prompt", "", "    # æ·»åŠ æœ€ç»ˆçš„åŠ©æ‰‹æç¤º", "    prompt = prompt + \"<|assistant|>\\n\"", "", "    return prompt", "", "", "def completion_to_prompt(completion):", "    return f\"<|system|>\\n</s>\\n<|user|>\\n{completion}</s>\\n<|assistant|>\\n\""]}, {"cell_type": "markdown", "id": "d3e21cef-b3c3-4ddd-a70c-728de440648e", "metadata": {}, "source": ["### æ¨¡å‹åŠ è½½\n", "\n", "å¯ä»¥é€šè¿‡ä½¿ç”¨ `OpenVINOLLM` æ–¹æ³•æ¥æŒ‡å®šæ¨¡å‹å‚æ•°æ¥åŠ è½½æ¨¡å‹ã€‚\n", "\n", "å¦‚æœä½ æœ‰è‹±ç‰¹å°”GPUï¼Œå¯ä»¥æŒ‡å®š `device_map=\"gpu\"` æ¥åœ¨å…¶ä¸Šè¿è¡Œæ¨æ–­ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "a27feba3-d027-4d10-b1af-1e130e764a67", "metadata": {}, "outputs": [], "source": ["ov_config = {\n", "    \"PERFORMANCE_HINT\": \"LATENCY\",\n", "    \"NUM_STREAMS\": \"1\",\n", "    \"CACHE_DIR\": \"\",\n", "}\n", "\n", "ov_llm = OpenVINOLLM(\n", "    model_name=\"HuggingFaceH4/zephyr-7b-beta\",\n", "    tokenizer_name=\"HuggingFaceH4/zephyr-7b-beta\",\n", "    context_window=3900,\n", "    max_new_tokens=256,\n", "    model_kwargs={\"ov_config\": ov_config},\n", "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n", "    messages_to_prompt=messages_to_prompt,\n", "    completion_to_prompt=completion_to_prompt,\n", "    device_map=\"cpu\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "e25c7162", "metadata": {}, "outputs": [], "source": ["response = ov_llm.complete(\"What is the meaning of life?\")\n", "print(str(response))"]}, {"cell_type": "markdown", "id": "072dd59e-e3e7-41b9-b6fb-07bb41a82d2c", "metadata": {}, "source": ["### ä½¿ç”¨æœ¬åœ°OpenVINOæ¨¡å‹è¿›è¡Œæ¨ç†\n", "\n", "å¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢å°†æ‚¨çš„æ¨¡å‹[å¯¼å‡º](https://github.com/huggingface/optimum-intel?tab=readme-ov-file#export)ä¸ºOpenVINO IRæ ¼å¼ï¼Œå¹¶ä»æœ¬åœ°æ–‡ä»¶å¤¹åŠ è½½æ¨¡å‹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "41dfc1a1-0aea-4136-a194-0428b89dc3cc", "metadata": {}, "outputs": [], "source": ["!optimum-cli export openvino --model HuggingFaceH4/zephyr-7b-beta ov_model_dir"]}, {"cell_type": "markdown", "id": "9e7683ab-66ae-4fbc-af20-6e3ec524d28a", "metadata": {}, "source": ["å»ºè®®ä½¿ç”¨`--weight-format`å¯¹æƒé‡è¿›è¡Œ8ä½æˆ–4ä½é‡åŒ–ï¼Œä»¥å‡å°‘æ¨ç†å»¶è¿Ÿå’Œæ¨¡å‹å ç”¨ç©ºé—´ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "92d69e87", "metadata": {}, "outputs": [], "source": ["!optimum-cli export openvino --model HuggingFaceH4/zephyr-7b-beta --weight-format int8 ov_model_dir"]}, {"cell_type": "code", "execution_count": null, "id": "b9e96c9d", "metadata": {}, "outputs": [], "source": ["!optimum-cli export openvino --model HuggingFaceH4/zephyr-7b-beta --weight-format int4 ov_model_dir"]}, {"cell_type": "code", "execution_count": null, "id": "a6982d98", "metadata": {}, "outputs": [], "source": ["ov_llm = OpenVINOLLM(\n", "    model_name=\"ov_model_dir\",\n", "    tokenizer_name=\"ov_model_dir\",\n", "    context_window=3900,\n", "    max_new_tokens=256,\n", "    model_kwargs={\"ov_config\": ov_config},\n", "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n", "    messages_to_prompt=messages_to_prompt,\n", "    completion_to_prompt=completion_to_prompt,\n", "    device_map=\"gpu\",\n", ")"]}, {"cell_type": "markdown", "id": "8e26a478-2974-4ced-89e8-c13a64a409b2", "metadata": {}, "source": ["æ‚¨å¯ä»¥é€šè¿‡æ¿€æ´»çš„åŠ¨æ€é‡åŒ–å’ŒKV-cacheé‡åŒ–æ¥è·å¾—é¢å¤–çš„æ¨ç†é€Ÿåº¦æå‡ã€‚å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åœ¨`ov_config`ä¸­å¯ç”¨è¿™äº›é€‰é¡¹ï¼š\n"]}, {"cell_type": "code", "execution_count": null, "id": "01c89828-a94b-4242-baf0-204eb0f1c87a", "metadata": {}, "outputs": [], "source": ["ov_config = {\n", "    \"KV_CACHE_PRECISION\": \"u8\",\n", "    \"DYNAMIC_QUANTIZATION_GROUP_SIZE\": \"32\",\n", "    \"PERFORMANCE_HINT\": \"LATENCY\",\n", "    \"NUM_STREAMS\": \"1\",\n", "    \"CACHE_DIR\": \"\",\n", "}"]}, {"cell_type": "markdown", "id": "dda1be10", "metadata": {}, "source": ["### æ•°æ®æµ\n", "\n", "ä½¿ç”¨ `stream_complete` ç»ˆç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "id": "12e0f3c0", "metadata": {}, "outputs": [], "source": ["response = ov_llm.stream_complete(\"Who is Paul Graham?\")\n", "for r in response:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "2c87c383", "metadata": {}, "source": ["ä½¿ç”¨ `stream_chat` ç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "id": "2db801a8", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llms import ChatMessage\n", "\n", "messages = [\n", "    ChatMessage(\n", "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n", "    ),\n", "    ChatMessage(role=\"user\", content=\"What is your name\"),\n", "]\n", "resp = ov_llm.stream_chat(messages)\n", "\n", "for r in resp:\n", "    print(r.delta, end=\"\")"]}, {"cell_type": "markdown", "id": "3fa723d6-4308-4d94-9609-8c51ce8184c3", "metadata": {}, "source": ["æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒï¼š\n", "\n", "* [OpenVINO LLMæŒ‡å—](https://docs.openvino.ai/2024/learn-openvino/llm_inference_guide.html)ã€‚\n", "\n", "* [OpenVINOæ–‡æ¡£](https://docs.openvino.ai/2024/home.html)ã€‚\n", "\n", "* [OpenVINOå…¥é—¨æŒ‡å—](https://www.intel.com/content/www/us/en/content-details/819067/openvino-get-started-guide.html)ã€‚\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}