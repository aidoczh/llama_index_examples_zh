{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/finetuning/gradient/gradient_text2sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 使用Gradient和LlamaIndex进行Text-to-SQL的微调\n", "\n", "在这个笔记本中，我们将向您展示如何在[sql-create-context](https://huggingface.co/datasets/b-mc2/sql-create-context)数据集上对llama2-7b进行微调，以使其在Text-to-SQL方面表现更好。\n", "\n", "我们将使用[gradient.ai](https://gradient.ai)来实现这一目标。\n", "\n", "**注意**：这是我们关于使用Modal对llama2-7b进行微调的repo/guide的另一种选择：https://github.com/run-llama/modal_finetune_sql\n", "\n", "**注意**：任何Text-to-SQL应用程序都应意识到执行任意SQL查询可能存在安全风险。建议根据需要采取预防措施，例如使用受限角色、只读数据库、沙箱等。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-gradient\n", "%pip install llama-index-finetuning"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index gradientai -q"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from llama_index.llms.gradient import GradientBaseModelLLM\n", "from llama_index.finetuning import GradientFinetuneEngine"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"GRADIENT_ACCESS_TOKEN\"] = os.getenv(\"GRADIENT_API_KEY\")\n", "os.environ[\"GRADIENT_WORKSPACE_ID\"] = \"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 准备数据\n", "\n", "我们从Hugging Face数据集中加载sql-create-context数据集。该数据集是WikiSQL和Spider的混合体，以输入查询、上下文和真实的SQL语句的格式进行组织。上下文是一个CREATE TABLE语句。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dialect = \"sqlite\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 加载数据，保存到目录\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datasets import load_dataset\n", "from pathlib import Path\n", "import json\n", "\n", "\n", "def load_jsonl(data_dir):\n", "    data_path = Path(data_dir).as_posix()\n", "    data = load_dataset(\"json\", data_files=data_path)\n", "    return data\n", "\n", "\n", "def save_jsonl(data_dicts, out_path):\n", "    with open(out_path, \"w\") as fp:\n", "        for data_dict in data_dicts:\n", "            fp.write(json.dumps(data_dict) + \"\\n\")\n", "\n", "\n", "def load_data_sql(data_dir: str = \"data_sql\"):\n", "    dataset = load_dataset(\"b-mc2/sql-create-context\")\n", "\n", "    dataset_splits = {\"train\": dataset[\"train\"]}\n", "    out_path = Path(data_dir)\n", "\n", "    out_path.parent.mkdir(parents=True, exist_ok=True)\n", "\n", "    for key, ds in dataset_splits.items():\n", "        with open(out_path, \"w\") as f:\n", "            for item in ds:\n", "                newitem = {\n", "                    \"input\": item[\"question\"],\n", "                    \"context\": item[\"context\"],\n", "                    \"output\": item[\"answer\"],\n", "                }\n", "                f.write(json.dumps(newitem) + \"\\n\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 将数据转储到data_sql\n", "load_data_sql(data_dir=\"data_sql\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 分割为训练/验证集\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from math import ceil\n", "\n", "\n", "def get_train_val_splits(\n", "    data_dir: str = \"data_sql\",\n", "    val_ratio: float = 0.1,\n", "    seed: int = 42,\n", "    shuffle: bool = True,\n", "):\n", "    data = load_jsonl(data_dir)\n", "    num_samples = len(data[\"train\"])\n", "    val_set_size = ceil(val_ratio * num_samples)\n", "\n", "    train_val = data[\"train\"].train_test_split(\n", "        test_size=val_set_size, shuffle=shuffle, seed=seed\n", "    )\n", "    return train_val[\"train\"].shuffle(), train_val[\"test\"].shuffle()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"application/json": {"ascii": false, "bar_format": null, "colour": null, "elapsed": 0.008841991424560547, "initial": 0, "n": 0, "ncols": null, "nrows": 28, "postfix": null, "prefix": "Downloading data files", "rate": null, "total": 1, "unit": "it", "unit_divisor": 1000, "unit_scale": false}, "application/vnd.jupyter.widget-view+json": {"model_id": "943f0cac2df34115b3f2a94615d806b8", "version_major": 2, "version_minor": 0}, "text/plain": ["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"application/json": {"ascii": false, "bar_format": null, "colour": null, "elapsed": 0.004725933074951172, "initial": 0, "n": 0, "ncols": null, "nrows": 28, "postfix": null, "prefix": "Extracting data files", "rate": null, "total": 1, "unit": "it", "unit_divisor": 1000, "unit_scale": false}, "application/vnd.jupyter.widget-view+json": {"model_id": "acefb752a3b947768c6c0a9281352880", "version_major": 2, "version_minor": 0}, "text/plain": ["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"application/json": {"ascii": false, "bar_format": null, "colour": null, "elapsed": 0.004148006439208984, "initial": 0, "n": 0, "ncols": null, "nrows": 28, "postfix": null, "prefix": "Generating train split", "rate": null, "total": 0, "unit": " examples", "unit_divisor": 1000, "unit_scale": false}, "application/vnd.jupyter.widget-view+json": {"model_id": "70e5c14e9b0e4bcd9f35014a9b0e1ff6", "version_major": 2, "version_minor": 0}, "text/plain": ["Generating train split: 0 examples [00:00, ? examples/s]"]}, "metadata": {}, "output_type": "display_data"}], "source": ["raw_train_data, raw_val_data = get_train_val_splits(data_dir=\"data_sql\")\n", "save_jsonl(raw_train_data, \"train_data_raw.jsonl\")\n", "save_jsonl(raw_val_data, \"val_data_raw.jsonl\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'input': 'If the record is 5-5, what is the game maximum?',\n", " 'context': 'CREATE TABLE table_23285805_4 (game INTEGER, record VARCHAR)',\n", " 'output': 'SELECT MAX(game) FROM table_23285805_4 WHERE record = \"5-5\"'}"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["raw_train_data[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 将训练/数据集字典映射到提示\n", "\n", "在这里，我们定义函数将数据集字典映射到一个提示格式，然后我们可以将其提供给gradient.ai的微调端点。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["### 格式类似于nous-hermes LLMs\n", "\n", "text_to_sql_tmpl_str = \"\"\"\\\n", "<s>### 指令:\\n{system_message}{user_message}\\n\\n### 响应:\\n{response}</s>\"\"\"\n", "\n", "text_to_sql_inference_tmpl_str = \"\"\"\\\n", "<s>### 指令:\\n{system_message}{user_message}\\n\\n### 响应:\\n\"\"\"\n", "\n", "### 替代格式\n", "### 推荐使用gradient.ai文档，但我们在实践中发现结果更差\n", "\n", "# text_to_sql_tmpl_str = \"\"\"\\\n", "# <s>[INST] SYS\\n{system_message}\\n<</SYS>>\\n\\n{user_message} [/INST] {response} </s>\"\"\"\n", "\n", "# text_to_sql_inference_tmpl_str = \"\"\"\\\n", "# <s>[INST] SYS\\n{system_message}\\n<</SYS>>\\n\\n{user_message} [/INST] \"\"\"\n", "\n", "def _generate_prompt_sql(input, context, dialect=\"sqlite\", output=\"\"):\n", "    system_message = f\"\"\"你是一个强大的文本到SQL模型。你的工作是回答关于数据库的问题。你会得到关于一个或多个表的问题和上下文。\n", "\n", "你必须输出能回答问题的SQL查询。\n", "    \n", "    \"\"\"\n", "    user_message = f\"\"\"### 方言:\n", "{dialect}\n", "\n", "### 输入:\n", "{input}\n", "\n", "### 上下文:\n", "{context}\n", "\n", "### 响应:\n", "\"\"\"\n", "    if output:\n", "        return text_to_sql_tmpl_str.format(\n", "            system_message=system_message,\n", "            user_message=user_message,\n", "            response=output,\n", "        )\n", "    else:\n", "        return text_to_sql_inference_tmpl_str.format(\n", "            system_message=system_message, user_message=user_message\n", "        )\n", "\n", "def generate_prompt(data_point):\n", "    full_prompt = _generate_prompt_sql(\n", "        data_point[\"input\"],\n", "        data_point[\"context\"],\n", "        dialect=\"sqlite\",\n", "        output=data_point[\"output\"],\n", "    )\n", "    return {\"inputs\": full_prompt}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = [\n", "    {\"inputs\": d[\"inputs\"] for d in raw_train_data.map(generate_prompt)}\n", "]\n", "save_jsonl(train_data, \"train_data.jsonl\")\n", "val_data = [{\"inputs\": d[\"inputs\"] for d in raw_val_data.map(generate_prompt)}]\n", "save_jsonl(val_data, \"val_data.jsonl\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<s>### Instruction:\n", "You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables. \n", "\n", "You must output the SQL query that answers the question.\n", "    \n", "    ### Dialect:\n", "sqlite\n", "\n", "### Input:\n", "Who had the fastest lap in bowmanville, ontario?\n", "\n", "### Context:\n", "CREATE TABLE table_30134667_2 (fastest_lap VARCHAR, location VARCHAR)\n", "\n", "### Response:\n", "\n", "\n", "### Response:\n", "SELECT fastest_lap FROM table_30134667_2 WHERE location = \"Bowmanville, Ontario\"</s>\n"]}], "source": ["print(train_data[0][\"inputs\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 使用gradient.ai进行微调\n", "\n", "在这里，我们使用`GradientFinetuneEngine`调用Gradient的微调端点。\n", "\n", "为了示例目的，我们限制了步骤，但您可以随意修改参数。\n", "\n", "最后，我们获取我们微调后的LLM。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 基础模型标识 = \"nous-hermes2\"\n", "base_model_slug = \"llama2-7b-chat\"\n", "base_llm = GradientBaseModelLLM(\n", "    base_model_slug=base_model_slug, max_tokens=300\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 步骤 最大步数为20，仅用于测试目的\n", "# 注意：只能指定base_model_slug或model_adapter_id中的一个\n", "finetune_engine = GradientFinetuneEngine(\n", "    base_model_slug=base_model_slug,\n", "    # model_adapter_id='805c6fd6-daa8-4fc8-a509-bebb2f2c1024_model_adapter',\n", "    name=\"text_to_sql\",\n", "    data_path=\"train_data.jsonl\",\n", "    verbose=True,\n", "    max_steps=200,\n", "    batch_size=4,\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["'805c6fd6-daa8-4fc8-a509-bebb2f2c1024_model_adapter'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["finetune_engine.model_adapter_id"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epochs = 1\n", "for i in range(epochs):\n", "    print(f\"** EPOCH {i} **\")\n", "    finetune_engine.finetune()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ft_llm = finetune_engine.get_finetuned_model(max_tokens=300)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 评估\n", "\n", "这包括两个部分：\n", "1. 我们在验证数据集中对一些样本数据点进行评估。\n", "2. 我们在一个新的玩具SQL数据集上进行评估，并将经过微调的LLM插入到我们的`NLSQLTableQueryEngine`中，以运行完整的文本到SQL的工作流程。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 第一部分：在验证数据集数据点上的评估\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_text2sql_completion(llm, raw_datapoint):\n", "    text2sql_tmpl_str = _generate_prompt_sql(\n", "        raw_datapoint[\"input\"],\n", "        raw_datapoint[\"context\"],\n", "        dialect=\"sqlite\",\n", "        output=None,\n", "    )\n", "\n", "    response = llm.complete(text2sql_tmpl_str)\n", "    return str(response)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'input': ' how many\\xa0reverse\\xa0with\\xa0series\\xa0being iii series',\n", " 'context': 'CREATE TABLE table_12284476_8 (reverse VARCHAR, series VARCHAR)',\n", " 'output': 'SELECT COUNT(reverse) FROM table_12284476_8 WHERE series = \"III series\"'}"]}, "metadata": {}, "output_type": "display_data"}], "source": ["test_datapoint = raw_val_data[2]\n", "display(test_datapoint)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 运行基础llama2-7b-chat模型\n", "get_text2sql_completion(base_llm, test_datapoint)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["'SELECT MIN(year) FROM table_name_35 WHERE venue = \"barcelona, spain\"'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# 运行微调的llama2-7b-chat模型\n", "get_text2sql_completion(ft_llm, test_datapoint)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 第二部分：对一个玩具数据集进行评估\n", "\n", "在这里，我们创建了一个包含城市及其人口的玩具数据表。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 创建表格\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 创建样本\n", "from sqlalchemy import (\n", "    create_engine,\n", "    MetaData,\n", "    Table,\n", "    Column,\n", "    String,\n", "    Integer,\n", "    select,\n", "    column,\n", ")\n", "from llama_index.core import SQLDatabase"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["engine = create_engine(\"sqlite:///:memory:\")\n", "metadata_obj = MetaData()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 创建城市SQL表\n", "table_name = \"city_stats\"\n", "city_stats_table = Table(\n", "    table_name,\n", "    metadata_obj,\n", "    Column(\"city_name\", String(16), primary_key=True),\n", "    Column(\"population\", Integer),\n", "    Column(\"country\", String(16), nullable=False),\n", ")\n", "metadata_obj.create_all(engine)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "CREATE TABLE city_stats (\n", "\tcity_name VARCHAR(16) NOT NULL, \n", "\tpopulation INTEGER, \n", "\tcountry VARCHAR(16) NOT NULL, \n", "\tPRIMARY KEY (city_name)\n", ")\n", "\n", "\n"]}], "source": ["# 这个上下文稍后会被使用\n", "from sqlalchemy.schema import CreateTable\n", "\n", "table_create_stmt = str(CreateTable(city_stats_table))\n", "print(table_create_stmt)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 使用测试数据填充\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 插入示例行\n", "from sqlalchemy import insert\n", "\n", "rows = [\n", "    {\"city_name\": \"多伦多\", \"population\": 2930000, \"country\": \"加拿大\"},\n", "    {\"city_name\": \"东京\", \"population\": 13960000, \"country\": \"日本\"},\n", "    {\n", "        \"city_name\": \"芝加哥\",\n", "        \"population\": 2679000,\n", "        \"country\": \"美国\",\n", "    },\n", "    {\"city_name\": \"首尔\", \"population\": 9776000, \"country\": \"韩国\"},\n", "]\n", "for row in rows:\n", "    stmt = insert(city_stats_table).values(**row)\n", "    with engine.connect() as connection:\n", "        cursor = connection.execute(stmt)\n", "        connection.commit()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 获取Text2SQL查询引擎\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import NLSQLTableQueryEngine\n", "from llama_index.core import PromptTemplate\n", "\n", "\n", "def get_text2sql_query_engine(llm, table_context, sql_database):\n", "    # 我们实质上是将现有的模板变量替换为新的模板变量\n", "    # 放入我们的 `NLSQLTableQueryEngine` 中\n", "    text2sql_tmpl_str = _generate_prompt_sql(\n", "        \"{query_str}\", \"{schema}\", dialect=\"{dialect}\", output=\"\"\n", "    )\n", "    sql_prompt = PromptTemplate(text2sql_tmpl_str)\n", "    # 在这里，我们明确将表上下文设置为 CREATE TABLE 字符串\n", "    # 所以我们将 `tables` 设置为空，并且硬性修复 `context_str` 前缀\n", "\n", "    query_engine = NLSQLTableQueryEngine(\n", "        sql_database,\n", "        tables=[],\n", "        context_str_prefix=table_context,\n", "        text_to_sql_prompt=sql_prompt,\n", "        llm=llm,\n", "        synthesize_response=False,\n", "    )\n", "    return query_engine"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 查询 = \"哪些城市的人口少于1000万人？\"\n", "查询 = \"东京的人口是多少？（确保城市/国家的名称首字母大写）\"\n", "# 查询 = \"这些城市的平均人口和总人口是多少？\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 使用基本llama2模型的结果\n", "基本的llama2模型在SQL语句中添加了大量文本，这破坏了我们的解析器（并且有一些小写字母的错误）。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["base_query_engine = get_text2sql_query_engine(\n", "    base_llm, table_create_stmt, sql_database\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["base_response = base_query_engine.query(query)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Error: You can only execute one statement at a time.\n"]}], "source": ["print(str(base_response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["\"SELECT population FROM city_stats WHERE country = 'JAPAN';\\n\\nThis will return the population of Tokyo, which is the only city in the table with a population value.\""]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["base_response.metadata[\"sql_query\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 经过微调模型的结果\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ft_query_engine = get_text2sql_query_engine(\n", "    ft_llm, table_create_stmt, sql_database\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ft_response = ft_query_engine.query(query)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[(13960000,)]\n"]}], "source": ["print(str(ft_response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/plain": ["'SELECT population FROM city_stats WHERE country = \"Japan\" AND city_name = \"Tokyo\"'"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["ft_response.metadata[\"sql_query\"]"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}