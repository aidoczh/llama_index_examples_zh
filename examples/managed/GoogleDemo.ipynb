{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/managed/GoogleDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在Colab中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 谷歌生成语义检索器\n", "\n", "在这个笔记本中，我们将向您展示如何快速开始使用谷歌的生成语义检索器，该检索器提供了专门针对高质量检索的嵌入模型，以及一个经过调整的模型，用于生成具有可定制安全设置的基于实际情况的输出。我们还将向您展示一些高级示例，演示如何结合LlamaIndex的强大功能和谷歌的这一独特提供。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 安装说明\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-gemini\n", "%pip install llama-index-vector-stores-google\n", "%pip install llama-index-indices-managed-google\n", "%pip install llama-index-response-synthesizers-google"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index\n", "%pip install \"google-ai-generativelanguage>=0.4,<=1.0\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Google身份验证概述\n", "\n", "Google语义检索器API允许您对自己的数据进行语义搜索。由于这是**您的数据**，因此需要比API密钥更严格的访问控制。可以使用OAuth通过服务帐户或通过用户凭据进行身份验证（示例在笔记本底部）。\n", "\n", "此快速入门使用了一种简化的身份验证方法，适用于测试环境，通常更容易从服务帐户设置开始。使用服务帐户进行身份验证的演示录像：[演示](https://drive.google.com/file/d/199LzrdhuuiordS15MJAxVrPKAwEJGPOh/view?usp=sharing)。\n", "\n", "对于生产环境，请在选择适合您的应用程序的[访问凭据](https://developers.google.com/workspace/guides/create-credentials#choose_the_access_credential_that_is_right_for_you)之前，了解有关[身份验证和授权](https://developers.google.com/workspace/guides/auth-overview)的信息。\n", "\n", "**注意**：目前，Google生成AI语义检索器API仅在[特定地区可用](https://ai.google.dev/available_regions)。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 使用服务账号设置OAuth\n", "\n", "按照以下步骤设置使用服务账号的OAuth：\n", "\n", "1. 启用[生成语言API](https://console.cloud.google.com/flows/enableapi?apiid=generativelanguage.googleapis.com)。\n", "\n", "2. 按照[文档](https://developers.google.com/identity/protocols/oauth2/service-account#creatinganaccount)创建服务账号。\n", "\n", " * 创建服务账号后，生成服务账号密钥。\n", "\n", "3. 使用左侧边栏上的文件图标，然后上传图标，上传您的服务账号文件，如下面的截图所示。\n", "\n", " * 将上传的文件重命名为`service_account_key.json`，或者在下面的代码中更改变量`service_account_file_name`。\n", "\n", "<img width=400 src=\"https://developers.generativeai.google/tutorials/images/colab_upload.png\">\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install google-auth-oauthlib"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from google.oauth2 import service_account\n", "from llama_index.vector_stores.google import set_google_config\n", "\n", "credentials = service_account.Credentials.from_service_account_file(\n", "    \"service_account_key.json\",\n", "    scopes=[\n", "        \"https://www.googleapis.com/auth/generative-language.retriever\",\n", "    ],\n", ")\n", "set_google_config(auth_credentials=credentials)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "首先，让我们在幕后创建一些辅助函数。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import llama_index.core.vector_stores.google.generativeai.genai_extension as genaix\n", "from typing import Iterable\n", "from random import randrange\n", "\n", "\n", "LLAMA_INDEX_COLAB_CORPUS_ID_PREFIX = f\"llama-index-colab\"\n", "SESSION_CORPUS_ID_PREFIX = (\n", "    f\"{LLAMA_INDEX_COLAB_CORPUS_ID_PREFIX}-{randrange(1000000)}\"\n", ")\n", "\n", "\n", "def corpus_id(num_id: int) -> str:\n", "    return f\"{SESSION_CORPUS_ID_PREFIX}-{num_id}\"\n", "\n", "\n", "SESSION_CORPUS_ID = corpus_id(1)\n", "\n", "\n", "def list_corpora() -> Iterable[genaix.Corpus]:\n", "    client = genaix.build_semantic_retriever()\n", "    yield from genaix.list_corpora(client=client)\n", "\n", "\n", "def delete_corpus(*, corpus_id: str) -> None:\n", "    client = genaix.build_semantic_retriever()\n", "    genaix.delete_corpus(corpus_id=corpus_id, client=client)\n", "\n", "\n", "def cleanup_colab_corpora():\n", "    for corpus in list_corpora():\n", "        if corpus.corpus_id.startswith(LLAMA_INDEX_COLAB_CORPUS_ID_PREFIX):\n", "            try:\n", "                delete_corpus(corpus_id=corpus.corpus_id)\n", "                print(f\"Deleted corpus {corpus.corpus_id}.\")\n", "            except Exception:\n", "                pass\n", "\n", "\n", "# 从此Colab中删除任何先前残留的语料库。\n", "cleanup_colab_corpora()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 基本用法\n", "\n", "一个`corpus`是一组`document`的集合。一个`document`是一段被分成`chunk`的文本。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "from llama_index.indices.managed.google import GoogleIndex\n", "from llama_index.core import Response\n", "import time\n", "\n", "# 创建一个语料库。\n", "index = GoogleIndex.create_corpus(\n", "    corpus_id=SESSION_CORPUS_ID, display_name=\"我的第一个语料库！\"\n", ")\n", "print(f\"新创建的语料库ID是 {index.corpus_id}。\")\n", "\n", "# 摄入。\n", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n", "index.insert_documents(documents)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["让我们检查一下我们已经摄入了什么。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for corpus in list_corpora():\n", "    print(corpus)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["让我们向索引提出一个问题。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 查询。\n", "query_engine = index.as_query_engine()\n", "response = query_engine.query(\"保罗·格雷厄姆在成长过程中做了什么？\")\n", "assert isinstance(response, Response)\n", "\n", "# 显示响应。\n", "print(f\"响应为 {response.response}\")\n", "\n", "# 显示被引用的段落，用于构建响应。\n", "for cited_text in [node.text for node in response.source_nodes]:\n", "    print(f\"被引用的文本：{cited_text}\")\n", "\n", "# 显示可回答性。0 表示无法从段落中得到答案。\n", "# 1 表示模型确定可以从段落中提供答案。\n", "if response.metadata:\n", "    print(\n", "        f\"可回答性：{response.metadata.get('answerable_probability', 0)}\"\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 创建语料库\n", "\n", "有多种方法可以创建语料库。\n", "\n", "```python\n", "# Google服务器将为您提供一个语料库ID。\n", "index = GoogleIndex.create_corpus(display_name=\"我的第一个语料库！\")\n", "print(index.corpus_id)\n", "\n", "# 您也可以提供自己的语料库ID。但是，此ID需要在全局范围内是唯一的。\n", "# 如果其他人已经使用了这个ID，您将收到一个异常。\n", "index = GoogleIndex.create_corpus(\n", "    corpus_id=\"my-first-corpus\", display_name=\"我的第一个语料库！\"\n", ")\n", "\n", "# 如果您不提供任何参数，Google将为您提供ID和默认的显示名称。\n", "index = GoogleIndex.create_corpus()\n", "```\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 重用语料库\n", "\n", "您创建的语料库将在您的Google账户下的服务器上保留。\n", "您可以使用其ID来重新获取一个句柄。\n", "然后，您可以查询它，添加更多文档等。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 使用先前创建的语料库。\n", "index = GoogleIndex.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "\n", "# 再次查询！\n", "query_engine = index.as_query_engine()\n", "response = query_engine.query(\"Paul Graham建立了哪家公司？\")\n", "assert isinstance(response, Response)\n", "\n", "# 显示响应。\n", "print(f\"响应是 {response.response}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 列出和删除语料库\n", "\n", "有关更多文档，请参阅Python库[google-generativeai](https://github.com/google/generative-ai-python)。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 加载文档\n", "\n", "LlamaIndex中的许多节点解析器和文本分割器会自动为每个节点添加一个*source_node*，以将其与文件关联起来，例如：\n", "\n", "```python\n", "    relationships={\n", "        NodeRelationship.SOURCE: RelatedNodeInfo(\n", "            node_id=\"abc-123\",\n", "            metadata={\"file_name\": \"文档的标题\"},\n", "        )\n", "    },\n", "```\n", "\n", "`GoogleIndex`和`GoogleVectorStore`都识别这个源节点，并将自动在Google服务器上的语料库下创建文档。\n", "\n", "如果您正在编写自己的分块器，您也应该像下面这样提供这个源节点关系：\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.schema import NodeRelationship, RelatedNodeInfo, TextNode\n", "\n", "index = GoogleIndex.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "index.insert_nodes(\n", "    [\n", "        TextNode(\n", "            text=\"It was the best of times.\",\n", "            relationships={\n", "                NodeRelationship.SOURCE: RelatedNodeInfo(\n", "                    node_id=\"123\",\n", "                    metadata={\"file_name\": \"Tale of Two Cities\"},\n", "                )\n", "            },\n", "        ),\n", "        TextNode(\n", "            text=\"It was the worst of times.\",\n", "            relationships={\n", "                NodeRelationship.SOURCE: RelatedNodeInfo(\n", "                    node_id=\"123\",\n", "                    metadata={\"file_name\": \"Tale of Two Cities\"},\n", "                )\n", "            },\n", "        ),\n", "        TextNode(\n", "            text=\"Bugs Bunny: Wassup doc?\",\n", "            relationships={\n", "                NodeRelationship.SOURCE: RelatedNodeInfo(\n", "                    node_id=\"456\",\n", "                    metadata={\"file_name\": \"Bugs Bunny Adventure\"},\n", "                )\n", "            },\n", "        ),\n", "    ]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["如果您的节点没有源节点，那么谷歌服务器将会将您的节点放在您语料库下的默认文档中。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 列出和删除文档\n", "\n", "请参阅Python库[google-generativeai](https://github.com/google/generative-ai-python)获取更多文档。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 查询语料库\n", "\n", "谷歌的查询引擎由一个经过特别调整的LLM支持，它根据检索到的段落来确定其响应。对于每个响应，都会返回一个“可回答概率”，以指示LLM在从检索到的段落中回答问题时的信心程度。\n", "\n", "此外，谷歌的查询引擎支持*回答风格*，例如`ABSTRACTIVE`（简洁但抽象）、`EXTRACTIVE`（非常简要和提取式）和`VERBOSE`（额外细节）。\n", "\n", "该引擎还支持*安全设置*。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from google.ai.generativelanguage import (\n", "    GenerateAnswerRequest,\n", "    HarmCategory,\n", "    SafetySetting,\n", ")\n", "\n", "index = GoogleIndex.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "query_engine = index.as_query_engine(\n", "    # 我们建议温度在0到0.2之间。\n", "    temperature=0.2,\n", "    # 查看`google-generativeai`包以获取其他语音风格。\n", "    answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE,\n", "    # 查看`google-generativeai`包以获取其他安全设置。\n", "    safety_setting=[\n", "        SafetySetting(\n", "            category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n", "            threshold=SafetySetting.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n", "        ),\n", "        SafetySetting(\n", "            category=HarmCategory.HARM_CATEGORY_VIOLENCE,\n", "            threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH,\n", "        ),\n", "    ],\n", ")\n", "\n", "response = query_engine.query(\"What was Bugs Bunny's favorite saying?\")\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["请查看Python库[google-generativeai](https://github.com/google/generative-ai-python)获取更多文档。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 解释响应\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import Response\n", "\n", "response = query_engine.query(\"Paul Graham的成就是什么？\")\n", "assert isinstance(response, Response)\n", "\n", "# 显示响应。\n", "print(f\"响应为 {response.response}\")\n", "\n", "# 显示用于构建响应的引用段落。\n", "for cited_text in [node.text for node in response.source_nodes]:\n", "    print(f\"引用文本：{cited_text}\")\n", "\n", "# 显示可回答性。0表示无法从段落中回答。\n", "# 1表示模型确定可以从段落中提供答案。\n", "if response.metadata:\n", "    print(\n", "        f\"可回答性：{response.metadata.get('answerable_probability', 0)}\"\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 高级RAG\n", "\n", "`GoogleIndex`是基于`GoogleVectorStore`和`GoogleTextSynthesizer`构建的。这些组件可以与LlamaIndex中的其他强大构造相结合，以生成高级的RAG应用程序。\n", "\n", "下面我们展示一些例子。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "首先，您需要一个API密钥。可以从[AI Studio](https://makersuite.google.com/app/apikey)获取一个。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.llms.gemini import Gemini\n", "\n", "GEMINI_API_KEY = \"\"  # @param {type:\"string\"}\n", "gemini = Gemini(api_key=GEMINI_API_KEY)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 重新排名器 + Google 检索器\n", "\n", "将内容转换为向量是一个有损的过程。基于LLM的重新排名通过使用LLM重新排名检索到的内容，从而弥补了这一缺陷，因为LLM具有更高的保真度，因为它可以访问实际查询和段落。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.response_synthesizers.google import GoogleTextSynthesizer\n", "from llama_index.vector_stores.google import GoogleVectorStore\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.core.postprocessor import LLMRerank\n", "from llama_index.core.query_engine import RetrieverQueryEngine\n", "from llama_index.core.retrievers import VectorIndexRetriever\n", "\n", "# 使用GoogleTextSynthesizer设置响应合成器。\n", "store = GoogleVectorStore.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "index = VectorStoreIndex.from_vector_store(\n", "    vector_store=store,\n", ")\n", "response_synthesizer = GoogleTextSynthesizer.from_defaults(\n", "    temperature=0.2,\n", "    answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE,\n", ")\n", "reranker = LLMRerank(\n", "    top_n=10,\n", "    llm=gemini,\n", ")\n", "query_engine = RetrieverQueryEngine.from_args(\n", "    retriever=VectorIndexRetriever(\n", "        index=index,\n", "        similarity_top_k=20,\n", "    ),\n", "    node_postprocessors=[reranker],\n", "    response_synthesizer=response_synthesizer,\n", ")\n", "\n", "# 查询。\n", "response = query_engine.query(\"What were Paul Graham's achievements?\")\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 多查询 + Google 检索器\n", "\n", "有时，用户的查询可能过于复杂。如果将原始查询分解为更小、更专注的查询，可能会获得更好的检索结果。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.indices.query.query_transform.base import (\n", "    StepDecomposeQueryTransform,\n", ")\n", "from llama_index.core.query_engine import MultiStepQueryEngine\n", "\n", "# 使用多轮查询重写设置查询引擎。\n", "store = GoogleVectorStore.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "index = VectorStoreIndex.from_vector_store(\n", "    vector_store=store,\n", ")\n", "response_synthesizer = GoogleTextSynthesizer.from_defaults(\n", "    temperature=0.2,\n", "    answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE,\n", ")\n", "single_step_query_engine = index.as_query_engine(\n", "    similarity_top_k=10,\n", "    response_synthesizer=response_synthesizer,\n", ")\n", "step_decompose_transform = StepDecomposeQueryTransform(\n", "    llm=gemini,\n", "    verbose=True,\n", ")\n", "query_engine = MultiStepQueryEngine(\n", "    query_engine=single_step_query_engine,\n", "    query_transform=step_decompose_transform,\n", "    response_synthesizer=response_synthesizer,\n", "    index_summary=\"Ask me anything.\",\n", "    num_steps=6,\n", ")\n", "\n", "# 查询。\n", "response = query_engine.query(\"What were Paul Graham's achievements?\")\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### HyDE + Google Retriever\n", "\n", "当你可以编写提示来产生与真实答案共享许多特征的虚假答案时，你可以尝试使用HyDE！\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n", "from llama_index.core.query_engine import TransformQueryEngine\n", "\n", "# 使用多轮查询重写器设置查询引擎。\n", "store = GoogleVectorStore.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "index = VectorStoreIndex.from_vector_store(\n", "    vector_store=store,\n", ")\n", "response_synthesizer = GoogleTextSynthesizer.from_defaults(\n", "    temperature=0.2,\n", "    answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE,\n", ")\n", "base_query_engine = index.as_query_engine(\n", "    similarity_top_k=10,\n", "    response_synthesizer=response_synthesizer,\n", ")\n", "hyde = HyDEQueryTransform(\n", "    llm=gemini,\n", "    include_original=False,\n", ")\n", "hyde_query_engine = TransformQueryEngine(base_query_engine, hyde)\n", "\n", "# 查询。\n", "response = query_engine.query(\"What were Paul Graham's achievements?\")\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 多查询 + 重新排序 + HyDE + Google检索器\n", "\n", "或者将它们全部结合起来！\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 谷歌的检索器和AQA模型设置。\n", "store = GoogleVectorStore.from_corpus(corpus_id=SESSION_CORPUS_ID)\n", "index = VectorStoreIndex.from_vector_store(\n", "    vector_store=store,\n", ")\n", "response_synthesizer = GoogleTextSynthesizer.from_defaults(\n", "    temperature=0.2, answer_style=GenerateAnswerRequest.AnswerStyle.ABSTRACTIVE\n", ")\n", "\n", "# 重新排序器设置。\n", "reranker = LLMRerank(\n", "    top_n=10,\n", "    llm=gemini,\n", ")\n", "single_step_query_engine = index.as_query_engine(\n", "    similarity_top_k=20,\n", "    node_postprocessors=[reranker],\n", "    response_synthesizer=response_synthesizer,\n", ")\n", "\n", "# HyDE设置。\n", "hyde = HyDEQueryTransform(\n", "    llm=gemini,\n", "    include_original=False,\n", ")\n", "hyde_query_engine = TransformQueryEngine(single_step_query_engine, hyde)\n", "\n", "# 多查询设置。\n", "step_decompose_transform = StepDecomposeQueryTransform(\n", "    llm=gemini, verbose=True\n", ")\n", "query_engine = MultiStepQueryEngine(\n", "    query_engine=hyde_query_engine,\n", "    query_transform=step_decompose_transform,\n", "    response_synthesizer=response_synthesizer,\n", "    index_summary=\"Ask me anything.\",\n", "    num_steps=6,\n", ")\n", "\n", "# 查询。\n", "response = query_engine.query(\"What were Paul Graham's achievements?\")\n", "print(response)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 清理在colab中创建的语料库\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cleanup_colab_corpora()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 附录：使用用户凭据设置OAuth\n", "\n", "请按照[OAuth快速入门](https://developers.generativeai.google/tutorials/oauth_quickstart)的步骤使用用户凭据设置OAuth。以下是文档中所需的步骤概述。\n", "\n", "1. 启用`生成语言API`：[文档](https://developers.generativeai.google/tutorials/oauth_quickstart#1_enable_the_api)\n", "\n", "2. 配置OAuth同意屏幕：[文档](https://developers.generativeai.google/tutorials/oauth_quickstart#2_configure_the_oauth_consent_screen)\n", "\n", "3. 为桌面应用程序授权凭据：[文档](https://developers.generativeai.google/tutorials/oauth_quickstart#3_authorize_credentials_for_a_desktop_application)\n", "   * 如果您想在Colab中运行此笔记本，请先使用“文件 > 上传”选项上传您的`client_secret*.json`文件。\n", "\n", "   * 将上传的文件重命名为`client_secret.json`，或者在下面的代码中更改变量`client_file_name`。\n", "\n", "<img width=400 src=\"https://developers.generativeai.google/tutorials/images/colab_upload.png\">\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "# 用OAuth快速入门中使用的项目替换TODO-your-project-name\n", "project_name = \"TODO-your-project-name\"  #  @param {type:\"string\"}\n", "# 用作OAuth快速入门中添加的测试用户的电子邮件替换TODO-your-email@gmail.com\n", "email = \"TODO-your-email@gmail.com\"  #  @param {type:\"string\"}\n", "# 用上传的client_secret_*文件名替换client_secret.json\n", "client_file_name = \"client_secret.json\"\n", "\n", "# 重要提示：按照输出中的说明操作 - 您必须将命令复制到您的终端，并将身份验证后的输出复制回这里。\n", "!gcloud config set project $project_name\n", "!gcloud config set account $email\n", "\n", "# 注意：本教程中简化的项目设置会触发“Google尚未验证此应用程序。”对话框。\n", "# 这是正常的，请单击“高级” -> “转到[应用程序名称]（不安全）”\n", "!gcloud auth application-default login --no-browser --client-id-file=$client_file_name --scopes=\"https://www.googleapis.com/auth/generative-language.retriever,https://www.googleapis.com/auth/cloud-platform\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["这将为您提供一个URL，您应该在本地浏览器中输入该URL。\n", "按照指示完成认证和授权。\n"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}