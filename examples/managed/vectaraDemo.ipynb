{"cells": [{"cell_type": "markdown", "id": "adf7d63d", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/managed/vectaraDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "db0855d0", "metadata": {}, "source": ["# Vectaraæ‰˜ç®¡ç´¢å¼•\n", "åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•å°† [Vectara](https://vectara.com) ä¸ LlamaIndex ç»“åˆä½¿ç”¨ã€‚\n", "\n", "Vectaraæä¾›äº†ç”¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„ç«¯åˆ°ç«¯æ‰˜ç®¡æœåŠ¡ï¼Œå…¶ä¸­åŒ…æ‹¬ï¼š\n", "1. ä»æ–‡æ¡£æ–‡ä»¶ä¸­æå–æ–‡æœ¬å¹¶å°†å…¶åˆ†å—æˆå¥å­çš„æ–¹æ³•ã€‚\n", "2. æœ€å…ˆè¿›çš„ [Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/) åµŒå…¥æ¨¡å‹ã€‚æ¯ä¸ªæ–‡æœ¬å—éƒ½ä½¿ç”¨Boomerangç¼–ç ä¸ºå‘é‡åµŒå…¥ï¼Œå¹¶å­˜å‚¨åœ¨Vectaraå†…éƒ¨å‘é‡å­˜å‚¨ä¸­ã€‚å› æ­¤ï¼Œå½“å°†Vectaraä¸LlamaIndexä¸€èµ·ä½¿ç”¨æ—¶ï¼Œæ‚¨æ— éœ€è°ƒç”¨å•ç‹¬çš„åµŒå…¥æ¨¡å‹ - è¿™åœ¨Vectaraåç«¯å†…éƒ¨è‡ªåŠ¨å®Œæˆã€‚\n", "3. ä¸€ä¸ªæŸ¥è¯¢æœåŠ¡ï¼Œè‡ªåŠ¨å°†æŸ¥è¯¢ç¼–ç ä¸ºåµŒå…¥ï¼Œå¹¶æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æœ¬æ®µè½ï¼ˆåŒ…æ‹¬å¯¹ [æ··åˆæœç´¢](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching) å’Œ [MMR](https://vectara.com/get-diverse-results-and-comprehensive-summaries-with-vectaras-mmr-reranker/) çš„æ”¯æŒï¼‰\n", "4. ä¸€ä¸ªé€‰é¡¹ï¼Œå¯ä»¥åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ›å»º [ç”Ÿæˆæ‘˜è¦](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview)ï¼ŒåŒ…æ‹¬å¼•ç”¨ã€‚\n", "\n", "è¯·å‚é˜… [Vectara APIæ–‡æ¡£](https://docs.vectara.com/docs/) ä»¥è·å–æœ‰å…³å¦‚ä½•ä½¿ç”¨APIçš„æ›´å¤šä¿¡æ¯ã€‚\n"]}, {"cell_type": "markdown", "id": "cfe2497c", "metadata": {}, "source": ["## å¼€å§‹\n", "\n", "å¦‚æœä½ åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œä½ å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "6019e01a", "metadata": {}, "outputs": [], "source": ["!pip install llama-index lama-index-indices-managed-vectara"]}, {"cell_type": "markdown", "id": "2b201796-4463-4ec4-b537-d855a384878c", "metadata": {}, "source": ["è¦å¼€å§‹ä½¿ç”¨Vectaraï¼Œè¯·[æ³¨å†Œ](https://vectara.com/integrations/llamaindex)ï¼ˆå¦‚æœå°šæœªæ³¨å†Œï¼‰ï¼Œå¹¶æŒ‰ç…§æˆ‘ä»¬çš„[å¿«é€Ÿå…¥é—¨æŒ‡å—](https://docs.vectara.com/docs/quickstart)åˆ›å»ºè¯­æ–™åº“å’ŒAPIå¯†é’¥ã€‚\n", "\n", "ä¸€æ—¦æ‚¨æ‹¥æœ‰è¿™äº›å†…å®¹ï¼Œæ‚¨å¯ä»¥å°†å®ƒä»¬ä½œä¸ºç¯å¢ƒå˜é‡æä¾›ï¼Œç¨åLlamaIndexä»£ç å°†ä½¿ç”¨å®ƒä»¬ã€‚\n", "\n", "```python\n", "import os\n", "os.environ['VECTARA_API_KEY'] = \"<YOUR_VECTARA_API_KEY>\"\n", "os.environ['VECTARA_CORPUS_ID'] = \"<YOUR_VECTARA_CORPUS_ID>\"\n", "os.environ['VECTARA_CUSTOMER_ID'] = \"<YOUR_VECTARA_CUSTOMER_ID>\"\n", "```\n"]}, {"cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["## ä½¿ç”¨LlamaIndexå’ŒVectaraè¿›è¡ŒRAG\n", "\n", "æœ‰å‡ ç§æ–¹æ³•å¯ä»¥å°†æ•°æ®ç´¢å¼•åˆ°Vectaraä¸­ï¼ŒåŒ…æ‹¬ï¼š\n", "1. ä½¿ç”¨`VectaraIndex`çš„`from_documents()`æˆ–`insert_file()`æ–¹æ³•\n", "2. ç›´æ¥åœ¨[Vectaraæ§åˆ¶å°](https://console.vectara.com/)ä¸­ä¸Šä¼ æ–‡ä»¶\n", "3. ä½¿ç”¨Vectaraçš„FILE_UPLOADæˆ–æ ‡å‡†ç´¢å¼•API\n", "4. ä½¿ç”¨[vectara-ingest](https://github.com/vectara/vectara-ingest)ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„çˆ¬è™«/ç´¢å¼•å™¨é¡¹ç›®\n", "5. ä½¿ç”¨æˆ‘ä»¬çš„æ•°æ®æ‘„å–é›†æˆåˆä½œä¼™ä¼´ï¼Œå¦‚Airbyteã€Unstructuredæˆ–DataVoloã€‚\n", "\n", "ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ç»„ç®€å•çš„å°å‹æ–‡æ¡£ï¼Œå› æ­¤ç›´æ¥ä½¿ç”¨`VectaraIndex`è¿›è¡Œæ‘„å–å°±è¶³å¤Ÿäº†ã€‚\n", "\n", "è®©æˆ‘ä»¬å°†â€œAIæƒåˆ©æ³•æ¡ˆâ€æ–‡æ¡£æ‘„å–åˆ°æˆ‘ä»¬çš„æ–°è¯­æ–™åº“ä¸­ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "c154dd4b", "metadata": {}, "outputs": [], "source": ["from llama_index.indices.managed.vectara import VectaraIndex\n", "import requests\n", "\n", "url = \"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\"\n", "response = requests.get(url)\n", "local_path = \"ai-bill-of-rights.pdf\"\n", "with open(local_path, \"wb\") as file:\n", "    file.write(response.content)\n", "\n", "index = VectaraIndex()\n", "index.insert_file(\n", "    local_path, metadata={\"name\": \"AI bill of rights\", \"year\": 2022}\n", ")"]}, {"cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["### ä½¿ç”¨VectaraæŸ¥è¯¢å¼•æ“è¿è¡Œå•ä¸ªæŸ¥è¯¢\n", "ç°åœ¨æˆ‘ä»¬å·²ç»ä¸Šä¼ äº†æ–‡æ¡£ï¼ˆæˆ–è€…ä¹‹å‰å·²ç»ä¸Šä¼ äº†æ–‡æ¡£ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨LlamaIndexä¸­æå‡ºé—®é¢˜ã€‚è¿™å°†æ¿€æ´»Vectaraçš„RAGç®¡é“ã€‚\n", "\n", "è¦ä½¿ç”¨Vectaraå†…éƒ¨çš„LLMè¿›è¡Œæ‘˜è¦ç”Ÿæˆï¼Œè¯·ç¡®ä¿åœ¨ç”ŸæˆæŸ¥è¯¢å¼•æ“æ—¶æŒ‡å®š`summary_enabled=True`ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š\n"]}, {"cell_type": "code", "execution_count": null, "id": "bb174ec3", "metadata": {}, "outputs": [], "source": ["questions = [\n", "    \"What are the risks of AI?\",\n", "    \"What should we do to prevent bad actors from using AI?\",\n", "    \"What are the benefits?\",\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "890f7133", "metadata": {}, "outputs": [{"data": {"text/plain": ["\"The risks associated with AI include potential biases leading to discriminatory outcomes, lack of transparency in decision-making processes, and challenges in establishing public trust and understanding of algorithmic systems [1]. Safety and efficacy concerns arise in the context of complex technologies like AI, necessitating strong regulations and proactive risk mitigation strategies [2]. The process of identifying and addressing risks before and during the deployment of automated systems is crucial to prevent harm to individuals' rights, opportunities, and access [5]. Furthermore, the impact of AI risks can be most visible at the community level, emphasizing the importance of considering and mitigating harms to various communities [6]. Efforts are being made to translate principles into practice through laws, policies, and technical approaches to ensure AI systems are lawful, respectful, accurate, safe, understandable, responsible, and accountable [7].\""]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["qe = index.as_query_engine(summary_enabled=True)\n", "qe.query(questions[0]).response"]}, {"cell_type": "markdown", "id": "5c464a9a-0386-43d5-b074-c7ee8eb1d3fe", "metadata": {}, "source": ["å¦‚æœå¸Œæœ›ä»¥æµæ¨¡å¼è¿”å›å“åº”ï¼Œåªéœ€è®¾ç½®`streaming=True`\n"]}, {"cell_type": "code", "execution_count": null, "id": "e4eafb4c-4fe7-4e81-b588-dd83979917fc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The risks of AI include biased data leading to discriminatory outcomes, opaque decision-making processes, and lack of public trust and understanding in algorithmic systems [1]. Organizations are implementing innovative solutions like risk assessments, auditing mechanisms, and ongoing monitoring to mitigate safety and efficacy risks of AI systems [2]. Stakeholder engagement and a risk management framework by institutions like NIST aim to address risks to individuals, organizations, and society posed by AI technology [3]. Risk identification, mitigation, and focusing on safety and effectiveness of AI systems are crucial before and during deployment to protect peopleâ€™s rights, opportunities, and access [5]. The concept of communities is integral in understanding the impact of AI and automated systems, as the potential harm may be most visible at the community level [6]. Practical implementation of principles such as lawful, purposeful, accurate, safe, and accountable AI is essential to address risks, with federal agencies adhering to guidelines promoting trustworthy AI [7]."]}], "source": ["qe = index.as_query_engine(summary_enabled=True, streaming=True)\n", "response = qe.query(questions[0])\n", "\n", "for chunk in response.response_gen:\n", "    print(chunk.delta or \"\", end=\"\", flush=True)"]}, {"cell_type": "markdown", "id": "d2e74c56-2fd3-4e0d-a387-d6088766ce2c", "metadata": {}, "source": ["### ä½¿ç”¨VectaraèŠå¤©\n", "\n", "Vectaraè¿˜æ”¯æŒç®€å•çš„èŠå¤©æ¨¡å¼ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼ŒèŠå¤©å†å²ç”±Vectaraç»´æŠ¤ï¼Œå› æ­¤æ‚¨ä¸å¿…æ‹…å¿ƒå®ƒã€‚è¦ä½¿ç”¨å®ƒï¼Œåªéœ€è°ƒç”¨`as_chat_engine`ã€‚\n", "\n", "ï¼ˆèŠå¤©æ¨¡å¼å§‹ç»ˆä½¿ç”¨Vectaraçš„æ‘˜è¦åŠŸèƒ½ï¼Œå› æ­¤æ‚¨æ— éœ€åƒä»¥å‰é‚£æ ·æ˜¾å¼åœ°æŒ‡å®š`summary_enabled=True`ï¼‰\n"]}, {"cell_type": "code", "execution_count": null, "id": "72eb45dc-b02b-4c5f-9f93-28d0e20d6b3f", "metadata": {}, "outputs": [], "source": ["ce = index.as_chat_engine()"]}, {"cell_type": "code", "execution_count": null, "id": "4907248f-ff80-41fa-98e9-b1e4bb1b1400", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Question: What are the risks of AI?\n", "\n", "Response: The risks of AI involve potential biases, opaque decision-making processes, and lack of public trust due to discriminatory outcomes and biased data [1]. To mitigate these risks, industry is implementing innovative solutions like risk assessments and monitoring mechanisms [2]. Stakeholder engagement and the development of a risk management framework by organizations like the National Institute of Standards and Technology aim to manage risks posed by AI to individuals, organizations, and society [3]. Identification and mitigation of potential risks, impact assessments, and balancing high impact risks with appropriate mitigation are crucial before and during the deployment of AI systems [5]. The Blueprint for an AI Bill of Rights emphasizes the protection of individuals from unsafe or ineffective AI systems [7].\n", "\n", "Question: What should we do to prevent bad actors from using AI?\n", "\n", "Response: To prevent the misuse of AI by malicious entities, several key measures can be implemented. Firstly, it is crucial to ensure that automated systems are designed with safety and effectiveness in mind, following principles such as being lawful, purposeful, accurate, secure, and transparent [2]. Entities should proactively identify and manage risks associated with sensitive data, conducting regular audits and limiting access to prevent misuse [3], [4], [5]. Additionally, ongoing monitoring of automated systems is essential to detect and address algorithmic discrimination and unforeseen interactions that could lead to misuse [6], [7]. By incorporating these practices into the design, development, and deployment of AI technologies, the potential for misuse by malicious entities can be significantly reduced.\n", "\n", "Question: What are the benefits?\n", "\n", "Response: Artificial Intelligence (AI) offers various advantages, such as promoting the use of trustworthy AI systems with principles focusing on legality, performance, safety, transparency, and accountability [1]. Organizations are incorporating protections and ethical principles in AI development, aligning with global recommendations for responsible AI stewardship [2]. Furthermore, research is ongoing to enhance explainable AI systems for better human understanding and trust in AI outcomes [5]. The U.S. government is establishing councils and frameworks to advance AI technologies, ensuring responsible AI implementation across sectors [4], . AI can streamline processes, improve decision-making, and enhance efficiency, although challenges like bias, flaws, and accessibility issues need to be addressed to maximize its benefits [5].\n", "\n"]}], "source": ["for q in questions:\n", "    print(f\"Question: {q}\\n\")\n", "    response = ce.chat(q).response\n", "    print(f\"Response: {response}\\n\")"]}, {"cell_type": "markdown", "id": "b105809b-efea-4937-b6a3-e3de8986aa8c", "metadata": {}, "source": ["å½“ç„¶ï¼Œæµå¼ä¼ è¾“åœ¨èŠå¤©ä¸­ä¹Ÿé€‚ç”¨ï¼š\n"]}, {"cell_type": "code", "execution_count": null, "id": "61cc0885-01a4-4569-864d-0eb8bbc70eab", "metadata": {}, "outputs": [], "source": ["ce = index.as_chat_engine(streaming=True)"]}, {"cell_type": "code", "execution_count": null, "id": "e44797ff-d23f-4d6a-9839-82aec6040af0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The search results indicate a focus on the relationship between humans and robots, emphasizing the need for co-intelligence and the best use of automated systems [2]. The discussions revolve around ensuring that automated systems are designed, tested, and protected to prevent potential harmful outcomes [1]. While there are concerns about the use of surveillance technology by companies like Amazon and Walmart, the emphasis is on balancing equities and maintaining oversight in law enforcement activities [5]. The search results do not directly answer whether robots will kill us all, but they highlight the importance of proactive protections, context-specific guidance, and existing policies to govern the use of automated systems in various settings [6]."]}], "source": ["response = ce.stream_chat(\"Will robots kill us all?\")\n", "for chunk in response.chat_stream:\n", "    print(chunk.delta or \"\", end=\"\", flush=True)"]}, {"cell_type": "markdown", "id": "e52fe86d-b0d5-4520-bac2-df9324a5eacc", "metadata": {}, "source": ["### ä»£ç† RAG\n", "\n", "è®©æˆ‘ä»¬ä½¿ç”¨ LlamaIndex åˆ›å»ºä¸€ä¸ª ReAct ä»£ç†ï¼Œè¯¥ä»£ç†åˆ©ç”¨ Vectara ä½œä¸ºå…¶ RAG å·¥å…·ã€‚\n", "ä¸ºæ­¤ï¼Œæ‚¨éœ€è¦ä½¿ç”¨å¦ä¸€ä¸ª LLM ä½œä¸ºä»£ç†æ¨ç†çš„é©±åŠ¨ç¨‹åºï¼Œè¿™é‡Œæˆ‘ä»¬ä»¥ OpenAI çš„ GPT4o ä½œä¸ºç¤ºä¾‹ã€‚\n", "ï¼ˆä¸ºä½¿æ­¤å·¥ä½œï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒä¸­å®šä¹‰äº† `OPENAI_API_KEY`ï¼‰ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "c6766a84-b228-4b80-a32b-0c167b843819", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import ReActAgent", "from llama_index.llms.openai import OpenAI", "from llama_index.core.tools import QueryEngineTool, ToolMetadata", "", "llm = OpenAI(model=\"gpt-4o\", temperature=0)", "vectara_tool = QueryEngineTool(", "    query_engine=index.as_query_engine(", "        summary_enabled=True,", "        summary_num_results=5,", "        summary_response_lang=\"en\",", "        summary_prompt_name=\"vectara-summary-ext-24-05-large\",", "        reranker=\"mmr\",", "        rerank_k=50,", "        mmr_diversity_bias=0.2,", "    ),", "    metadata=ToolMetadata(", "        name=\"Vectara\",", "        description=\"Vectara Query Engine that is able to answer Questions about AI regulation.\",", "    ),", ")", "agent = ReActAgent.from_tools(", "    tools=[vectara_tool],", "    llm=llm,", "    context=\"\"\"", "        ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„èŠå¤©æœºå™¨äººï¼Œå¯ä»¥ä½¿ç”¨Vectaraå·¥å…·å›ç­”å…³äºAIç›‘ç®¡çš„ä»»ä½•ç”¨æˆ·é—®é¢˜ã€‚", "        ä½ å°†å¤æ‚çš„é—®é¢˜åˆ†è§£æˆæ›´ç®€å•çš„é—®é¢˜ã€‚", "        ä½ ä½¿ç”¨VectaraæŸ¥è¯¢å¼•æ“æ¥å¸®åŠ©å›ç­”æ›´ç®€å•çš„é—®é¢˜ã€‚", "    \"\"\",", "    verbose=True,", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8a68dbca-613a-4f44-aa9e-67a758f76683", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n", "Action: Vectara\n", "Action Input: {'input': 'What are the risks of AI?'}\n", "\u001b[0m\u001b[1;3;34mObservation: The risks of AI include biased data leading to discriminatory outcomes, opaque decision-making processes, and a lack of public trust and understanding in algorithmic systems. Mitigation strategies discussed involve ongoing transparency, participatory design, and engaging with impacted communities to understand potential harms and integrate protections into the design of AI systems [1]. Additionally, there's a focus on identifying and mitigating risks before deployment, particularly those impacting people's rights, opportunities, or safety, with a strong emphasis on avoiding systems that inherently violate safety norms [5].\n", "\u001b[0m\u001b[1;3;38;5;200mThought: I have obtained information about the risks of AI. Now, I need to gather information about the benefits of AI to provide a comprehensive comparison.\n", "Action: Vectara\n", "Action Input: {'input': 'What are the benefits of AI?'}\n", "\u001b[0m\u001b[1;3;34mObservation: The benefits of AI include its transformative potential to improve people's lives by building better and more innovative infrastructure. It also offers the possibility to enhance community health, safety, and welfare by ensuring better representation of all voices, particularly those traditionally marginalized by technological advances [1]. AI can also prevent harms and improve opportunities, rights, and access for Americans, playing a central role in shaping important policies like the Blueprint for an AI Bill of Rights [2].\n", "\u001b[0m\u001b[1;3;38;5;200mThought: I have gathered information about both the risks and benefits of AI. Now, I need to compare and contrast these points and provide a summary with arguments for and against from experts.\n", "Answer: ### Comparison of Risks and Benefits of AI\n", "\n", "#### Risks of AI:\n", "1. **Biased Data and Discriminatory Outcomes**: AI systems can perpetuate and even exacerbate biases present in the data they are trained on, leading to unfair and discriminatory outcomes.\n", "2. **Opaque Decision-Making**: The decision-making processes of AI systems can be complex and not easily understandable, leading to a lack of transparency.\n", "3. **Lack of Public Trust**: The opacity and potential biases in AI systems can result in a lack of trust and understanding from the public.\n", "4. **Safety and Rights Violations**: There is a risk of AI systems violating safety norms and impacting people's rights, opportunities, or safety.\n", "\n", "#### Benefits of AI:\n", "1. **Improved Infrastructure**: AI has the potential to transform and improve infrastructure, making it more innovative and efficient.\n", "2. **Enhanced Community Health and Safety**: AI can play a significant role in improving community health, safety, and welfare by ensuring better representation and inclusivity.\n", "3. **Prevention of Harms**: AI can help prevent harms and improve opportunities, rights, and access, particularly for marginalized communities.\n", "4. **Policy Shaping**: AI is central to shaping important policies, such as the Blueprint for an AI Bill of Rights, which aims to protect and enhance the rights of individuals.\n", "\n", "### Summary with Arguments For and Against AI\n", "\n", "#### Arguments For AI:\n", "- **Innovation and Efficiency**: AI can drive significant advancements in technology and infrastructure, leading to more efficient and innovative solutions.\n", "- **Inclusivity and Representation**: AI can ensure better representation of marginalized voices, leading to more equitable outcomes.\n", "- **Health and Safety**: AI can enhance community health and safety by providing better tools and systems for monitoring and intervention.\n", "- **Policy and Rights**: AI can play a crucial role in shaping policies that protect and enhance individual rights and opportunities.\n", "\n", "#### Arguments Against AI:\n", "- **Bias and Discrimination**: The risk of biased data leading to discriminatory outcomes is a significant concern.\n", "- **Transparency and Trust**: The opaque nature of AI decision-making processes can erode public trust and understanding.\n", "- **Safety Risks**: There is a potential for AI systems to violate safety norms and impact people's rights and safety negatively.\n", "- **Complexity of Mitigation**: Mitigating the risks associated with AI requires ongoing transparency, participatory design, and engagement with impacted communities, which can be complex and resource-intensive.\n", "\n", "In conclusion, while AI offers numerous benefits, including innovation, improved infrastructure, and enhanced community welfare, it also poses significant risks related to bias, transparency, and safety. Experts argue that a balanced approach, involving robust mitigation strategies and inclusive design, is essential to harness the benefits of AI while minimizing its risks.\n", "\u001b[0m### Comparison of Risks and Benefits of AI\n", "\n", "#### Risks of AI:\n", "1. **Biased Data and Discriminatory Outcomes**: AI systems can perpetuate and even exacerbate biases present in the data they are trained on, leading to unfair and discriminatory outcomes.\n", "2. **Opaque Decision-Making**: The decision-making processes of AI systems can be complex and not easily understandable, leading to a lack of transparency.\n", "3. **Lack of Public Trust**: The opacity and potential biases in AI systems can result in a lack of trust and understanding from the public.\n", "4. **Safety and Rights Violations**: There is a risk of AI systems violating safety norms and impacting people's rights, opportunities, or safety.\n", "\n", "#### Benefits of AI:\n", "1. **Improved Infrastructure**: AI has the potential to transform and improve infrastructure, making it more innovative and efficient.\n", "2. **Enhanced Community Health and Safety**: AI can play a significant role in improving community health, safety, and welfare by ensuring better representation and inclusivity.\n", "3. **Prevention of Harms**: AI can help prevent harms and improve opportunities, rights, and access, particularly for marginalized communities.\n", "4. **Policy Shaping**: AI is central to shaping important policies, such as the Blueprint for an AI Bill of Rights, which aims to protect and enhance the rights of individuals.\n", "\n", "### Summary with Arguments For and Against AI\n", "\n", "#### Arguments For AI:\n", "- **Innovation and Efficiency**: AI can drive significant advancements in technology and infrastructure, leading to more efficient and innovative solutions.\n", "- **Inclusivity and Representation**: AI can ensure better representation of marginalized voices, leading to more equitable outcomes.\n", "- **Health and Safety**: AI can enhance community health and safety by providing better tools and systems for monitoring and intervention.\n", "- **Policy and Rights**: AI can play a crucial role in shaping policies that protect and enhance individual rights and opportunities.\n", "\n", "#### Arguments Against AI:\n", "- **Bias and Discrimination**: The risk of biased data leading to discriminatory outcomes is a significant concern.\n", "- **Transparency and Trust**: The opaque nature of AI decision-making processes can erode public trust and understanding.\n", "- **Safety Risks**: There is a potential for AI systems to violate safety norms and impact people's rights and safety negatively.\n", "- **Complexity of Mitigation**: Mitigating the risks associated with AI requires ongoing transparency, participatory design, and engagement with impacted communities, which can be complex and resource-intensive.\n", "\n", "In conclusion, while AI offers numerous benefits, including innovation, improved infrastructure, and enhanced community welfare, it also poses significant risks related to bias, transparency, and safety. Experts argue that a balanced approach, involving robust mitigation strategies and inclusive design, is essential to harness the benefits of AI while minimizing its risks.\n"]}], "source": ["é—®é¢˜ = \"\"\"", "    äººå·¥æ™ºèƒ½çš„é£é™©æ˜¯ä»€ä¹ˆï¼Ÿæœ‰å“ªäº›å¥½å¤„ï¼Ÿ", "    ä»ä¸“å®¶çš„è§‚ç‚¹æ¯”è¾ƒå’Œå¯¹æ¯”ï¼Œå¹¶æä¾›èµæˆå’Œåå¯¹çš„è®ºç‚¹çš„æ‘˜è¦ã€‚", "\"\"\"", "", "print(agent.chat(question).response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}