{"cells": [{"cell_type": "markdown", "id": "adf7d63d", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/examples/managed/vectaraDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "db0855d0", "metadata": {}, "source": ["# Vectara托管索引\n", "在这个笔记本中，我们将展示如何将 [Vectara](https://vectara.com) 与 LlamaIndex 结合使用。\n", "\n", "Vectara提供了用于检索增强生成（RAG）的端到端托管服务，其中包括：\n", "1. 从文档文件中提取文本并将其分块成句子的方法。\n", "2. 最先进的 [Boomerang](https://vectara.com/how-boomerang-takes-retrieval-augmented-generation-to-the-next-level-via-grounded-generation/) 嵌入模型。每个文本块都使用Boomerang编码为向量嵌入，并存储在Vectara内部向量存储中。因此，当将Vectara与LlamaIndex一起使用时，您无需调用单独的嵌入模型 - 这在Vectara后端内部自动完成。\n", "3. 一个查询服务，自动将查询编码为嵌入，并检索最相关的文本段落（包括对 [混合搜索](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching) 和 [MMR](https://vectara.com/get-diverse-results-and-comprehensive-summaries-with-vectaras-mmr-reranker/) 的支持）\n", "4. 一个选项，可以基于检索到的文档创建 [生成摘要](https://docs.vectara.com/docs/learn/grounded-generation/grounded-generation-overview)，包括引用。\n", "\n", "请参阅 [Vectara API文档](https://docs.vectara.com/docs/) 以获取有关如何使用API的更多信息。\n"]}, {"cell_type": "markdown", "id": "cfe2497c", "metadata": {}, "source": ["## 开始\n", "\n", "如果你在colab上打开这个笔记本，你可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "6019e01a", "metadata": {}, "outputs": [], "source": ["!pip install llama-index lama-index-indices-managed-vectara"]}, {"cell_type": "markdown", "id": "2b201796-4463-4ec4-b537-d855a384878c", "metadata": {}, "source": ["要开始使用Vectara，请[注册](https://vectara.com/integrations/llamaindex)（如果尚未注册），并按照我们的[快速入门指南](https://docs.vectara.com/docs/quickstart)创建语料库和API密钥。\n", "\n", "一旦您拥有这些内容，您可以将它们作为环境变量提供，稍后LlamaIndex代码将使用它们。\n", "\n", "```python\n", "import os\n", "os.environ['VECTARA_API_KEY'] = \"<YOUR_VECTARA_API_KEY>\"\n", "os.environ['VECTARA_CORPUS_ID'] = \"<YOUR_VECTARA_CORPUS_ID>\"\n", "os.environ['VECTARA_CUSTOMER_ID'] = \"<YOUR_VECTARA_CUSTOMER_ID>\"\n", "```\n"]}, {"cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["## 使用LlamaIndex和Vectara进行RAG\n", "\n", "有几种方法可以将数据索引到Vectara中，包括：\n", "1. 使用`VectaraIndex`的`from_documents()`或`insert_file()`方法\n", "2. 直接在[Vectara控制台](https://console.vectara.com/)中上传文件\n", "3. 使用Vectara的FILE_UPLOAD或标准索引API\n", "4. 使用[vectara-ingest](https://github.com/vectara/vectara-ingest)，这是一个开源的爬虫/索引器项目\n", "5. 使用我们的数据摄取集成合作伙伴，如Airbyte、Unstructured或DataVolo。\n", "\n", "为此，我们将使用一组简单的小型文档，因此直接使用`VectaraIndex`进行摄取就足够了。\n", "\n", "让我们将“AI权利法案”文档摄取到我们的新语料库中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "c154dd4b", "metadata": {}, "outputs": [], "source": ["from llama_index.indices.managed.vectara import VectaraIndex\n", "import requests\n", "\n", "url = \"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\"\n", "response = requests.get(url)\n", "local_path = \"ai-bill-of-rights.pdf\"\n", "with open(local_path, \"wb\") as file:\n", "    file.write(response.content)\n", "\n", "index = VectaraIndex()\n", "index.insert_file(\n", "    local_path, metadata={\"name\": \"AI bill of rights\", \"year\": 2022}\n", ")"]}, {"cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["### 使用Vectara查询引擎运行单个查询\n", "现在我们已经上传了文档（或者之前已经上传了文档），我们可以直接在LlamaIndex中提出问题。这将激活Vectara的RAG管道。\n", "\n", "要使用Vectara内部的LLM进行摘要生成，请确保在生成查询引擎时指定`summary_enabled=True`。以下是一个示例：\n"]}, {"cell_type": "code", "execution_count": null, "id": "bb174ec3", "metadata": {}, "outputs": [], "source": ["questions = [\n", "    \"What are the risks of AI?\",\n", "    \"What should we do to prevent bad actors from using AI?\",\n", "    \"What are the benefits?\",\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "890f7133", "metadata": {}, "outputs": [{"data": {"text/plain": ["\"The risks associated with AI include potential biases leading to discriminatory outcomes, lack of transparency in decision-making processes, and challenges in establishing public trust and understanding of algorithmic systems [1]. Safety and efficacy concerns arise in the context of complex technologies like AI, necessitating strong regulations and proactive risk mitigation strategies [2]. The process of identifying and addressing risks before and during the deployment of automated systems is crucial to prevent harm to individuals' rights, opportunities, and access [5]. Furthermore, the impact of AI risks can be most visible at the community level, emphasizing the importance of considering and mitigating harms to various communities [6]. Efforts are being made to translate principles into practice through laws, policies, and technical approaches to ensure AI systems are lawful, respectful, accurate, safe, understandable, responsible, and accountable [7].\""]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["qe = index.as_query_engine(summary_enabled=True)\n", "qe.query(questions[0]).response"]}, {"cell_type": "markdown", "id": "5c464a9a-0386-43d5-b074-c7ee8eb1d3fe", "metadata": {}, "source": ["如果希望以流模式返回响应，只需设置`streaming=True`\n"]}, {"cell_type": "code", "execution_count": null, "id": "e4eafb4c-4fe7-4e81-b588-dd83979917fc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The risks of AI include biased data leading to discriminatory outcomes, opaque decision-making processes, and lack of public trust and understanding in algorithmic systems [1]. Organizations are implementing innovative solutions like risk assessments, auditing mechanisms, and ongoing monitoring to mitigate safety and efficacy risks of AI systems [2]. Stakeholder engagement and a risk management framework by institutions like NIST aim to address risks to individuals, organizations, and society posed by AI technology [3]. Risk identification, mitigation, and focusing on safety and effectiveness of AI systems are crucial before and during deployment to protect people’s rights, opportunities, and access [5]. The concept of communities is integral in understanding the impact of AI and automated systems, as the potential harm may be most visible at the community level [6]. Practical implementation of principles such as lawful, purposeful, accurate, safe, and accountable AI is essential to address risks, with federal agencies adhering to guidelines promoting trustworthy AI [7]."]}], "source": ["qe = index.as_query_engine(summary_enabled=True, streaming=True)\n", "response = qe.query(questions[0])\n", "\n", "for chunk in response.response_gen:\n", "    print(chunk.delta or \"\", end=\"\", flush=True)"]}, {"cell_type": "markdown", "id": "d2e74c56-2fd3-4e0d-a387-d6088766ce2c", "metadata": {}, "source": ["### 使用Vectara聊天\n", "\n", "Vectara还支持简单的聊天模式。在这种模式下，聊天历史由Vectara维护，因此您不必担心它。要使用它，只需调用`as_chat_engine`。\n", "\n", "（聊天模式始终使用Vectara的摘要功能，因此您无需像以前那样显式地指定`summary_enabled=True`）\n"]}, {"cell_type": "code", "execution_count": null, "id": "72eb45dc-b02b-4c5f-9f93-28d0e20d6b3f", "metadata": {}, "outputs": [], "source": ["ce = index.as_chat_engine()"]}, {"cell_type": "code", "execution_count": null, "id": "4907248f-ff80-41fa-98e9-b1e4bb1b1400", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Question: What are the risks of AI?\n", "\n", "Response: The risks of AI involve potential biases, opaque decision-making processes, and lack of public trust due to discriminatory outcomes and biased data [1]. To mitigate these risks, industry is implementing innovative solutions like risk assessments and monitoring mechanisms [2]. Stakeholder engagement and the development of a risk management framework by organizations like the National Institute of Standards and Technology aim to manage risks posed by AI to individuals, organizations, and society [3]. Identification and mitigation of potential risks, impact assessments, and balancing high impact risks with appropriate mitigation are crucial before and during the deployment of AI systems [5]. The Blueprint for an AI Bill of Rights emphasizes the protection of individuals from unsafe or ineffective AI systems [7].\n", "\n", "Question: What should we do to prevent bad actors from using AI?\n", "\n", "Response: To prevent the misuse of AI by malicious entities, several key measures can be implemented. Firstly, it is crucial to ensure that automated systems are designed with safety and effectiveness in mind, following principles such as being lawful, purposeful, accurate, secure, and transparent [2]. Entities should proactively identify and manage risks associated with sensitive data, conducting regular audits and limiting access to prevent misuse [3], [4], [5]. Additionally, ongoing monitoring of automated systems is essential to detect and address algorithmic discrimination and unforeseen interactions that could lead to misuse [6], [7]. By incorporating these practices into the design, development, and deployment of AI technologies, the potential for misuse by malicious entities can be significantly reduced.\n", "\n", "Question: What are the benefits?\n", "\n", "Response: Artificial Intelligence (AI) offers various advantages, such as promoting the use of trustworthy AI systems with principles focusing on legality, performance, safety, transparency, and accountability [1]. Organizations are incorporating protections and ethical principles in AI development, aligning with global recommendations for responsible AI stewardship [2]. Furthermore, research is ongoing to enhance explainable AI systems for better human understanding and trust in AI outcomes [5]. The U.S. government is establishing councils and frameworks to advance AI technologies, ensuring responsible AI implementation across sectors [4], . AI can streamline processes, improve decision-making, and enhance efficiency, although challenges like bias, flaws, and accessibility issues need to be addressed to maximize its benefits [5].\n", "\n"]}], "source": ["for q in questions:\n", "    print(f\"Question: {q}\\n\")\n", "    response = ce.chat(q).response\n", "    print(f\"Response: {response}\\n\")"]}, {"cell_type": "markdown", "id": "b105809b-efea-4937-b6a3-e3de8986aa8c", "metadata": {}, "source": ["当然，流式传输在聊天中也适用：\n"]}, {"cell_type": "code", "execution_count": null, "id": "61cc0885-01a4-4569-864d-0eb8bbc70eab", "metadata": {}, "outputs": [], "source": ["ce = index.as_chat_engine(streaming=True)"]}, {"cell_type": "code", "execution_count": null, "id": "e44797ff-d23f-4d6a-9839-82aec6040af0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The search results indicate a focus on the relationship between humans and robots, emphasizing the need for co-intelligence and the best use of automated systems [2]. The discussions revolve around ensuring that automated systems are designed, tested, and protected to prevent potential harmful outcomes [1]. While there are concerns about the use of surveillance technology by companies like Amazon and Walmart, the emphasis is on balancing equities and maintaining oversight in law enforcement activities [5]. The search results do not directly answer whether robots will kill us all, but they highlight the importance of proactive protections, context-specific guidance, and existing policies to govern the use of automated systems in various settings [6]."]}], "source": ["response = ce.stream_chat(\"Will robots kill us all?\")\n", "for chunk in response.chat_stream:\n", "    print(chunk.delta or \"\", end=\"\", flush=True)"]}, {"cell_type": "markdown", "id": "e52fe86d-b0d5-4520-bac2-df9324a5eacc", "metadata": {}, "source": ["### 代理 RAG\n", "\n", "让我们使用 LlamaIndex 创建一个 ReAct 代理，该代理利用 Vectara 作为其 RAG 工具。\n", "为此，您需要使用另一个 LLM 作为代理推理的驱动程序，这里我们以 OpenAI 的 GPT4o 作为示例。\n", "（为使此工作，请确保您的环境中定义了 `OPENAI_API_KEY`）。\n"]}, {"cell_type": "code", "execution_count": null, "id": "c6766a84-b228-4b80-a32b-0c167b843819", "metadata": {}, "outputs": [], "source": ["from llama_index.core.agent import ReActAgent", "from llama_index.llms.openai import OpenAI", "from llama_index.core.tools import QueryEngineTool, ToolMetadata", "", "llm = OpenAI(model=\"gpt-4o\", temperature=0)", "vectara_tool = QueryEngineTool(", "    query_engine=index.as_query_engine(", "        summary_enabled=True,", "        summary_num_results=5,", "        summary_response_lang=\"en\",", "        summary_prompt_name=\"vectara-summary-ext-24-05-large\",", "        reranker=\"mmr\",", "        rerank_k=50,", "        mmr_diversity_bias=0.2,", "    ),", "    metadata=ToolMetadata(", "        name=\"Vectara\",", "        description=\"Vectara Query Engine that is able to answer Questions about AI regulation.\",", "    ),", ")", "agent = ReActAgent.from_tools(", "    tools=[vectara_tool],", "    llm=llm,", "    context=\"\"\"", "        你是一个乐于助人的聊天机器人，可以使用Vectara工具回答关于AI监管的任何用户问题。", "        你将复杂的问题分解成更简单的问题。", "        你使用Vectara查询引擎来帮助回答更简单的问题。", "    \"\"\",", "    verbose=True,", ")"]}, {"cell_type": "code", "execution_count": null, "id": "8a68dbca-613a-4f44-aa9e-67a758f76683", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n", "Action: Vectara\n", "Action Input: {'input': 'What are the risks of AI?'}\n", "\u001b[0m\u001b[1;3;34mObservation: The risks of AI include biased data leading to discriminatory outcomes, opaque decision-making processes, and a lack of public trust and understanding in algorithmic systems. Mitigation strategies discussed involve ongoing transparency, participatory design, and engaging with impacted communities to understand potential harms and integrate protections into the design of AI systems [1]. Additionally, there's a focus on identifying and mitigating risks before deployment, particularly those impacting people's rights, opportunities, or safety, with a strong emphasis on avoiding systems that inherently violate safety norms [5].\n", "\u001b[0m\u001b[1;3;38;5;200mThought: I have obtained information about the risks of AI. Now, I need to gather information about the benefits of AI to provide a comprehensive comparison.\n", "Action: Vectara\n", "Action Input: {'input': 'What are the benefits of AI?'}\n", "\u001b[0m\u001b[1;3;34mObservation: The benefits of AI include its transformative potential to improve people's lives by building better and more innovative infrastructure. It also offers the possibility to enhance community health, safety, and welfare by ensuring better representation of all voices, particularly those traditionally marginalized by technological advances [1]. AI can also prevent harms and improve opportunities, rights, and access for Americans, playing a central role in shaping important policies like the Blueprint for an AI Bill of Rights [2].\n", "\u001b[0m\u001b[1;3;38;5;200mThought: I have gathered information about both the risks and benefits of AI. Now, I need to compare and contrast these points and provide a summary with arguments for and against from experts.\n", "Answer: ### Comparison of Risks and Benefits of AI\n", "\n", "#### Risks of AI:\n", "1. **Biased Data and Discriminatory Outcomes**: AI systems can perpetuate and even exacerbate biases present in the data they are trained on, leading to unfair and discriminatory outcomes.\n", "2. **Opaque Decision-Making**: The decision-making processes of AI systems can be complex and not easily understandable, leading to a lack of transparency.\n", "3. **Lack of Public Trust**: The opacity and potential biases in AI systems can result in a lack of trust and understanding from the public.\n", "4. **Safety and Rights Violations**: There is a risk of AI systems violating safety norms and impacting people's rights, opportunities, or safety.\n", "\n", "#### Benefits of AI:\n", "1. **Improved Infrastructure**: AI has the potential to transform and improve infrastructure, making it more innovative and efficient.\n", "2. **Enhanced Community Health and Safety**: AI can play a significant role in improving community health, safety, and welfare by ensuring better representation and inclusivity.\n", "3. **Prevention of Harms**: AI can help prevent harms and improve opportunities, rights, and access, particularly for marginalized communities.\n", "4. **Policy Shaping**: AI is central to shaping important policies, such as the Blueprint for an AI Bill of Rights, which aims to protect and enhance the rights of individuals.\n", "\n", "### Summary with Arguments For and Against AI\n", "\n", "#### Arguments For AI:\n", "- **Innovation and Efficiency**: AI can drive significant advancements in technology and infrastructure, leading to more efficient and innovative solutions.\n", "- **Inclusivity and Representation**: AI can ensure better representation of marginalized voices, leading to more equitable outcomes.\n", "- **Health and Safety**: AI can enhance community health and safety by providing better tools and systems for monitoring and intervention.\n", "- **Policy and Rights**: AI can play a crucial role in shaping policies that protect and enhance individual rights and opportunities.\n", "\n", "#### Arguments Against AI:\n", "- **Bias and Discrimination**: The risk of biased data leading to discriminatory outcomes is a significant concern.\n", "- **Transparency and Trust**: The opaque nature of AI decision-making processes can erode public trust and understanding.\n", "- **Safety Risks**: There is a potential for AI systems to violate safety norms and impact people's rights and safety negatively.\n", "- **Complexity of Mitigation**: Mitigating the risks associated with AI requires ongoing transparency, participatory design, and engagement with impacted communities, which can be complex and resource-intensive.\n", "\n", "In conclusion, while AI offers numerous benefits, including innovation, improved infrastructure, and enhanced community welfare, it also poses significant risks related to bias, transparency, and safety. Experts argue that a balanced approach, involving robust mitigation strategies and inclusive design, is essential to harness the benefits of AI while minimizing its risks.\n", "\u001b[0m### Comparison of Risks and Benefits of AI\n", "\n", "#### Risks of AI:\n", "1. **Biased Data and Discriminatory Outcomes**: AI systems can perpetuate and even exacerbate biases present in the data they are trained on, leading to unfair and discriminatory outcomes.\n", "2. **Opaque Decision-Making**: The decision-making processes of AI systems can be complex and not easily understandable, leading to a lack of transparency.\n", "3. **Lack of Public Trust**: The opacity and potential biases in AI systems can result in a lack of trust and understanding from the public.\n", "4. **Safety and Rights Violations**: There is a risk of AI systems violating safety norms and impacting people's rights, opportunities, or safety.\n", "\n", "#### Benefits of AI:\n", "1. **Improved Infrastructure**: AI has the potential to transform and improve infrastructure, making it more innovative and efficient.\n", "2. **Enhanced Community Health and Safety**: AI can play a significant role in improving community health, safety, and welfare by ensuring better representation and inclusivity.\n", "3. **Prevention of Harms**: AI can help prevent harms and improve opportunities, rights, and access, particularly for marginalized communities.\n", "4. **Policy Shaping**: AI is central to shaping important policies, such as the Blueprint for an AI Bill of Rights, which aims to protect and enhance the rights of individuals.\n", "\n", "### Summary with Arguments For and Against AI\n", "\n", "#### Arguments For AI:\n", "- **Innovation and Efficiency**: AI can drive significant advancements in technology and infrastructure, leading to more efficient and innovative solutions.\n", "- **Inclusivity and Representation**: AI can ensure better representation of marginalized voices, leading to more equitable outcomes.\n", "- **Health and Safety**: AI can enhance community health and safety by providing better tools and systems for monitoring and intervention.\n", "- **Policy and Rights**: AI can play a crucial role in shaping policies that protect and enhance individual rights and opportunities.\n", "\n", "#### Arguments Against AI:\n", "- **Bias and Discrimination**: The risk of biased data leading to discriminatory outcomes is a significant concern.\n", "- **Transparency and Trust**: The opaque nature of AI decision-making processes can erode public trust and understanding.\n", "- **Safety Risks**: There is a potential for AI systems to violate safety norms and impact people's rights and safety negatively.\n", "- **Complexity of Mitigation**: Mitigating the risks associated with AI requires ongoing transparency, participatory design, and engagement with impacted communities, which can be complex and resource-intensive.\n", "\n", "In conclusion, while AI offers numerous benefits, including innovation, improved infrastructure, and enhanced community welfare, it also poses significant risks related to bias, transparency, and safety. Experts argue that a balanced approach, involving robust mitigation strategies and inclusive design, is essential to harness the benefits of AI while minimizing its risks.\n"]}], "source": ["问题 = \"\"\"", "    人工智能的风险是什么？有哪些好处？", "    从专家的观点比较和对比，并提供赞成和反对的论点的摘要。", "\"\"\"", "", "print(agent.chat(question).response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}