{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "bccd47fc", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/Lantern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "db0855d0", "metadata": {}, "source": ["# ç¯ç¬¼å‘é‡å­˜å‚¨\n", "åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨[Postgresql](https://www.postgresql.org)å’Œ[Lantern](https://github.com/lanterndata/lantern)åœ¨LlamaIndexä¸­æ‰§è¡Œå‘é‡æœç´¢ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "e4f33fc9", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "59632875", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-lantern\n", "%pip install llama-index-embeddings-openai"]}, {"cell_type": "code", "execution_count": null, "id": "712daea5", "metadata": {}, "outputs": [], "source": ["\n", "!pip install psycopg2-binary llama-index asyncpg \n"]}, {"cell_type": "code", "execution_count": null, "id": "c2d1c538", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader, StorageContext\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.vector_stores.lantern import LanternVectorStore\n", "import textwrap\n", "import openai"]}, {"cell_type": "markdown", "id": "26c71b6d", "metadata": {}, "source": ["### è®¾ç½®OpenAI\n", "ç¬¬ä¸€æ­¥æ˜¯é…ç½®OpenAIå¯†é’¥ã€‚å®ƒå°†ç”¨äºä¸ºåŠ è½½åˆ°ç´¢å¼•ä¸­çš„æ–‡æ¡£åˆ›å»ºåµŒå…¥ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "67b86621", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"<your_key>\"\n", "openai.api_key = \"<your_key>\""]}, {"attachments": {}, "cell_type": "markdown", "id": "eecf4bd5", "metadata": {}, "source": ["ä¸‹è½½æ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "6df9fa89", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"attachments": {}, "cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["### åŠ è½½æ–‡æ¡£\n", "ä½¿ç”¨SimpleDirectoryReaderåŠ è½½å­˜å‚¨åœ¨`data/paul_graham/`ä¸­çš„æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "c154dd4b", "metadata": {}, "outputs": [], "source": ["documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\n", "print(\"Document ID:\", documents[0].doc_id)"]}, {"cell_type": "markdown", "id": "7bd24f0a", "metadata": {}, "source": ["### åˆ›å»ºæ•°æ®åº“\n", "ä½¿ç”¨å·²ç»åœ¨æœ¬åœ°è¿è¡Œçš„postgresï¼Œåˆ›å»ºæˆ‘ä»¬å°†è¦ä½¿ç”¨çš„æ•°æ®åº“ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "e6d61e73", "metadata": {}, "outputs": [], "source": ["import psycopg2\n", "\n", "connection_string = \"postgresql://postgres:postgres@localhost:5432\"\n", "db_name = \"postgres\"\n", "conn = psycopg2.connect(connection_string)\n", "conn.autocommit = True\n", "\n", "with conn.cursor() as c:\n", "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n", "    c.execute(f\"CREATE DATABASE {db_name}\")"]}, {"cell_type": "code", "execution_count": null, "id": "8883b6b0-8a1e-42ca-9134-ade42285e7dc", "metadata": {}, "outputs": [], "source": ["from llama_index.embeddings.openai import OpenAIEmbedding", "from llama_index.core import Settings", "", "# ä½¿ç”¨åµŒå…¥æ¨¡å‹è®¾ç½®å…¨å±€è®¾ç½®", "# å› æ­¤æŸ¥è¯¢å­—ç¬¦ä¸²å°†è¢«è½¬æ¢ä¸ºåµŒå…¥ï¼Œå¹¶ä¸”å°†ä½¿ç”¨HNSWç´¢å¼•", "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"]}, {"cell_type": "markdown", "id": "c0232fd1", "metadata": {}, "source": ["### åˆ›å»ºç´¢å¼•\n", "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¹‹å‰åŠ è½½çš„æ–‡æ¡£åˆ›å»ºä¸€ä¸ªç”±Postgresæ”¯æŒçš„ç´¢å¼•ã€‚LanternVectorStoreéœ€è¦ä¸€äº›å‚æ•°ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "8731da62", "metadata": {}, "outputs": [], "source": ["from sqlalchemy import make_url", "", "url = make_url(connection_string)", "vector_store = LanternVectorStore.from_params(", "    database=db_name,", "    host=url.host,", "    password=url.password,", "    port=url.port,", "    user=url.username,", "    table_name=\"paul_graham_essay\",", "    embed_dim=1536,  # openai embedding dimension", ")", "", "storage_context = StorageContext.from_defaults(vector_store=vector_store)", "index = VectorStoreIndex.from_documents(", "    documents, storage_context=storage_context, show_progress=True", ")", "query_engine = index.as_query_engine()"]}, {"cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["### æŸ¥è¯¢ç´¢å¼•\n", "ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„ç´¢å¼•æ¥æå‡ºé—®é¢˜ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a2bcc07", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\"What did the author do?\")"]}, {"cell_type": "code", "execution_count": null, "id": "8cf55bf7", "metadata": {}, "outputs": [], "source": ["print(textwrap.fill(str(response), 100))"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\"What happened in the mid 1980s?\")"]}, {"cell_type": "code", "execution_count": null, "id": "fdf5287f", "metadata": {}, "outputs": [], "source": ["print(textwrap.fill(str(response), 100))"]}, {"cell_type": "markdown", "id": "b3bed9e1", "metadata": {}, "source": ["### æŸ¥è¯¢ç°æœ‰ç´¢å¼•\n"]}, {"cell_type": "code", "execution_count": null, "id": "e6b2634b", "metadata": {}, "outputs": [], "source": ["vector_store = LanternVectorStore.from_params(", "    database=db_name,  # æ•°æ®åº“åç§°", "    host=url.host,  # ä¸»æœºåœ°å€", "    password=url.password,  # å¯†ç ", "    port=url.port,  # ç«¯å£", "    user=url.username,  # ç”¨æˆ·å", "    table_name=\"paul_graham_essay\",  # è¡¨åç§°", "    embed_dim=1536,  # openaiåµŒå…¥ç»´åº¦", "    m=16,  # HNSW Må‚æ•°", "    ef_construction=128,  # HNSW efæ„å»ºå‚æ•°", "    ef=64,  # HNSW efæœç´¢å‚æ•°", ")", "", "# äº†è§£æœ‰å…³HNSWå‚æ•°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®ï¼šhttps://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md", "", "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)", "query_engine = index.as_query_engine()"]}, {"cell_type": "code", "execution_count": null, "id": "e7075af3-156e-4bde-8f76-6d9dee86861f", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\"What did the author do?\")"]}, {"cell_type": "code", "execution_count": null, "id": "b088c090", "metadata": {}, "outputs": [], "source": ["print(textwrap.fill(str(response), 100))"]}, {"cell_type": "markdown", "id": "55745895-8f01-4275-abaa-b2ebef2cb4c7", "metadata": {}, "source": ["### æ··åˆæœç´¢\n"]}, {"cell_type": "markdown", "id": "91cae40f-3cd4-4403-8af4-aca2705e96a2", "metadata": {}, "source": ["è¦å¯ç”¨æ··åˆæœç´¢ï¼Œæ‚¨éœ€è¦ï¼š\n", "1. åœ¨æ„å»º`LanternVectorStore`æ—¶ä¼ å…¥`hybrid_search=True`ï¼ˆå¹¶å¯é€‰æ‹©ä½¿ç”¨æ‰€éœ€çš„è¯­è¨€é…ç½®`text_search_config`ï¼‰\n", "2. åœ¨æ„å»ºæŸ¥è¯¢å¼•æ“æ—¶ä¼ å…¥`vector_store_query_mode=\"hybrid\"`ï¼ˆæ­¤é…ç½®ä¼šåœ¨å¹•åä¼ é€’ç»™æ£€ç´¢å™¨ï¼‰ã€‚æ‚¨è¿˜å¯ä»¥é€‰æ‹©è®¾ç½®`sparse_top_k`æ¥é…ç½®ä»ç¨€ç–æ–‡æœ¬æœç´¢ä¸­è·å–å¤šå°‘ç»“æœï¼ˆé»˜è®¤å€¼ä¸`similarity_top_k`ç›¸åŒï¼‰ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "65a7e133-39da-40c5-b2c5-7af2c0a3a792", "metadata": {}, "outputs": [], "source": ["from sqlalchemy import make_url", "", "url = make_url(connection_string)", "hybrid_vector_store = LanternVectorStore.from_params(", "    database=db_name,", "    host=url.host,", "    password=url.password,", "    port=url.port,", "    user=url.username,", "    table_name=\"paul_graham_essay_hybrid_search\",", "    embed_dim=1536,  # openai embedding dimension", "    hybrid_search=True,", "    text_search_config=\"english\",", ")", "", "storage_context = StorageContext.from_defaults(", "    vector_store=hybrid_vector_store", ")", "hybrid_index = VectorStoreIndex.from_documents(", "    documents, storage_context=storage_context", ")"]}, {"cell_type": "code", "execution_count": null, "id": "6f8edee4-6c19-4d99-b602-110bdc5708e5", "metadata": {}, "outputs": [], "source": ["hybrid_query_engine = hybrid_index.as_query_engine(\n", "    vector_store_query_mode=\"hybrid\", sparse_top_k=2\n", ")\n", "hybrid_response = hybrid_query_engine.query(\n", "    \"Who does Paul Graham think of with the word schtick\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "bd454b25-b66c-4733-8ff4-24fb2ee84cec", "metadata": {}, "outputs": [], "source": ["print(hybrid_response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}