{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "1496f9de", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/MilvusIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "0b692c73", "metadata": {}, "source": ["# Milvus向量存储\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "1e7787c2", "metadata": {}, "source": ["在这个笔记本中，我们将展示如何快速使用MilvusVectorStore的演示。\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "f81e2c81", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "3e0c18ca", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-milvus"]}, {"cell_type": "code", "execution_count": null, "id": "6b80700a", "metadata": {}, "outputs": [], "source": ["%pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "47264e32", "metadata": {}, "outputs": [], "source": ["import logging", "import sys", "", "# 取消注释以查看调试日志", "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)", "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))", "", "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document", "from llama_index.vector_stores.milvus import MilvusVectorStore", "import textwrap"]}, {"attachments": {}, "cell_type": "markdown", "id": "f9b97a89", "metadata": {}, "source": ["### 设置OpenAI\n", "首先，让我们添加OpenAI的API密钥。这将允许我们访问OpenAI以获取嵌入和使用ChatGPT。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0c9f4d21-145a-401e-95ff-ccb259e8ef84", "metadata": {}, "outputs": [], "source": ["import openai\n", "\n", "openai.api_key = \"sk-***********\""]}, {"attachments": {}, "cell_type": "markdown", "id": "a3d4e638", "metadata": {}, "source": ["下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "2a2e24d1", "metadata": {}, "outputs": [], "source": ["! mkdir -p 'data/paul_graham/'\n", "! wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"attachments": {}, "cell_type": "markdown", "id": "59ff935d", "metadata": {}, "source": ["### 生成我们的数据\n", "有了我们的LLM集合，让我们开始使用Milvus索引。作为第一个示例，让我们从`data/paul_graham/`文件夹中找到的文件生成一个文档。在这个文件夹中，有一篇来自Paul Graham的单篇文章，标题为`What I Worked On`。为了生成这些文档，我们将使用SimpleDirectoryReader。\n"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Document ID: 11c3a6fe-799e-4e40-8122-2339936c2722\n"]}], "source": ["# 加载文档", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()", "", "print(\"文档ID:\", documents[0].doc_id)"]}, {"attachments": {}, "cell_type": "markdown", "id": "dd270925", "metadata": {}, "source": ["### 在数据中创建索引\n", "现在我们有了一个文档，我们可以创建一个索引并插入文档。对于索引，我们将使用一个GPTMilvusIndex。GPTMilvusIndex接受一些参数：\n", "\n", "- `uri (str, optional)`: 连接的URI，如果使用Milvus或Zilliz Cloud服务，格式为\"https://address:port\"，如果使用本地的lite Milvus，则为\"path/to/local/milvus.db\"。默认为\"./milvus_llamaindex.db\"。\n", "- `token (str, optional)`: 登录的令牌。如果不使用rbac，则为空，如果使用rbac，则可能是\"username:password\"。默认为\"\"。\n", "- `collection_name (str, optional)`: 数据将存储的集合的名称。默认为\"llamalection\"。\n", "- `dim (int, optional)`: 嵌入的维度。如果未提供，将在第一次插入时创建集合。默认为None。\n", "- `embedding_field (str, optional)`: 集合的嵌入字段的名称，默认为DEFAULT_EMBEDDING_KEY。\n", "- `doc_id_field (str, optional)`: 集合的doc_id字段的名称，默认为DEFAULT_DOC_ID_KEY。\n", "- `similarity_metric (str, optional)`: 要使用的相似度度量，目前支持IP和L2。默认为\"IP\"。\n", "- `consistency_level (str, optional)`: 为新创建的集合使用的一致性级别。默认为\"Strong\"。\n", "- `overwrite (bool, optional)`: 是否覆盖同名的现有集合。默认为False。\n", "- `text_key (str, optional)`: 在传递的集合中存储文本的键。在使用自己的集合时使用。默认为None。\n", "- `index_config (dict, optional)`: 用于构建Milvus索引的配置。默认为None。\n", "- `search_config (dict, optional)`: 用于搜索Milvus索引的配置。请注意，这必须与index_config指定的索引类型兼容。默认为None。\n", "\n", "> 请注意，**Milvus Lite** 需要 `pymilvus>=2.4.2`。\n"]}, {"cell_type": "code", "execution_count": null, "id": "ba1558b3", "metadata": {}, "outputs": [], "source": ["# 在文档上创建索引", "from llama_index.core import StorageContext", "", "# 创建一个MilvusVectorStore对象", "vector_store = MilvusVectorStore(", "    uri=\"./milvus_demo.db\", dim=1536, overwrite=True", ")", "", "# 从默认值创建StorageContext对象", "storage_context = StorageContext.from_defaults(vector_store=vector_store)", "", "# 从文档创建VectorStoreIndex对象", "index = VectorStoreIndex.from_documents(", "    documents, storage_context=storage_context", ")"]}, {"attachments": {}, "cell_type": "markdown", "id": "04304299-fc3e-40a0-8600-f50c3292767e", "metadata": {}, "source": ["### 查询数据\n", "现在我们已经将文档存储在索引中，我们可以针对索引提出问题。索引将使用自身存储的数据作为chatgpt的知识库。\n"]}, {"cell_type": "code", "execution_count": null, "id": "35369eda", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author learned about programming on early computers like the IBM 1401 using Fortran, the\n", "limitations of early computing technology, the transition to microcomputers, and the excitement of\n", "having a personal computer like the TRS-80. Additionally, the author explored different academic\n", "paths, initially planning to study philosophy but eventually switching to AI due to a lack of\n", "interest in philosophy courses. Later on, the author pursued art education, attending RISD and the\n", "Accademia di Belli Arti in Florence, where they encountered a different approach to teaching art.\n"]}], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"What did the author learn?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"cell_type": "code", "execution_count": null, "id": "99212d33", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Dealing with the stress and challenges related to managing Hacker News was a difficult moment for\n", "the author.\n"]}], "source": ["response = query_engine.query(\"What was a hard moment for the author?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"attachments": {}, "cell_type": "markdown", "id": "64cc925b", "metadata": {}, "source": ["这个测试显示，覆盖会删除先前的数据。\n"]}, {"cell_type": "code", "execution_count": null, "id": "8d641e24", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Res: The author is the individual who created the content or work in question.\n"]}], "source": ["vector_store = MilvusVectorStore(\n", "    uri=\"./milvus_demo.db\", dim=1536, overwrite=True\n", ")\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n", "index = VectorStoreIndex.from_documents(\n", "    [Document(text=\"The number that is being searched for is ten.\")],\n", "    storage_context,\n", ")\n", "query_engine = index.as_query_engine()\n", "res = query_engine.query(\"Who is the author?\")\n", "print(\"Res:\", res)"]}, {"attachments": {}, "cell_type": "markdown", "id": "d8123529", "metadata": {}, "source": ["下一个测试展示了向已经存在的索引中添加额外数据。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a5c429a4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Res: The number is ten.\n"]}], "source": ["del index, vector_store, storage_context, query_engine\n", "\n", "vector_store = MilvusVectorStore(uri=\"./milvus_demo.db\", overwrite=False)\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n", "index = VectorStoreIndex.from_documents(\n", "    documents, storage_context=storage_context\n", ")\n", "query_engine = index.as_query_engine()\n", "res = query_engine.query(\"What is the number?\")\n", "print(\"Res:\", res)"]}, {"cell_type": "code", "execution_count": null, "id": "e5287c2d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Res: Paul Graham\n"]}], "source": ["res = query_engine.query(\"Who is the author?\")\n", "print(\"Res:\", res)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}