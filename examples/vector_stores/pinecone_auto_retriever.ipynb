{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "0cf577bb", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/pinecone_auto_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "307804a3-c02b-4a57-ac0d-172c30ddc851", "metadata": {}, "source": ["# 使用Pinecone + Arize Phoenix进行自动检索的简单到高级指南\n", "\n", "在这个笔记本中，我们展示了如何针对Pinecone执行**自动检索**，这使您能够执行广泛的半结构化查询，超出了您可以通过标准的top-k语义搜索所能做的范围。\n", "\n", "我们展示了如何设置基本的自动检索，以及如何通过自定义提示和动态元数据检索来扩展它。\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "e97ec52a", "metadata": {}, "source": ["如果您在Colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "19206ae7", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-pinecone"]}, {"cell_type": "code", "execution_count": null, "id": "e08012b0", "metadata": {}, "outputs": [], "source": ["# !pip install llama-index>=0.9.31 scikit-learn==1.2.2 arize-phoenix==2.4.1 pinecone-client>=3.0.0"]}, {"cell_type": "markdown", "id": "afdbefce-c48e-4802-bf53-796adf3d6b4b", "metadata": {}, "source": ["## 第一部分：设置自动检索\n", "\n", "要设置自动检索，请执行以下操作：\n", "\n", "1. 我们将进行一些设置，加载数据，构建一个Pinecone向量索引。\n", "2. 我们将定义我们的自动检索器并运行一些示例查询。\n", "3. 我们将使用Phoenix观察每个跟踪并可视化提示的输入/输出。\n", "4. 我们将向您展示如何自定义自动检索提示。\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["### 1.a 设置Pinecone/Phoenix，加载数据并构建向量索引\n", "\n", "在本节中，我们将设置Pinecone并导入一些关于书籍/电影的玩具数据（包括文本数据和元数据）。\n", "\n", "我们还将设置Phoenix，以便它捕获下游的跟踪信息。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a70609af-1ccb-48de-8cb2-335eb783143f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["🌍 To view the Phoenix app in your browser, visit http://127.0.0.1:6006/\n", "📺 To view the Phoenix app in a notebook, run `px.active_session().view()`\n", "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"]}], "source": ["# 设置Phoenix", "import phoenix as px", "import llama_index.core", "", "px.launch_app()", "llama_index.core.set_global_handler(\"arize_phoenix\")"]}, {"cell_type": "code", "execution_count": null, "id": "7062610f-8ad0-4ef9-a0e8-aaafc66ad71c", "metadata": {}, "outputs": [], "source": ["import os", "", "os.environ[", "    \"PINECONE_API_KEY\"", "] = \"<您的Pinecone API密钥，来自app.pinecone.io>\"", "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""]}, {"cell_type": "code", "execution_count": null, "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee", "metadata": {}, "outputs": [], "source": ["from pinecone import Pinecone\n", "from pinecone import ServerlessSpec\n", "\n", "api_key = os.environ[\"PINECONE_API_KEY\"]\n", "pc = Pinecone(api_key=api_key)"]}, {"cell_type": "code", "execution_count": null, "id": "aaa45ffc-456c-452a-978f-694ae8c426d1", "metadata": {}, "outputs": [], "source": ["# 如果需要的话删除", "# pc.delete_index(\"quickstart-index\")"]}, {"cell_type": "code", "execution_count": null, "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88", "metadata": {}, "outputs": [], "source": ["# 文本嵌入维度为1536的注释", "try:", "    pc.create_index(", "        \"quickstart-index\",", "        dimension=1536,", "        metric=\"euclidean\",", "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-west-2\"),", "    )", "except Exception as e:", "    # 最有可能是索引已经存在", "    print(e)", "    pass"]}, {"cell_type": "code", "execution_count": null, "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6", "metadata": {}, "outputs": [], "source": ["pinecone_index = pc.Index(\"quickstart-index\")"]}, {"attachments": {}, "cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["#### 加载文档，构建PineconeVectorStore和VectorStoreIndex\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a2bcc07", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, StorageContext\n", "from llama_index.vector_stores.pinecone import PineconeVectorStore"]}, {"cell_type": "code", "execution_count": null, "id": "9ae59590", "metadata": {}, "outputs": [], "source": ["from llama_index.core.schema import TextNode\n", "\n", "nodes = [\n", "    TextNode(\n", "        text=\"The Shawshank Redemption\",\n", "        metadata={\n", "            \"author\": \"Stephen King\",\n", "            \"theme\": \"Friendship\",\n", "            \"year\": 1994,\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=\"The Godfather\",\n", "        metadata={\n", "            \"director\": \"Francis Ford Coppola\",\n", "            \"theme\": \"Mafia\",\n", "            \"year\": 1972,\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=\"Inception\",\n", "        metadata={\n", "            \"director\": \"Christopher Nolan\",\n", "            \"theme\": \"Fiction\",\n", "            \"year\": 2010,\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=\"To Kill a Mockingbird\",\n", "        metadata={\n", "            \"author\": \"Harper Lee\",\n", "            \"theme\": \"Fiction\",\n", "            \"year\": 1960,\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=\"1984\",\n", "        metadata={\n", "            \"author\": \"George Orwell\",\n", "            \"theme\": \"Totalitarianism\",\n", "            \"year\": 1949,\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=\"The Great Gatsby\",\n", "        metadata={\n", "            \"author\": \"F. Scott Fitzgerald\",\n", "            \"theme\": \"The American Dream\",\n", "            \"year\": 1925,\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=\"Harry Potter and the Sorcerer's Stone\",\n", "        metadata={\n", "            \"author\": \"J.K. Rowling\",\n", "            \"theme\": \"Fiction\",\n", "            \"year\": 1997,\n", "        },\n", "    ),\n", "]"]}, {"cell_type": "code", "execution_count": null, "id": "ee6eeecb-d54f-4a71-b5fe-0cda8a5c3e10", "metadata": {}, "outputs": [], "source": ["vector_store = PineconeVectorStore(\n", "    pinecone_index=pinecone_index,\n", "    namespace=\"test\",\n", ")\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)"]}, {"cell_type": "code", "execution_count": null, "id": "cad08884", "metadata": {}, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "baa557a65efa45c484ee050ffde1ad0f", "version_major": 2, "version_minor": 0}, "text/plain": ["Upserted vectors:   0%|          | 0/7 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}], "source": ["index = VectorStoreIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "markdown", "id": "ee4e3c36-eed0-4cd1-953f-116f6e33b123", "metadata": {}, "source": ["### 1.b 定义自动检索器，运行一些示例查询\n"]}, {"cell_type": "markdown", "id": "c388e1fd-e897-42b5-ba64-5e6dea874668", "metadata": {}, "source": ["#### 设置`VectorIndexAutoRetriever`\n", "\n", "其中一个输入是描述向量存储集合包含的内容的`schema`。这类似于SQL数据库中描述表的表模式。然后将这个模式信息注入到提示中，传递给LLM来推断完整的查询应该是什么（包括元数据过滤器）。\n"]}, {"cell_type": "code", "execution_count": null, "id": "1a57e62f", "metadata": {}, "outputs": [], "source": ["from llama_index.core.retrievers import VectorIndexAutoRetriever", "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo", "", "", "vector_store_info = VectorStoreInfo(", "    content_info=\"著名书籍和电影\",", "    metadata_info=[", "        MetadataInfo(", "            name=\"导演\",", "            type=\"str\",", "            description=(\"导演的姓名\"),", "        ),", "        MetadataInfo(", "            name=\"主题\",", "            type=\"str\",", "            description=(\"书籍/电影的主题\"),", "        ),", "        MetadataInfo(", "            name=\"年份\",", "            type=\"int\",", "            description=(\"书籍/电影的年份\"),", "        ),", "    ],", ")", "retriever = VectorIndexAutoRetriever(", "    index,", "    vector_store_info=vector_store_info,", "    empty_query_top_k=10,", "    # 这是一个hack，允许在pinecone中进行空查询", "    default_empty_query_vector=[0] * 1536,", "    verbose=True,", ")"]}, {"cell_type": "markdown", "id": "827d73c3-51fd-4191-84f9-14dcaf35a287", "metadata": {}, "source": ["#### 让我们运行一些查询\n", "\n", "让我们运行一些使用结构化信息的示例查询。\n"]}, {"cell_type": "code", "execution_count": null, "id": "e8a0453a-fbc4-446c-879f-340040247f76", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Using query str: \n", "Using filters: [('year', '>', 2000)]\n"]}], "source": ["nodes = retriever.retrieve(\n", "    \"Tell me about some books/movies after the year 2000\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "eaa3b724-e7a3-464a-962e-8c2c8e6e2e81", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Inception\n", "{'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}\n"]}], "source": ["for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}, {"cell_type": "code", "execution_count": null, "id": "3a1a9287", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Using query str: Fiction\n", "Using filters: [('theme', '==', 'Fiction')]\n"]}], "source": ["nodes = retriever.retrieve(\"Tell me about some books that are Fiction\")"]}, {"cell_type": "code", "execution_count": null, "id": "1222e259-3146-4c79-9491-fe8453f0cf40", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Inception\n", "{'director': 'Christopher Nolan', 'theme': 'Fiction', 'year': 2010}\n", "To Kill a Mockingbird\n", "{'author': 'Harper Lee', 'theme': 'Fiction', 'year': 1960}\n"]}], "source": ["for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}, {"cell_type": "markdown", "id": "1a1ec4bb-8b20-476f-a21c-6d895fbe7ef9", "metadata": {}, "source": ["#### 传递额外的元数据过滤器\n", "\n", "如果您有额外的元数据过滤器需要传递进来，而不是自动推断的话，可以按照以下步骤操作。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0761b152-f91e-4233-b47e-f9564cb14eaf", "metadata": {}, "outputs": [], "source": ["from llama_index.core.vector_stores import MetadataFilters", "", "filter_dicts = [{\"key\": \"year\", \"operator\": \"==\", \"value\": 1997}]", "filters = MetadataFilters.from_dicts(filter_dicts)", "retriever2 = VectorIndexAutoRetriever(", "    index,", "    vector_store_info=vector_store_info,", "    empty_query_top_k=10,", "    # 这是一个hack，允许在pinecone中进行空查询", "    default_empty_query_vector=[0] * 1536,", "    extra_filters=filters,", ")"]}, {"cell_type": "code", "execution_count": null, "id": "34a35a85-97fa-45bb-87a5-aee5c1b134ef", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Harry Potter and the Sorcerer's Stone\n", "{'author': 'J.K. Rowling', 'theme': 'Fiction', 'year': 1997}\n"]}], "source": ["nodes = retriever2.retrieve(\"Tell me about some books that are Fiction\")\n", "for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}, {"cell_type": "markdown", "id": "414f3907-180c-4bf1-b414-a34bc552708e", "metadata": {}, "source": ["#### 查询失败的示例\n", "\n", "请注意，未检索到任何结果！我们稍后会修复这个问题。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d0f772b3-b455-4afe-8312-8b16fd989fc0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Using query str: books\n", "Using filters: [('theme', '==', 'mafia')]\n"]}], "source": ["nodes = retriever.retrieve(\"Tell me about some books that are mafia-themed\")"]}, {"cell_type": "code", "execution_count": null, "id": "13877106-8f8a-43f9-a624-789a2c1be4a6", "metadata": {}, "outputs": [], "source": ["for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}, {"cell_type": "markdown", "id": "75f00668-0316-468b-a57c-2d999d319df8", "metadata": {}, "source": ["### 可视化跟踪\n", "\n", "让我们打开Phoenix来查看这些跟踪！\n", "\n", "<img src=\"https://drive.google.com/uc?export=view&id=1PCEwIdv7GcInk3i6ebd2WWjTp9ducG5F\"/>\n", "\n", "让我们来看看自动检索提示。我们可以看到自动检索提示使用了两个少样本示例。\n"]}, {"cell_type": "markdown", "id": "9ab0eae8-6d55-4c6d-acbd-32879b8f7edc", "metadata": {}, "source": ["## 第二部分：扩展自动检索（使用动态元数据检索）\n", "\n", "现在我们通过定制提示来扩展自动检索。在第一部分中，我们明确添加了一些规则。\n", "\n", "在第二部分中，我们实现了**动态元数据检索**，它将对向量数据库进行第一阶段检索，从中提取相关的元数据，并将其插入自动检索提示中作为少量示例。（当然，第二阶段检索会从向量数据库中检索实际的项目）。\n"]}, {"cell_type": "markdown", "id": "ed8718ff-b3fa-4430-af69-0a0f31e38a09", "metadata": {}, "source": ["### 2.a 改进自动检索提示\n", "\n", "我们的自动检索提示功能虽然可以工作，但还有许多方面可以改进。例如，它包含了2个硬编码的few-shot示例（如何包含自己的示例？），而且自动检索并不总是能够推断出正确的元数据过滤器。\n", "\n", "例如，所有的“theme”字段都是大写的。我们如何告诉LLM这一点，以便它不会错误地推断出一个小写的“theme”？\n", "\n", "让我们试着修改一下提示！\n"]}, {"cell_type": "code", "execution_count": null, "id": "fc818138-c1f4-401b-95bb-680db43f8508", "metadata": {}, "outputs": [], "source": ["from llama_index.core.prompts import display_prompt_dict\n", "from llama_index.core import PromptTemplate"]}, {"cell_type": "code", "execution_count": null, "id": "87445682-4330-4eee-acff-c06b20781b2a", "metadata": {}, "outputs": [], "source": ["prompts_dict = retriever.get_prompts()"]}, {"cell_type": "code", "execution_count": null, "id": "80ab823b-f6a1-4071-b57c-7357c62709c3", "metadata": {}, "outputs": [], "source": ["display_prompt_dict(prompts_dict)"]}, {"cell_type": "code", "execution_count": null, "id": "27d97d40-b953-4b5e-83c1-9f06dc069bda", "metadata": {}, "outputs": [{"data": {"text/plain": ["['schema_str', 'info_str', 'query_str']"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["＃查看所需的模板变量。", "prompts_dict [\"prompt\"] .template_vars"]}, {"cell_type": "markdown", "id": "0f4cadea-337a-498e-bb85-fac0efc95ad8", "metadata": {}, "source": ["#### 自定义提示\n", "\n", "让我们稍微定制一下提示。我们要做以下操作：\n", "- 去掉前面的几个示例以节省标记\n", "- 添加一条消息，始终将一个字母大写，如果推断出是\"主题\"。\n", "\n", "请注意，提示模板期望`schema_str`、`info_str`和`query_str`被定义。\n"]}, {"cell_type": "code", "execution_count": null, "id": "7a1bfd0c-7bba-4a78-b273-bde378a7b8e4", "metadata": {}, "outputs": [], "source": ["# 写入提示模板，并对其进行修改。", "", "prompt_tmpl_str = \"\"\"\\", "您的目标是构造用户的查询，以匹配下面提供的请求模式。", "", "<< 结构化请求模式 >>", "在回复时，使用一个Markdown代码片段，其中包含一个JSON对象，格式如下所示：", "", "{schema_str}", "", "查询字符串应仅包含预期与文档内容匹配的文本。在查询中不应提及筛选条件中的任何条件。", "", "确保筛选器仅涉及数据源中存在的属性。", "确保筛选器考虑属性的描述。", "确保仅在需要时使用筛选器。如果没有应用筛选器，为筛选值返回[]。", "如果用户的查询明确提到要检索的文档数量，请将top_k设置为该数字，否则不设置top_k。", "绝对不要推断筛选器的空值。这将破坏下游程序。相反，不要包括筛选器。", "", "<< 示例1。 >>", "数据源：", "{{", "    \"metadata_info\": [", "        {{", "            \"name\": \"author\",", "            \"type\": \"str\",", "            \"description\": \"作者姓名\"", "        }},", "        {{", "            \"name\": \"book_title\",", "            \"type\": \"str\",", "            \"description\": \"书名\"", "        }},", "        {{", "            \"name\": \"year\",", "            \"type\": \"int\",", "            \"description\": \"出版年份\"", "        }},", "        {{", "            \"name\": \"pages\",", "            \"type\": \"int\",", "            \"description\": \"页数\"", "        }},", "        {{", "            \"name\": \"summary\",", "            \"type\": \"str\",", "            \"description\": \"书的简介\"", "        }}", "    ],", "    \"content_info\": \"经典文学\"", "}}", "", "用户查询：", "简要介绍一些简奥斯汀在1813年后出版的探讨社会地位的婚姻主题的书籍。", "", "附加说明：", "无", "", "结构化请求：", "{{\"query\": \"与社会地位的婚姻主题相关的书籍\", \"filters\": [{{\"key\": \"year\", \"value\": \"1813\", \"operator\": \">\"}}, {{\"key\": \"author\", \"value\": \"简奥斯汀\", \"operator\": \"==\"}}], \"top_k\": null}}", "", "", "<< 示例2。 >>", "数据源：", "{info_str}", "", "用户查询：", "{query_str}", "", "附加说明：", "{additional_instructions}", "", "结构化请求：", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "id": "733257c5-5791-42d1-9745-a795a360a989", "metadata": {}, "outputs": [], "source": ["prompt_tmpl = PromptTemplate(prompt_tmpl_str)"]}, {"cell_type": "markdown", "id": "a47da253-9220-4d12-acf7-964bf183fa8c", "metadata": {}, "source": ["您会注意到我们添加了一个`additional_instructions`模板变量。这使我们能够插入特定于向量集合的指令。\n", "\n", "我们将使用`partial_format`来添加这个指令。\n"]}, {"cell_type": "code", "execution_count": null, "id": "14b84e65-44d7-42a0-9fcb-fbd7a2319cbb", "metadata": {}, "outputs": [], "source": ["add_instrs = \"\"\"\\", "如果过滤器中有一个是'theme'，请确保推断值的第一个字母是大写的。只有首字母大写的单词才是\"theme\"的有效值。\\", "\"\"\"", "prompt_tmpl = prompt_tmpl.partial_format(additional_instructions=add_instrs)", ""]}, {"cell_type": "code", "execution_count": null, "id": "b4d5f60d-d515-480b-8551-1ed2bc4da67b", "metadata": {}, "outputs": [], "source": ["retriever.update_prompts({\"prompt\": prompt_tmpl})"]}, {"cell_type": "markdown", "id": "28e14b7a-3b63-41f3-8e26-47eb185b63c9", "metadata": {}, "source": ["#### 重新运行一些查询\n", "\n", "现在让我们尝试重新运行一些查询，我们会发现数值是自动推断的。\n"]}, {"cell_type": "code", "execution_count": null, "id": "32c2f01e-0df2-4196-8875-8859283f3391", "metadata": {}, "outputs": [], "source": ["nodes = retriever.retrieve(\n", "    \"Tell me about some books that are friendship-themed\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "600bfdfb-8690-4a14-9c78-672377bee292", "metadata": {}, "outputs": [], "source": ["for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}, {"cell_type": "markdown", "id": "a9ef0f9f-ba3f-420c-b22f-d9ef7b53c160", "metadata": {}, "source": ["### 2.b 实现动态元数据检索\n"]}, {"cell_type": "markdown", "id": "77e00cd2-58a7-4373-ad0e-14b1eb48b43f", "metadata": {}, "source": ["除了在提示中硬编码规则之外，另一个选择是获取**相关的少样本元数据示例**，以帮助LLM更好地推断正确的元数据过滤器。\n", "\n", "这将更好地防止LLM在推断“where”子句时犯错，特别是在拼写/值的正确格式等方面。\n", "\n", "我们可以通过向量检索来实现这一点。现有的向量数据库集合存储了原始文本+元数据；我们可以直接查询这个集合，或者单独地只索引元数据并从中检索。在本节中，我们选择前者，但在实际操作中，您可能希望选择后者。\n"]}, {"cell_type": "code", "execution_count": null, "id": "bdb55b00-a606-44ec-9365-cd99b35cb828", "metadata": {}, "outputs": [], "source": ["# 定义检索器，用于获取前2个示例。 ", "metadata_retriever = index.as_retriever(similarity_top_k=2)"]}, {"cell_type": "markdown", "id": "e837047b-defb-4365-98d2-22f35de1a69a", "metadata": {}, "source": ["我们使用前一节中定义的相同的 `prompt_tmpl_str`。\n"]}, {"cell_type": "code", "execution_count": null, "id": "5d9cc3d5-1dc6-43dc-940e-188c8e53856b", "metadata": {}, "outputs": [], "source": ["from typing import List, Any", "", "", "def format_additional_instrs(**kwargs: Any) -> str:", "    \"\"\"将示例格式化为字符串。\"\"\"", "", "    nodes = metadata_retriever.retrieve(kwargs[\"query_str\"])", "    context_str = (", "        \"这是来自数据库集合的相关条目的元数据。\"", "        \"这应该帮助您推断出正确的过滤器：\\n\"", "    )", "    for node in nodes:", "        context_str += str(node.node.metadata) + \"\\n\"", "    return context_str", "", "", "ext_prompt_tmpl = PromptTemplate(", "    prompt_tmpl_str,", "    function_mappings={\"additional_instructions\": format_additional_instrs},", ")"]}, {"cell_type": "code", "execution_count": null, "id": "1d153643-d8fd-4058-bac2-7d6eddb01468", "metadata": {}, "outputs": [], "source": ["retriever.update_prompts({\"prompt\": ext_prompt_tmpl})"]}, {"cell_type": "markdown", "id": "ee5e81ef-583f-43bf-8fa3-beadce02b298", "metadata": {}, "source": ["#### 重新运行一些查询\n", "\n", "现在让我们尝试重新运行一些查询，我们会发现数值是自动推断的。\n"]}, {"cell_type": "code", "execution_count": null, "id": "52a104a3-1854-4193-aca8-d1287060d41a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Using query str: books\n", "Using filters: [('theme', '==', 'Mafia')]\n", "The Godfather\n", "{'director': 'Francis Ford Coppola', 'theme': 'Mafia', 'year': 1972}\n"]}], "source": ["nodes = retriever.retrieve(\"Tell me about some books that are mafia-themed\")\n", "for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}, {"cell_type": "code", "execution_count": null, "id": "18ce4501-711c-4047-b9d6-c58a48d55a86", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Using query str: Books authored by Harper Lee\n", "Using filters: [('author', '==', 'Harper Lee')]\n", "To Kill a Mockingbird\n", "{'author': 'Harper Lee', 'theme': 'Fiction', 'year': 1960}\n"]}], "source": ["nodes = retriever.retrieve(\"Tell me some books authored by HARPER LEE\")\n", "for node in nodes:\n", "    print(node.text)\n", "    print(node.metadata)"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}