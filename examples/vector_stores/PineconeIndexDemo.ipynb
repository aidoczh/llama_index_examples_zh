{"cells": [{"cell_type": "markdown", "id": "714eb664", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/PineconeIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "307804a3-c02b-4a57-ac0d-172c30ddc851", "metadata": {}, "source": ["# Pineconeå‘é‡å­˜å‚¨\n", "\n", "Pineconeæ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„å‘é‡æ•°æ®åº“ï¼Œä¸“é—¨ç”¨äºŽå­˜å‚¨å’Œæ£€ç´¢å¤§è§„æ¨¡å‘é‡æ•°æ®ã€‚å®ƒæä¾›äº†å¿«é€Ÿçš„ç›¸ä¼¼å‘é‡æœç´¢å’Œé«˜æ•ˆçš„å‘é‡ç´¢å¼•åŠŸèƒ½ï¼Œé€‚ç”¨äºŽå„ç§åº”ç”¨åœºæ™¯ï¼Œå¦‚æŽ¨èç³»ç»Ÿã€æœç´¢å¼•æ“Žã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚Pineconeæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¶æä¾›äº†ç®€å•æ˜“ç”¨çš„APIï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿè½»æ¾åœ°é›†æˆå’Œä½¿ç”¨è¯¥æœåŠ¡ã€‚\n"]}, {"cell_type": "markdown", "id": "36be66bf", "metadata": {}, "source": ["å¦‚æžœæ‚¨åœ¨Colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ðŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "9ddff1e4", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-pinecone"]}, {"cell_type": "code", "execution_count": null, "id": "6807106d", "metadata": {}, "outputs": [], "source": ["!pip install llama-index>=0.9.31 pinecone-client>=3.0.0"]}, {"cell_type": "code", "execution_count": null, "id": "d48af8e1", "metadata": {}, "outputs": [], "source": ["import logging\n", "import sys\n", "import os\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["#### åˆ›å»ºä¸€ä¸ªPineconeç´¢å¼•\n"]}, {"cell_type": "code", "execution_count": null, "id": "0ce3143d-198c-4dd2-8e5a-c5cdf94f017a", "metadata": {}, "outputs": [], "source": ["from pinecone import Pinecone, ServerlessSpec"]}, {"cell_type": "code", "execution_count": null, "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee", "metadata": {}, "outputs": [], "source": ["os.environ[\n", "    \"PINECONE_API_KEY\"\n", "] = \"<Your Pinecone API key, from app.pinecone.io>\"\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n", "\n", "api_key = os.environ[\"PINECONE_API_KEY\"]\n", "\n", "pc = Pinecone(api_key=api_key)"]}, {"cell_type": "code", "execution_count": null, "id": "233a080f", "metadata": {}, "outputs": [], "source": ["# å¦‚æžœéœ€è¦ï¼Œåˆ é™¤\n", "# pc.delete_index(\"quickstart\")"]}, {"cell_type": "code", "execution_count": null, "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88", "metadata": {}, "outputs": [], "source": ["# dimensions are for text-embedding-ada-002\n", "\n", "pc.create_index(\n", "    name=\"quickstart\",\n", "    dimension=1536,\n", "    metric=\"euclidean\",\n", "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-west-2\"),\n", ")\n", "\n", "# å¦‚æžœæ‚¨éœ€è¦åˆ›å»ºåŸºäºŽPodçš„Pineconeç´¢å¼•ï¼Œæ‚¨ä¹Ÿå¯ä»¥è¿™æ ·åšï¼š\n", "\n", "# from pinecone import Pinecone, PodSpec\n", "#\n", "# pc = Pinecone(api_key='xxx')\n", "#\n", "# pc.create_index(\n", "# \t name='my-index',\n", "# \t dimension=1536,\n", "# \t metric='cosine',\n", "# \t spec=PodSpec(\n", "# \t\t environment='us-east1-gcp',\n", "# \t\t pod_type='p1.x1',\n", "# \t\t pods=1\n", "# \t )\n", "# )\n", "#"]}, {"cell_type": "code", "execution_count": null, "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6", "metadata": {}, "outputs": [], "source": ["pinecone_index = pc.Index(\"quickstart\")"]}, {"cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["#### åŠ è½½æ–‡æ¡£ï¼Œæž„å»ºPineconeVectorStoreå’ŒVectorStoreIndex\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a2bcc07", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "from llama_index.vector_stores.pinecone import PineconeVectorStore\n", "from IPython.display import Markdown, display"]}, {"cell_type": "markdown", "id": "7d782f76", "metadata": {}, "source": ["### ä¸‹è½½æ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "5104674e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n", "ERROR: could not open HSTS store at '/home/loganm/.wget-hsts'. HSTS will be disabled.\n", "--2024-01-16 11:56:25--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 75042 (73K) [text/plain]\n", "Saving to: â€˜data/paul_graham/paul_graham_essay.txtâ€™\n", "\n", "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.04s   \n", "\n", "2024-01-16 11:56:25 (1.79 MB/s) - â€˜data/paul_graham/paul_graham_essay.txtâ€™ saved [75042/75042]\n", "\n"]}], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£\n", "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "ba1558b3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "b9ce8a4615fe4162be2eaa2a5573f948", "version_major": 2, "version_minor": 0}, "text/plain": ["Upserted vectors:   0%|          | 0/22 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}], "source": ["# åˆå§‹åŒ–ï¼Œä¸å¸¦å…ƒæ•°æ®è¿‡æ»¤å™¨\n", "from llama_index.core import StorageContext\n", "\n", "if \"OPENAI_API_KEY\" not in os.environ:\n", "    raise EnvironmentError(f\"çŽ¯å¢ƒå˜é‡ OPENAI_API_KEY æœªè®¾ç½®\")\n", "\n", "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n", "index = VectorStoreIndex.from_documents(\n", "    documents, storage_context=storage_context\n", ")"]}, {"cell_type": "markdown", "id": "04304299-fc3e-40a0-8600-f50c3292767e", "metadata": {}, "source": ["#### æŸ¥è¯¢ç´¢å¼•\n", "\n", "å¯èƒ½éœ€è¦ä¸€åˆ†é’Ÿå·¦å³æ¥å‡†å¤‡ç´¢å¼•ï¼\n"]}, {"cell_type": "code", "execution_count": null, "id": "35369eda", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n", "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]}], "source": ["# å°†æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºDEBUGï¼Œä»¥èŽ·å¾—æ›´è¯¦ç»†çš„è¾“å‡º\n", "query_engine = index.as_query_engine()\n", "response = query_engine.query(\"ä½œè€…åœ¨æˆé•¿è¿‡ç¨‹ä¸­åšäº†ä»€ä¹ˆï¼Ÿ\")"]}, {"cell_type": "code", "execution_count": null, "id": "bedbb693-725f-478f-be26-fa7180ea38b2", "metadata": {}, "outputs": [{"data": {"text/markdown": ["<b>The author, growing up, worked on writing and programming. They wrote short stories and tried writing programs on an IBM 1401 computer. They later got a microcomputer and started programming more extensively, writing simple games and a word processor.</b>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["display(Markdown(f\"<b>{response}</b>\"))"]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}