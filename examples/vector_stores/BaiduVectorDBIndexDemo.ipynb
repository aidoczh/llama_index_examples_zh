{"cells": [{"cell_type": "markdown", "id": "0b692c73", "metadata": {}, "source": ["# 百度 VectorDB\n"]}, {"cell_type": "markdown", "id": "1e7787c2", "metadata": {}, "source": ["[Baidu VectorDB](https://cloud.baidu.com/product/vdb.html)是一种强大的企业级分布式数据库服务，由百度智能云精心开发和全面管理。它以其出色的存储、检索和分析多维向量数据的能力脱颖而出。在其核心，VectorDB运行在百度专有的“Mochow”向量数据库内核上，确保高性能、可用性和安全性，同时具有卓越的可扩展性和用户友好性。\n", "\n", "这个数据库服务支持各种不同类型的索引和相似性计算方法，满足各种用例需求。VectorDB的一个显著特点是其能够管理高达100亿的巨大向量规模，同时保持令人印象深刻的查询性能，支持每秒数百万次的查询(QPS)，并具有毫秒级的查询延迟。\n", "\n", "**这个笔记本展示了BaiduVectorDB在LlamaIndex中作为向量存储的基本用法。**\n", "\n", "要运行，您应该拥有一个[数据库实例。](https://cloud.baidu.com/doc/VDB/s/hlrsoazuf)\n"]}, {"cell_type": "markdown", "id": "daff81fe", "metadata": {}, "source": ["## 设置\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "f5e26095", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "cf987167", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-baiduvectordb"]}, {"cell_type": "code", "execution_count": null, "id": "156e71f4", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "e9f8dbcb", "metadata": {}, "outputs": [], "source": ["!pip install pymochow"]}, {"cell_type": "code", "execution_count": null, "id": "47264e32", "metadata": {}, "outputs": [], "source": ["from llama_index.core import (\n", "    VectorStoreIndex,\n", "    SimpleDirectoryReader,\n", "    StorageContext,\n", ")\n", "from llama_index.vector_stores.baiduvectordb import (\n", "    BaiduVectorDB,\n", "    TableParams,\n", "    TableField,\n", ")\n", "import pymochow"]}, {"cell_type": "markdown", "id": "f9b97a89", "metadata": {}, "source": ["### 请提供OpenAI访问密钥\n", "\n", "为了使用OpenAI提供的嵌入，您需要提供一个OpenAI API密钥：\n"]}, {"cell_type": "code", "execution_count": null, "id": "0c9f4d21-145a-401e-95ff-ccb259e8ef84", "metadata": {}, "outputs": [], "source": ["import openai\n", "\n", "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n", "openai.api_key = OPENAI_API_KEY"]}, {"attachments": {}, "cell_type": "markdown", "id": "cb63ec81", "metadata": {}, "source": ["## 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "b869a554", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "id": "59ff935d", "metadata": {}, "source": ["## 创建和填充向量存储\n", "\n", "现在，您将从本地文件加载一些Paul Graham的文章，并将它们存储到百度VectorDB中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [], "source": ["# 加载文档\n", "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\n", "print(f\"总文档数：{len(documents)}\")\n", "print(f\"第一个文档，id：{documents[0].doc_id}\")\n", "print(f\"第一个文档，哈希值：{documents[0].hash}\")\n", "print(\n", "    f\"第一个文档，文本（{len(documents[0].text)}个字符）：\\n{'='*20}\\n{documents[0].text[:360]} ...\"\n", ")"]}, {"cell_type": "markdown", "id": "dd270925", "metadata": {}, "source": ["### 初始化百度VectorDB\n", "\n", "如果尚不存在，则创建向量存储的过程包括创建底层数据库集合：\n"]}, {"cell_type": "code", "execution_count": null, "id": "afc5c44f", "metadata": {}, "outputs": [], "source": ["vector_store = BaiduVectorDB(\n", "    endpoint=\"http://192.168.X.X\",\n", "    api_key=\"*******\",\n", "    table_params=TableParams(dimension=1536, drop_exists=True),\n", ")"]}, {"cell_type": "markdown", "id": "cbabd1a7", "metadata": {}, "source": ["现在将这个存储包装成一个`index` LlamaIndex抽象，以便以后进行查询：\n"]}, {"cell_type": "code", "execution_count": null, "id": "ca205b88", "metadata": {}, "outputs": [], "source": ["storage_context = StorageContext.from_defaults(vector_store=vector_store)\n", "\n", "index = VectorStoreIndex.from_documents(\n", "    documents, storage_context=storage_context\n", ")"]}, {"cell_type": "markdown", "id": "cb11e2e2", "metadata": {}, "source": ["请注意，上面的`from_documents`调用同时执行了几项操作：将输入文档分割成可管理的大小块（\"节点\"），为每个节点计算嵌入向量，并将它们全部存储在百度VectorDB中。\n"]}, {"cell_type": "markdown", "id": "04304299-fc3e-40a0-8600-f50c3292767e", "metadata": {}, "source": ["## 查询商店\n"]}, {"cell_type": "markdown", "id": "b241797e", "metadata": {}, "source": ["### 基础查询\n"]}, {"cell_type": "code", "execution_count": null, "id": "35369eda", "metadata": {}, "outputs": [], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"Why did the author choose to work on AI?\")\n", "print(response)"]}, {"cell_type": "markdown", "id": "48761020", "metadata": {}, "source": ["### 基于MMR的查询\n", "\n", "MMR（最大边际相关性）方法旨在从存储中获取文本块，这些文本块既与查询相关，又尽可能不同，其目标是为最终答案的构建提供更广泛的上下文。\n"]}, {"cell_type": "code", "execution_count": null, "id": "eb2054c0", "metadata": {}, "outputs": [], "source": ["query_engine = index.as_query_engine(vector_store_query_mode=\"mmr\")\n", "response = query_engine.query(\"Why did the author choose to work on AI?\")\n", "print(response)"]}, {"cell_type": "markdown", "id": "4d7bc976", "metadata": {}, "source": ["## 连接到现有的存储库\n", "\n", "由于这个存储库是由百度VectorDB支持的，根据定义它是持久的。因此，如果您想连接到之前创建和填充的存储库，可以按照以下步骤操作：\n"]}, {"cell_type": "code", "execution_count": null, "id": "f0aae26e", "metadata": {}, "outputs": [], "source": ["vector_store = BaiduVectorDB(\n", "    endpoint=\"http://192.168.X.X\",\n", "    api_key=\"*******\",\n", "    table_params=TableParams(dimension=1536, drop_exists=False),\n", ")\n", "\n", "# 创建索引（从预先存储的向量中）\n", "new_index_instance = VectorStoreIndex.from_vector_store(\n", "    vector_store=new_vector_store\n", ")\n", "\n", "# 现在可以进行查询等操作：\n", "query_engine = index.as_query_engine(similarity_top_k=5)\n", "response = query_engine.query(\n", "    \"作者在从事人工智能之前学习了什么？\"\n", ")\n", "print(response)"]}, {"cell_type": "markdown", "id": "9fa59402", "metadata": {}, "source": ["## 元数据过滤\n", "\n", "百度VectorDB向量存储支持在查询时以精确匹配的`key=value`对的形式进行元数据过滤。下面的单元格将在一个全新的集合上演示这个功能。\n", "\n", "在这个演示中，为了简洁起见，加载了一个单一的源文件（`../data/paul_graham/paul_graham_essay.txt`文本文件）。尽管如此，您将附加一些自定义元数据到文档上，以说明如何通过对文档附加的元数据设置条件来限制查询。\n"]}, {"cell_type": "code", "execution_count": null, "id": "23c6ff1a", "metadata": {}, "outputs": [], "source": ["filter_fields = [\n", "    TableField(name=\"source_type\"),\n", "]\n", "\n", "md_storage_context = StorageContext.from_defaults(\n", "    vector_store=BaiduVectorDB(\n", "        endpoint=\"http://192.168.X.X\",\n", "        api_key=\"=\"*******\",\",\n", "        table_params=TableParams(\n", "            dimension=1536, drop_exists=True, filter_fields=filter_fields\n", "        ),\n", "    )\n", ")\n", "\n", "\n", "def my_file_metadata(file_name: str):\n", "    \"\"\"根据输入的文件名，关联不同的元数据。\"\"\"\n", "    if \"essay\" in file_name:\n", "        source_type = \"essay\"\n", "    elif \"dinosaur\" in file_name:\n", "        # 在这个演示中（不幸地）不会发生\n", "        source_type = \"dinos\"\n", "    else:\n", "        source_type = \"other\"\n", "    return {\"source_type\": source_type}\n", "\n", "\n", "# 加载文档并构建索引\n", "md_documents = SimpleDirectoryReader(\n", "    \"../data/paul_graham\", file_metadata=my_file_metadata\n", ").load_data()\n", "md_index = VectorStoreIndex.from_documents(\n", "    md_documents, storage_context=md_storage_context\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "d4bfd6f6", "metadata": {}, "outputs": [], "source": ["from llama_index.core.vector_stores import MetadataFilter, MetadataFilters"]}, {"cell_type": "code", "execution_count": null, "id": "733467f3", "metadata": {}, "outputs": [], "source": ["md_query_engine = md_index.as_query_engine(\n", "    filters=MetadataFilters(\n", "        filters=[MetadataFilter(key=\"source_type\", value=\"essay\")]\n", "    )\n", ")\n", "md_response = md_query_engine.query(\n", "    \"How long it took the author to write his thesis?\"\n", ")\n", "print(md_response.response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}