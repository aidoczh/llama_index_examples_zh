{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/VertexAIVectorSearchDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Google Vertex AI çŸ¢é‡æœç´¢\n", "\n", "è¿™ä¸ªç¬”è®°æœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¸`Google Cloud Vertex AI çŸ¢é‡æœç´¢`å‘é‡æ•°æ®åº“ç›¸å…³çš„åŠŸèƒ½ã€‚\n", "\n", "> [Google Vertex AI çŸ¢é‡æœç´¢](https://cloud.google.com/vertex-ai/docs/vector-search/overview)ï¼Œä¹‹å‰è¢«ç§°ä¸º Vertex AI åŒ¹é…å¼•æ“ï¼Œæä¾›äº†è¡Œä¸šé¢†å…ˆçš„é«˜è§„æ¨¡ä½å»¶è¿Ÿå‘é‡æ•°æ®åº“ã€‚è¿™äº›å‘é‡æ•°æ®åº“é€šå¸¸è¢«ç§°ä¸ºå‘é‡ç›¸ä¼¼åº¦åŒ¹é…æˆ–è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰æœåŠ¡ã€‚\n", "\n", "**æ³¨æ„**ï¼šLlamaIndex æœŸæœ› Vertex AI çŸ¢é‡æœç´¢ç«¯ç‚¹å’Œéƒ¨ç½²çš„ç´¢å¼•å·²ç»åˆ›å»ºã€‚åˆ›å»ºç©ºç´¢å¼•å¯èƒ½éœ€è¦æœ€å¤šä¸€åˆ†é’Ÿçš„æ—¶é—´ï¼Œå°†ç´¢å¼•éƒ¨ç½²åˆ°ç«¯ç‚¹å¯èƒ½éœ€è¦æœ€å¤š30åˆ†é’Ÿçš„æ—¶é—´ã€‚\n", "\n", "> è¦æŸ¥çœ‹å¦‚ä½•åˆ›å»ºç´¢å¼•ï¼Œè¯·å‚è€ƒ[åˆ›å»ºç´¢å¼•å¹¶å°†å…¶éƒ¨ç½²åˆ°ç«¯ç‚¹](#create-index-and-deploy-it-to-an-endpoint)  \n", "å¦‚æœæ‚¨å·²ç»éƒ¨ç½²äº†ä¸€ä¸ªç´¢å¼•ï¼Œè¯·è·³è½¬åˆ°[ä»æ–‡æœ¬åˆ›å»º VectorStore](#create-vector-store-from-texts)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## å®‰è£…\n", "\n", "å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€æ­¤ç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["! pip install llama-index llama-index-vector-stores-vertexaivectorsearch llama-index-llms-vertex"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## åˆ›å»ºç´¢å¼•å¹¶éƒ¨ç½²åˆ°ç»ˆç«¯\n", "\n", "- æœ¬èŠ‚æ¼”ç¤ºäº†å¦‚ä½•åˆ›å»ºä¸€ä¸ªæ–°çš„ç´¢å¼•å¹¶å°†å…¶éƒ¨ç½²åˆ°ä¸€ä¸ªç»ˆç«¯ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# TODOï¼šæ ¹æ®æ‚¨çš„éœ€æ±‚è®¾ç½®å€¼\n", "\n", "# é¡¹ç›®å’Œå­˜å‚¨å¸¸é‡\n", "PROJECT_ID = \"[your_project_id]\"\n", "REGION = \"[your_region]\"\n", "GCS_BUCKET_NAME = \"[your_gcs_bucket]\"\n", "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\"\n", "\n", "# textembedding-gecko@003 çš„ç»´åº¦ä¸º 768\n", "# å¦‚æœä½¿ç”¨å…¶ä»–åµŒå…¥å™¨ï¼Œç»´åº¦å¯èƒ½éœ€è¦æ›´æ”¹ã€‚\n", "VS_DIMENSIONS = 768\n", "\n", "# Vertex AI çŸ¢é‡æœç´¢ç´¢å¼•é…ç½®\n", "# å‚æ•°æè¿°åœ¨è¿™é‡Œ\n", "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index\n", "VS_INDEX_NAME = \"llamaindex-doc-index\"  # @param {type:\"string\"}\n", "VS_INDEX_ENDPOINT_NAME = \"llamaindex-doc-endpoint\"  # @param {type:\"string\"}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from google.cloud import aiplatform\n", "\n", "aiplatform.init(project=PROJECT_ID, location=REGION)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## å…ƒæ•°æ®è¿‡æ»¤ç¤ºä¾‹\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# åˆ›å»ºä¸€ä¸ªå­˜å‚¨æ¡¶ã€‚\n", "! gsutil mb -l $REGION -p $PROJECT_ID $GCS_BUCKET_URI"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### åˆ›å»ºä¸€ä¸ªç©ºçš„ç´¢å¼•\n", "\n", "**æ³¨æ„ï¼š** åœ¨åˆ›å»ºç´¢å¼•æ—¶ï¼Œæ‚¨åº”è¯¥æŒ‡å®šä¸€ä¸ªâ€œindex_update_methodâ€ - `BATCH_UPDATE` æˆ– `STREAM_UPDATE`\n", "\n", "> æ‰¹é‡ç´¢å¼•ç”¨äºå½“æ‚¨æƒ³è¦ä»¥æ‰¹é‡æ–¹å¼æ›´æ–°ç´¢å¼•æ—¶ï¼Œä½¿ç”¨å·²å­˜å‚¨ä¸€å®šæ—¶é—´çš„æ•°æ®ï¼Œæ¯”å¦‚æ¯å‘¨æˆ–æ¯æœˆå¤„ç†çš„ç³»ç»Ÿã€‚\n", ">\n", "> æµå¼ç´¢å¼•æ˜¯æŒ‡å½“æ‚¨å¸Œæœ›ç´¢å¼•æ•°æ®åœ¨æ–°æ•°æ®æ·»åŠ åˆ°æ•°æ®å­˜å‚¨æ—¶è¿›è¡Œæ›´æ–°ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰ä¸€å®¶ä¹¦åº—ï¼Œå¹¶å¸Œæœ›å°½å¿«åœ¨ç½‘ä¸Šå±•ç¤ºæ–°çš„åº“å­˜ã€‚\n", ">\n", "> é€‰æ‹©å“ªç§ç±»å‹å¾ˆé‡è¦ï¼Œå› ä¸ºè®¾ç½®å’Œè¦æ±‚æ˜¯ä¸åŒçš„ã€‚\n", "\n", "æœ‰å…³é…ç½®ç´¢å¼•çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[å®˜æ–¹æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index)å’Œ[APIå‚è€ƒ](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index)ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æ³¨æ„ï¼šæ­¤æ“ä½œå¯èƒ½éœ€è¦é•¿è¾¾30ç§’çš„æ—¶é—´\n", "\n", "# æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨\n", "index_names = [\n", "    index.resource_name\n", "    for index in aiplatform.MatchingEngineIndex.list(\n", "        filter=f\"display_name={VS_INDEX_NAME}\"\n", "    )\n", "]\n", "\n", "if len(index_names) == 0:\n", "    print(f\"æ­£åœ¨åˆ›å»ºå‘é‡æœç´¢ç´¢å¼• {VS_INDEX_NAME} ...\")\n", "    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n", "        display_name=VS_INDEX_NAME,\n", "        dimensions=VS_DIMENSIONS,\n", "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n", "        shard_size=\"SHARD_SIZE_SMALL\",\n", "        index_update_method=\"STREAM_UPDATE\",  # å…è®¸çš„å€¼ä¸º BATCH_UPDATEï¼ŒSTREAM_UPDATE\n", "    )\n", "    print(\n", "        f\"å·²åˆ›å»ºå…·æœ‰èµ„æºåç§° {vs_index.resource_name} çš„å‘é‡æœç´¢ç´¢å¼• {vs_index.display_name}\"\n", "    )\n", "else:\n", "    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n", "    print(\n", "        f\"å…·æœ‰èµ„æºåç§° {vs_index.resource_name} çš„å‘é‡æœç´¢ç´¢å¼• {vs_index.display_name} å·²å­˜åœ¨\"\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### åˆ›å»ºä¸€ä¸ªç«¯ç‚¹\n", "\n", "è¦ä½¿ç”¨ç´¢å¼•ï¼Œæ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ªç´¢å¼•ç«¯ç‚¹ã€‚å®ƒä½œä¸ºä¸€ä¸ªæœåŠ¡å™¨å®ä¾‹ï¼Œæ¥å—é’ˆå¯¹æ‚¨çš„ç´¢å¼•çš„æŸ¥è¯¢è¯·æ±‚ã€‚ç«¯ç‚¹å¯ä»¥æ˜¯[å…¬å…±ç«¯ç‚¹](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public)æˆ–[ç§æœ‰ç«¯ç‚¹](https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-vpc)ã€‚\n", "\n", "è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå…¬å…±ç«¯ç‚¹ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["endpoint_names = [\n", "    endpoint.resource_name\n", "    for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n", "        filter=f\"display_name={VS_INDEX_ENDPOINT_NAME}\"\n", "    )\n", "]\n", "\n", "if len(endpoint_names) == 0:\n", "    print(\n", "        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n", "    )\n", "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n", "        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n", "    )\n", "    print(\n", "        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n", "    )\n", "else:\n", "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n", "        index_endpoint_name=endpoint_names[0]\n", "    )\n", "    print(\n", "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### éƒ¨ç½²ç´¢å¼•åˆ°ç«¯ç‚¹\n", "\n", "ä½¿ç”¨ç´¢å¼•ç«¯ç‚¹ï¼Œé€šè¿‡æŒ‡å®šå”¯ä¸€çš„éƒ¨ç½²ç´¢å¼•IDæ¥éƒ¨ç½²ç´¢å¼•ã€‚\n", "\n", "**æ³¨æ„ï¼šæ­¤æ“ä½œå¯èƒ½éœ€è¦æœ€å¤š30åˆ†é’Ÿã€‚**\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æ£€æŸ¥ç«¯ç‚¹æ˜¯å¦å­˜åœ¨\n", "index_endpoints = [\n", "    (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n", "    for deployed_index in vs_index.deployed_indexes\n", "]\n", "\n", "if len(index_endpoints) == 0:\n", "    print(\n", "        f\"æ­£åœ¨å°†å‘é‡æœç´¢ç´¢å¼• {vs_index.display_name} éƒ¨ç½²åˆ°ç«¯ç‚¹ {vs_endpoint.display_name} ...\"\n", "    )\n", "    vs_deployed_index = vs_endpoint.deploy_index(\n", "        index=vs_index,\n", "        deployed_index_id=VS_INDEX_NAME,\n", "        display_name=VS_INDEX_NAME,\n", "        machine_type=\"e2-standard-16\",\n", "        min_replica_count=1,\n", "        max_replica_count=1,\n", "    )\n", "    print(\n", "        f\"å‘é‡æœç´¢ç´¢å¼• {vs_index.display_name} å·²éƒ¨ç½²åˆ°ç«¯ç‚¹ {vs_deployed_index.display_name}\"\n", "    )\n", "else:\n", "    vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n", "        index_endpoint_name=index_endpoints[0][0]\n", "    )\n", "    print(\n", "        f\"å‘é‡æœç´¢ç´¢å¼• {vs_index.display_name} å·²ç»éƒ¨ç½²åˆ°ç«¯ç‚¹ {vs_deployed_index.display_name}\"\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ä»æ–‡æœ¬åˆ›å»ºå‘é‡å­˜å‚¨\n", "\n", "æ³¨æ„ï¼šå¦‚æœæ‚¨å·²ç»æœ‰ç°æœ‰çš„Vertex AIå‘é‡æœç´¢ç´¢å¼•å’Œç«¯ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¿›è¡Œåˆ†é…ï¼š\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# å¾…åŠäº‹é¡¹ï¼šç”¨å®é™…çš„ç´¢å¼•IDæ›¿æ¢1234567890123456789\n", "vs_index = aiplatform.MatchingEngineIndex(index_name=\"1234567890123456789\")\n", "\n", "# å¾…åŠäº‹é¡¹ï¼šç”¨å®é™…çš„ç«¯ç‚¹IDæ›¿æ¢1234567890123456789\n", "vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n", "    index_endpoint_name=\"1234567890123456789\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# å¯¼å…¥æ‰€éœ€çš„æ¨¡å—\n", "from llama_index.core import (\n", "    StorageContext,\n", "    Settings,\n", "    VectorStoreIndex,\n", "    SimpleDirectoryReader,\n", ")\n", "from llama_index.core.schema import TextNode\n", "from llama_index.core.vector_stores.types import (\n", "    MetadataFilters,\n", "    MetadataFilter,\n", "    FilterOperator,\n", ")\n", "from llama_index.llms.vertex import Vertex\n", "from llama_index.embeddings.vertex import VertexTextEmbedding\n", "from llama_index.vector_stores.vertexaivectorsearch import VertexAIVectorStore"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### ä»çº¯æ–‡æœ¬åˆ›å»ºä¸€ä¸ªç®€å•çš„å‘é‡å­˜å‚¨ï¼Œä¸åŒ…å«å…ƒæ•°æ®è¿‡æ»¤å™¨\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è®¾ç½®å­˜å‚¨\n", "vector_store = VertexAIVectorStore(\n", "    project_id=PROJECT_ID,\n", "    region=REGION,\n", "    index_id=vs_index.resource_name,\n", "    endpoint_id=vs_endpoint.resource_name,\n", "    gcs_bucket_name=GCS_BUCKET_NAME,\n", ")\n", "\n", "# è®¾ç½®å­˜å‚¨ä¸Šä¸‹æ–‡\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### ä½¿ç”¨[Vertex AI Embeddings](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/embeddings/llama-index-embeddings-vertex)ä½œä¸ºåµŒå…¥æ¨¡å‹\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# é…ç½®åµŒå…¥æ¨¡å‹\n", "embed_model = VertexTextEmbedding(\n", "    model_name=\"textembedding-gecko@003\",\n", "    project=PROJECT_ID,\n", "    location=REGION,\n", ")\n", "\n", "# è®¾ç½®ç´¢å¼•/æŸ¥è¯¢è¿‡ç¨‹ï¼Œå³åµŒå…¥æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨åˆ™åŒ…æ‹¬å®Œæˆï¼‰\n", "Settings.embed_model = embed_model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### å°†å‘é‡å’Œæ˜ å°„çš„æ–‡æœ¬å—æ·»åŠ åˆ°æ‚¨çš„å‘é‡å­˜å‚¨åº“\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è¾“å…¥æ–‡æœ¬\n", "texts = [\n", "    \"çŒ«ååœ¨\",\n", "    \"å«å­ä¸Šã€‚\",\n", "    \"æˆ‘å–œæ¬¢\",\n", "    \"æ™šé¤åƒæ¯”è¨\",\n", "    \"ã€‚\",\n", "    \"å¤ªé˜³åœ¨è¥¿è¾¹\",\n", "    \"è½ä¸‹ã€‚\"\n", "]\n", "nodes = [\n", "    TextNode(text=text, embedding=embed_model.get_text_embedding(text))\n", "    for text in texts\n", "]\n", "\n", "vector_store.add(nodes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### è¿è¡Œç›¸ä¼¼åº¦æœç´¢\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä»å‘é‡å­˜å‚¨ä¸­å®šä¹‰ç´¢å¼•\n", "index = VectorStoreIndex.from_vector_store(\n", "    vector_store=vector_store, embed_model=embed_model\n", ")\n", "retriever = index.as_retriever()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Score: 0.703 Text: eat pizza for\n", "Score: 0.626 Text: dinner.\n"]}], "source": ["response = retriever.retrieve(\"pizza\")\n", "for row in response:\n", "    print(f\"Score: {row.get_score():.3f} Text: {row.get_text()}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## æ·»åŠ å¸¦æœ‰å…ƒæ•°æ®å±æ€§çš„æ–‡æ¡£å¹¶ä½¿ç”¨è¿‡æ»¤å™¨\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è¾“å…¥å¸¦æœ‰å…ƒæ•°æ®çš„æ–‡æœ¬\n", "records = [\n", "    {\n", "        \"description\": \"ä¸€æ¡å¤šåŠŸèƒ½çš„æ·±è‰²ç‰›ä»”è£¤ã€‚ç”±è€ç”¨çš„æ£‰å¸ƒåˆ¶æˆï¼Œç»å…¸çš„ç›´ç­’è£å‰ªï¼Œè¿™æ¡ç‰›ä»”è£¤å¯ä»¥è½»æ¾ä»ä¼‘é—²æ—¥ç©¿åˆ°æ›´æ­£å¼çš„åœºåˆã€‚\",\n", "        \"price\": 65.00,\n", "        \"color\": \"blue\",\n", "        \"season\": [\"ç§‹å­£\", \"å†¬å­£\", \"æ˜¥å­£\"],\n", "    },\n", "    {\n", "        \"description\": \"ä¸€ä»¶æ¸…çˆ½çš„ç™½è‰²äºšéº»è¡¬è¡«ã€‚é€æ°”çš„é¢æ–™å’Œå®½æ¾çš„ç‰ˆå‹ï¼Œéå¸¸é€‚åˆä¿æŒæ¸…å‡‰ã€‚\",\n", "        \"price\": 34.99,\n", "        \"color\": \"white\",\n", "        \"season\": [\"å¤å­£\", \"æ˜¥å­£\"],\n", "    },\n", "    {\n", "        \"description\": \"ä¸€ä»¶æŸ”è½¯åšå®çš„æ·±ç»¿è‰²ç²—é’ˆç»‡æ¯›è¡£ã€‚å®½æ¾çš„ç‰ˆå‹å’Œèˆ’é€‚çš„ç¾Šæ¯›æ··çººæè´¨ï¼Œéå¸¸é€‚åˆåœ¨æ°”æ¸©ä¸‹é™æ—¶ä¿æš–ã€‚\",\n", "        \"price\": 89.99,\n", "        \"color\": \"green\",\n", "        \"season\": [\"ç§‹å­£\", \"å†¬å­£\"],\n", "    },\n", "    {\n", "        \"description\": \"ä¸€ä»¶æŸ”è½¯çš„æ··çººè“è‰²åœ†é¢†Tæ¤ã€‚ç”±èˆ’é€‚çš„æ£‰è´¨æ°è¥¿å¸ƒåˆ¶æˆï¼Œè¿™ä»¶Tæ¤æ˜¯é€‚åˆæ¯ä¸ªå­£èŠ‚çš„åŸºæœ¬æ¬¾ã€‚\",\n", "        \"price\": 19.99,\n", "        \"color\": \"blue\",\n", "        \"season\": [\"ç§‹å­£\", \"å†¬å­£\", \"å¤å­£\", \"æ˜¥å­£\"],\n", "    },\n", "    {\n", "        \"description\": \"ä¸€æ¡è½»ç›ˆçš„ä¸­é•¿è£™ï¼Œå°æœ‰ç²¾è‡´çš„èŠ±å‰å›¾æ¡ˆã€‚è½»ç›ˆé€æ°”ï¼Œè¿™æ¡è£™å­ä¸ºæ¸©æš–çš„æ—¥å­å¢æ·»äº†ä¸€ä¸å¥³æ€§é£æƒ…ã€‚\",\n", "        \"price\": 45.00,\n", "        \"color\": \"white\",\n", "        \"season\": [\"æ˜¥å­£\", \"å¤å­£\"],\n", "    },\n", "]\n", "\n", "nodes = []\n", "for record in records:\n", "    text = record.pop(\"description\")\n", "    embedding = embed_model.get_text_embedding(text)\n", "    metadata = {**record}\n", "    nodes.append(TextNode(text=text, embedding=embedding, metadata=metadata))\n", "\n", "vector_store.add(nodes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### ä½¿ç”¨è¿‡æ»¤å™¨è¿›è¡Œç›¸ä¼¼æ€§æœç´¢\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä»å‘é‡å­˜å‚¨ä¸­å®šä¹‰ç´¢å¼•\n", "index = VectorStoreIndex.from_vector_store(\n", "    vector_store=vector_store, embed_model=embed_model\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Text: A pair of well-tailored dress pants in a neutral grey. Made from a wrinkle-resistant blend, these pants look sharp and professional for workwear or formal occasions.\n", "   Score: 0.669\n", "   Metadata: {'price': 69.99, 'color': 'grey', 'season': ['fall', 'winter', 'summer', 'spring']}\n", "Text: A pair of tailored black trousers in a comfortable stretch fabric. Perfect for work or dressier events, these trousers provide a sleek, polished look.\n", "   Score: 0.642\n", "   Metadata: {'price': 59.99, 'color': 'black', 'season': ['fall', 'winter', 'spring']}\n"]}], "source": ["# ç®€å•çš„ç›¸ä¼¼åº¦æœç´¢ï¼Œä¸å¸¦è¿‡æ»¤å™¨\n", "retriever = index.as_retriever()\n", "response = retriever.retrieve(\"pants\")\n", "\n", "for row in response:\n", "    print(f\"æ–‡æœ¬: {row.get_text()}\")\n", "    print(f\"   åˆ†æ•°: {row.get_score():.3f}\")\n", "    print(f\"   å…ƒæ•°æ®: {row.metadata}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Text: A versatile pair of dark-wash denim jeans.Made from durable cotton with a classic straight-leg cut, these jeans transition easily from casual days to dressier occasions.\n", "   Score: 0.704\n", "   Metadata: {'price': 65.0, 'color': 'blue', 'season': ['fall', 'winter', 'spring']}\n", "Text: A denim jacket with a faded wash and distressed details. This wardrobe staple adds a touch of effortless cool to any outfit.\n", "   Score: 0.667\n", "   Metadata: {'price': 79.99, 'color': 'blue', 'season': ['fall', 'spring', 'summer']}\n"]}], "source": ["# ä½¿ç”¨æ–‡æœ¬è¿‡æ»¤è¿›è¡Œç›¸ä¼¼æ€§æœç´¢\n", "filters = MetadataFilters(filters=[MetadataFilter(key=\"color\", value=\"blue\")])\n", "retriever = index.as_retriever(filters=filters, similarity_top_k=3)\n", "response = retriever.retrieve(\"ç‰›ä»”è£¤\")\n", "\n", "for row in response:\n", "    print(f\"æ–‡æœ¬: {row.get_text()}\")\n", "    print(f\"   å¾—åˆ†: {row.get_score():.3f}\")\n", "    print(f\"   å…ƒæ•°æ®: {row.metadata}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Text: A denim jacket with a faded wash and distressed details. This wardrobe staple adds a touch of effortless cool to any outfit.\n", "   Score: 0.667\n", "   Metadata: {'price': 79.99, 'color': 'blue', 'season': ['fall', 'spring', 'summer']}\n"]}], "source": ["# ä½¿ç”¨æ–‡æœ¬å’Œæ•°å€¼è¿‡æ»¤è¿›è¡Œç›¸ä¼¼åº¦æœç´¢\n", "filters = MetadataFilters(\n", "    filters=[\n", "        MetadataFilter(key=\"color\", value=\"blue\"),\n", "        MetadataFilter(key=\"price\", operator=FilterOperator.GT, value=70.0),\n", "    ]\n", ")\n", "retriever = index.as_retriever(filters=filters, similarity_top_k=3)\n", "response = retriever.retrieve(\"denims\")\n", "\n", "for row in response:\n", "    print(f\"æ–‡æœ¬: {row.get_text()}\")\n", "    print(f\"   å¾—åˆ†: {row.get_score():.3f}\")\n", "    print(f\"   å…ƒæ•°æ®: {row.metadata}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ä½¿ç”¨Vertex AI Vector Searchå’ŒGemini Proè§£æã€ç´¢å¼•å’ŒæŸ¥è¯¢PDFæ–‡ä»¶\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["E0501 00:56:50.842446801  266241 backup_poller.cc:127]                 Run client channel backup poller: UNKNOWN:pollset_work {created_time:\"2024-05-01T00:56:50.841935606+00:00\", children:[UNKNOWN:Bad file descriptor {created_time:\"2024-05-01T00:56:50.841810434+00:00\", errno:9, os_error:\"Bad file descriptor\", syscall:\"epoll_wait\"}]}\n", "--2024-05-01 00:56:52--  https://arxiv.org/pdf/1706.03762.pdf\n", "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.195.42, 151.101.131.42, ...\n", "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n", "HTTP request sent, awaiting response... 301 Moved Permanently\n", "Location: http://arxiv.org/pdf/1706.03762 [following]\n", "--2024-05-01 00:56:52--  http://arxiv.org/pdf/1706.03762\n", "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:80... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 2215244 (2.1M) [application/pdf]\n", "Saving to: â€˜./data/arxiv/test.pdfâ€™\n", "\n", "./data/arxiv/test.p 100%[===================>]   2.11M  --.-KB/s    in 0.07s   \n", "\n", "2024-05-01 00:56:52 (31.5 MB/s) - â€˜./data/arxiv/test.pdfâ€™ saved [2215244/2215244]\n", "\n"]}], "source": ["! mkdir -p ./data/arxiv/\n", "! wget 'https://arxiv.org/pdf/1706.03762.pdf' -O ./data/arxiv/test.pdf"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["# of documents = 15\n"]}], "source": ["# åŠ è½½æ–‡æ¡£\n", "documents = SimpleDirectoryReader(\"./data/arxiv/\").load_data()\n", "print(f\"æ–‡æ¡£æ•°é‡ = {len(documents)}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# è®¾ç½®å­˜å‚¨\n", "vector_store = VertexAIVectorStore(\n", "    project_id=PROJECT_ID,\n", "    region=REGION,\n", "    index_id=vs_index.resource_name,\n", "    endpoint_id=vs_endpoint.resource_name,\n", "    gcs_bucket_name=GCS_BUCKET_NAME,\n", ")\n", "\n", "# è®¾ç½®å­˜å‚¨ä¸Šä¸‹æ–‡\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n", "\n", "# é…ç½®åµŒå…¥æ¨¡å‹\n", "embed_model = VertexTextEmbedding(\n", "    model_name=\"textembedding-gecko@003\",\n", "    project=PROJECT_ID,\n", "    location=REGION,\n", ")\n", "\n", "vertex_gemini = Vertex(model=\"gemini-pro\", temperature=0, additional_kwargs={})\n", "\n", "# è®¾ç½®ç´¢å¼•/æŸ¥è¯¢è¿‡ç¨‹ï¼Œå³åµŒå…¥æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨ï¼‰\n", "Settings.llm = vertex_gemini\n", "Settings.embed_model = embed_model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ä»å‘é‡å­˜å‚¨ä¸­å®šä¹‰ç´¢å¼•\n", "index = VectorStoreIndex.from_documents(\n", "    documents, storage_context=storage_context\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = index.as_query_engine()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Response:\n", "--------------------------------------------------------------------------------\n", "The authors of the paper \"Attention Is All You Need\" are:\n", "\n", "* Ashish Vaswani\n", "* Noam Shazeer\n", "* Niki Parmar\n", "* Jakob Uszkoreit\n", "* Llion Jones\n", "* Aidan N. Gomez\n", "* Åukasz Kaiser\n", "* Illia Polosukhin\n", "--------------------------------------------------------------------------------\n", "Source Documents:\n", "--------------------------------------------------------------------------------\n", "Sample Text: Provided proper attribution is provided, Google he\n", "Relevance score: 0.720\n", "File Name: test.pdf\n", "Page #: 1\n", "File Path: /home/jupyter/llama_index/docs/docs/examples/vector_stores/data/arxiv/test.pdf\n", "--------------------------------------------------------------------------------\n", "Sample Text: length nis smaller than the representation dimensi\n", "Relevance score: 0.678\n", "File Name: test.pdf\n", "Page #: 7\n", "File Path: /home/jupyter/llama_index/docs/docs/examples/vector_stores/data/arxiv/test.pdf\n", "--------------------------------------------------------------------------------\n"]}], "source": ["response = query_engine.query(\n", "    \"è°æ˜¯è®ºæ–‡ã€Šæ³¨æ„åŠ›æœºåˆ¶å°±æ˜¯ä½ æ‰€éœ€è¦çš„ä¸€åˆ‡ã€‹çš„ä½œè€…ï¼Ÿ\"\n", ")\n", "\n", "print(f\"å›å¤:\")\n", "print(\"-\" * 80)\n", "print(response.response)\n", "print(\"-\" * 80)\n", "print(f\"æºæ–‡ä»¶:\")\n", "print(\"-\" * 80)\n", "for source in response.source_nodes:\n", "    print(f\"æ ·æœ¬æ–‡æœ¬: {source.text[:50]}\")\n", "    print(f\"ç›¸å…³æ€§åˆ†æ•°: {source.get_score():.3f}\")\n", "    print(f\"æ–‡ä»¶å: {source.metadata.get('file_name')}\")\n", "    print(f\"é¡µç : {source.metadata.get('page_label')}\")\n", "    print(f\"æ–‡ä»¶è·¯å¾„: {source.metadata.get('file_path')}\")\n", "    print(\"-\" * 80)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ç¿»è¯‘ç»“æœå·²åˆ é™¤ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## æ¸…ç†\n", "\n", "è¯·åœ¨è¿è¡Œå®éªŒååˆ é™¤ Vertex AI Vector Search Index å’Œ Index Endpointï¼Œä»¥é¿å…äº§ç”Ÿé¢å¤–çš„è´¹ç”¨ã€‚è¯·æ³¨æ„ï¼Œåªè¦ç«¯ç‚¹æ­£åœ¨è¿è¡Œï¼Œæ‚¨å°±ä¼šè¢«æ”¶è´¹ã€‚\n", "\n", "<div class=\"alert alert-block alert-warning\">\n", "    <b>âš ï¸ æ³¨æ„ï¼šå¯ç”¨ `CLEANUP_RESOURCES` æ ‡å¿—ä¼šåˆ é™¤ Vector Search Indexã€Index Endpoint å’Œ Cloud Storage å­˜å‚¨æ¡¶ã€‚è¯·è°¨æ…è¿è¡Œã€‚</b>\n", "</div>\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CLEANUP_RESOURCES = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- å–æ¶ˆéƒ¨ç½²ç´¢å¼•å’Œåˆ é™¤ç´¢å¼•ç«¯ç‚¹\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if CLEANUP_RESOURCES:\n", "    print(\n", "        f\"Undeploying all indexes and deleting the index endpoint {vs_endpoint.display_name}\"\n", "    )\n", "    vs_endpoint.undeploy_all()\n", "    vs_endpoint.delete()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- åˆ é™¤ç´¢å¼•\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if CLEANUP_RESOURCES:\n", "    print(f\"Deleting the index {vs_index.display_name}\")\n", "    vs_index.delete()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- ä»äº‘å­˜å‚¨æ¡¶ä¸­åˆ é™¤å†…å®¹\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if CLEANUP_RESOURCES and \"GCS_BUCKET_NAME\" in globals():\n", "    print(f\"æ­£åœ¨åˆ é™¤äº‘å­˜å‚¨æ¡¶ {GCS_BUCKET_NAME} ä¸­çš„å†…å®¹\")\n", "\n", "    shell_output = ! gsutil du -ash gs://$GCS_BUCKET_NAME\n", "    print(shell_output)\n", "    print(\n", "        f\"åˆ é™¤å‰å­˜å‚¨æ¡¶ {GCS_BUCKET_NAME} çš„å¤§å° = {' '.join(shell_output[0].split()[:2])}\"\n", "    )\n", "\n", "    # å–æ¶ˆä¸‹é¢ä¸€è¡Œçš„æ³¨é‡Šä»¥åˆ é™¤å­˜å‚¨æ¡¶çš„å†…å®¹\n", "    # ! gsutil -m rm -r gs://$GCS_BUCKET_NAME"]}], "metadata": {"kernelspec": {"display_name": "python", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}