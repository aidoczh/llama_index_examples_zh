{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "f71d19de", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/SimpleIndexDemoLlama2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05", "metadata": {}, "source": ["# Llama2 + VectorStoreIndex\n", "\n", "æœ¬ç¬”è®°æœ¬ä»‹ç»äº†ä½¿ç”¨LlamaIndexä¸llama-2çš„æ­£ç¡®è®¾ç½®æ­¥éª¤ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å‘é‡å­˜å‚¨ç´¢å¼•ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "91f09a23", "metadata": {}, "source": ["## è®¾ç½®\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "b67d9bd5", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "fe23f913", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-replicate"]}, {"cell_type": "code", "execution_count": null, "id": "24fbf539", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"attachments": {}, "cell_type": "markdown", "id": "ba765302", "metadata": {}, "source": ["### å¯†é’¥\n"]}, {"cell_type": "code", "execution_count": null, "id": "3d8cab38", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n", "os.environ[\"REPLICATE_API_TOKEN\"] = \"YOUR_REPLICATE_TOKEN\""]}, {"attachments": {}, "cell_type": "markdown", "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119", "metadata": {}, "source": ["### åŠ è½½æ–‡æ¡£ï¼Œæ„å»ºVectorStoreIndex\n"]}, {"cell_type": "code", "execution_count": null, "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7", "metadata": {}, "outputs": [], "source": ["# å¯é€‰çš„æ—¥å¿—è®°å½•", "# å¯¼å…¥æ—¥å¿—è®°å½•", "# å¯¼å…¥sys", "", "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)", "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))", "", "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader", "", "from IPython.display import Markdown, display"]}, {"cell_type": "code", "execution_count": null, "id": "be92665d", "metadata": {}, "outputs": [], "source": ["from llama_index.llms.replicate import Replicate", "from llama_index.core.llms.llama_utils import (", "    messages_to_prompt,", "    completion_to_prompt,", ")", "", "# å¤åˆ¶ç«¯ç‚¹", "LLAMA_13B_V2_CHAT = \"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5\"", "", "", "# å°†è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºæ³¨å…¥åˆ°llama-2ä¸­", "def custom_completion_to_prompt(completion: str) -> str:", "    return completion_to_prompt(", "        completion,", "        system_prompt=(", "            \"æ‚¨æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚æ‚¨çš„ç›®æ ‡æ˜¯æ ¹æ®æä¾›çš„æŒ‡ç¤ºå’Œä¸Šä¸‹æ–‡å°½å¯èƒ½å‡†ç¡®åœ°å›ç­”é—®é¢˜ã€‚\"", "        ),", "    )", "", "", "llm = Replicate(", "    model=LLAMA_13B_V2_CHAT,", "    temperature=0.01,", "    # ç”±äºå®ƒè¢«è§£é‡Šä¸ºä¸Šä¸‹æ–‡çª—å£è€Œä¸æ˜¯æœ€å¤§æ ‡è®°æ•°ï¼Œå› æ­¤è¦†ç›–æœ€å¤§æ ‡è®°æ•°", "    context_window=4096,", "    # ä¸ºllama 2è¦†ç›–å®Œæˆè¡¨ç¤º", "    completion_to_prompt=custom_completion_to_prompt,", "    # å¦‚æœä½¿ç”¨llama 2è¿›è¡Œæ•°æ®ä»£ç†ï¼Œè¿˜éœ€è¦è¦†ç›–æ¶ˆæ¯è¡¨ç¤º", "    messages_to_prompt=messages_to_prompt,", ")"]}, {"cell_type": "code", "execution_count": null, "id": "13799473", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "Settings.llm = llm"]}, {"attachments": {}, "cell_type": "markdown", "id": "a1555336", "metadata": {}, "source": ["ä¸‹è½½æ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "03d1691e-544b-454f-825b-5ee12f7faa8a", "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58", "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex.from_documents(documents)"]}, {"attachments": {}, "cell_type": "markdown", "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4", "metadata": {}, "source": ["## æŸ¥è¯¢\n"]}, {"cell_type": "code", "execution_count": null, "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f", "metadata": {}, "outputs": [], "source": ["# å°†æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºDEBUGï¼Œä»¥è·å¾—æ›´è¯¦ç»†çš„è¾“å‡º", "query_engine = index.as_query_engine()"]}, {"cell_type": "code", "execution_count": null, "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b", "metadata": {}, "outputs": [{"data": {"text/markdown": ["<b> Based on the context information provided, the author's activities growing up were:\n", "1. Writing short stories, which were \"awful\" and had \"hardly any plot.\"\n", "2. Programming on an IBM 1401 computer in 9th grade, using an early version of Fortran language.\n", "3. Building simple games, a program to predict the height of model rockets, and a word processor for his father.\n", "4. Reading science fiction novels, such as \"The Moon is a Harsh Mistress\" by Heinlein, which inspired him to work on AI.\n", "5. Living in Florence, Italy, and walking through the city's streets to the Accademia.\n", "\n", "Please note that these activities are mentioned in the text and are not based on prior knowledge or assumptions.</b>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["response = query_engine.query(\"What did the author do growing up?\")\n", "display(Markdown(f\"<b>{response}</b>\"))"]}, {"attachments": {}, "cell_type": "markdown", "id": "24935a47", "metadata": {}, "source": ["### æµæ”¯æŒ\n"]}, {"cell_type": "code", "execution_count": null, "id": "446406f9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": [" Based on the context information provided, it appears that the author worked at Interleaf, a company that made software for creating and managing documents. The author mentions that Interleaf was \"on the way down\" and that the company's Release Engineering group was large compared to the group that actually wrote the software. It is inferred that Interleaf was experiencing financial difficulties and that the author was nervous about money. However, there is no explicit mention of what specifically happened at Interleaf."]}], "source": ["query_engine = index.as_query_engine(streaming=True)\n", "response = query_engine.query(\"What happened at interleaf?\")\n", "for token in response.response_gen:\n", "    print(token, end=\"\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}