{"cells": [{"cell_type": "markdown", "id": "f168e06c", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/PineconeIndexDemo-Hybrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "307804a3-c02b-4a57-ac0d-172c30ddc851", "metadata": {}, "source": ["PineconeçŸ¢é‡å­˜å‚¨ - æ··åˆæœç´¢\n"]}, {"cell_type": "markdown", "id": "4f821db5", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "4fe98b73", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-pinecone"]}, {"cell_type": "code", "execution_count": null, "id": "8604a171", "metadata": {}, "outputs": [], "source": ["!pip install llama-index>=0.9.31 pinecone-client>=3.0.0 \"transformers[torch]\""]}, {"cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["#### åˆ›å»ºä¸€ä¸ªPineconeç´¢å¼•\n"]}, {"cell_type": "code", "execution_count": null, "id": "d48af8e1", "metadata": {}, "outputs": [], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"cell_type": "code", "execution_count": null, "id": "0ce3143d-198c-4dd2-8e5a-c5cdf94f017a", "metadata": {}, "outputs": [], "source": ["from pinecone import Pinecone, ServerlessSpec"]}, {"cell_type": "code", "execution_count": null, "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee", "metadata": {}, "outputs": [], "source": ["import os", "", "os.environ[", "    \"PINECONE_API_KEY\"", "] = #\"<æ‚¨çš„Pinecone APIå¯†é’¥ï¼Œæ¥è‡ªapp.pinecone.io>\"", "os.environ[", "    \"OPENAI_API_KEY\"", "] = \"sk-...\"", "", "api_key = os.environ[\"PINECONE_API_KEY\"]", "", "pc = Pinecone(api_key=api_key)"]}, {"cell_type": "code", "execution_count": null, "id": "6123399c", "metadata": {}, "outputs": [], "source": ["# å¦‚æœéœ€è¦çš„è¯åˆ é™¤", "# pc.delete_index(\"quickstart\")"]}, {"cell_type": "code", "execution_count": null, "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88", "metadata": {}, "outputs": [], "source": ["# dimensions are for text-embedding-ada-002", "# æ³¨æ„ï¼šéœ€è¦ä½¿ç”¨ç‚¹ç§¯è¿›è¡Œæ··åˆæœç´¢", "", "pc.create_index(", "    name=\"quickstart\",", "    dimension=1536,", "    metric=\"dotproduct\",", "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-west-2\"),", ")", "", "# å¦‚æœéœ€è¦åˆ›å»ºåŸºäºPodçš„Pineconeç´¢å¼•ï¼Œä¹Ÿå¯ä»¥è¿™æ ·åšï¼š", "#", "# from pinecone import Pinecone, PodSpec", "#", "# pc = Pinecone(api_key='xxx')", "#", "# pc.create_index(", "# \t name='my-index',", "# \t dimension=1536,", "# \t metric='cosine',", "# \t spec=PodSpec(", "# \t\t environment='us-east1-gcp',", "# \t\t pod_type='p1.x1',", "# \t\t pods=1", "# \t )", "# )", "#"]}, {"cell_type": "code", "execution_count": null, "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6", "metadata": {}, "outputs": [], "source": ["pinecone_index = pc.Index(\"quickstart\")"]}, {"cell_type": "markdown", "id": "01c6bb69", "metadata": {}, "source": ["ä¸‹è½½æ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "664f01b4", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["#### åŠ è½½æ–‡æ¡£ï¼Œæ„å»ºPineconeVectorStore\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a2bcc07", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n", "from llama_index.vector_stores.pinecone import PineconeVectorStore\n", "from IPython.display import Markdown, display"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "ba1558b3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "5e6a2a5579ce45e7953eed31c4c24e14", "version_major": 2, "version_minor": 0}, "text/plain": ["Upserted vectors:   0%|          | 0/22 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}], "source": ["# å°†add_sparse_vectorè®¾ç½®ä¸ºTrueä»¥åœ¨upsertæœŸé—´è®¡ç®—ç¨€ç–å‘é‡", "from llama_index.core import StorageContext", "", "if \"OPENAI_API_KEY\" not in os.environ:", "    raise EnvironmentError(f\"Environment variable OPENAI_API_KEY is not set\")", "", "vector_store = PineconeVectorStore(", "    pinecone_index=pinecone_index,", "    add_sparse_vector=True,", ")", "storage_context = StorageContext.from_defaults(vector_store=vector_store)", "index = VectorStoreIndex.from_documents(", "    documents, storage_context=storage_context", ")"]}, {"cell_type": "markdown", "id": "04304299-fc3e-40a0-8600-f50c3292767e", "metadata": {}, "source": ["#### æŸ¥è¯¢ç´¢å¼•\n", "\n", "å¯èƒ½éœ€è¦ç­‰å¾…ä¸€ä¸¤åˆ†é’Ÿï¼Œç›´åˆ°ç´¢å¼•å‡†å¤‡å°±ç»ªã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "35369eda", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n", "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]}], "source": ["# å°†æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºDEBUGï¼Œä»¥è·å¾—æ›´è¯¦ç»†çš„è¾“å‡º", "query_engine = index.as_query_engine(vector_store_query_mode=\"hybrid\")", "response = query_engine.query(\"What happened at Viaweb?\")"]}, {"cell_type": "code", "execution_count": null, "id": "bedbb693-725f-478f-be26-fa7180ea38b2", "metadata": {}, "outputs": [{"data": {"text/markdown": ["<b>At Viaweb, Lisp was used as a programming language. The speaker gave a talk at a Lisp conference about how Lisp was used at Viaweb, and afterward, the talk gained a lot of attention when it was posted online. This led to a realization that publishing essays online could reach a wider audience than traditional print media. The speaker also wrote a collection of essays, which was later published as a book called \"Hackers & Painters.\"</b>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["display(Markdown(f\"<b>{response}</b>\"))"]}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}