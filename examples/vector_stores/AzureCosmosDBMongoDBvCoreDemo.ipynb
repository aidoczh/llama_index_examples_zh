{"cells": [{"cell_type": "markdown", "id": "bccd47fc", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/AzureCosmosDBMongoDBvCoreDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "db0855d0", "metadata": {}, "source": ["# Azure CosmosDB MongoDB 向量存储\n", "在本笔记本中，我们将展示如何使用 Azure CosmosDB MongoDB vCore 在 LlamaIndex 中执行向量搜索。我们将使用 Azure Open AI 创建嵌入。\n"]}, {"cell_type": "markdown", "id": "e4f33fc9", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "cc10b892", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-openai\n", "%pip install llama-index-vector-stores-azurecosmosmongo\n", "%pip install llama-index-llms-azure-openai"]}, {"cell_type": "code", "execution_count": null, "id": "712daea5", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "c2d1c538", "metadata": {}, "outputs": [], "source": ["import os\n", "import json\n", "import openai\n", "from llama_index.llms.azure_openai import AzureOpenAI\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"]}, {"cell_type": "markdown", "id": "26c71b6d", "metadata": {}, "source": ["### 设置Azure OpenAI\n", "第一步是配置模型。它们将用于为加载到数据库中的文档创建嵌入，并用于llm完成。\n"]}, {"cell_type": "code", "execution_count": null, "id": "67b86621", "metadata": {}, "outputs": [], "source": ["import os", "", "# 设置AzureOpenAI实例", "llm = AzureOpenAI(", "    model_name=os.getenv(\"OPENAI_MODEL_COMPLETION\"),", "    deployment_name=os.getenv(\"OPENAI_MODEL_COMPLETION\"),", "    api_base=os.getenv(\"OPENAI_API_BASE\"),", "    api_key=os.getenv(\"OPENAI_API_KEY\"),", "    api_type=os.getenv(\"OPENAI_API_TYPE\"),", "    api_version=os.getenv(\"OPENAI_API_VERSION\"),", "    temperature=0,", ")", "", "# 设置OpenAIEmbedding实例", "embed_model = OpenAIEmbedding(", "    model=os.getenv(\"OPENAI_MODEL_EMBEDDING\"),", "    deployment_name=os.getenv(\"OPENAI_DEPLOYMENT_EMBEDDING\"),", "    api_base=os.getenv(\"OPENAI_API_BASE\"),", "    api_key=os.getenv(\"OPENAI_API_KEY\"),", "    api_type=os.getenv(\"OPENAI_API_TYPE\"),", "    api_version=os.getenv(\"OPENAI_API_VERSION\"),", ")"]}, {"cell_type": "code", "execution_count": null, "id": "0f3c2643", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "Settings.llm = llm\n", "Settings.embed_model = embed_model"]}, {"cell_type": "markdown", "id": "eecf4bd5", "metadata": {}, "source": ["# 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "6df9fa89", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396", "metadata": {}, "source": ["### 加载文档\n", "使用SimpleDirectoryReader加载存储在`data/paul_graham/`中的文档。\n"]}, {"cell_type": "code", "execution_count": null, "id": "c154dd4b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Document ID: c432ff1c-61ea-4c91-bd89-62be29078e79\n"]}], "source": ["documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n", "\n", "print(\"Document ID:\", documents[0].doc_id)"]}, {"cell_type": "markdown", "id": "c0232fd1", "metadata": {}, "source": ["### 创建索引\n", "在这里，我们建立与 Azure Cosmosdb mongodb vCore 集群的连接，并创建一个向量搜索索引。\n"]}, {"cell_type": "code", "execution_count": null, "id": "8731da62", "metadata": {}, "outputs": [], "source": ["import pymongo\n", "from llama_index.vector_stores.azurecosmosmongo import (\n", "    AzureCosmosDBMongoDBVectorSearch,\n", ")\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.core import StorageContext\n", "from llama_index.core import SimpleDirectoryReader\n", "\n", "connection_string = os.environ.get(\"AZURE_COSMOSDB_MONGODB_URI\")\n", "mongodb_client = pymongo.MongoClient(connection_string)\n", "store = AzureCosmosDBMongoDBVectorSearch(\n", "    mongodb_client=mongodb_client,\n", "    db_name=\"demo_vectordb\",\n", "    collection_name=\"paul_graham_essay\",\n", ")\n", "storage_context = StorageContext.from_defaults(vector_store=store)\n", "index = VectorStoreIndex.from_documents(\n", "    documents, storage_context=storage_context\n", ")"]}, {"cell_type": "markdown", "id": "8ee4473a-094f-4d0a-a825-e1213db07240", "metadata": {}, "source": ["### 查询索引\n", "现在我们可以使用我们的索引来提出问题。\n"]}, {"cell_type": "code", "execution_count": null, "id": "0a2bcc07", "metadata": {}, "outputs": [], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"What did the author love working on?\")"]}, {"cell_type": "code", "execution_count": null, "id": "8cf55bf7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author loved working on multiple projects that were not their thesis while in grad school,\n", "including Lisp hacking and writing On Lisp. They eventually wrote a dissertation on applications of\n", "continuations in just 5 weeks to graduate. Afterward, they applied to art schools and were accepted\n", "into the BFA program at RISD.\n"]}], "source": ["import textwrap\n", "\n", "print(textwrap.fill(str(response), 100))"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\"What did he/she do in summer of 2016?\")"]}, {"cell_type": "code", "execution_count": null, "id": "fdf5287f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The person moved to England with their family in the summer of 2016.\n"]}], "source": ["print(textwrap.fill(str(response), 100))"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}