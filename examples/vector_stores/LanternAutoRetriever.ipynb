{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "4e4f9a0f", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/BagelAutoRetriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "307804a3-c02b-4a57-ac0d-172c30ddc851", "metadata": {}, "source": ["# 灯笼向量存储（自动检索器）\n", "\n", "本指南展示了如何在LlamaIndex中执行**自动检索**。\n", "\n", "许多流行的向量数据库除了语义搜索的查询字符串外，还支持一组元数据过滤器。给定一个自然语言查询，我们首先使用LLM推断一组元数据过滤器以及传递给向量数据库的正确查询字符串（也可以为空）。然后对整个查询包进行针对向量数据库的执行。\n", "\n", "这允许进行比top-k语义搜索更动态、更有表现力的检索形式。对于给定查询的相关上下文，可能只需要在元数据标签上进行过滤，或者需要在过滤集合内进行过滤+语义搜索的联合组合，或者只需要进行原始的语义搜索。\n", "\n", "我们以灯笼为例进行演示，但自动检索也已在许多其他向量数据库中实现（例如Pinecone、Chroma、Weaviate等）。\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "15119a5b", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "841c6bb2", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-lantern"]}, {"cell_type": "code", "execution_count": null, "id": "feb74914", "metadata": {}, "outputs": [], "source": ["!pip install llama-index psycopg2-binary asyncpg"]}, {"cell_type": "code", "execution_count": null, "id": "d48af8e1", "metadata": {}, "outputs": [], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"cell_type": "code", "execution_count": null, "id": "bf49ac18", "metadata": {}, "outputs": [], "source": ["# 设置OpenAI", "import os", "", "os.environ[\"OPENAI_API_KEY\"] = \"<your-api-key>\"", "", "import openai", "", "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"]}, {"cell_type": "code", "execution_count": null, "id": "0ce3143d-198c-4dd2-8e5a-c5cdf94f017a", "metadata": {}, "outputs": [], "source": ["import psycopg2\n", "from sqlalchemy import make_url\n", "\n", "connection_string = \"postgresql://postgres:postgres@localhost:5432\"\n", "\n", "url = make_url(connection_string)\n", "\n", "db_name = \"postgres\"\n", "conn = psycopg2.connect(connection_string)\n", "conn.autocommit = True"]}, {"cell_type": "code", "execution_count": null, "id": "0a2bcc07", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, StorageContext\n", "from llama_index.vector_stores.lantern import LanternVectorStore"]}, {"cell_type": "code", "execution_count": null, "id": "68cbd239-880e-41a3-98d8-dbb3fab55431", "metadata": {}, "outputs": [], "source": ["from llama_index.core.schema import TextNode\n", "\n", "nodes = [\n", "    TextNode(\n", "        text=(\n", "            \"Michael Jordan is a retired professional basketball player,\"\n", "            \" widely regarded as one of the greatest basketball players of all\"\n", "            \" time.\"\n", "        ),\n", "        metadata={\n", "            \"category\": \"Sports\",\n", "            \"country\": \"United States\",\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=(\n", "            \"Angelina Jolie is an American actress, filmmaker, and\"\n", "            \" humanitarian. She has received numerous awards for her acting\"\n", "            \" and is known for her philanthropic work.\"\n", "        ),\n", "        metadata={\n", "            \"category\": \"Entertainment\",\n", "            \"country\": \"United States\",\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=(\n", "            \"Elon Musk is a business magnate, industrial designer, and\"\n", "            \" engineer. He is the founder, CEO, and lead designer of SpaceX,\"\n", "            \" Tesla, Inc., Neuralink, and The Boring Company.\"\n", "        ),\n", "        metadata={\n", "            \"category\": \"Business\",\n", "            \"country\": \"United States\",\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=(\n", "            \"Rihanna is a Barbadian singer, actress, and businesswoman. She\"\n", "            \" has achieved significant success in the music industry and is\"\n", "            \" known for her versatile musical style.\"\n", "        ),\n", "        metadata={\n", "            \"category\": \"Music\",\n", "            \"country\": \"Barbados\",\n", "        },\n", "    ),\n", "    TextNode(\n", "        text=(\n", "            \"Cristiano Ronaldo is a Portuguese professional footballer who is\"\n", "            \" considered one of the greatest football players of all time. He\"\n", "            \" has won numerous awards and set multiple records during his\"\n", "            \" career.\"\n", "        ),\n", "        metadata={\n", "            \"category\": \"Sports\",\n", "            \"country\": \"Portugal\",\n", "        },\n", "    ),\n", "]"]}, {"cell_type": "markdown", "id": "f6021786", "metadata": {}, "source": ["## 使用 Lantern Vector Store 构建向量索引\n", "\n", "在这里，我们将数据加载到向量存储中。如上所述，每个节点的文本和元数据都将转换为 Lantern 中相应的表示。现在我们可以从 Lantern 对这些数据运行语义查询，也可以进行元数据过滤。\n"]}, {"cell_type": "code", "execution_count": null, "id": "ba1558b3", "metadata": {}, "outputs": [], "source": ["vector_store = LanternVectorStore.from_params(", "    database=db_name,", "    host=url.host,", "    password=url.password,", "    port=url.port,", "    user=url.username,", "    table_name=\"famous_people\",", "    embed_dim=1536,  # openai embedding dimension", "    m=16,  # HNSW M parameter", "    ef_construction=128,  # HNSW ef construction parameter", "    ef=64,  # HNSW ef search parameter", ")", "", "storage_context = StorageContext.from_defaults(vector_store=vector_store)"]}, {"cell_type": "code", "execution_count": null, "id": "35369eda", "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "markdown", "id": "7eb20e49", "metadata": {}, "source": ["## 定义 `VectorIndexAutoRetriever`\n", "\n", "我们定义了核心的 `VectorIndexAutoRetriever` 模块。该模块接收 `VectorStoreInfo`，其中包含向量存储集合的结构化描述以及其支持的元数据过滤器。然后这些信息将被用于自动检索提示，LLM 将推断元数据过滤器。\n"]}, {"cell_type": "code", "execution_count": null, "id": "bedbb693-725f-478f-be26-fa7180ea38b2", "metadata": {}, "outputs": [], "source": ["from llama_index.core.retrievers import VectorIndexAutoRetriever\n", "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n", "\n", "\n", "vector_store_info = VectorStoreInfo(\n", "    content_info=\"brief biography of celebrities\",\n", "    metadata_info=[\n", "        MetadataInfo(\n", "            name=\"category\",\n", "            type=\"str\",\n", "            description=(\n", "                \"Category of the celebrity, one of [Sports, Entertainment,\"\n", "                \" Business, Music]\"\n", "            ),\n", "        ),\n", "        MetadataInfo(\n", "            name=\"country\",\n", "            type=\"str\",\n", "            description=(\n", "                \"Country of the celebrity, one of [United States, Barbados,\"\n", "                \" Portugal]\"\n", "            ),\n", "        ),\n", "    ],\n", ")\n", "retriever = VectorIndexAutoRetriever(\n", "    index, vector_store_info=vector_store_info\n", ")"]}, {"cell_type": "markdown", "id": "31ac4a3b", "metadata": {}, "source": ["## 运行一些示例数据\n", "\n", "我们尝试运行一些示例数据。请注意元数据过滤器是如何被推断出来的 - 这有助于更精确地检索！\n"]}, {"cell_type": "code", "execution_count": null, "id": "eeb18e9c", "metadata": {}, "outputs": [], "source": ["retriever.retrieve(\"Tell me about two celebrities from United States\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "vscode": {"interpreter": {"hash": "0ac390d292208ca2380c85f5bce7ded36a7a25670a97c40b8009630eb36cb06e"}}}, "nbformat": 4, "nbformat_minor": 5}