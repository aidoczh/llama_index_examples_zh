{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/EpsillaIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# Epsillaå‘é‡å­˜å‚¨\n", "åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨[Epsilla](https://www.epsilla.com/)åœ¨LlamaIndexä¸­æ‰§è¡Œå‘é‡æœç´¢ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["ä½œä¸ºå…ˆå†³æ¡ä»¶ï¼Œæ‚¨éœ€è¦è¿è¡Œ Epsilla å‘é‡æ•°æ®åº“ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡æˆ‘ä»¬çš„ Docker é•œåƒï¼‰ï¼Œå¹¶å®‰è£… ``pyepsilla`` åŒ…ã€‚\n", "å¯åœ¨ [æ–‡æ¡£](https://epsilla-inc.gitbook.io/epsilladb/quick-start) ä¸­æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-vector-stores-epsilla"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip/pip3 install pyepsilla"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging", "import sys", "", "# å–æ¶ˆæ³¨é‡Šä»¥æŸ¥çœ‹è°ƒè¯•æ—¥å¿—", "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)", "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))", "", "from llama_index.core import SimpleDirectoryReader, Document, StorageContext", "from llama_index.core import VectorStoreIndex", "from llama_index.vector_stores.epsilla import EpsillaVectorStore", "import textwrap"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### è®¾ç½®OpenAI\n", "é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ·»åŠ OpenAI APIå¯†é’¥ã€‚å®ƒå°†ç”¨äºä¸ºåŠ è½½åˆ°ç´¢å¼•ä¸­çš„æ–‡æ¡£åˆ›å»ºåµŒå…¥ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import openai\n", "import getpass\n", "\n", "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n", "openai.api_key = OPENAI_API_KEY"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["```python\n", "# ä¸‹è½½æ•°æ®\n", "```\n", "\n", "åœ¨è¿™ä¸ªéƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä¸‹è½½æ‰€éœ€çš„æ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### åŠ è½½æ–‡æ¡£\n", "ä½¿ç”¨SimpleDirectoryReaderåŠ è½½å­˜å‚¨åœ¨`/data/paul_graham`æ–‡ä»¶å¤¹ä¸­çš„æ–‡æ¡£ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Total documents: 1\n", "First document, id: ac7f23f0-ce15-4d94-a0a2-5020fa87df61\n", "First document, hash: 4c702b4df575421e1d1af4b1fd50511b226e0c9863dbfffeccb8b689b8448f35\n"]}], "source": ["# åŠ è½½æ–‡æ¡£", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()", "print(f\"æ€»æ–‡æ¡£æ•°ï¼š{len(documents)}\")", "print(f\"ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼Œidï¼š{documents[0].doc_id}\")", "print(f\"ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼Œå“ˆå¸Œå€¼ï¼š{documents[0].hash}\")"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### åˆ›å»ºç´¢å¼•\n", "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¹‹å‰åŠ è½½çš„æ–‡æ¡£åˆ›å»ºä¸€ä¸ªç”±Epsillaæ”¯æŒçš„ç´¢å¼•ã€‚EpsillaVectorStoreæ¥å—ä¸€äº›å‚æ•°ã€‚\n", "- client (Any): ç”¨äºè¿æ¥çš„Epsillaå®¢æˆ·ç«¯ã€‚\n", "\n", "- collection_name (str, optional): è¦ä½¿ç”¨çš„é›†åˆã€‚é»˜è®¤ä¸º\"llama_collection\"ã€‚\n", "- db_path (str, optional): æ•°æ®åº“å°†è¢«æŒä¹…åŒ–çš„è·¯å¾„ã€‚é»˜è®¤ä¸º\"/tmp/langchain-epsilla\"ã€‚\n", "- db_name (str, optional): ç»™åŠ è½½çš„æ•°æ®åº“ä¸€ä¸ªåç§°ã€‚é»˜è®¤ä¸º\"langchain_store\"ã€‚\n", "- dimension (int, optional): åµŒå…¥çš„ç»´åº¦ã€‚å¦‚æœæœªæä¾›ï¼Œå°†åœ¨ç¬¬ä¸€æ¬¡æ’å…¥æ—¶åˆ›å»ºé›†åˆã€‚é»˜è®¤ä¸ºNoneã€‚\n", "- overwrite (bool, optional): æ˜¯å¦è¦†ç›–åŒåçš„ç°æœ‰é›†åˆã€‚é»˜è®¤ä¸ºFalseã€‚\n", "\n", "Epsilla vectordbæ­£åœ¨ä½¿ç”¨é»˜è®¤ä¸»æœº\"localhost\"å’Œç«¯å£\"8888\"è¿è¡Œã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[INFO] Connected to localhost:8888 successfully.\n"]}], "source": ["# åœ¨æ–‡æ¡£ä¸Šåˆ›å»ºç´¢å¼•", "from pyepsilla import vectordb", "", "client = vectordb.Client()", "vector_store = EpsillaVectorStore(client=client, db_path=\"/tmp/llamastore\")", "", "storage_context = StorageContext.from_defaults(vector_store=vector_store)", "index = VectorStoreIndex.from_documents(", "    documents, storage_context=storage_context", ")"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### æŸ¥è¯¢æ•°æ®\n", "ç°åœ¨æˆ‘ä»¬å·²ç»å°†æ–‡æ¡£å­˜å‚¨åœ¨ç´¢å¼•ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é’ˆå¯¹ç´¢å¼•æå‡ºé—®é¢˜ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author of the given context information is Paul Graham.\n"]}], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"Who is the author?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author learned about AI through various sources. One source was a novel called \"The Moon is a\n", "Harsh Mistress\" by Heinlein, which featured an intelligent computer called Mike. Another source was\n", "a PBS documentary that showed Terry Winograd using SHRDLU, a program that could understand natural\n", "language. These experiences sparked the author's interest in AI and motivated them to start learning\n", "about it, including teaching themselves Lisp, which was regarded as the language of AI at the time.\n"]}], "source": ["response = query_engine.query(\"How did the author learn about AI?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å°è¯•è¦†ç›–ä¹‹å‰çš„æ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["There is no information provided about the author in the given context.\n"]}], "source": ["vector_store = EpsillaVectorStore(client=client, overwrite=True)\n", "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n", "single_doc = Document(text=\"Epsilla is the vector database we are using.\")\n", "index = VectorStoreIndex.from_documents(\n", "    [single_doc],\n", "    storage_context=storage_context,\n", ")\n", "\n", "query_engine = index.as_query_engine()\n", "response = query_engine.query(\"Who is the author?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Epsilla is the vector database being used.\n"]}], "source": ["response = query_engine.query(\"What vector database is being used?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å‘ç°æœ‰é›†åˆæ·»åŠ æ›´å¤šæ•°æ®ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author of the given context information is Paul Graham.\n"]}], "source": ["vector_store = EpsillaVectorStore(client=client, overwrite=False)\n", "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n", "for doc in documents:\n", "    index.insert(document=doc)\n", "\n", "query_engine = index.as_query_engine()\n", "response = query_engine.query(\"Who is the author?\")\n", "print(textwrap.fill(str(response), 100))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Epsilla is the vector database being used.\n"]}], "source": ["response = query_engine.query(\"What vector database is being used?\")\n", "print(textwrap.fill(str(response), 100))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}