{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/callbacks/UpTrainCallback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# UpTrain回调处理程序\n", "\n", "UpTrain ([github](https://github.com/uptrain-ai/uptrain) || [website](https://github.com/uptrain-ai/uptrain/) || [docs](https://docs.uptrain.ai/)) 是一个开源平台，用于评估和改进GenAI应用程序。它为20多个预配置的检查提供评分（涵盖语言、代码、嵌入使用案例），对失败案例进行根本原因分析，并提供如何解决这些问题的见解。\n", "\n", "本笔记本展示了如何使用UpTrain回调处理程序来评估RAG管道的不同组件。\n", "\n", "## 1. **RAG查询引擎评估**：\n", "RAG查询引擎在检索上下文和生成响应方面起着至关重要的作用。为了确保其性能和响应质量，我们进行以下评估：\n", "\n", "- **[上下文相关性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-relevance)**：确定检索到的上下文是否具有足够的信息来回答用户的查询。\n", "- **[事实准确性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/factual-accuracy)**：评估LLM的响应是否可以通过检索到的上下文进行验证。\n", "- **[响应完整性](https://docs.uptrain.ai/predefined-evaluations/response-quality/response-completeness)**：检查响应是否包含回答用户查询所需的所有信息。\n", "\n", "## 2. **子问题查询生成评估**：\n", "SubQuestionQueryGeneration操作符将问题分解为子问题，并使用RAG查询引擎为每个子问题生成响应。为了衡量其准确性，我们使用：\n", "\n", "- **[子查询完整性](https://docs.uptrain.ai/predefined-evaluations/query-quality/sub-query-completeness)**：确保子问题准确全面地涵盖原始查询。\n", "\n", "## 3. **重新排序评估**：\n", "重新排序涉及根据与查询相关性重新排序节点并选择顶部节点。根据重新排序后返回的节点数量执行不同的评估。\n", "\n", "a. 相同数量的节点\n", "- **[上下文重新排序](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-reranking)**：检查重新排序后的节点顺序是否比原始顺序更相关于查询。\n", "\n", "b. 不同数量的节点：\n", "- **[上下文简洁性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-conciseness)**：检查减少的节点数量是否仍然提供所有所需的信息。\n", "\n", "这些评估共同确保了RAG查询引擎、SubQuestionQueryGeneration操作符和LlamaIndex管道中的重新排序过程的健壮性和有效性。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### **注意：**\n", "- 我们已经使用基本的RAG查询引擎进行了评估，同样的评估也可以使用高级RAG查询引擎进行。\n", "- 对于重新排序的评估也是如此，我们已经使用了SentenceTransformerRerank进行了评估，同样的评估也可以使用其他重新排序器进行。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 安装依赖项并导入库\n", "\n", "安装笔记本的依赖项。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-readers-web\n", "%pip install llama-index-callbacks-uptrain\n", "%pip install -q html2text llama-index pandas tqdm uptrain torch sentence-transformers"]}, {"cell_type": "markdown", "metadata": {}, "source": ["导入库。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from getpass import getpass\n", "\n", "from llama_index.core import Settings, VectorStoreIndex\n", "from llama_index.core.node_parser import SentenceSplitter\n", "from llama_index.readers.web import SimpleWebPageReader\n", "from llama_index.core.callbacks import CallbackManager\n", "from llama_index.callbacks.uptrain.base import UpTrainCallbackHandler\n", "from llama_index.core.query_engine import SubQuestionQueryEngine\n", "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n", "from llama_index.core.postprocessor import SentenceTransformerRerank\n", "\n", "import os"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "UpTrain为您提供：\n", "1. 具有高级钻取和过滤选项的仪表板\n", "1. 失败案例中的见解和常见主题\n", "1. 对生产数据的可观察性和实时监控\n", "1. 通过与CI/CD流水线的无缝集成进行回归测试\n", "\n", "您可以选择以下选项来使用UpTrain进行评估：\n", "### 1. **UpTrain的开源软件（OSS）**：\n", "您可以使用开源评估服务来评估您的模型。在这种情况下，您需要提供OpenAI API密钥。您可以在[这里](https://platform.openai.com/account/api-keys)获取您自己的密钥。\n", "\n", "为了在UpTrain仪表板中查看您的评估结果，您需要通过在终端中运行以下命令来设置它：\n", "\n", "```bash\n", "git clone https://github.com/uptrain-ai/uptrain\n", "cd uptrain\n", "bash run_uptrain.sh\n", "```\n", "\n", "这将在您的本地机器上启动UpTrain仪表板。您可以在`http://localhost:3000/dashboard`上访问它。\n", "\n", "参数：\n", "- key_type=\"openai\"\n", "- api_key=\"OPENAI_API_KEY\"\n", "- project_name=\"PROJECT_NAME\"\n", "\n", "\n", "### 2. **UpTrain托管服务和仪表板**：\n", "或者，您可以使用UpTrain的托管服务来评估您的模型。您可以在[这里](https://uptrain.ai/)创建免费的UpTrain账户并获得免费试用积分。如果您想要更多的试用积分，可以在[这里](https://calendly.com/uptrain-sourabh/30min)与UpTrain的维护人员预约电话。\n", "\n", "使用托管服务的好处包括：\n", "1. 无需在本地机器上设置UpTrain仪表板。\n", "1. 可以访问许多LLM而无需它们的API密钥。\n", "\n", "一旦您执行评估，您可以在UpTrain仪表板上查看它们，网址为`https://dashboard.uptrain.ai/dashboard`\n", "\n", "参数：\n", "- key_type=\"uptrain\"\n", "- api_key=\"UPTRAIN_API_KEY\"\n", "- project_name=\"PROJECT_NAME\"\n", "\n", "\n", "**注意：** `project_name`将是在UpTrain仪表板中显示执行的评估的项目名称。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 创建UpTrain回调处理程序\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"OPENAI_API_KEY\"] = getpass()\n", "\n", "callback_handler = UpTrainCallbackHandler(\n", "    key_type=\"openai\",\n", "    api_key=os.environ[\"OPENAI_API_KEY\"],\n", "    project_name=\"uptrain_llamaindex\",\n", ")\n", "\n", "Settings.callback_manager = CallbackManager([callback_handler])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 加载和解析文档\n", "\n", "从Paul Graham的文章\"What I Worked On\"中加载文档。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["documents = SimpleWebPageReader().load_data(\n", "    [\n", "        \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\"\n", "    ]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["解析文档为节点。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["parser = SentenceSplitter()\n", "nodes = parser.get_nodes_from_documents(documents)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 1. RAG 查询引擎评估\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["UpTrain回调处理程序将自动捕获查询、上下文和生成的响应，并将在响应上运行以下三个评估（从0到1分）：\n", "- **[上下文相关性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-relevance)**：确定检索到的上下文是否具有足够的信息来回答用户的查询。\n", "- **[事实准确性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/factual-accuracy)**：评估LLM的响应是否可以通过检索到的上下文进行验证。\n", "- **[响应完整性](https://docs.uptrain.ai/predefined-evaluations/response-quality/response-completeness)**：检查响应是否包含回答用户查询所需的所有信息。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n", "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What did Paul Graham do growing up?\n", "Response: Growing up, Paul Graham worked on writing short stories and programming. He started programming on an IBM 1401 in 9th grade using an early version of Fortran. Later, he got a TRS-80 computer and wrote simple games, a rocket prediction program, and a word processor. Despite his interest in programming, he initially planned to study philosophy in college before eventually switching to AI.\n", "\n", "Context Relevance Score: 0.0\n", "Factual Accuracy Score: 1.0\n", "Response Completeness Score: 1.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n", "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n", "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: When and how did Paul Graham's mother die?\n", "Response: Paul Graham's mother died when he was 18 years old, from a brain tumor.\n", "\n", "Context Relevance Score: 0.0\n", "Factual Accuracy Score: 0.0\n", "Response Completeness Score: 0.5\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n", "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What, in Paul Graham's opinion, is the most distinctive thing about YC?\n", "Response: The most distinctive thing about Y Combinator, according to Paul Graham, is that instead of deciding for himself what to work on, the problems come to him. Every 6 months, a new batch of startups brings their problems, which then become the focus of YC. This engagement with a variety of startup problems and the direct involvement in solving them is what Graham finds most unique about Y Combinator.\n", "\n", "Context Relevance Score: 1.0\n", "Factual Accuracy Score: 0.3333333333333333\n", "Response Completeness Score: 1.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n", "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n", "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: When and how did Paul Graham meet Jessica Livingston?\n", "Response: Paul Graham met Jessica Livingston at a big party at his house in October 2003.\n", "\n", "Context Relevance Score: 1.0\n", "Factual Accuracy Score: 0.5\n", "Response Completeness Score: 1.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n", "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What is Bel, and when and where was it written?\n", "Response: Bel is a new Lisp that was written in Arc. It was developed over a period of 4 years, from March 26, 2015 to October 12, 2019. The majority of Bel was written in England.\n", "\n", "Context Relevance Score: 1.0\n", "Factual Accuracy Score: 1.0\n", "Response Completeness Score: 1.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["index = VectorStoreIndex.from_documents(\n", "    documents,\n", ")\n", "query_engine = index.as_query_engine()\n", "\n", "max_characters_per_line = 80\n", "queries = [\n", "    \"What did Paul Graham do growing up?\",\n", "    \"When and how did Paul Graham's mother die?\",\n", "    \"What, in Paul Graham's opinion, is the most distinctive thing about YC?\",\n", "    \"When and how did Paul Graham meet Jessica Livingston?\",\n", "    \"What is Bel, and when and where was it written?\",\n", "]\n", "for query in queries:\n", "    response = query_engine.query(query)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 2. 子问题查询引擎评估\n", "\n", "**子问题查询引擎**用于解决使用多个数据源回答复杂查询的问题。它首先将复杂查询分解为每个相关数据源的子问题，然后收集所有中间响应并合成最终响应。\n", "\n", "一旦生成，UpTrain回调处理程序将自动捕获子问题和它们的响应，并对响应运行以下三个评估（从0到1分）：\n", "- **[上下文相关性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-relevance)**：确定检索到的上下文是否具有足够的信息来回答用户查询。\n", "- **[事实准确性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/factual-accuracy)**：评估LLM的响应是否可以通过检索到的上下文进行验证。\n", "- **[响应完整性](https://docs.uptrain.ai/predefined-evaluations/response-quality/response-completeness)**：检查响应是否包含回答用户查询所需的所有信息。\n", "\n", "除了上述评估之外，回调处理程序还将运行以下评估：\n", "- **[子查询完整性](https://docs.uptrain.ai/predefined-evaluations/query-quality/sub-query-completeness)**：确保子问题准确全面地涵盖了原始查询。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Generated 3 sub questions.\n", "\u001b[1;3;38;2;237;90;200m[documents] Q: What did Paul Graham work on before YC?\n", "\u001b[0m\u001b[1;3;38;2;90;149;237m[documents] Q: What did Paul Graham work on during YC?\n", "\u001b[0m\u001b[1;3;38;2;11;159;203m[documents] Q: What did Paul Graham work on after YC?\n", "\u001b[0m\u001b[1;3;38;2;11;159;203m[documents] A: After Y Combinator, Paul Graham decided to focus on painting as his next endeavor.\n", "\u001b[0m\u001b[1;3;38;2;90;149;237m[documents] A: Paul Graham worked on writing essays and working on Y Combinator during YC.\n", "\u001b[0m\u001b[1;3;38;2;237;90;200m[documents] A: Before Y Combinator, Paul Graham worked on projects with his colleagues Robert and Trevor.\n", "\u001b[0m"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n", "100%|██████████| 3/3 [00:00<00:00,  3.28it/s]\n", "100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\n", "100%|██████████| 3/3 [00:01<00:00,  2.28it/s]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What did Paul Graham work on after YC?\n", "Response: After Y Combinator, Paul Graham decided to focus on painting as his next endeavor.\n", "\n", "Context Relevance Score: 0.0\n", "Factual Accuracy Score: 0.0\n", "Response Completeness Score: 0.5\n", "\n", "\n", "Question: What did Paul Graham work on during YC?\n", "Response: Paul Graham worked on writing essays and working on Y Combinator during YC.\n", "\n", "Context Relevance Score: 0.0\n", "Factual Accuracy Score: 1.0\n", "Response Completeness Score: 0.5\n", "\n", "\n", "Question: What did Paul Graham work on before YC?\n", "Response: Before Y Combinator, Paul Graham worked on projects with his colleagues Robert and Trevor.\n", "\n", "Context Relevance Score: 0.0\n", "Factual Accuracy Score: 0.0\n", "Response Completeness Score: 0.5\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.24s/it]"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: How was Paul Grahams life different before, during, and after YC?\n", "Sub Query Completeness Score: 1.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["# 构建索引和查询引擎", "vector_query_engine = VectorStoreIndex.from_documents(", "    documents=documents,", "    use_async=True,", ").as_query_engine()", "", "query_engine_tools = [", "    QueryEngineTool(", "        query_engine=vector_query_engine,", "        metadata=ToolMetadata(", "            name=\"documents\",", "            description=\"Paul Graham关于我所从事的工作的文章\",", "        ),", "    ),", "]", "", "query_engine = SubQuestionQueryEngine.from_defaults(", "    query_engine_tools=query_engine_tools,", "    use_async=True,", ")", "", "response = query_engine.query(", "    \"Paul Graham在YC之前、期间和之后的生活有何不同？\"", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 3. 重新排序\n", "\n", "重新排序是根据查询与节点的相关性对节点进行重新排序的过程。Llamaindex提供了多种重新排序算法。在本示例中，我们使用了LLMRerank。\n", "\n", "重新排序器允许您输入返回重新排序后的前n个节点的数量。如果这个值与原始节点数量保持不变，重新排序器将只重新排序节点而不改变节点数量。否则，它将重新排序节点并返回前n个节点。\n", "\n", "我们将根据重新排序后返回的节点数量进行不同的评估。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3a. 重新排序（节点数相同）\n", "\n", "如果重新排序后返回的节点数与原始节点数相同，则将执行以下评估：\n", "\n", "- **[上下文重新排序](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-reranking)**：检查重新排序后节点的顺序是否比原始顺序更相关于查询。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What did Sam Altman do in this essay?\n", "Context Reranking Score: 1.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n", "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What did Sam Altman do in this essay?\n", "Response: Sam Altman was asked to become the president of Y Combinator after the original founders decided to step down and reorganize the company for long-term sustainability.\n", "\n", "Context Relevance Score: 1.0\n", "Factual Accuracy Score: 1.0\n", "Response Completeness Score: 0.5\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["callback_handler = UpTrainCallbackHandler(", "    key_type=\"openai\",", "    api_key=os.environ[\"OPENAI_API_KEY\"],", "    project_name=\"uptrain_llamaindex\",", ")", "Settings.callback_manager = CallbackManager([callback_handler])", "", "rerank_postprocessor = SentenceTransformerRerank(", "    top_n=3,  # 重新排序后的节点数", "    keep_retrieval_score=True,", ")", "", "index = VectorStoreIndex.from_documents(", "    documents=documents,", ")", "", "query_engine = index.as_query_engine(", "    similarity_top_k=3,  # 重新排序前的节点数", "    node_postprocessors=[rerank_postprocessor],", ")", "", "response = query_engine.query(", "    \"Sam Altman在这篇文章中做了什么？\",", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 3b. 重新排名（使用不同数量的节点）\n", "\n", "如果重新排名后返回的节点数量少于原始节点数量，则将执行以下评估：\n", "\n", "- **[上下文简洁性](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-conciseness)**：检查减少的节点数量是否仍然提供所有所需的信息。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What did Sam Altman do in this essay?\n", "Context Conciseness Score: 0.0\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n", "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n", "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n", "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "Question: What did Sam Altman do in this essay?\n", "Response: Sam Altman offered unsolicited advice to the author during a visit to California for interviews.\n", "\n", "Context Relevance Score: 0.0\n", "Factual Accuracy Score: 1.0\n", "Response Completeness Score: 0.5\n", "\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["callback_handler = UpTrainCallbackHandler(", "    key_type=\"openai\",", "    api_key=os.environ[\"OPENAI_API_KEY\"],", "    project_name=\"uptrain_llamaindex\",", ")", "Settings.callback_manager = CallbackManager([callback_handler])", "", "rerank_postprocessor = SentenceTransformerRerank(", "    top_n=2,  # 重新排序后的节点数", "    keep_retrieval_score=True,", ")", "", "index = VectorStoreIndex.from_documents(", "    documents=documents,", ")", "query_engine = index.as_query_engine(", "    similarity_top_k=5,  # 重新排序前的节点数", "    node_postprocessors=[rerank_postprocessor],", ")", "", "# 使用您的高级RAG", "response = query_engine.query(", "    \"Sam Altman在这篇文章中做了什么？\",", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# UpTrain的仪表板和洞察\n", "\n", "这里有一个简短的视频展示了仪表板和洞察： \n", "\n", "![llamaindex_uptrain.gif](https://uptrain-assets.s3.ap-south-1.amazonaws.com/images/llamaindex/llamaindex_uptrain.gif)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}