{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "13d2b729", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/callbacks/HoneyHiveLlamaIndexTracer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "c0d8b66c", "metadata": {}, "source": ["# HoneyHive LlamaIndex Tracer\n", "\n", "[HoneyHive](https://honeyhive.ai) 是一个平台，帮助开发人员监控、评估和持续改进其基于LLM的应用程序。\n", "\n", "`HoneyHiveLlamaIndexTracer` 与HoneyHive集成，帮助开发人员调试和分析LLM管道的执行流程，或让开发人员定制特定跟踪事件的反馈，从而在生产环境中创建评估或微调数据集。\n"]}, {"cell_type": "code", "execution_count": null, "id": "e5e47da1", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "612f35ad", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Paste your OpenAI key from: https://platform.openai.com/account/api-keys\n", " ········\n"]}, {"name": "stdout", "output_type": "stream", "text": ["OpenAI API key configured\n"]}], "source": ["import os\n", "from getpass import getpass\n", "\n", "if os.getenv(\"OPENAI_API_KEY\") is None:\n", "    os.environ[\"OPENAI_API_KEY\"] = getpass(\n", "        \"Paste your OpenAI key from:\"\n", "        \" https://platform.openai.com/account/api-keys\\n\"\n", "    )\n", "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\n", "    \"sk-\"\n", "), \"This doesn't look like a valid OpenAI API key\"\n", "print(\"OpenAI API key configured\")"]}, {"cell_type": "code", "execution_count": null, "id": "b565e3ef-61cb-4196-81b3-71b4d724434c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Paste your HoneyHive key from: https://app.honeyhive.ai/settings/account\n", " ········\n"]}, {"name": "stdout", "output_type": "stream", "text": ["HoneyHive API key configured\n"]}], "source": ["import os\n", "from getpass import getpass\n", "\n", "if os.getenv(\"HONEYHIVE_API_KEY\") is None:\n", "    os.environ[\"HONEYHIVE_API_KEY\"] = getpass(\n", "        \"Paste your HoneyHive key from:\"\n", "        \" https://app.honeyhive.ai/settings/account\\n\"\n", "    )\n", "print(\"HoneyHive API key configured\")"]}, {"attachments": {}, "cell_type": "markdown", "id": "fdd01a48", "metadata": {}, "source": ["如果您在Colab上打开此笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "5c5cb91e", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "78a29d9a", "metadata": {}, "outputs": [], "source": ["from llama_index.core.callbacks import CallbackManager\n", "from llama_index.core.callbacks import LlamaDebugHandler\n", "from llama_index.core import (\n", "    VectorStoreIndex,\n", "    SimpleDirectoryReader,\n", "    SimpleKeywordTableIndex,\n", "    StorageContext,\n", ")\n", "from llama_index.core import ComposableGraph\n", "from llama_index.llms.openai import OpenAI\n", "from honeyhive.utils.llamaindex_tracer import HoneyHiveLlamaIndexTracer"]}, {"cell_type": "markdown", "id": "e6feb252", "metadata": {}, "source": ["## 设置LLM\n", "\n", "在这个notebook中，我们将使用Hugging Face的transformers库来微调一个语言模型。我们将使用GPT-2模型来演示，但你也可以使用其他预训练的语言模型来进行微调。 \n", "\n", "首先，我们需要安装transformers库。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d22fee33", "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "Settings.llm = OpenAI(model=\"gpt-4\", temperature=0)"]}, {"cell_type": "markdown", "id": "d7cff711-8704-4db9-ba81-8160b7bd1447", "metadata": {}, "source": ["## HoneyHive 回调管理器设置\n"]}, {"cell_type": "markdown", "id": "8a32b984-772e-4832-945e-cb6fc7be9e0b", "metadata": {}, "source": ["**选项 1**：设置全局评估处理程序\n"]}, {"cell_type": "code", "execution_count": null, "id": "2a3b9d22-cd67-4fb5-9785-254e58179a02", "metadata": {}, "outputs": [], "source": ["import llama_index.core\n", "from llama_index.core import set_global_handler\n", "\n", "set_global_handler(\n", "    \"honeyhive\",\n", "    project=\"My LlamaIndex Project\",\n", "    name=\"My LlamaIndex Pipeline\",\n", "    api_key=os.environ[\"HONEYHIVE_API_KEY\"],\n", ")\n", "hh_tracer = llama_index.core.global_handler"]}, {"cell_type": "markdown", "id": "d1755516-f8ad-458e-b52f-f7665c023e43", "metadata": {}, "source": ["**选项2**：手动配置回调处理程序\n", "\n", "还可以为额外的笔记本可见性配置调试处理程序。\n"]}, {"cell_type": "code", "execution_count": null, "id": "defa9155-daca-4a8f-8ca6-87d1ee98f084", "metadata": {}, "outputs": [], "source": ["llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n", "\n", "hh_tracer = HoneyHiveLlamaIndexTracer(\n", "    project=\"My LlamaIndex Project\",\n", "    name=\"My LlamaIndex Pipeline\",\n", "    api_key=os.environ[\"HONEYHIVE_API_KEY\"],\n", ")\n", "\n", "callback_manager = CallbackManager([llama_debug, hh_tracer])\n", "\n", "Settings.callback_manager = callback_manager"]}, {"cell_type": "markdown", "id": "a4a7c101", "metadata": {}, "source": ["## 1. 索引操作\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "81633478", "metadata": {}, "source": ["下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "4d0aa69f", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "id": "d1011596", "metadata": {}, "outputs": [], "source": ["docs = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "d3d6975c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["**********\n", "Trace: index_construction\n", "    |_node_parsing ->  0.080298 seconds\n", "      |_chunking ->  0.078948 seconds\n", "    |_embedding ->  1.117244 seconds\n", "    |_embedding ->  0.382624 seconds\n", "**********\n"]}], "source": ["index = VectorStoreIndex.from_documents(docs)"]}, {"cell_type": "markdown", "id": "ae4de4a9", "metadata": {}, "source": ["## 2. 在索引上查询\n"]}, {"cell_type": "code", "execution_count": null, "id": "42221465", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["**********\n", "Trace: query\n", "    |_query ->  11.334982 seconds\n", "      |_retrieve ->  0.255016 seconds\n", "        |_embedding ->  0.247083 seconds\n", "      |_synthesize ->  11.079581 seconds\n", "        |_templating ->  5.7e-05 seconds\n", "        |_llm ->  11.065533 seconds\n", "**********\n", "Growing up, the author was involved in writing and programming. They wrote short stories and tried their hand at programming on an IBM 1401, using an early version of Fortran. Later, they started programming on a TRS-80 microcomputer that their father bought, creating simple games, a program to predict the flight of their model rockets, and a word processor. Despite their interest in programming, they initially planned to study philosophy in college, but eventually switched to AI.\n"]}], "source": ["query_engine = index.as_query_engine()\n", "response = query_engine.query(\"What did the author do growing up?\")\n", "print(response, sep=\"\\n\")"]}, {"cell_type": "markdown", "id": "c49ff101", "metadata": {}, "source": ["## 查看HoneyHive跟踪\n", "\n", "当我们完成对事件的跟踪后，可以通过[HoneyHive平台](https://app.honeyhive.ai)查看它们。只需登录HoneyHive，转到您的`My LlamaIndex Project`项目，点击`Data Store`选项卡，然后查看您的`Sessions`。\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}