{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "c91d7b0a", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/query_engine/custom_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨Colabä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "id": "c2598b32-dfc1-48bf-8ccc-719873aeb05f", "metadata": {}, "source": ["# å®šä¹‰è‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“\n", "\n", "æ‚¨å¯ä»¥ï¼ˆä¹Ÿåº”è¯¥ï¼‰å®šä¹‰è‡ªå·±çš„è‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“ï¼Œä»¥ä¾¿å°†å…¶æ’å…¥åˆ°ä¸‹æ¸¸çš„LlamaIndexå·¥ä½œæµä¸­ï¼Œæ— è®ºæ‚¨æ˜¯åœ¨æ„å»ºRAGã€ä»£ç†è¿˜æ˜¯å…¶ä»–åº”ç”¨ç¨‹åºã€‚\n", "\n", "æˆ‘ä»¬æä¾›äº†ä¸€ä¸ª`CustomQueryEngine`ï¼Œå®ƒå¯ä»¥æ–¹ä¾¿åœ°å®šä¹‰æ‚¨è‡ªå·±çš„æŸ¥è¯¢ã€‚\n"]}, {"cell_type": "markdown", "id": "f47027d5-19b4-4850-bc14-3f054899f472", "metadata": {}, "source": ["## è®¾ç½®\n", "\n", "æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸€äº›ç¤ºä¾‹æ•°æ®å¹¶å¯¹å…¶è¿›è¡Œç´¢å¼•ã€‚\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "0193f7c3", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "76a072e4", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "c136286f", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "id": "1b6e547e-af15-4506-9a4f-ec28c4bf3ce8", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"]}, {"attachments": {}, "cell_type": "markdown", "id": "29e58b49", "metadata": {}, "source": ["ä¸‹è½½æ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "8cdaf0f6", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "id": "4a3b2e77-fbea-451a-b714-696f2c9eb396", "metadata": {}, "outputs": [], "source": ["# åŠ è½½æ–‡æ¡£", "documents = SimpleDirectoryReader(\"./data//paul_graham/\").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "b94287a5-4ae8-4369-a245-4a8c53790b17", "metadata": {}, "outputs": [], "source": ["index = VectorStoreIndex.from_documents(documents)\n", "retriever = index.as_retriever()"]}, {"cell_type": "markdown", "id": "0697f50b-5238-4b96-a925-68dfc70138fb", "metadata": {}, "source": ["## æ„å»ºè‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“\n", "\n", "æˆ‘ä»¬æ„å»ºä¸€ä¸ªè‡ªå®šä¹‰æŸ¥è¯¢å¼•æ“ï¼Œæ¨¡æ‹Ÿä¸€ä¸ªRAGæµæ°´çº¿ã€‚é¦–å…ˆè¿›è¡Œæ£€ç´¢ï¼Œç„¶åè¿›è¡Œåˆæˆã€‚\n", "\n", "è¦å®šä¹‰ä¸€ä¸ª `CustomQueryEngine`ï¼Œä½ åªéœ€è¦å°†ä¸€äº›åˆå§‹åŒ–å‚æ•°å®šä¹‰ä¸ºå±æ€§ï¼Œå¹¶å®ç° `custom_query` å‡½æ•°ã€‚\n", "\n", "é»˜è®¤æƒ…å†µä¸‹ï¼Œ`custom_query` å¯ä»¥è¿”å›ä¸€ä¸ª `Response` å¯¹è±¡ï¼ˆå“åº”åˆæˆå™¨è¿”å›çš„å¯¹è±¡ï¼‰ï¼Œä½†ä¹Ÿå¯ä»¥åªè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚è¿™åˆ†åˆ«æ˜¯é€‰é¡¹1å’Œé€‰é¡¹2ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "d3d9c2af-bf04-4ce6-b2ed-b6dd12c7176c", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import CustomQueryEngine\n", "from llama_index.core.retrievers import BaseRetriever\n", "from llama_index.core import get_response_synthesizer\n", "from llama_index.core.response_synthesizers import BaseSynthesizer"]}, {"cell_type": "markdown", "id": "480d6dde-84af-4185-a505-78c95dbf884d", "metadata": {}, "source": ["### é€‰é¡¹ 1 (`RAGQueryEngine`)\n"]}, {"cell_type": "code", "execution_count": null, "id": "8fd6c9cb-2240-40da-8e69-1bb3d60913dd", "metadata": {}, "outputs": [], "source": ["class RAGQueryEngine(CustomQueryEngine):", "    \"\"\"RAGæŸ¥è¯¢å¼•æ“ã€‚\"\"\"", "", "    retriever: BaseRetriever", "    response_synthesizer: BaseSynthesizer", "", "    def custom_query(self, query_str: str):", "        nodes = self.retriever.retrieve(query_str)", "        response_obj = self.response_synthesizer.synthesize(query_str, nodes)", "        return response_obj"]}, {"cell_type": "markdown", "id": "de9b50c1-8c0f-4ca1-9ca0-aa984d7270ae", "metadata": {}, "source": ["### é€‰é¡¹ 2 (`RAGStringQueryEngine`)\n"]}, {"cell_type": "code", "execution_count": null, "id": "ef7b34bb-f14a-4e6e-a677-8213cb53f4b8", "metadata": {}, "outputs": [], "source": ["# é€‰é¡¹2ï¼šè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆæˆ‘ä»¬ä½¿ç”¨åŸå§‹LLMè°ƒç”¨è¿›è¡Œè¯´æ˜ï¼‰", "", "from llama_index.llms.openai import OpenAI", "from llama_index.core import PromptTemplate", "", "qa_prompt = PromptTemplate(", "    \"ä¸‹é¢æ˜¯ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\\n\"", "    \"---------------------\\n\"", "    \"{context_str}\\n\"", "    \"---------------------\\n\"", "    \"æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œéå…ˆéªŒçŸ¥è¯†ï¼Œå›ç­”æŸ¥è¯¢ã€‚\\n\"", "    \"æŸ¥è¯¢ï¼š{query_str}\\n\"", "    \"ç­”æ¡ˆï¼š\"", ")", "", "", "class RAGStringQueryEngine(CustomQueryEngine):", "    \"\"\"RAGå­—ç¬¦ä¸²æŸ¥è¯¢å¼•æ“ã€‚\"\"\"", "", "    retriever: BaseRetriever", "    response_synthesizer: BaseSynthesizer", "    llm: OpenAI", "    qa_prompt: PromptTemplate", "", "    def custom_query(self, query_str: str):", "        nodes = self.retriever.retrieve(query_str)", "", "        context_str = \"\\n\\n\".join([n.node.get_content() for n in nodes])", "        response = self.llm.complete(", "            qa_prompt.format(context_str=context_str, query_str=query_str)", "        )", "", "        return str(response)"]}, {"cell_type": "markdown", "id": "cb13986c-0431-4f29-9bc3-924424832373", "metadata": {}, "source": ["## å°è¯•ä¸€ä¸‹\n", "\n", "ç°åœ¨æˆ‘ä»¬å°†åœ¨æˆ‘ä»¬çš„æ ·æœ¬æ•°æ®ä¸Šå°è¯•ä¸€ä¸‹ã€‚\n"]}, {"cell_type": "markdown", "id": "022d0ae1-74e8-4cae-a460-8f895ed3b293", "metadata": {}, "source": ["### å°è¯•é€‰é¡¹1ï¼ˆ`RAGQueryEngine`ï¼‰\n"]}, {"cell_type": "code", "execution_count": null, "id": "e2b22e9b-fd1d-40ff-ad66-1718384cb5ed", "metadata": {}, "outputs": [], "source": ["synthesizer = get_response_synthesizer(response_mode=\"compact\")\n", "query_engine = RAGQueryEngine(\n", "    retriever=retriever, response_synthesizer=synthesizer\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "26fd76a0-451c-4796-97f8-4524af499c3a", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\"What did the author do growing up?\")"]}, {"cell_type": "code", "execution_count": null, "id": "71d885de-10fc-4c85-b782-108a7c33805e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author worked on writing and programming outside of school before college. They wrote short stories and tried writing programs on an IBM 1401 computer using an early version of Fortran. They also mentioned getting a microcomputer, building it themselves, and writing simple games and programs on it.\n"]}], "source": ["print(str(response))"]}, {"cell_type": "code", "execution_count": null, "id": "d4da52b0-77a6-43dc-9860-d1a52cee907d", "metadata": {}, "outputs": [], "source": ["print(response.source_nodes[0].get_content())"]}, {"cell_type": "markdown", "id": "d0c7c860-06c4-445c-95a7-858240053648", "metadata": {}, "source": ["### å°è¯•é€‰é¡¹2 (`RAGStringQueryEngine`)\n"]}, {"cell_type": "code", "execution_count": null, "id": "09bdd1c9-7bd2-4de0-a807-3eb20f6ede46", "metadata": {}, "outputs": [], "source": ["llm = OpenAI(model=\"gpt-3.5-turbo\")\n", "\n", "query_engine = RAGStringQueryEngine(\n", "    retriever=retriever,\n", "    response_synthesizer=synthesizer,\n", "    llm=llm,\n", "    qa_prompt=qa_prompt,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "370a3d91-e16f-4424-b839-5a57b28f21a6", "metadata": {}, "outputs": [], "source": ["response = query_engine.query(\"What did the author do growing up?\")"]}, {"cell_type": "code", "execution_count": null, "id": "307831fa-2c8d-4ab2-9d95-78e6c0c61a97", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author worked on writing and programming before college. They wrote short stories and started programming on the IBM 1401 computer in 9th grade. They later got a microcomputer and continued programming, writing simple games and a word processor.\n"]}], "source": ["print(str(response))"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}