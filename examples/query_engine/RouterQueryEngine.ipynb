{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/query_engine/RouterQueryEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨Colabä¸­æ‰“å¼€\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# è·¯ç”±å™¨æŸ¥è¯¢å¼•æ“\n", "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰è·¯ç”±å™¨æŸ¥è¯¢å¼•æ“ï¼Œç”¨äºä»å¤šä¸ªå€™é€‰æŸ¥è¯¢å¼•æ“ä¸­é€‰æ‹©ä¸€ä¸ªæ¥æ‰§è¡ŒæŸ¥è¯¢ã€‚\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### é…ç½®\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-openai\n", "%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# æ³¨æ„ï¼šè¿™ä»…åœ¨jupyterç¬”è®°æœ¬ä¸­æ˜¯å¿…éœ€çš„ã€‚\n", "# è¯¦æƒ…ï¼šJupyteråœ¨åå°è¿è¡Œä¸€ä¸ªäº‹ä»¶å¾ªç¯ã€‚\n", "#       å½“æˆ‘ä»¬å¯åŠ¨ä¸€ä¸ªäº‹ä»¶å¾ªç¯æ¥è¿›è¡Œå¼‚æ­¥æŸ¥è¯¢æ—¶ï¼Œä¼šå¯¼è‡´åµŒå¥—çš„äº‹ä»¶å¾ªç¯ã€‚\n", "#       é€šå¸¸æƒ…å†µä¸‹æ˜¯ä¸å…è®¸è¿™æ ·åšçš„ï¼Œæˆ‘ä»¬ä½¿ç”¨nest_asyncioæ¥å…è®¸è¿™æ ·åšä»¥æ–¹ä¾¿æ“ä½œã€‚\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## å…¨å±€æ¨¡å‹\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.llms.openai import OpenAI\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "from llama_index.core import Settings\n", "\n", "Settings.llm = OpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)\n", "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### åŠ è½½æ•°æ®\n", "\n", "æˆ‘ä»¬é¦–å…ˆå±•ç¤ºå¦‚ä½•å°†ä¸€ä¸ªæ–‡æ¡£è½¬æ¢ä¸ºä¸€ç»„èŠ‚ç‚¹ï¼Œå¹¶æ’å…¥åˆ°æ–‡æ¡£å­˜å‚¨ä¸­ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "\n", "# åŠ è½½æ–‡æ¡£\n", "documents = SimpleDirectoryReader(\"../data/paul_graham\").load_data()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "# åˆå§‹åŒ–è®¾ç½®ï¼ˆè®¾ç½®å—å¤§å°ï¼‰\n", "Settings.chunk_size = 1024\n", "nodes = Settings.node_parser.get_nodes_from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import StorageContext\n", "\n", "# åˆå§‹åŒ–å­˜å‚¨ä¸Šä¸‹æ–‡ï¼ˆé»˜è®¤æƒ…å†µä¸‹æ˜¯å†…å­˜ä¸­çš„ï¼‰\n", "storage_context = StorageContext.from_defaults()\n", "storage_context.docstore.add_documents(nodes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### å®šä¹‰ç›¸åŒæ•°æ®çš„æ‘˜è¦ç´¢å¼•å’Œå‘é‡ç´¢å¼•\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SummaryIndex\n", "from llama_index.core import VectorStoreIndex\n", "\n", "summary_index = SummaryIndex(nodes, storage_context=storage_context)\n", "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### å®šä¹‰æŸ¥è¯¢å¼•æ“å¹¶è®¾ç½®å…ƒæ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list_query_engine = summary_index.as_query_engine(\n", "    response_mode=\"tree_summarize\",\n", "    use_async=True,\n", ")\n", "vector_query_engine = vector_index.as_query_engine()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.tools import QueryEngineTool\n", "\n", "\n", "list_tool = QueryEngineTool.from_defaults(\n", "    query_engine=list_query_engine,\n", "    description=(\n", "        \"Useful for summarization questions related to Paul Graham eassy on\"\n", "        \" What I Worked On.\"\n", "    ),\n", ")\n", "\n", "vector_tool = QueryEngineTool.from_defaults(\n", "    query_engine=vector_query_engine,\n", "    description=(\n", "        \"Useful for retrieving specific context from Paul Graham essay on What\"\n", "        \" I Worked On.\"\n", "    ),\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### å®šä¹‰è·¯ç”±æŸ¥è¯¢å¼•æ“\n", "\n", "æœ‰å‡ ä¸ªå¯ç”¨çš„é€‰æ‹©å™¨ï¼Œæ¯ä¸ªé€‰æ‹©å™¨éƒ½å…·æœ‰ä¸€äº›ç‹¬ç‰¹çš„å±æ€§ã€‚\n", "\n", "LLMé€‰æ‹©å™¨ä½¿ç”¨LLMè¾“å‡ºä¸€ä¸ªJSONï¼Œç„¶åå¯¹å…¶è¿›è¡Œè§£æï¼Œå¹¶æŸ¥è¯¢ç›¸åº”çš„ç´¢å¼•ã€‚\n", "\n", "Pydanticé€‰æ‹©å™¨ï¼ˆç›®å‰ä»…ç”±`gpt-4-0613`å’Œ`gpt-3.5-turbo-0613`ï¼ˆé»˜è®¤ï¼‰æ”¯æŒï¼‰ä½¿ç”¨OpenAI Function Call APIç”Ÿæˆpydanticé€‰æ‹©å¯¹è±¡ï¼Œè€Œä¸æ˜¯è§£æåŸå§‹JSONã€‚\n", "\n", "å¯¹äºæ¯ç§ç±»å‹çš„é€‰æ‹©å™¨ï¼Œè¿˜å¯ä»¥é€‰æ‹©å°†è·¯ç”±åˆ°ä¸€ä¸ªç´¢å¼•ï¼Œæˆ–è€…å¤šä¸ªç´¢å¼•ã€‚\n", "\n", "#### PydanticSingleSelector\n", "\n", "ä½¿ç”¨OpenAI Function APIåœ¨è·¯ç”±é€‰æ‹©å™¨ä¸‹ç”Ÿæˆ/è§£æpydanticå¯¹è±¡ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import RouterQueryEngine\n", "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n", "from llama_index.core.selectors import (\n", "    PydanticMultiSelector,\n", "    PydanticSingleSelector,\n", ")\n", "\n", "\n", "query_engine = RouterQueryEngine(\n", "    selector=PydanticSingleSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        list_tool,\n", "        vector_tool,\n", "    ],\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The document provides a comprehensive account of the author's diverse experiences, including writing, programming, founding and running startups, and investing in early-stage companies. It covers the challenges, successes, and lessons learned in these ventures, as well as the author's personal and professional growth, interactions with colleagues, and evolving interests and priorities over time.\n"]}], "source": ["response = query_engine.query(\"What is the summary of the document?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Paul Graham started painting after leaving Y Combinator. He wanted to see how good he could get if he really focused on it. After spending most of 2014 painting, he eventually ran out of steam and stopped working on it. He then started writing essays again and wrote a bunch of new ones over the next few months. Later, in March 2015, he started working on Lisp again.\n"]}], "source": ["response = query_engine.query(\"What did Paul Graham do after RICS?\")\n", "print(str(response))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### LLMSingleSelector\n", "\n", "ä½¿ç”¨OpenAIï¼ˆæˆ–ä»»ä½•å…¶ä»–LLMï¼‰åœ¨å†…éƒ¨è§£æç”Ÿæˆçš„JSONï¼Œä»¥é€‰æ‹©ç”¨äºè·¯ç”±çš„å­ç´¢å¼•ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = RouterQueryEngine(\n", "    selector=LLMSingleSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        list_tool,\n", "        vector_tool,\n", "    ],\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The document provides a comprehensive account of the author's professional journey, covering his involvement in various projects such as Viaweb, Y Combinator, and Hacker News, as well as his transition to focusing on writing essays and working on Y Combinator. It also delves into his experiences with the Summer Founders Program, the growth and challenges of Y Combinator, personal struggles, and his return to working on Lisp. The author reflects on the challenges and successes encountered throughout his career, including funding startups, developing a new version of Arc, and the impact of Hacker News. Additionally, the document touches on the author's interactions with colleagues, his time in Italy, experiences with painting, and the completion of a new Lisp called Bel. Throughout, the author shares insights and lessons learned from his diverse experiences.\n"]}], "source": ["response = query_engine.query(\"What is the summary of the document?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Paul Graham started painting after leaving Y Combinator. He wanted to see how good he could get if he really focused on it. After spending most of 2014 painting, he eventually ran out of steam and stopped working on it. He then started writing essays again and wrote a bunch of new ones over the next few months. In March 2015, he started working on Lisp again.\n"]}], "source": ["response = query_engine.query(\"What did Paul Graham do after RICS?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["selections=[SingleSelection(index=1, reason='The question is asking for specific context about what Paul Graham did after RICS, which would require retrieving specific information from his essay.')]\n"]}], "source": ["# [å¯é€‰] æŸ¥çœ‹æ‰€é€‰ç»“æœ\n", "print(str(response.metadata[\"selector_result\"]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### PydanticMultiSelector\n", "\n", "å¦‚æœä½ æœŸæœ›æŸ¥è¯¢è¢«è·¯ç”±åˆ°å¤šä¸ªç´¢å¼•ï¼Œä½ åº”è¯¥ä½¿ç”¨å¤šé€‰æ‹©å™¨ã€‚å¤šé€‰æ‹©å™¨å°†æŸ¥è¯¢å‘é€åˆ°å¤šä¸ªå­ç´¢å¼•ï¼Œç„¶åä½¿ç”¨æ±‡æ€»ç´¢å¼•èšåˆæ‰€æœ‰å“åº”ï¼Œå½¢æˆå®Œæ•´çš„ç­”æ¡ˆã€‚\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleKeywordTableIndex\n", "\n", "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)\n", "\n", "keyword_tool = QueryEngineTool.from_defaults(\n", "    query_engine=vector_query_engine,\n", "    description=(\n", "        \"Useful for retrieving specific context using keywords from Paul\"\n", "        \" Graham essay on What I Worked On.\"\n", "    ),\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = RouterQueryEngine(\n", "    selector=PydanticMultiSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        list_tool,\n", "        vector_tool,\n", "        keyword_tool,\n", "    ],\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author's time at Interleaf involved working on software for creating documents and learning valuable lessons about what not to do. Notable individuals associated with Y Combinator during the author's time there include Jessica Livingston, Robert Morris, and Sam Altman, who eventually became the second president of YC. The author's time at Y Combinator included notable events such as the creation of the Summer Founders Program, which attracted impressive individuals like Reddit, Justin Kan, Emmett Shear, Aaron Swartz, and Sam Altman.\n"]}], "source": ["# è¿™ä¸ªæŸ¥è¯¢å¯ä»¥ä½¿ç”¨å…³é”®å­—æŸ¥è¯¢å¼•æ“æˆ–å‘é‡æŸ¥è¯¢å¼•æ“ï¼Œå› æ­¤å®ƒå°†åˆå¹¶ä¸¤è€…çš„å“åº”\n", "response = query_engine.query(\n", "    \"ä½œè€…åœ¨Interleafå’ŒYCçš„æ—¶ä»£æœ‰å“ªäº›å€¼å¾—æ³¨æ„çš„äº‹ä»¶å’Œäººç‰©ï¼Ÿ\"\n", ")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["selections=[SingleSelection(index=0, reason='Summarization questions related to Paul Graham essay on What I Worked On.'), SingleSelection(index=2, reason='Retrieving specific context using keywords from Paul Graham essay on What I Worked On.')]\n"]}], "source": ["# [å¯é€‰] æŸ¥çœ‹é€‰å®šçš„ç»“æœ\n", "print(str(response.metadata[\"selector_result\"]))"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}