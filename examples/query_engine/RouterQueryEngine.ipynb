{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/query_engine/RouterQueryEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在Colab中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 路由器查询引擎\n", "在本教程中，我们将定义一个自定义路由器查询引擎，用于从多个候选查询引擎中选择一个来执行查询。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 配置\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-embeddings-openai\n", "%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 注意：这仅在jupyter笔记本中是必需的。\n", "# 详情：Jupyter在后台运行一个事件循环。\n", "#       当我们启动一个事件循环来进行异步查询时，会导致嵌套的事件循环。\n", "#       通常情况下是不允许这样做的，我们使用nest_asyncio来允许这样做以方便操作。\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 全局模型\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.llms.openai import OpenAI\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "from llama_index.core import Settings\n", "\n", "Settings.llm = OpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.2)\n", "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 加载数据\n", "\n", "我们首先展示如何将一个文档转换为一组节点，并插入到文档存储中。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "\n", "# 加载文档\n", "documents = SimpleDirectoryReader(\"../data/paul_graham\").load_data()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import Settings\n", "\n", "# 初始化设置（设置块大小）\n", "Settings.chunk_size = 1024\n", "nodes = Settings.node_parser.get_nodes_from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import StorageContext\n", "\n", "# 初始化存储上下文（默认情况下是内存中的）\n", "storage_context = StorageContext.from_defaults()\n", "storage_context.docstore.add_documents(nodes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 定义相同数据的摘要索引和向量索引\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SummaryIndex\n", "from llama_index.core import VectorStoreIndex\n", "\n", "summary_index = SummaryIndex(nodes, storage_context=storage_context)\n", "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 定义查询引擎并设置元数据\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["list_query_engine = summary_index.as_query_engine(\n", "    response_mode=\"tree_summarize\",\n", "    use_async=True,\n", ")\n", "vector_query_engine = vector_index.as_query_engine()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.tools import QueryEngineTool\n", "\n", "\n", "list_tool = QueryEngineTool.from_defaults(\n", "    query_engine=list_query_engine,\n", "    description=(\n", "        \"Useful for summarization questions related to Paul Graham eassy on\"\n", "        \" What I Worked On.\"\n", "    ),\n", ")\n", "\n", "vector_tool = QueryEngineTool.from_defaults(\n", "    query_engine=vector_query_engine,\n", "    description=(\n", "        \"Useful for retrieving specific context from Paul Graham essay on What\"\n", "        \" I Worked On.\"\n", "    ),\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 定义路由查询引擎\n", "\n", "有几个可用的选择器，每个选择器都具有一些独特的属性。\n", "\n", "LLM选择器使用LLM输出一个JSON，然后对其进行解析，并查询相应的索引。\n", "\n", "Pydantic选择器（目前仅由`gpt-4-0613`和`gpt-3.5-turbo-0613`（默认）支持）使用OpenAI Function Call API生成pydantic选择对象，而不是解析原始JSON。\n", "\n", "对于每种类型的选择器，还可以选择将路由到一个索引，或者多个索引。\n", "\n", "#### PydanticSingleSelector\n", "\n", "使用OpenAI Function API在路由选择器下生成/解析pydantic对象。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import RouterQueryEngine\n", "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n", "from llama_index.core.selectors import (\n", "    PydanticMultiSelector,\n", "    PydanticSingleSelector,\n", ")\n", "\n", "\n", "query_engine = RouterQueryEngine(\n", "    selector=PydanticSingleSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        list_tool,\n", "        vector_tool,\n", "    ],\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The document provides a comprehensive account of the author's diverse experiences, including writing, programming, founding and running startups, and investing in early-stage companies. It covers the challenges, successes, and lessons learned in these ventures, as well as the author's personal and professional growth, interactions with colleagues, and evolving interests and priorities over time.\n"]}], "source": ["response = query_engine.query(\"What is the summary of the document?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Paul Graham started painting after leaving Y Combinator. He wanted to see how good he could get if he really focused on it. After spending most of 2014 painting, he eventually ran out of steam and stopped working on it. He then started writing essays again and wrote a bunch of new ones over the next few months. Later, in March 2015, he started working on Lisp again.\n"]}], "source": ["response = query_engine.query(\"What did Paul Graham do after RICS?\")\n", "print(str(response))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### LLMSingleSelector\n", "\n", "使用OpenAI（或任何其他LLM）在内部解析生成的JSON，以选择用于路由的子索引。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = RouterQueryEngine(\n", "    selector=LLMSingleSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        list_tool,\n", "        vector_tool,\n", "    ],\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The document provides a comprehensive account of the author's professional journey, covering his involvement in various projects such as Viaweb, Y Combinator, and Hacker News, as well as his transition to focusing on writing essays and working on Y Combinator. It also delves into his experiences with the Summer Founders Program, the growth and challenges of Y Combinator, personal struggles, and his return to working on Lisp. The author reflects on the challenges and successes encountered throughout his career, including funding startups, developing a new version of Arc, and the impact of Hacker News. Additionally, the document touches on the author's interactions with colleagues, his time in Italy, experiences with painting, and the completion of a new Lisp called Bel. Throughout, the author shares insights and lessons learned from his diverse experiences.\n"]}], "source": ["response = query_engine.query(\"What is the summary of the document?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Paul Graham started painting after leaving Y Combinator. He wanted to see how good he could get if he really focused on it. After spending most of 2014 painting, he eventually ran out of steam and stopped working on it. He then started writing essays again and wrote a bunch of new ones over the next few months. In March 2015, he started working on Lisp again.\n"]}], "source": ["response = query_engine.query(\"What did Paul Graham do after RICS?\")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["selections=[SingleSelection(index=1, reason='The question is asking for specific context about what Paul Graham did after RICS, which would require retrieving specific information from his essay.')]\n"]}], "source": ["# [可选] 查看所选结果\n", "print(str(response.metadata[\"selector_result\"]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### PydanticMultiSelector\n", "\n", "如果你期望查询被路由到多个索引，你应该使用多选择器。多选择器将查询发送到多个子索引，然后使用汇总索引聚合所有响应，形成完整的答案。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleKeywordTableIndex\n", "\n", "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)\n", "\n", "keyword_tool = QueryEngineTool.from_defaults(\n", "    query_engine=vector_query_engine,\n", "    description=(\n", "        \"Useful for retrieving specific context using keywords from Paul\"\n", "        \" Graham essay on What I Worked On.\"\n", "    ),\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = RouterQueryEngine(\n", "    selector=PydanticMultiSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        list_tool,\n", "        vector_tool,\n", "        keyword_tool,\n", "    ],\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The author's time at Interleaf involved working on software for creating documents and learning valuable lessons about what not to do. Notable individuals associated with Y Combinator during the author's time there include Jessica Livingston, Robert Morris, and Sam Altman, who eventually became the second president of YC. The author's time at Y Combinator included notable events such as the creation of the Summer Founders Program, which attracted impressive individuals like Reddit, Justin Kan, Emmett Shear, Aaron Swartz, and Sam Altman.\n"]}], "source": ["# 这个查询可以使用关键字查询引擎或向量查询引擎，因此它将合并两者的响应\n", "response = query_engine.query(\n", "    \"作者在Interleaf和YC的时代有哪些值得注意的事件和人物？\"\n", ")\n", "print(str(response))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["selections=[SingleSelection(index=0, reason='Summarization questions related to Paul Graham essay on What I Worked On.'), SingleSelection(index=2, reason='Retrieving specific context using keywords from Paul Graham essay on What I Worked On.')]\n"]}], "source": ["# [可选] 查看选定的结果\n", "print(str(response.metadata[\"selector_result\"]))"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}