{"cells": [{"cell_type": "markdown", "id": "8329aae0", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/query_engine/pandas_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"åœ¨ Colab ä¸­æ‰“å¼€\"/></a>\n"]}, {"attachments": {}, "cell_type": "markdown", "id": "e45f9b60-cd6b-4c15-958f-1feca5438128", "metadata": {}, "source": ["# Pandas æŸ¥è¯¢å¼•æ“\n", "\n", "æœ¬æŒ‡å—å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„ `PandasQueryEngine`ï¼šä½¿ç”¨LLMså°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºPandas Pythonä»£ç ã€‚\n", "\n", "`PandasQueryEngine`çš„è¾“å…¥æ˜¯ä¸€ä¸ªPandasæ•°æ®æ¡†ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªå“åº”ã€‚LLMæ¨æ–­è¦æ‰§è¡Œçš„æ•°æ®æ¡†æ“ä½œï¼Œä»¥æ£€ç´¢ç»“æœã€‚\n", "\n", "**è­¦å‘Šï¼š** æ­¤å·¥å…·ä¸ºLLMæä¾›äº†å¯¹ `eval` å‡½æ•°çš„è®¿é—®æƒé™ã€‚\n", "åœ¨è¿è¡Œæ­¤å·¥å…·çš„è®¡ç®—æœºä¸Šå¯èƒ½ä¼šå‘ç”Ÿä»»æ„ä»£ç æ‰§è¡Œã€‚\n", "è™½ç„¶å¯¹ä»£ç è¿›è¡Œäº†ä¸€å®šç¨‹åº¦çš„è¿‡æ»¤ï¼Œä½†ä¸å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æ­¤å·¥å…·ï¼Œé™¤éè¿›è¡Œäº†ä¸¥æ ¼çš„æ²™ç›’åŒ–æˆ–è™šæ‹ŸæœºåŒ–ã€‚\n"]}, {"cell_type": "markdown", "id": "8a6a0f96", "metadata": {}, "source": ["å¦‚æœæ‚¨åœ¨colabä¸Šæ‰“å¼€è¿™ä¸ªç¬”è®°æœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…LlamaIndex ğŸ¦™ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "82fa3d16", "metadata": {}, "outputs": [], "source": ["!pip install llama-index llama-index-experimental"]}, {"cell_type": "code", "execution_count": null, "id": "119eb42b", "metadata": {}, "outputs": [], "source": ["import logging\n", "import sys\n", "from IPython.display import Markdown, display\n", "\n", "import pandas as pd\n", "from llama_index.experimental.query_engine import PandasQueryEngine\n", "\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"attachments": {}, "cell_type": "markdown", "id": "5ece7d73-0f67-4ff5-95e5-249a25bd118c", "metadata": {}, "source": ["## è®©æˆ‘ä»¬ä»ä¸€ä¸ªç©å…·DataFrameå¼€å§‹\n", "\n", "åœ¨è¿™é‡Œï¼Œè®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªéå¸¸ç®€å•çš„åŒ…å«åŸå¸‚å’Œäººå£å¯¹çš„DataFrameï¼Œå¹¶åœ¨å…¶ä¸Šè¿è¡Œ`PandasQueryEngine`ã€‚\n", "\n", "é€šè¿‡è®¾ç½®`verbose=True`ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç”Ÿæˆçš„ä¸­é—´æŒ‡ä»¤ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "1484fe58-4853-4a76-bffc-435a9cce3e2e", "metadata": {}, "outputs": [], "source": ["# åœ¨ä¸€äº›æ ·æœ¬æ•°æ®ä¸Šè¿›è¡Œæµ‹è¯•", "df = pd.DataFrame(", "    {", "        \"city\": [\"å¤šä¼¦å¤š\", \"ä¸œäº¬\", \"æŸæ—\"],", "        \"population\": [2930000, 13960000, 3645000],", "    }", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4fea2edb-b3d4-4313-a656-d6edb00d93c0", "metadata": {}, "outputs": [], "source": ["query_engine = PandasQueryEngine(df=df, verbose=True)"]}, {"cell_type": "code", "execution_count": null, "id": "451836bc-b073-4838-8ab8-3def7d2c4d9d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "> Pandas Instructions:\n", "```\n", "df['city'][df['population'].idxmax()]\n", "```\n", "> Pandas Output: Tokyo\n"]}], "source": ["response = query_engine.query(\n", "    \"What is the city with the highest population?\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4253d4c3-f3e5-4779-bcd1-2e6e2818305f", "metadata": {}, "outputs": [{"data": {"text/markdown": ["<b>Tokyo</b>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["display(Markdown(f\"<b>{response}</b>\"))"]}, {"cell_type": "code", "execution_count": null, "id": "5e10b7da-b355-49b2-9f80-f17541d4f850", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["df['city'][df['population'].idxmax()]\n"]}], "source": ["# è·å–pandas pythonæŒ‡ä»¤", "print(response.metadata[\"pandas_instruction_str\"])"]}, {"cell_type": "markdown", "id": "7c86a122-b65f-40af-92fe-b3054d526eb4", "metadata": {}, "source": ["æˆ‘ä»¬è¿˜å¯ä»¥é‡‡å–ä½¿ç”¨LLMæ¥åˆæˆå›å¤çš„æ­¥éª¤ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "79829afa-5d7e-4e7c-a5c8-433f8e5fceb7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "> Pandas Instructions:\n", "```\n", "df.loc[df['population'].idxmax()]\n", "```\n", "> Pandas Output: city             Tokyo\n", "population    13960000\n", "Name: 1, dtype: object\n", "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "The city with the highest population is Tokyo, with a population of 13,960,000.\n"]}], "source": ["query_engine = PandasQueryEngine(df=df, verbose=True, synthesize_response=True)\n", "response = query_engine.query(\n", "    \"What is the city with the highest population? Give both the city and population\",\n", ")\n", "print(str(response))"]}, {"attachments": {}, "cell_type": "markdown", "id": "1de5eaf3-6129-47b1-b630-faf9138a04c5", "metadata": {}, "source": ["## åˆ†ææ³°å¦å°¼å…‹å·æ•°æ®é›†\n", "\n", "æ³°å¦å°¼å…‹å·æ•°æ®é›†æ˜¯å…¥é—¨æœºå™¨å­¦ä¹ ä¸­æœ€å—æ¬¢è¿çš„è¡¨æ ¼æ•°æ®é›†ä¹‹ä¸€\n", "æ¥æºï¼šhttps://www.kaggle.com/c/titanic\n"]}, {"cell_type": "markdown", "id": "0e84f82e", "metadata": {}, "source": ["#### ä¸‹è½½æ•°æ®\n"]}, {"cell_type": "code", "execution_count": null, "id": "dc2e1896", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2024-01-13 17:45:15--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8002::154, 2606:50c0:8001::154, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 57726 (56K) [text/plain]\n", "Saving to: â€˜titanic_train.csvâ€™\n", "\n", "titanic_train.csv   100%[===================>]  56.37K  --.-KB/s    in 0.009s  \n", "\n", "2024-01-13 17:45:15 (6.45 MB/s) - â€˜titanic_train.csvâ€™ saved [57726/57726]\n", "\n"]}], "source": ["!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"]}, {"cell_type": "code", "execution_count": null, "id": "809f18c8-e38b-449e-b5ee-c2ea700f8698", "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"./titanic_train.csv\")"]}, {"cell_type": "code", "execution_count": null, "id": "fb1758de-6310-4ed5-ae02-2dbf50d2c55f", "metadata": {}, "outputs": [], "source": ["query_engine = PandasQueryEngine(df=df, verbose=True)"]}, {"cell_type": "code", "execution_count": null, "id": "f9dd658d-b62c-4e3b-aee9-0a06f57de032", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n", "> Pandas Instructions:\n", "```\n", "df['survived'].corr(df['age'])\n", "```\n", "> Pandas Output: -0.07722109457217755\n"]}], "source": ["response = query_engine.query(\n", "    \"What is the correlation between survival and age?\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "60474389-341b-4187-87b2-83811546dcea", "metadata": {}, "outputs": [{"data": {"text/markdown": ["<b>-0.07722109457217755</b>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["display(Markdown(f\"<b>{response}</b>\"))"]}, {"cell_type": "code", "execution_count": null, "id": "af999a1f-fea6-4734-82e6-4450f1a06a3b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["df['survived'].corr(df['age'])\n"]}], "source": ["# è·å–pandas pythonæŒ‡ä»¤", "print(response.metadata[\"pandas_instruction_str\"])"]}, {"cell_type": "markdown", "id": "1896e6d8-9324-4ea8-a903-bcbd94c5fb4b", "metadata": {}, "source": ["## é™„åŠ æ­¥éª¤\n", "\n", "### åˆ†æ/ä¿®æ”¹æç¤º\n", "\n", "è®©æˆ‘ä»¬æ¥çœ‹çœ‹æç¤ºï¼\n"]}, {"cell_type": "code", "execution_count": null, "id": "c7007101-20f0-4081-bee3-ef8e2e7f3796", "metadata": {}, "outputs": [], "source": ["from llama_index.core import PromptTemplate"]}, {"cell_type": "code", "execution_count": null, "id": "6a4a924d-315a-48e5-a404-f029c8962fc5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["You are working with a pandas dataframe in Python.\n", "The name of the dataframe is `df`.\n", "This is the result of `print(df.head())`:\n", "{df_str}\n", "\n", "Follow these instructions:\n", "{instruction_str}\n", "Query: {query_str}\n", "\n", "Expression:\n"]}], "source": ["query_engine = PandasQueryEngine(df=df, verbose=True)\n", "prompts = query_engine.get_prompts()\n", "print(prompts[\"pandas_prompt\"].template)"]}, {"cell_type": "code", "execution_count": null, "id": "0c561301-3cfe-4d61-86e3-9d43847534f8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Given an input question, synthesize a response from the query results.\n", "Query: {query_str}\n", "\n", "Pandas Instructions (optional):\n", "{pandas_instructions}\n", "\n", "Pandas Output: {pandas_output}\n", "\n", "Response: \n"]}], "source": ["print(prompts[\"response_synthesis_prompt\"].template)"]}, {"cell_type": "markdown", "id": "9f30b563-ba0d-445f-83e9-46a8f480a83a", "metadata": {}, "source": ["æ‚¨ä¹Ÿå¯ä»¥æ›´æ–°æç¤ºï¼š\n"]}, {"cell_type": "code", "execution_count": null, "id": "e0118dfb-80e2-40d2-88dc-b8f6c62d786b", "metadata": {}, "outputs": [], "source": ["new_prompt = PromptTemplate(", "    \"\"\"\\", "æ‚¨æ­£åœ¨ä½¿ç”¨Pythonä¸­çš„pandas dataframeã€‚", "æ•°æ®æ¡†çš„åç§°æ˜¯`df`ã€‚", "è¿™æ˜¯`print(df.head())`çš„ç»“æœï¼š", "{df_str}", "", "è¯·æŒ‰ç…§ä»¥ä¸‹è¯´æ˜æ“ä½œï¼š", "{instruction_str}", "æŸ¥è¯¢ï¼š{query_str}", "", "è¡¨è¾¾å¼ï¼š\"\"\"", ")", "", "query_engine.update_prompts({\"pandas_prompt\": new_prompt})", ""]}, {"cell_type": "markdown", "id": "93f95796-2044-4ff4-829c-9c4ff21f924f", "metadata": {}, "source": ["è¿™æ˜¯æŒ‡ä»¤å­—ç¬¦ä¸²ï¼ˆæ‚¨å¯ä»¥é€šè¿‡åœ¨åˆå§‹åŒ–æ—¶ä¼ å…¥`instruction_str`æ¥è‡ªå®šä¹‰ï¼‰ã€‚\n"]}, {"cell_type": "code", "execution_count": null, "id": "62d0fb52-685e-438b-890a-a88c2cb83292", "metadata": {}, "outputs": [], "source": ["æŒ‡ä»¤å­—ç¬¦ä¸² = \"\"\"\\", "1. ä½¿ç”¨Pandaså°†æŸ¥è¯¢è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„Pythonä»£ç ã€‚", "2. ä»£ç çš„æœ€åä¸€è¡Œåº”è¯¥æ˜¯ä¸€ä¸ªå¯ä»¥ä½¿ç”¨`eval()`å‡½æ•°è°ƒç”¨çš„Pythonè¡¨è¾¾å¼ã€‚", "3. ä»£ç åº”è¯¥ä»£è¡¨å¯¹æŸ¥è¯¢çš„è§£å†³æ–¹æ¡ˆã€‚", "4. ä»…æ‰“å°è¡¨è¾¾å¼ã€‚", "5. ä¸è¦å¼•ç”¨è¡¨è¾¾å¼ã€‚", "\"\"\""]}, {"cell_type": "markdown", "id": "29c78a8e-d3ff-4c0e-b8c3-7fc79de83839", "metadata": {}, "source": ["### ä½¿ç”¨æŸ¥è¯¢ç®¡é“è¯­æ³•å®ç°æŸ¥è¯¢å¼•æ“\n", "\n", "å¦‚æœä½ æƒ³å­¦ä¹ å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„æŸ¥è¯¢ç®¡é“è¯­æ³•å’Œä¸Šé¢çš„æç¤ºç»„ä»¶æ„å»ºè‡ªå·±çš„PandasæŸ¥è¯¢å¼•æ“ï¼Œè¯·æŸ¥çœ‹ä¸‹é¢çš„æ•™ç¨‹ã€‚\n", "\n", "[ä½¿ç”¨æŸ¥è¯¢ç®¡é“è®¾ç½®Pandas DataFrameæŸ¥è¯¢å¼•æ“](https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_pandas.html)\n"]}], "metadata": {"kernelspec": {"display_name": "llama_index_v2", "language": "python", "name": "llama_index_v2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}