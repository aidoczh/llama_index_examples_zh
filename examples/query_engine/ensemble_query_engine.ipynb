{"cells": [{"cell_type": "markdown", "id": "9bbed780", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/query_engine/ensemble_query_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在Colab中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "5bf1de44-4047-46cf-a04c-dbf910d9e179", "metadata": {}, "source": ["# 集成查询引擎指南\n", "\n", "在构建RAG应用程序时，通常需要尝试不同的查询管道（例如，前k个检索、关键词搜索、知识图谱）。\n", "\n", "想法：如果我们可以同时尝试一系列策略，并让LLM 1）评估每个查询的相关性，2）综合结果呢？\n", "\n", "本指南展示了在《了不起的盖茨比》上的集成检索。我们对不同的块大小和不同的索引进行集成检索。\n", "\n", "**注意**：还请参阅我们密切相关的[集成检索指南](https://gpt-index.readthedocs.io/en/stable/examples/retrievers/ensemble_retrieval.html)！\n"]}, {"cell_type": "markdown", "id": "f985735c", "metadata": {}, "source": ["如果您在colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "id": "a48679c7", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "d3ce71f9", "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "markdown", "id": "6e73fead-ec2c-4346-bd08-e183c13c7e29", "metadata": {}, "source": ["## 设置\n"]}, {"cell_type": "code", "execution_count": null, "id": "a2d59778-4cda-47b5-8cd0-b80fee91d1e4", "metadata": {}, "outputs": [], "source": ["# 注意：这仅在jupyter笔记本中才是必需的。", "# 详情：Jupyter在后台运行一个事件循环。", "#       当我们启动一个事件循环来进行异步查询时，这会导致嵌套的事件循环。", "#       通常情况下是不允许这样做的，我们使用nest_asyncio来允许它以方便使用。 ", "", "import nest_asyncio", "", "nest_asyncio.apply()"]}, {"attachments": {}, "cell_type": "markdown", "id": "a0e96ae8", "metadata": {}, "source": ["## 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "ddd930fa", "metadata": {}, "outputs": [], "source": ["!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/examples/gatsby/gatsby_full.txt' -O 'gatsby_full.txt'"]}, {"cell_type": "markdown", "id": "787174ed-10ce-47d7-82fd-9ca7f891eea7", "metadata": {}, "source": ["## 加载数据\n", "\n", "我们首先展示如何将一个文档转换为一组节点，并插入到文档存储中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "7b16c74c-213d-413f-916f-158189fe29a5", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader", "", "# 尝试加载了《了不起的盖茨比》", "", "documents = SimpleDirectoryReader(", "    input_files=[\"./gatsby_full.txt\"]", ").load_data()"]}, {"cell_type": "markdown", "id": "aba2c77c-0621-4239-922d-31b976b48efe", "metadata": {}, "source": ["## 定义查询引擎\n"]}, {"cell_type": "code", "execution_count": null, "id": "ebc46e63-c5fd-4ea2-b3ff-3d2a8660ad44", "metadata": {}, "outputs": [], "source": ["# 初始化设置（设置块大小）", "from llama_index.llms.openai import OpenAI", "from llama_index.core import Settings", "", "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")", "Settings.chunk_size = 1024", "", "nodes = Settings.node_parser.get_nodes_from_documents(documents)"]}, {"cell_type": "code", "execution_count": null, "id": "d3bb1738-51c1-4079-885c-ad78ec10683d", "metadata": {}, "outputs": [], "source": ["from llama_index.core import StorageContext", "", "# 初始化存储上下文（默认情况下是内存中的）", "storage_context = StorageContext.from_defaults()", "storage_context.docstore.add_documents(nodes)"]}, {"cell_type": "code", "execution_count": null, "id": "cc201fb0-abc9-443d-be77-5a084797bae7", "metadata": {}, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "ac6abedbc02d4335b73045d056a8e0b7", "version_major": 2, "version_minor": 0}, "text/plain": ["Extracting keywords from nodes:   0%|          | 0/77 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "33cf0bc8c99942249d7b0268a02a82ad", "version_major": 2, "version_minor": 0}, "text/plain": ["Generating embeddings:   0%|          | 0/77 [00:00<?, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}], "source": ["from llama_index.core import SimpleKeywordTableIndex, VectorStoreIndex\n", "\n", "keyword_index = SimpleKeywordTableIndex(\n", "    nodes,\n", "    storage_context=storage_context,\n", "    show_progress=True,\n", ")\n", "vector_index = VectorStoreIndex(\n", "    nodes,\n", "    storage_context=storage_context,\n", "    show_progress=True,\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "b58db24b-8c38-42df-9e0f-bfb91c1d4f0a", "metadata": {}, "outputs": [], "source": ["from llama_index.core import PromptTemplate\n", "\n", "QA_PROMPT_TMPL = (\n", "    \"Context information is below.\\n\"\n", "    \"---------------------\\n\"\n", "    \"{context_str}\\n\"\n", "    \"---------------------\\n\"\n", "    \"Given the context information and not prior knowledge, \"\n", "    \"answer the question. If the answer is not in the context, inform \"\n", "    \"the user that you can't answer the question - DO NOT MAKE UP AN ANSWER.\\n\"\n", "    \"In addition to returning the answer, also return a relevance score as to \"\n", "    \"how relevant the answer is to the question. \"\n", "    \"Question: {query_str}\\n\"\n", "    \"Answer (including relevance score): \"\n", ")\n", "QA_PROMPT = PromptTemplate(QA_PROMPT_TMPL)\n", "\n", "keyword_query_engine = keyword_index.as_query_engine(\n", "    text_qa_template=QA_PROMPT\n", ")\n", "vector_query_engine = vector_index.as_query_engine(text_qa_template=QA_PROMPT)"]}, {"cell_type": "code", "execution_count": null, "id": "a6b79668-8ca6-45fd-8f3b-dffe986040f8", "metadata": {}, "outputs": [], "source": ["response = vector_query_engine.query(\n", "    \"Describe and summarize the interactions between Gatsby and Daisy\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "0124f5b9-b2df-4fcf-828a-d8c12339f01a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Gatsby and Daisy's interactions are described as intimate and conspiring. They sit opposite each other at a kitchen table, with Gatsby's hand covering Daisy's hand. They communicate through nods and seem to have a natural intimacy. Gatsby waits for Daisy to go to bed and is reluctant to leave until he knows what she will do. They have a conversation in which Gatsby tells the story of his youth with Dan Cody. Daisy's face is smeared with tears, but Gatsby glows with a new well-being. Gatsby invites Daisy to his house and expresses his desire for her to come. They admire Gatsby's house together and discuss the interesting people who visit. The relevance score of this answer is 10/10.\n"]}], "source": ["print(response)"]}, {"cell_type": "code", "execution_count": null, "id": "7bf73d14-451f-4854-a899-7100dfe12fa2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["> Starting query: Describe and summarize the interactions between Gatsby and Daisy\n", "query keywords: ['describe', 'interactions', 'gatsby', 'summarize', 'daisy']\n", "> Extracted keywords: ['gatsby', 'daisy']\n"]}], "source": ["response = keyword_query_engine.query(\n", "    \"Describe and summarize the interactions between Gatsby and Daisy\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "32ef656b-f477-4851-8a70-4071e38735ee", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The interactions between Gatsby and Daisy are characterized by a sense of tension and longing. Gatsby is visibly disappointed when Daisy expresses her dissatisfaction with their time together and insists that she didn't have a good time. He feels distant from her and struggles to make her understand his emotions. Gatsby dismisses the significance of the dance and instead focuses on his desire for Daisy to confess her love for him and leave Tom. He yearns for a deep connection with Daisy, but feels that she doesn't fully comprehend his feelings. These interactions highlight the complexities of their relationship and the challenges they face in rekindling their romance. The relevance score for these interactions is 8 out of 10.\n"]}], "source": ["print(response)"]}, {"cell_type": "markdown", "id": "65212ae9-7ac3-4d90-a9b7-0950e040ebdd", "metadata": {}, "source": ["## 定义路由器查询引擎\n"]}, {"cell_type": "code", "execution_count": null, "id": "ea43a659-3bde-4fb8-a534-36ba3b48406a", "metadata": {}, "outputs": [], "source": ["from llama_index.core.tools import QueryEngineTool\n", "\n", "\n", "keyword_tool = QueryEngineTool.from_defaults(\n", "    query_engine=keyword_query_engine,\n", "    description=\"Useful for answering questions about this essay\",\n", ")\n", "\n", "vector_tool = QueryEngineTool.from_defaults(\n", "    query_engine=vector_query_engine,\n", "    description=\"Useful for answering questions about this essay\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "c962d312-1d2d-4396-8e1a-071df493ebce", "metadata": {}, "outputs": [], "source": ["from llama_index.core.query_engine import RouterQueryEngine\n", "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n", "from llama_index.core.selectors import (\n", "    PydanticMultiSelector,\n", "    PydanticSingleSelector,\n", ")\n", "from llama_index.core.response_synthesizers import TreeSummarize\n", "\n", "TREE_SUMMARIZE_PROMPT_TMPL = (\n", "    \"Context information from multiple sources is below. Each source may or\"\n", "    \" may not have \\na relevance score attached to\"\n", "    \" it.\\n---------------------\\n{context_str}\\n---------------------\\nGiven\"\n", "    \" the information from multiple sources and their associated relevance\"\n", "    \" scores (if provided) and not prior knowledge, answer the question. If\"\n", "    \" the answer is not in the context, inform the user that you can't answer\"\n", "    \" the question.\\nQuestion: {query_str}\\nAnswer: \"\n", ")\n", "\n", "tree_summarize = TreeSummarize(\n", "    summary_template=PromptTemplate(TREE_SUMMARIZE_PROMPT_TMPL)\n", ")\n", "\n", "query_engine = RouterQueryEngine(\n", "    selector=LLMMultiSelector.from_defaults(),\n", "    query_engine_tools=[\n", "        keyword_tool,\n", "        vector_tool,\n", "    ],\n", "    summarizer=tree_summarize,\n", ")"]}, {"cell_type": "markdown", "id": "94e3310d-bfb3-4b12-b158-b905c01cb802", "metadata": {}, "source": ["## 使用查询进行实验\n"]}, {"cell_type": "code", "execution_count": null, "id": "c8b29879-0f9d-463c-a710-dd8dbf58ec20", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1590 request_id=b049001384d0e2f2d96e308903351ca3 response_code=200\n", "Selecting query engine 0: Useful for answering questions about this essay.\n", "Selecting query engine 1: Useful for answering questions about this essay.\n", "> Starting query: Describe and summarize the interactions between Gatsby and Daisy\n", "query keywords: ['interactions', 'summarize', 'describe', 'daisy', 'gatsby']\n", "> Extracted keywords: ['daisy', 'gatsby']\n", "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=75 request_id=3f76f611bb063605c3c2365437480f87 response_code=200\n", "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4482 request_id=597221bd776638356f16034c4d8ad2f6 response_code=200\n", "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5773 request_id=50a6030879054f470a1e45952b4b80b3 response_code=200\n", "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6478 request_id=9171e42c7ced18baedc77cc89ec7478c response_code=200\n", "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6166 request_id=f3218012e3f9a12e00daeee0b9b06f67 response_code=200\n", "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4808 request_id=ab6887cbec9a44c2342d6402e28129d6 response_code=200\n", "Combining responses from multiple query engines.\n", "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4506 request_id=5fd128dab043f58111521d19e7c4f59a response_code=200\n", "The interactions between Gatsby and Daisy are portrayed as intense, passionate, and filled with longing and desire. Gatsby is deeply in love with Daisy and throws extravagant parties in the hopes of winning her back. Despite Daisy's marriage to Tom Buchanan, they reconnect and begin an affair. They spend time together at Gatsby's lavish house and even plan to run away together. However, their relationship ends tragically when Daisy accidentally kills Tom's mistress, Myrtle, while driving Gatsby's car. Gatsby takes the blame for the accident and is later killed by Myrtle's husband. Overall, their interactions explore themes of love, wealth, and the pursuit of happiness.\n"]}], "source": ["response = await query_engine.aquery(\n", "    \"Describe and summarize the interactions between Gatsby and Daisy\"\n", ")\n", "print(response)"]}, {"cell_type": "code", "execution_count": null, "id": "48a13f7d-4073-4fdd-b783-cb62f5b28014", "metadata": {}, "outputs": [{"data": {"text/plain": ["[]"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["response.source_nodes"]}, {"cell_type": "code", "execution_count": null, "id": "d30f30e6-d34e-4c0e-aa22-c72ec6dc1c57", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Selecting query engine 0: Keywords: Gatsby, past, recapture.\n", "> Starting query: What part of his past is Gatsby trying to recapture?\n", "query keywords: ['gatsby', 'past', 'recapture']\n", "> Extracted keywords: ['gatsby', 'past']\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n", "KeyboardInterrupt\n", "\n"]}], "source": ["response = await query_engine.aquery(\n", "    \"What part of his past is Gatsby trying to recapture?\"\n", ")\n", "print(response)"]}], "metadata": {"kernelspec": {"display_name": "py38", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}