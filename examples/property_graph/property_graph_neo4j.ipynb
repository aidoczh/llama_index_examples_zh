{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Neo4j属性图索引\n", "\n", "Neo4j是一个生产级的图数据库，能够存储属性图，执行向量搜索、过滤等操作。\n", "\n", "最简单的入门方式是使用[Neo4j Aura](https://neo4j.com/cloud/platform/aura-graph-database/)提供的云托管实例。\n", "\n", "对于本笔记本，我们将介绍如何使用docker在本地运行数据库。\n", "\n", "如果您已经有现有的图数据库，请直接跳到本笔记本的末尾。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index llama-index-graph-stores-neo4j"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Docker设置\n", "\n", "要在本地启动Neo4j，请确保已安装docker。然后，您可以使用以下docker命令启动数据库\n", "\n", "```bash\n", "docker run \\\n", "    -p 7474:7474 -p 7687:7687 \\\n", "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n", "    --name neo4j-apoc \\\n", "    -e NEO4J_apoc_export_file_enabled=true \\\n", "    -e NEO4J_apoc_import_file_enabled=true \\\n", "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n", "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n", "    neo4j:latest\n", "```\n", "\n", "从这里，您可以在[http://localhost:7474/](http://localhost:7474/)打开数据库。在此页面上，您将被要求登录。使用默认的用户名/密码 `neo4j` 和 `neo4j`。\n", "\n", "第一次登录后，您将被要求更改密码。\n", "\n", "之后，您就可以准备创建您的第一个属性图了！\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 环境设置\n", "\n", "我们只需要进行一些环境设置就可以开始了。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "\n", "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 索引构建\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.graph_stores.neo4j import Neo4jPGStore\n", "\n", "graph_store = Neo4jPGStore(\n", "    username=\"neo4j\",\n", "    password=\"<password>\",\n", "    url=\"bolt://localhost:7687\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/Users/loganmarkewich/Library/Caches/pypoetry/virtualenvs/llama-index-bXUwlEfH-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n", "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 26.07it/s]\n", "Extracting paths from text: 100%|██████████| 22/22 [00:10<00:00,  2.10it/s]\n", "Extracting implicit paths: 100%|██████████| 22/22 [00:00<00:00, 31418.01it/s]\n", "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n", "Generating embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.05it/s]\n"]}], "source": ["from llama_index.core import PropertyGraphIndex\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "from llama_index.llms.openai import OpenAI\n", "\n", "index = PropertyGraphIndex.from_documents(\n", "    documents,\n", "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3),\n", "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n", "    property_graph_store=graph_store,\n", "    show_progress=True,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["现在图已经创建，我们可以通过访问[http://localhost:7474/](http://localhost:7474/)在UI中探索它。\n", "\n", "查看整个图的最简单方法是在顶部使用类似`\"match n=() return n\"`的cypher命令。\n", "\n", "要删除整个图，一个有用的命令是`\"match n=() detach delete n\"`。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 查询和检索\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Interleaf -> Got crushed by -> Moore's law\n", "Interleaf -> Made -> Scripting language\n", "Interleaf -> Had -> Smart people\n", "Interleaf -> Inspired by -> Emacs\n", "Interleaf -> Had -> Few years to live\n", "Interleaf -> Made -> Software\n", "Interleaf -> Had done -> Something bold\n", "Interleaf -> Added -> Scripting language\n", "Interleaf -> Built -> Impressive technology\n", "Interleaf -> Was -> Company\n", "Viaweb -> Was -> Profitable\n", "Viaweb -> Was -> Growing rapidly\n", "Viaweb -> Suggested -> Hospital\n", "Idea -> Was clear from -> Experience\n", "Idea -> Would have to be embodied as -> Company\n", "Painting department -> Seemed to be -> Rigorous\n"]}], "source": ["# 检索器", "retriever = index.as_retriever(", "    include_text=False,  # 在返回的节点中包含源文本，默认为True", ")", "", "nodes = retriever.retrieve(\"Interleaf和Viaweb发生了什么事情？\")", "", "for node in nodes:", "    print(node.text)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Interleaf had smart people and built impressive technology but got crushed by Moore's Law. Viaweb was profitable and growing rapidly.\n"]}], "source": ["query_engine = index.as_query_engine(include_text=True)\n", "\n", "response = query_engine.query(\"What happened at Interleaf and Viaweb?\")\n", "\n", "print(str(response))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 从现有图中加载\n", "\n", "如果你有一个已经存在的图（无论是使用LlamaIndex创建的还是其他方式创建的），我们可以连接并使用它！\n", "\n", "**注意：** 如果你的图是在LlamaIndex之外创建的，最有用的检索器将是[text to cypher](../../module_guides/indexing/lpg_index_guide.md#texttocypherretriever)或[cypher templates](../../module_guides/indexing/lpg_index_guide.md#cyphertemplateretriever)。其他检索器依赖于LlamaIndex插入的属性。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.graph_stores.neo4j import Neo4jPGStore\n", "from llama_index.core import PropertyGraphIndex\n", "from llama_index.embeddings.openai import OpenAIEmbedding\n", "from llama_index.llms.openai import OpenAI\n", "\n", "graph_store = Neo4jPGStore(\n", "    username=\"neo4j\",\n", "    password=\"794613852\",\n", "    url=\"bolt://localhost:7687\",\n", ")\n", "\n", "index = PropertyGraphIndex.from_existing(\n", "    property_graph_store=graph_store,\n", "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3),\n", "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["从这里开始，我们仍然可以插入更多的文档！\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import Document\n", "\n", "document = Document(text=\"LlamaIndex is great!\")\n", "\n", "index.insert(document)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Llamaindex -> Is -> Great\n"]}], "source": ["nodes = index.as_retriever(include_text=False).retrieve(\"LlamaIndex\")\n", "\n", "print(nodes[0].text)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["有关构建、检索和查询属性图的详细信息，请参阅[完整文档页面](../../module_guides/indexing/lpg_index_guide.md)。\n"]}], "metadata": {"kernelspec": {"display_name": "llama-index-bXUwlEfH-py3.11", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 2}