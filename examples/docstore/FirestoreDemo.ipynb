{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Firestore演示\n", "\n", "本指南向您展示如何直接使用由Google Firestore支持的`DocumentStore`抽象。通过将节点放入文档存储中，这使您能够在相同的基础文档存储上定义多个索引，而不是在索引之间复制数据。\n", "\n", "<a href=\"https://colab.research.google.com/github/jerryjliu/llama_index/blob/main/docs/docs/examples/docstore/FirestoreDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在Colab中打开\"/></a>\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["如果您在Colab上打开这个笔记本，您可能需要安装LlamaIndex 🦙。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%pip install llama-index-storage-docstore-firestore\n", "%pip install llama-index-storage-kvstore-firestore\n", "%pip install llama-index-storage-index-store-firestore\n", "%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install llama-index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import logging\n", "import sys\n", "\n", "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n", "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader, StorageContext\n", "from llama_index.core import VectorStoreIndex, SimpleKeywordTableIndex\n", "from llama_index.core import SummaryIndex\n", "from llama_index.core import ComposableGraph\n", "from llama_index.llms.openai import OpenAI\n", "from llama_index.core.response.notebook_utils import display_response\n", "from llama_index.core import Settings"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 下载数据\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 加载文档\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["reader = SimpleDirectoryReader(\"./data/paul_graham/\")\n", "documents = reader.load_data()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 解析到节点\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.core.node_parser import SentenceSplitter\n", "\n", "nodes = SentenceSplitter().get_nodes_from_documents(documents)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 添加到文档库\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llama_index.storage.kvstore.firestore import FirestoreKVStore\n", "from llama_index.storage.docstore.firestore import FirestoreDocumentStore\n", "from llama_index.storage.index_store.firestore import FirestoreIndexStore"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["kvstore = FirestoreKVStore()\n", "\n", "storage_context = StorageContext.from_defaults(\n", "    docstore=FirestoreDocumentStore(kvstore),\n", "    index_store=FirestoreIndexStore(kvstore),\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["storage_context.docstore.add_documents(nodes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 定义多个索引\n", "\n", "每个索引使用相同的基础节点。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["summary_index = SummaryIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["keyword_table_index = SimpleKeywordTableIndex(\n", "    nodes, storage_context=storage_context\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 注意：文档存储仍然具有相同的节点\n", "len(storage_context.docstore.docs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 测试保存和加载\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 注意：默认情况下，docstore和index_store会持久化到Firestore中\n", "# 注意：这里只需要将简单的向量存储持久化到磁盘中\n", "storage_context.persist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 记录索引ID\n", "list_id = summary_index.index_id  # 摘要索引ID\n", "vector_id = vector_index.index_id  # 向量索引ID\n", "keyword_id = keyword_table_index.index_id  # 关键词表索引ID"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "from llama_index.core import load_index_from_storage\n", "\n", "kvstore = FirestoreKVStore()\n", "\n", "# 重新创建存储上下文\n", "storage_context = StorageContext.from_defaults(\n", "    docstore=FirestoreDocumentStore(kvstore),\n", "    index_store=FirestoreIndexStore(kvstore),\n", ")\n", "\n", "# 加载索引\n", "summary_index = load_index_from_storage(\n", "    storage_context=storage_context, index_id=list_id\n", ")\n", "vector_index = load_index_from_storage(\n", "    storage_context=storage_context, vector_id=vector_id\n", ")\n", "keyword_table_index = load_index_from_storage(\n", "    storage_context=storage_context, keyword_id=keyword_id\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 测试一些查询语句\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["chatgpt = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n", "Settings.llm = chatgpt\n", "Settings.chunk_size = 1024"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = summary_index.as_query_engine()\n", "list_response = query_engine.query(\"What is a summary of this document?\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["display_response(list_response)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = vector_index.as_query_engine()\n", "vector_response = query_engine.query(\"What did the author do growing up?\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["display_response(vector_response)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_engine = keyword_table_index.as_query_engine()\n", "keyword_response = query_engine.query(\n", "    \"What did the author do after his time at YC?\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["display_response(keyword_response)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 4}