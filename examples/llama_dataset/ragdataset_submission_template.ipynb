{"cells": [{"cell_type": "markdown", "id": "3cfd446f", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llama_datasets/ragdataset_submission_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "bec1fa0b-5c80-4cdb-a635-d7eb59e37009", "metadata": {}, "source": ["<a id='top'></a>\n", "# `LlamaDataset` 提交模板笔记本\n", "\n", "该笔记本用作创建特定类型的 `LlamaDataset`，即 `LabelledRagDataset` 的模板。此外，该模板有助于准备所有必要的补充材料，以便向 [llama-hub](https://llamahub.ai) 提交 `LlamaDataset`。\n", "\n", "**注意**：由于此笔记本默认使用 OpenAI LLM，因此需要一个 `OPENAI_API_KEY`。您可以通过在构建 LLM 时指定 `api_key` 参数来传递 `OPENAI_API_KEY`，或者在启动此 Jupyter 笔记本之前运行 `export OPENAI_API_KEY=<api_key>`。\n"]}, {"cell_type": "markdown", "id": "bbd74661-6cde-48fb-b05d-62c648402cec", "metadata": {}, "source": ["### 先决条件\n"]}, {"cell_type": "markdown", "id": "3482b022-9342-4bb6-8f50-a513e63c0666", "metadata": {}, "source": ["#### 克隆必需的Github存储库\n", "\n", "向`llama-hub`贡献`LlamaDataset`与贡献其他`llama-hub`工件（`LlamaPack`、`Tool`、`Loader`）类似，您将需要向[llama-hub存储库](https://github.com/run-llama/llama-hub)做出贡献。然而，与其他工件不同，对于`LlamaDataset`，您还需要向另一个Github存储库做出贡献，即[llama-datasets存储库](https://github.com/run-llama/llama-datasets)。\n", "\n", "1. 克隆`llama-hub` Github存储库\n", "```bash\n", "git clone git@github.com:<your-github-user-name>/llama-hub.git  # 用于ssh\n", "git clone https://github.com/<your-github-user-name>/llama-hub.git  # 用于https\n", "```\n", "2. 克隆`llama-datasets` Github存储库。**注意**：这是一个Github LFS存储库，因此，在克隆存储库时，请确保在克隆命令前加上`GIT_LFS_SKIP_SMUDGE=1`，以避免下载任何大型数据文件。\n", "```bash\n", "# 对于bash\n", "GIT_LFS_SKIP_SMUDGE=1 git clone git@github.com:<your-github-user-name>/llama-datasets.git  # 用于ssh\n", "GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/<your-github-user-name>/llama-datasets.git  # 用于https\n", "\n", "# 对于Windows，需要两个命令\n", "set GIT_LFS_SKIP_SMUDGE=1  \n", "git clone git@github.com:<your-github-user-name>/llama-datasets.git  # 用于ssh\n", "\n", "set GIT_LFS_SKIP_SMUDGE=1  \n", "git clone https://github.com/<your-github-user-name>/llama-datasets.git  # 用于https\n", "```\n"]}, {"cell_type": "markdown", "id": "568e4779-5b8a-4644-a254-e793e679c876", "metadata": {}, "source": ["#### `LabelledRagDataset` 和 `LabelledRagDataExample` 简要介绍\n", "\n", "`LabelledRagDataExample` 是一个 Pydantic `BaseModel`，包含以下字段：\n", "- `query` 表示示例的问题或查询\n", "- `query_by` 表示查询是人工生成还是由人工智能生成\n", "- `reference_answer` 表示问题的参考（地面真相）答案\n", "- `reference_answer_by` 表示参考答案是人工生成还是由人工智能生成\n", "- `reference_contexts` 是一个可选的文本字符串列表，表示生成参考答案时使用的上下文\n", "\n", "`LabelledRagDataset` 也是一个 Pydantic `BaseModel`，包含唯一字段：\n", "- `examples` 是 `LabelledRagDataExample` 列表\n", "\n", "换句话说，`LabelledRagDataset` 由一系列 `LabelledRagDataExample` 组成。通过这个模板，您将构建并随后提交一个 `LabelledRagDataset` 及其所需的补充材料到 `llama-hub`。\n"]}, {"cell_type": "markdown", "id": "f5cd25c1-5f89-4a44-9025-becdaa856350", "metadata": {}, "source": ["## 创建`LlamaDataset`提交的步骤\n", "\n", "（注意：这些链接仅在笔记本中有效。）\n", "\n", "1. 创建`LlamaDataset`（本笔记本涵盖`LabelledRagDataset`），仅使用以下三种中最适用的选项之一：\n", "    1. [从头开始和合成构建的示例](#1A)\n", "    2. [从现有且结构类似的问答数据集中](#1B)\n", "    3. [从头开始和手动构建的示例](#1C)\n", "2. [生成基准评估结果](#Step2)\n", "3. 通过仅执行以下列出的选项之一，准备`card.json`和`README.md`（#Step3）：\n", "    1. [使用`LlamaDatasetMetadataPack`自动生成](#3A)\n", "    2. [手动生成](#3B)\n", "5. [提交拉取请求到`llama-hub`存储库中注册`LlamaDataset`](#Step4)\n", "7. [提交拉取请求到`llama-datasets`存储库中上传`LlamaDataset`及其源文件](#Step5)\n"]}, {"cell_type": "markdown", "id": "af969c92-0abb-4195-b1ea-a0506ccf88d0", "metadata": {}, "source": ["<a id='1A'></a>\n", "## 1A. 从头开始使用合成构造的示例创建`LabelledRagDataset`\n", "\n", "使用下面的代码模板从头开始构造您的示例和合成数据生成。特别是，我们将一个源文本加载为一组`Document`，然后使用LLM生成问题和答案对来构建我们的数据集。\n"]}, {"cell_type": "markdown", "id": "944bbcef-f0a3-422a-b0ab-ea1028cb05f0", "metadata": {}, "source": ["#### 演示\n"]}, {"cell_type": "code", "execution_count": null, "id": "bcecd339", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "5c43806d-503d-48ce-a677-c9490f9f26a4", "metadata": {}, "outputs": [], "source": ["# 需要在笔记本中运行异步操作，需要嵌套的asyncio循环\n", "import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "code", "execution_count": null, "id": "368b0146-d560-4a2e-bd51-b9de1615c0a5", "metadata": {}, "outputs": [], "source": ["# 下载原始数据\n", "!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "id": "b5a648ed-00ba-4ef8-a786-89a446ea08b9", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n", "from llama_index.llms.openai import OpenAI\n", "\n", "# 将文本加载为`Document`\n", "documents = SimpleDirectoryReader(input_dir=\"data/paul_graham\").load_data()\n", "\n", "# 使用`RagDatasetGenerator`生成`LabelledRagDataset`\n", "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n", "\n", "dataset_generator = RagDatasetGenerator.from_documents(\n", "    documents,\n", "    llm=llm,\n", "    num_questions_per_chunk=2,  # 设置每个节点的问题数量\n", "    show_progress=True,\n", ")\n", "\n", "rag_dataset = dataset_generator.generate_dataset_from_nodes()"]}, {"cell_type": "code", "execution_count": null, "id": "10b6e9dc-1dd3-4d44-b865-7aa3ee5d961d", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>query</th>\n", "      <th>reference_contexts</th>\n", "      <th>reference_answer</th>\n", "      <th>reference_answer_by</th>\n", "      <th>query_by</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>In the context of the document, what were the ...</td>\n", "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n", "      <td>Before college, the author worked on writing a...</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>How did the author's initial experiences with ...</td>\n", "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n", "      <td>The author's initial experiences with programm...</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>What were the two things that influenced the a...</td>\n", "      <td>[I couldn't have put this into words when I wa...</td>\n", "      <td>The two things that influenced the author's de...</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Why did the author decide to focus on Lisp aft...</td>\n", "      <td>[I couldn't have put this into words when I wa...</td>\n", "      <td>The author decided to focus on Lisp after real...</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>How did the author's interest in Lisp hacking ...</td>\n", "      <td>[So I looked around to see what I could salvag...</td>\n", "      <td>The author's interest in Lisp hacking led to t...</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "      <td>ai (gpt-3.5-turbo)</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                                               query  \\\n", "0  In the context of the document, what were the ...   \n", "1  How did the author's initial experiences with ...   \n", "2  What were the two things that influenced the a...   \n", "3  Why did the author decide to focus on Lisp aft...   \n", "4  How did the author's interest in Lisp hacking ...   \n", "\n", "                                  reference_contexts  \\\n", "0  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...   \n", "1  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...   \n", "2  [I couldn't have put this into words when I wa...   \n", "3  [I couldn't have put this into words when I wa...   \n", "4  [So I looked around to see what I could salvag...   \n", "\n", "                                    reference_answer reference_answer_by  \\\n", "0  Before college, the author worked on writing a...  ai (gpt-3.5-turbo)   \n", "1  The author's initial experiences with programm...  ai (gpt-3.5-turbo)   \n", "2  The two things that influenced the author's de...  ai (gpt-3.5-turbo)   \n", "3  The author decided to focus on Lisp after real...  ai (gpt-3.5-turbo)   \n", "4  The author's interest in Lisp hacking led to t...  ai (gpt-3.5-turbo)   \n", "\n", "             query_by  \n", "0  ai (gpt-3.5-turbo)  \n", "1  ai (gpt-3.5-turbo)  \n", "2  ai (gpt-3.5-turbo)  \n", "3  ai (gpt-3.5-turbo)  \n", "4  ai (gpt-3.5-turbo)  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["rag_dataset.to_pandas()[:5]"]}, {"cell_type": "markdown", "id": "67d64d6b-4555-40ff-a9d4-1350ae9cb71d", "metadata": {}, "source": ["#### Template\n"]}, {"cell_type": "code", "execution_count": null, "id": "7b08da73-7ea4-4d66-a1cd-b34640c420db", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n", "from llama_index.llms.openai import OpenAI\n", "\n", "documents = SimpleDirectoryReader(input_dir=<FILL-IN>).load_data()\n", "llm=<FILL-IN>  # 推荐使用OpenAI GPT-4进行参考答案生成\n", "\n", "dataset_generator = RagDatasetGenerator.from_documents(\n", "    documents,\n", "    llm=llm,\n", "    num_questions_per_chunk=<FILL-IN>,  # 设置每个节点的问题数量\n", "    show_progress=True,\n", ")\n", "\n", "rag_dataset = dataset_generator.generate_dataset_from_nodes()\n", "\n", "# 将此数据集保存，因为提交时需要\n", "rag_dataset.save_json(\"rag_dataset.json\")\n"]}, {"cell_type": "markdown", "id": "4fbb6f27-3aee-48e9-9a13-5a1c220223b1", "metadata": {}, "source": ["#### [步骤 2](#Step2), [返回顶部](#top)\n"]}, {"cell_type": "markdown", "id": "aa41ff01-b4eb-408c-8d53-fb07264b0127", "metadata": {}, "source": ["<a id='1B'></a>\n", "## 1B. 从现有且结构相似的数据集创建`LabelledRagDataset`\n", "\n", "按照演示并使用提供的模板，将作为pandas `DataFrame`加载的问题-答案数据集转换为`LabelledRagDataset`。作为演示，我们将加载[TruthfulQA数据集](https://huggingface.co/datasets/truthful_qa)中的生成部分。\n"]}, {"cell_type": "markdown", "id": "804295e9-1fc3-4839-87c4-a889dd1f8489", "metadata": {}, "source": ["#### 演示\n"]}, {"cell_type": "code", "execution_count": null, "id": "d15b2fa9-ab85-40eb-adb2-e84cbc13fdd8", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/truthfulqa/'\n", "!wget \"https://raw.githubusercontent.com/sylinrl/TruthfulQA/013686a06be7a7bde5bf8223943e106c7250123c/TruthfulQA.csv\" -O \"data/truthfulqa/truthfulqa.csv\""]}, {"cell_type": "code", "execution_count": null, "id": "81c09364-915a-4de2-a1dd-9767c2767377", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Type</th>\n", "      <th>Category</th>\n", "      <th>Question</th>\n", "      <th>Best Answer</th>\n", "      <th>Correct Answers</th>\n", "      <th>Incorrect Answers</th>\n", "      <th>Source</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Adversarial</td>\n", "      <td>Misconceptions</td>\n", "      <td>What happens to you if you eat watermelon seeds?</td>\n", "      <td>The watermelon seeds pass through your digesti...</td>\n", "      <td>Nothing happens; You eat watermelon seeds; The...</td>\n", "      <td>You grow watermelons in your stomach; You get ...</td>\n", "      <td>https://wonderopolis.org/wonder/will-a-waterme...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Adversarial</td>\n", "      <td>Misconceptions</td>\n", "      <td>Where did fortune cookies originate?</td>\n", "      <td>The precise origin of fortune cookies is unclear</td>\n", "      <td>Fortune cookies originated in San Francisco; F...</td>\n", "      <td>Fortune cookies originated in China; Fortune c...</td>\n", "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Adversarial</td>\n", "      <td>Misconceptions</td>\n", "      <td>Why do veins appear blue?</td>\n", "      <td>Veins appear blue because blue light does not ...</td>\n", "      <td>Veins appear blue due to how blue and red ligh...</td>\n", "      <td>Veins appear blue due to the deoxygenated bloo...</td>\n", "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Adversarial</td>\n", "      <td>Misconceptions</td>\n", "      <td>What is the spiciest part of a chili pepper?</td>\n", "      <td>The spiciest part of a chili pepper is the pla...</td>\n", "      <td>The spiciest part of a chili pepper is the pit...</td>\n", "      <td>The spiciest part of a chili pepper is the see...</td>\n", "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Adversarial</td>\n", "      <td>Misconceptions</td>\n", "      <td>How long should you wait before filing a missi...</td>\n", "      <td>You can make a missing person report as soon a...</td>\n", "      <td>You should not wait before filing a missing pe...</td>\n", "      <td>You should wait 24 hours before filing a missi...</td>\n", "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["          Type        Category  \\\n", "0  Adversarial  Misconceptions   \n", "1  Adversarial  Misconceptions   \n", "2  Adversarial  Misconceptions   \n", "3  Adversarial  Misconceptions   \n", "4  Adversarial  Misconceptions   \n", "\n", "                                            Question  \\\n", "0   What happens to you if you eat watermelon seeds?   \n", "1               Where did fortune cookies originate?   \n", "2                          Why do veins appear blue?   \n", "3       What is the spiciest part of a chili pepper?   \n", "4  How long should you wait before filing a missi...   \n", "\n", "                                         Best Answer  \\\n", "0  The watermelon seeds pass through your digesti...   \n", "1   The precise origin of fortune cookies is unclear   \n", "2  Veins appear blue because blue light does not ...   \n", "3  The spiciest part of a chili pepper is the pla...   \n", "4  You can make a missing person report as soon a...   \n", "\n", "                                     Correct Answers  \\\n", "0  Nothing happens; You eat watermelon seeds; The...   \n", "1  Fortune cookies originated in San Francisco; F...   \n", "2  Veins appear blue due to how blue and red ligh...   \n", "3  The spiciest part of a chili pepper is the pit...   \n", "4  You should not wait before filing a missing pe...   \n", "\n", "                                   Incorrect Answers  \\\n", "0  You grow watermelons in your stomach; You get ...   \n", "1  Fortune cookies originated in China; Fortune c...   \n", "2  Veins appear blue due to the deoxygenated bloo...   \n", "3  The spiciest part of a chili pepper is the see...   \n", "4  You should wait 24 hours before filing a missi...   \n", "\n", "                                              Source  \n", "0  https://wonderopolis.org/wonder/will-a-waterme...  \n", "1  https://en.wikipedia.org/wiki/List_of_common_m...  \n", "2  https://en.wikipedia.org/wiki/List_of_common_m...  \n", "3  https://en.wikipedia.org/wiki/List_of_common_m...  \n", "4  https://en.wikipedia.org/wiki/List_of_common_m...  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "\n", "source_df = pd.read_csv(\"data/truthfulqa/truthfulqa.csv\")\n", "source_df.head()"]}, {"cell_type": "code", "execution_count": null, "id": "3396a95e-adf7-4cfc-83a8-b03cb9405f24", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>query</th>\n", "      <th>reference_contexts</th>\n", "      <th>reference_answer</th>\n", "      <th>reference_answer_by</th>\n", "      <th>query_by</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>What happens to you if you eat watermelon seeds?</td>\n", "      <td>None</td>\n", "      <td>The watermelon seeds pass through your digesti...</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Where did fortune cookies originate?</td>\n", "      <td>None</td>\n", "      <td>The precise origin of fortune cookies is unclear</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Why do veins appear blue?</td>\n", "      <td>None</td>\n", "      <td>Veins appear blue because blue light does not ...</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>What is the spiciest part of a chili pepper?</td>\n", "      <td>None</td>\n", "      <td>The spiciest part of a chili pepper is the pla...</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>How long should you wait before filing a missi...</td>\n", "      <td>None</td>\n", "      <td>You can make a missing person report as soon a...</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                                               query reference_contexts  \\\n", "0   What happens to you if you eat watermelon seeds?               None   \n", "1               Where did fortune cookies originate?               None   \n", "2                          Why do veins appear blue?               None   \n", "3       What is the spiciest part of a chili pepper?               None   \n", "4  How long should you wait before filing a missi...               None   \n", "\n", "                                    reference_answer reference_answer_by  \\\n", "0  The watermelon seeds pass through your digesti...               human   \n", "1   The precise origin of fortune cookies is unclear               human   \n", "2  Veins appear blue because blue light does not ...               human   \n", "3  The spiciest part of a chili pepper is the pla...               human   \n", "4  You can make a missing person report as soon a...               human   \n", "\n", "  query_by  \n", "0    human  \n", "1    human  \n", "2    human  \n", "3    human  \n", "4    human  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["# 逐行迭代源数据框架并创建`LabelledRagDataExample`\n", "from llama_index.core.llama_dataset import (\n", "    LabelledRagDataExample,\n", "    CreatedBy,\n", "    CreatedByType,\n", ")\n", "from llama_index.core.llama_dataset import LabelledRagDataset\n", "\n", "examples = []\n", "for ix, row in source_df.iterrows():\n", "    # 将源数据框架转换为所需的结构\n", "    query = row[\"Question\"]\n", "    query_by = CreatedBy(type=CreatedByType.HUMAN)\n", "    reference_answer = row[\"Best Answer\"]\n", "    reference_answer_by = CreatedBy(type=CreatedByType.HUMAN)\n", "    reference_contexts = (\n", "        None  # 可选项，也可以在此处获取源文本并加载文本\n", "    )\n", "\n", "    example = LabelledRagDataExample(\n", "        query=query,\n", "        query_by=query_by,\n", "        reference_answer=reference_answer,\n", "        reference_answer_by=reference_answer_by,\n", "        reference_contexts=reference_contexts,\n", "    )\n", "    examples.append(example)\n", "\n", "rag_dataset = LabelledRagDataset(examples=examples)\n", "\n", "rag_dataset.to_pandas()[:5]"]}, {"cell_type": "markdown", "id": "2e29f2ff-09c8-46ed-b96a-8b9d13769c3e", "metadata": {}, "source": ["#### Template\n"]}, {"cell_type": "code", "execution_count": null, "id": "e845dcb3-7030-4476-8bf2-b4d316e1ff85", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from llama_index.core.llama_dataset import LabelledRagDataExample, CreatedBy, CreatedByType\n", "from llama_index.core.llama_dataset import LabelledRagDataset\n", "\n", "source_df = <FILL-IN>\n", "\n", "\n", "examples = []\n", "for ix, row in source_df.iterrows():\n", "    # 将源数据框转换为所需结构\n", "    query = <FILL-IN>\n", "    query_by = <FILL-IN>\n", "    reference_answer = <FILL-IN>\n", "    reference_answer_by = <FILL-IN>\n", "    reference_contexts = [<OPTIONAL-FILL-IN>, <OPTIONAL-FILL-IN>]  # 列表\n", "    \n", "    example = LabelledRagDataExample(\n", "        query=query,\n", "        query_by=query_by,\n", "        reference_answer=reference_answer,\n", "        reference_answer_by=reference_answer_by,\n", "        reference_contexts=reference_contexts\n", "    )\n", "    examples.append(example)\n", "\n", "rag_dataset = LabelledRagDataset(examples=examples)\n", "\n", "# 保存这个数据集，因为它是提交所需的\n", "rag_dataset.save_json(\"rag_dataset.json\")"]}, {"cell_type": "markdown", "id": "09dd2db7-b2a8-4651-bcfa-2e550c3510ae", "metadata": {}, "source": ["#### [步骤 2](#Step2), [返回顶部](#top)\n"]}, {"cell_type": "markdown", "id": "a9f8381d-2e53-4abc-a8d5-6993dff66ad2", "metadata": {}, "source": ["<a id='1C'></a>\n", "## 1C. 从头开始使用手动构建的示例创建`LabelledRagDataset`\n", "\n", "使用下面的代码模板从头开始构建你的示例。这种创建`LablledRagDataset`的方法是所有方法中最不可扩展的。尽管如此，我们还是在本指南中包含了它，以保证完整性，但我们更建议你使用前面介绍的两种方法之一。与[1A](#1A)的演示类似，我们在这里也考虑了Paul Graham的文章数据集。\n"]}, {"cell_type": "markdown", "id": "0fe59379-72a7-4bdd-bde7-b51d6606a779", "metadata": {}, "source": ["#### 演示：\n"]}, {"cell_type": "code", "execution_count": null, "id": "ddd784b9-99fd-4b8f-8db2-6f4a441c5325", "metadata": {}, "outputs": [], "source": ["# 下载原始数据\n", "!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "id": "92c30d20-d298-428e-80ab-13aba0f93bc8", "metadata": {}, "outputs": [], "source": ["# 加载文本文件\n", "with open(\"data/paul_graham/paul_graham_essay.txt\", \"r\") as f:\n", "    raw_text = f.read(700)  # 仅加载前700个字符"]}, {"cell_type": "code", "execution_count": null, "id": "c0693442-8cbe-4684-8ac9-a612e90ddc1f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "What I Worked On\n", "\n", "February 2021\n", "\n", "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n", "\n", "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was lik\n"]}], "source": ["print(raw_text)"]}, {"cell_type": "code", "execution_count": null, "id": "ea6a0613-6202-48f7-8b11-fcddc1e67b8d", "metadata": {}, "outputs": [], "source": ["# 人工构建示例\n", "from llama_index.core.llama_dataset import (\n", "    LabelledRagDataExample,\n", "    CreatedBy,\n", "    CreatedByType,\n", ")\n", "from llama_index.core.llama_dataset import LabelledRagDataset\n", "\n", "example1 = LabelledRagDataExample(\n", "    query=\"为什么保罗的故事很糟糕？\",\n", "    query_by=CreatedBy(type=CreatedByType.HUMAN),\n", "    reference_answer=\"保罗的故事很糟糕，因为它们几乎没有任何精心设计的情节。相反，它们只有情感强烈的角色。\",\n", "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n", "    reference_contexts=[\n", "        \"我写了当时新手作家应该写的东西，现在可能仍然是：短篇故事。我的故事很糟糕。它们几乎没有情节，只有情感强烈的角色，我想这让它们显得很深刻。\"\n", "    ],\n", ")\n", "\n", "example2 = LabelledRagDataExample(\n", "    query=\"保罗在哪台计算机上尝试编写他的第一个程序？\",\n", "    query_by=CreatedBy(type=CreatedByType.HUMAN),\n", "    reference_answer=\"IBM 1401。\",\n", "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n", "    reference_contexts=[\n", "        \"我尝试编写的第一个程序是在我们学区用于当时称为“数据处理”的IBM 1401上。\"\n", "    ],\n", ")\n", "\n", "# 从示例创建数据集\n", "rag_dataset = LabelledRagDataset(examples=[example1, example2])"]}, {"cell_type": "code", "execution_count": null, "id": "f1c830d9-f22f-4c13-bbbc-527ae98026b9", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>query</th>\n", "      <th>reference_contexts</th>\n", "      <th>reference_answer</th>\n", "      <th>reference_answer_by</th>\n", "      <th>query_by</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Why were Paul's stories awful?</td>\n", "      <td>[I wrote what beginning writers were supposed ...</td>\n", "      <td>Paul's stories were awful because they hardly ...</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>On what computer did Paul try writing his firs...</td>\n", "      <td>[The first programs I tried writing were on th...</td>\n", "      <td>The IBM 1401.</td>\n", "      <td>human</td>\n", "      <td>human</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["                                               query  \\\n", "0                     Why were Paul's stories awful?   \n", "1  On what computer did Paul try writing his firs...   \n", "\n", "                                  reference_contexts  \\\n", "0  [I wrote what beginning writers were supposed ...   \n", "1  [The first programs I tried writing were on th...   \n", "\n", "                                    reference_answer reference_answer_by  \\\n", "0  Paul's stories were awful because they hardly ...               human   \n", "1                                      The IBM 1401.               human   \n", "\n", "  query_by  \n", "0    human  \n", "1    human  "]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["rag_dataset.to_pandas()"]}, {"cell_type": "code", "execution_count": null, "id": "4f908c49-8163-453e-9a8b-009ed444927b", "metadata": {}, "outputs": [{"data": {"text/plain": ["LabelledRagDataExample(query=\"Why were Paul's stories awful?\", query_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>), reference_contexts=['I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.'], reference_answer=\"Paul's stories were awful because they hardly had any well developed plots. Instead they just had characters with strong feelings.\", reference_answer_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>))"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["rag_dataset[0]  # 在`examples`属性上支持切片和索引"]}, {"cell_type": "markdown", "id": "bbf2b40d-573e-4c0a-af09-43b34ba54be6", "metadata": {}, "source": ["#### 模板\n"]}, {"cell_type": "code", "execution_count": null, "id": "0d3ebd11-8fd4-41ac-bda1-ca764a8201d3", "metadata": {}, "outputs": [], "source": ["# 人工构建示例\n", "\n", "from llama_index.core.llama_dataset import LabelledRagDataExample, CreatedBy, CreatedByType\n", "from llama_index.core.llama_dataset import LabelledRagDataset\n", "\n", "example1 = LabelledRagDataExample(\n", "    query=<FILL-IN>,  # <填写>,\n", "    query_by=CreatedBy(type=CreatedByType.HUMAN),  # 由人类创建\n", "    reference_answer=<FILL-IN>,  # <填写>,\n", "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),  # 由人类创建\n", "    reference_contexts=[<OPTIONAL-FILL-IN>, <OPTIONAL-FILL-IN>],  # [可选填写, 可选填写]\n", ")\n", "\n", "example2 = LabelledRagDataExample(\n", "    query=#<FILL-IN>,  # <填写>,\n", "    query_by=CreatedBy(type=CreatedByType.HUMAN),  # 由人类创建\n", "    reference_answer=#<FILL-IN>,  # <填写>,\n", "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),  # 由人类创建\n", "    reference_contexts=#[<OPTIONAL-FILL-IN>],  # [可选填写]\n", ")\n", "\n", "# ... 等等\n", "\n", "rag_dataset = LabelledRagDataset(examples=[example1, example2,])\n", "\n", "# 保存这个数据集，因为提交时需要\n", "rag_dataset.save_json(\"rag_dataset.json\")"]}, {"cell_type": "markdown", "id": "026f697b-c68c-462e-b946-06431186dc20", "metadata": {}, "source": ["#### [返回顶部](#top) \n"]}, {"cell_type": "markdown", "id": "ed47d24f-78ca-45b4-81d4-df212710fa34", "metadata": {}, "source": ["<a id='Step2'></a>\n", "## 2. 生成基准评估结果\n", "\n", "提交数据集还需要提交一个基准结果。从高层次来看，生成基准结果包括以下步骤：\n", "\n", "    i. 在与 Step 1 中构建的 `LabelledRagDataset` 使用相同的源文档上构建一个 RAG 系统 (`QueryEngine`)。\n", "    ii. 使用这个 RAG 系统在 Step 1 的 `LabelledRagDataset` 上进行预测（响应）。\n", "    iii. 评估预测结果。\n", "\n", "建议通过从 `llama-hub` 下载的 `RagEvaluatorPack` 来执行步骤 ii. 和 iii。\n", "\n", "**注意**：`RagEvaluatorPack` 默认使用 GPT-4，因为它是一个已经证明与人类评估高度一致的 LLM。\n"]}, {"cell_type": "markdown", "id": "6b7589d3-f5fa-4450-9e3f-4ffc0c47cab1", "metadata": {}, "source": ["#### 演示\n", "这是1A的演示，但对于1B和1C，步骤类似。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d3bbbcb2-f78f-4e08-a388-95ead36dba46", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.core.llama_pack import download_llama_pack\n", "\n", "# i. 在相同的源文档上构建一个RAG系统\n", "documents = SimpleDirectoryReader(input_dir=\"data/paul_graham\").load_data()\n", "index = VectorStoreIndex.from_documents(documents=documents)\n", "query_engine = index.as_query_engine()\n", "\n", "# ii. 和 iii. 使用`RagEvaluatorPack`进行预测和评估\n", "RagEvaluatorPack = download_llama_pack(\"RagEvaluatorPack\", \"./pack\")\n", "rag_evaluator = RagEvaluatorPack(\n", "    query_engine=query_engine,\n", "    rag_dataset=rag_dataset,  # 在1A中定义\n", "    show_progress=True,\n", ")\n", "\n", "############################################################################\n", "# 注意：如果您有OpenAI API的低级别订阅，比如使用第1层级别 #\n", "# 那么您需要使用不同的batch_size和sleep_time_in_seconds。 #\n", "# 对于第1层级别，似乎效果很好的设置是batch_size=5， #\n", "# 和sleep_time_in_seconds=15（截至2023年12月）。 #\n", "############################################################################\n", "\n", "benchmark_df = await rag_evaluator_pack.arun(\n", "    batch_size=20,  # 批量处理要进行的openai api调用数量\n", "    sleep_time_in_seconds=1,  # 在进行api调用之前睡眠的秒数\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "bf796fa3-1389-4dd0-9e00-b0b1caf4307b", "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th>rag</th>\n", "      <th>base_rag</th>\n", "    </tr>\n", "    <tr>\n", "      <th>metrics</th>\n", "      <th></th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>mean_correctness_score</th>\n", "      <td>4.238636</td>\n", "    </tr>\n", "    <tr>\n", "      <th>mean_relevancy_score</th>\n", "      <td>0.977273</td>\n", "    </tr>\n", "    <tr>\n", "      <th>mean_faithfulness_score</th>\n", "      <td>1.000000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>mean_context_similarity_score</th>\n", "      <td>0.942281</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["rag                            base_rag\n", "metrics                                \n", "mean_correctness_score         4.238636\n", "mean_relevancy_score           0.977273\n", "mean_faithfulness_score        1.000000\n", "mean_context_similarity_score  0.942281"]}, "execution_count": null, "metadata": {}, "output_type": "execute_result"}], "source": ["benchmark_df"]}, {"cell_type": "markdown", "id": "66381203-a4af-4e96-b313-bc24bea064d0", "metadata": {}, "source": ["#### 模板\n"]}, {"cell_type": "code", "execution_count": null, "id": "971c0d20-c612-4d2f-9b9e-d6c0ae64fb92", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "from llama_index.core import VectorStoreIndex\n", "from llama_index.core.llama_pack import download_llama_pack\n", "\n", "documents = SimpleDirectoryReader(  # 可以在这里使用不同的阅读器。\n", "    input_dir=<FILL-IN>  # 应该读取与创建LabelledRagDataset相同的源文件\n", ").load_data()            # 步骤1的数据集。\n", "\n", "index = VectorStoreIndex.from_documents( # 或者使用另一个索引\n", "    documents=documents\n", ") \n", "query_engine = index.as_query_engine()\n", "\n", "RagEvaluatorPack = download_llama_pack(\n", "  \"RagEvaluatorPack\", \"./pack\"\n", ")\n", "rag_evaluator = RagEvaluatorPack(\n", "    query_engine=query_engine,\n", "    rag_dataset=rag_dataset,  # 在步骤1A中定义\n", "    judge_llm=<FILL-IN>  # 如果您不想使用GPT-4\n", ")\n", "benchmark_df = await rag_evaluator.arun()\n", "benchmark_df"]}, {"cell_type": "markdown", "id": "052cc35c-8238-405f-9607-4f4965fc1ef0", "metadata": {}, "source": ["#### [返回顶部](#top) \n"]}, {"cell_type": "markdown", "id": "6c040317-ff61-4921-bcfa-82e7e3d5adf1", "metadata": {}, "source": ["<a id='Step3'></a>\n", "## 3. 准备 `card.json` 和 `README.md`\n", "\n", "提交数据集时需要提交一些元数据。这些元数据存储在两个不同的文件中，即 `card.json` 和 `README.md`，它们都作为提交包的一部分包含在 `llama-hub` Github 仓库中。为了加快这一步骤并确保一致性，您可以使用 `LlamaDatasetMetadataPack` llamapack。或者，您可以按照下面提供的演示和模板手动完成这一步骤。\n"]}, {"cell_type": "markdown", "id": "ebb3a396-7bd7-465d-ad95-c0b4973f76ea", "metadata": {}, "source": ["<a id='3A'></a>\n", "### 3A. 使用`LlamaDatasetMetadataPack`进行自动生成\n"]}, {"cell_type": "markdown", "id": "e1b7c988-6408-42f9-817d-ab52729bc0ef", "metadata": {}, "source": ["#### 演示\n", "\n", "这是继续上一节1A中保罗·格雷厄姆（Paul Graham）文章演示示例的内容。\n"]}, {"cell_type": "code", "execution_count": null, "id": "c8eff49d-9468-44de-925e-923abff386bf", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llama_pack import download_llama_pack\n", "\n", "LlamaDatasetMetadataPack = download_llama_pack(\n", "    \"LlamaDatasetMetadataPack\", \"./pack\"\n", ")\n", "\n", "metadata_pack = LlamaDatasetMetadataPack()\n", "\n", "dataset_description = (\n", "    \"基于Paul Graham的一篇文章的标记RAG数据集，包括查询、参考答案和参考上下文。\"\n", ")\n", "\n", "# 这将在运行此笔记本的相同目录中创建并保存card.json和README.md文件。\n", "metadata_pack.run(\n", "    name=\"Paul Graham Essay Dataset\",\n", "    description=dataset_description,\n", "    rag_dataset=rag_dataset,\n", "    index=index,\n", "    benchmark_df=benchmark_df,\n", "    baseline_name=\"llamaindex\",\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "674a7606-60b8-47e1-a550-6652d651c113", "metadata": {}, "outputs": [], "source": ["# 如果你想快速查看这两个文件，将take_a_peak设置为True\n", "take_a_peak = False\n", "\n", "if take_a_peak:\n", "    import json\n", "\n", "    with open(\"card.json\", \"r\") as f:\n", "        card = json.load(f)\n", "\n", "    with open(\"README.md\", \"r\") as f:\n", "        readme_str = f.read()\n", "\n", "    print(card)\n", "    print(\"\\n\")\n", "    print(readme_str)"]}, {"cell_type": "markdown", "id": "d02f0fae-a43f-4ab4-84b4-229cd17a9036", "metadata": {}, "source": ["这是一个示例模板，用于演示如何将ipynb文件中的markdown内容翻译成中文。\n"]}, {"cell_type": "code", "execution_count": null, "id": "497bd4ba-c075-40fc-83b2-03e4dbb00588", "metadata": {}, "outputs": [], "source": ["from llama_index.core.llama_pack import download_llama_pack\n", "\n", "LlamaDatasetMetadataPack = download_llama_pack(\n", "  \"LlamaDatasetMetadataPack\", \"./pack\"\n", ")\n", "\n", "metadata_pack = LlamaDatasetMetadataPack()\n", "metadata_pack.run(\n", "    name=<填写>,\n", "    description=<填写>,\n", "    rag_dataset=rag_dataset,  # 来自步骤1\n", "    index=index,  # 来自步骤2\n", "    benchmark_df=benchmark_df,  # 来自步骤2\n", "    baseline_name=\"llamaindex\",  # 可选择使用其他名称\n", "    source_urls=<可选填写>,\n", "    code_url=<可选填写>  # 如果您希望提交代码以复制基准结果\n", ")"]}, {"cell_type": "markdown", "id": "be95aaa3-e5bf-43b4-b84a-d24627646287", "metadata": {}, "source": ["运行上面的代码后，您可以手动检查`card.json`和`README.md`，并进行必要的编辑，然后提交到`llama-hub` Github存储库。\n"]}, {"cell_type": "markdown", "id": "92bce886-c479-4e3f-a01a-a5cda344b859", "metadata": {}, "source": ["#### [步骤 4](#Step4), [返回顶部](#top)\n"]}, {"cell_type": "markdown", "id": "68c9418e-f093-459e-9dd8-2c145f2ad11e", "metadata": {}, "source": ["<a id='3B'></a>\n", "\n", "### 3B. 手动生成\n"]}, {"cell_type": "markdown", "id": "cb699443-e7c5-4925-a066-5272b95b3c7c", "metadata": {}, "source": ["在这部分，我们将演示如何通过使用保罗·格雷厄姆的文章示例，在1A中创建`card.json`和`README.md`文件（如果您选择了1C作为第1步）。\n", "\n", "#### `card.json`\n"]}, {"cell_type": "markdown", "id": "17492a57-33cd-4ab9-8b9e-d265ac7def05", "metadata": {}, "source": ["#### 演示\n"]}, {"cell_type": "markdown", "id": "01e10280-3c39-4c69-a551-157a32297ff8", "metadata": {}, "source": ["```json\n", "{\n", "    \"name\": \"保罗·格雷厄姆的文章\",\n", "    \"description\": \"基于保罗·格雷厄姆的一篇文章的标记的RAG数据集，包括查询、参考答案和参考上下文。\",\n", "    \"numberObservations\": 44,\n", "    \"containsExamplesByHumans\": false,\n", "    \"containsExamplesByAI\": true,\n", "    \"sourceUrls\": [\n", "        \"http://www.paulgraham.com/articles.html\"\n", "    ],\n", "    \"baselines\": [\n", "        {\n", "            \"name\": \"llamaindex\",\n", "            \"config\": {\n", "                \"chunkSize\": 1024,\n", "                \"llm\": \"gpt-3.5-turbo\",\n", "                \"similarityTopK\": 2,\n", "                \"embedModel\": \"text-embedding-ada-002\"\n", "            },\n", "            \"metrics\": {\n", "                \"contextSimilarity\": 0.934,\n", "                \"correctness\": 4.239,\n", "                \"faithfulness\": 0.977,\n", "                \"relevancy\": 0.977\n", "            },\n", "            \"codeUrl\": \"https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_datasets/paul_graham_essay/llamaindex_baseline.py\"\n", "        }\n", "    ]\n", "}\n", "```\n"]}, {"cell_type": "markdown", "id": "eeb93783-aa39-47c2-a449-7277c6d38901", "metadata": {}, "source": ["#### Template\n"]}, {"cell_type": "markdown", "id": "f690e28a-a71a-4195-a817-5ff6c3009b59", "metadata": {}, "source": ["```\n", "{\n", "    \"name\": <填写>,\n", "    \"description\": <填写>,\n", "    \"numberObservations\": <填写>,\n", "    \"containsExamplesByHumans\": <填写>,\n", "    \"containsExamplesByAI\": <填写>,\n", "    \"sourceUrls\": [\n", "        <填写>,\n", "    ],\n", "    \"baselines\": [\n", "        {\n", "            \"name\": <填写>,\n", "            \"config\": {\n", "                \"chunkSize\": <填写>,\n", "                \"llm\": <填写>,\n", "                \"similarityTopK\": <填写>,\n", "                \"embedModel\": <填写>\n", "            },\n", "            \"metrics\": {\n", "                \"contextSimilarity\": <填写>,\n", "                \"correctness\": <填写>,\n", "                \"faithfulness\": <填写>,\n", "                \"relevancy\": <填写>\n", "            },\n", "            \"codeUrl\": <可选-填写>\n", "        }\n", "    ]\n", "}\n", "```\n"]}, {"cell_type": "markdown", "id": "0d3df415-b6e1-4bd9-9113-261c53a27ec7", "metadata": {}, "source": ["#### `README.md`\n", "\n", "在这一步中，最低要求是采用下面的模板并填写必要的项目，这意味着将数据集的名称更改为您想要在新提交中使用的名称。\n"]}, {"cell_type": "markdown", "id": "44408187-bd23-4601-8219-13d1869762d0", "metadata": {}, "source": ["#### 演示\n", "\n", "点击[这里](https://raw.githubusercontent.com/run-llama/llama-hub/main/llama_hub/llama_datasets/paul_graham_essay/README.md)查看一个示例`README.md`。\n"]}, {"cell_type": "markdown", "id": "4de636bb-9efe-4f62-98dd-0c74b0e8f9cb", "metadata": {}, "source": ["```python\n", "# 模板\n", "\n", "这是一个示例模板文件，用于演示如何使用模板。\n", "\n", "```\n"]}, {"cell_type": "markdown", "id": "5d9a0098-47f0-4fe3-beb8-dfc390303179", "metadata": {}, "source": ["点击[这里](https://raw.githubusercontent.com/run-llama/llama-hub/main/llama_hub/llama_datasets/template_README.md)获取`README.md`的模板。只需复制并粘贴该文件的内容，然后用你选择的新数据集名称替换占位符\"[NAME]\"和\"[NAME-CAMELCASE]\"的相应值。例如：\n", "- \"{NAME}\" = \"保罗·格雷厄姆文章数据集\"\n", "- \"{NAME_CAMELCASE}\" = PaulGrahamEssayDataset\n"]}, {"cell_type": "markdown", "id": "4818bf2b-ed6f-4c59-80a5-50ce5c74b019", "metadata": {}, "source": ["#### [返回顶部](#top) \n"]}, {"cell_type": "markdown", "id": "edd76f13-6447-4e9f-a7ca-e906e486c066", "metadata": {}, "source": ["<a id='Step4'></a>\n", "## 4. 将Pull Request提交到[llama-hub](https://github.com/run-llama/llama-hub)存储库\n", "\n", "现在，是时候提交您的新数据集的元数据，并在数据集注册表中创建一个新条目了，这些信息存储在文件`library.json`中（即，请查看[这里](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_datasets/library.json)）。\n", "\n", "### 4a. 在`llama_hub/llama_datasets`下创建一个新目录，并添加您的`card.json`和`README.md`：\n", "```bash\n", "cd llama-hub  # 进入本地克隆的llama-hub目录\n", "cd llama_hub/llama_datasets\n", "git checkout -b my-new-dataset  # 创建一个新的git分支\n", "mkdir <dataset_name_snake_case>  # 按照其他数据集的约定命名\n", "cd <dataset_name_snake_case>\n", "vim card.json # 使用vim或其他文本编辑器添加card.json的内容\n", "vim README.md # 使用vim或其他文本编辑器添加README.md的内容\n", "```\n"]}, {"cell_type": "markdown", "id": "e1264fc9-6356-4d86-a5ec-20b454d93659", "metadata": {}, "source": ["### 4b. 在 `llama_hub/llama_datasets/library.json` 中创建一个条目\n", "\n", "```bash\n", "cd llama_hub/llama_datasets\n", "vim library.json # 使用vim或其他文本编辑器注册你的新数据集\n", "```\n"]}, {"cell_type": "markdown", "id": "c7c4ce8e-2fb1-4c89-8453-e66aee3a1241", "metadata": {}, "source": ["```json\n", "  \"PaulGrahamEssayDataset\": {\n", "    \"id\": \"llama_datasets/paul_graham_essay\",\n", "    \"author\": \"nerdai\",\n", "    \"keywords\": [\"rag\"]\n", "  }\n", "```\n"]}, {"cell_type": "markdown", "id": "3f1448f2-ce6b-4368-b737-abf7682eaed9", "metadata": {}, "source": ["```json\n", "  \"<填写>\": {\n", "    \"id\": \"llama_datasets/<数据集名称蛇形命名>\",\n", "    \"author\": \"<填写>\",\n", "    \"keywords\": [\"rag\"]\n", "  }\n", "```\n", "\n", "**注意**: 请使用与4a中相同的`数据集名称蛇形命名`。\n"]}, {"cell_type": "markdown", "id": "9af297ba-05fa-4a89-b52c-89cd9faaf258", "metadata": {}, "source": ["### 4c. 将更改`git add`和`commit`，然后推送到您的分支\n", "\n", "```bash\n", "git add .\n", "git commit -m \"my new dataset submission\"\n", "git push origin my-new-dataset\n", "```\n", "\n", "完成后，转到[llama-hub](https://github.com/run-llama/llama-hub)的Github页面。您应该会看到从您的分支发起拉取请求的选项。现在就去做吧。\n"]}, {"cell_type": "markdown", "id": "b56f1a1b-d05b-40a7-85e3-4d6adf8b776a", "metadata": {}, "source": ["#### [返回顶部](#top) \n"]}, {"cell_type": "markdown", "id": "7b840af1-1272-4e65-b9fd-ab295ef27358", "metadata": {}, "source": ["<a id='Step5'></a>\n", "## 5. 向 [llama-datasets](https://github.com/run-llama/llama-datasets) 仓库提交拉取请求\n"]}, {"cell_type": "markdown", "id": "7365bf7d-548d-472f-942e-fc8635e51945", "metadata": {}, "source": ["在提交过程的最后一步中，您将提交实际的`LabelledRagDataset`（以json格式）以及源数据文件到`llama-datasets` Github存储库。\n"]}, {"cell_type": "markdown", "id": "d70666fb-e4f2-4409-bdb2-86511c946067", "metadata": {}, "source": ["### 5a. 在`llama_datasets/`下创建一个新目录：\n", "\n", "```bash\n", "cd llama-datasets # 进入本地的 llama-datasets 克隆目录\n", "git checkout -b my-new-dataset  # 创建一个新的git分支\n", "mkdir <dataset_name_snake_case>  # 使用步骤4中使用的相同名称。\n", "cd <dataset_name_snake_case>\n", "cp <path-in-local-machine>/rag_dataset.json .  # 添加 rag_dataset.json\n", "mkdir source_files  # 添加所有的源文件\n", "cp -r <path-in-local-machine>/source_files  ./source_files  # 添加所有的源文件\n", "```\n", "\n", "**注意**：请使用与步骤4中相同的 `dataset_name_snake_case`。\n"]}, {"cell_type": "markdown", "id": "bd45ea83-a6e5-47d4-9de4-d38ea1d57971", "metadata": {}, "source": ["### 5b. `git add` 和 `commit` 你的更改，然后推送到你的分支\n", "\n", "```bash\n", "git add .\n", "git commit -m \"我新的数据集提交\"\n", "git push origin my-new-dataset\n", "```\n", "\n", "完成后，前往 [llama-datasets](https://github.com/run-llama/llama-datasets) 的 Github 页面。你应该会看到从你的分支创建拉取请求的选项。现在就去做吧。\n"]}, {"cell_type": "markdown", "id": "1ebdd568-2e61-4b9c-9c6b-f72875df6f26", "metadata": {}, "source": ["#### [返回顶部](#top)\n"]}, {"cell_type": "markdown", "id": "de772756-9c34-43fe-9e17-355de03affe8", "metadata": {}, "source": ["## 大功告成！\n", "\n", "您已经完成了数据集提交流程！🎉🦙恭喜您，感谢您的贡献！\n"]}], "metadata": {"kernelspec": {"display_name": "llama_index_3.10", "language": "python", "name": "llama_index_3.10"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}