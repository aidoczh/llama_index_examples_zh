{"cells": [{"cell_type": "markdown", "id": "9c8368b2", "metadata": {}, "source": ["<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llama_datasets/uploading_llama_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在 Colab 中打开\"/></a>\n"]}, {"cell_type": "markdown", "id": "1448e661-eaab-4e88-9f37-80566567e677", "metadata": {}, "source": ["# 将LlamaDataset 贡献给 LlamaHub\n"]}, {"cell_type": "markdown", "id": "ee479cd5-40eb-4e7d-92a8-42202bc700af", "metadata": {}, "source": ["`LlamaDataset`的存储是通过一个git仓库进行管理的。要贡献一个数据集，需要向`llama_index/llama_datasets` Github（LFS）仓库发起一个拉取请求。\n", "\n", "要贡献一个`LabelledRagDataset`（`BaseLlamaDataset`的子类），需要两组文件：\n", "\n", "1. 以`rag_dataset.json`命名的json格式的`LabelledRagDataset`文件\n", "2. 用于创建`LabelledRagDataset`的源文档文件\n", "\n", "这个简短的笔记本提供了一个使用Paul Graham Essay文本文件的快速示例。\n"]}, {"cell_type": "code", "execution_count": null, "id": "d1ec7dfd", "metadata": {}, "outputs": [], "source": ["%pip install llama-index-llms-openai"]}, {"cell_type": "code", "execution_count": null, "id": "4639b268-e0d4-40de-af97-198be1c62c62", "metadata": {}, "outputs": [], "source": ["import nest_asyncio\n", "\n", "nest_asyncio.apply()"]}, {"cell_type": "markdown", "id": "2acea4a6-30a5-45fb-a5e3-f4c0ba013154", "metadata": {}, "source": ["### 加载数据\n"]}, {"cell_type": "code", "execution_count": null, "id": "0784e81f-7845-4d34-a196-9f699356c999", "metadata": {}, "outputs": [], "source": ["!mkdir -p 'data/paul_graham/'\n", "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"]}, {"cell_type": "code", "execution_count": null, "id": "7ef0150c-1bce-4474-8fec-8b769aff192c", "metadata": {}, "outputs": [], "source": ["from llama_index.core import SimpleDirectoryReader\n", "\n", "# 加载文档并构建索引\n", "documents = SimpleDirectoryReader(\n", "    input_files=[\"data/paul_graham/paul_graham_essay.txt\"]\n", ").load_data()"]}, {"cell_type": "code", "execution_count": null, "id": "8de410fc-8ceb-49f2-9b43-06caf3dced31", "metadata": {}, "outputs": [], "source": ["# 生成与块相对应的问题\n", "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n", "from llama_index.llms.openai import OpenAI\n", "\n", "# 为llm提供者设置上下文\n", "llm_gpt35 = OpenAI(model=\"gpt-4\", temperature=0.3)\n", "\n", "# 实例化一个DatasetGenerator\n", "dataset_generator = RagDatasetGenerator.from_documents(\n", "    documents,\n", "    llm=llm_gpt35,\n", "    num_questions_per_chunk=2,  # 设置每个节点的问题数量\n", "    show_progress=True,\n", ")\n", "\n", "rag_dataset = dataset_generator.generate_dataset_from_nodes()"]}, {"cell_type": "markdown", "id": "45a36b15-19c5-4a69-997b-5ded125544e5", "metadata": {}, "source": ["现在我们已经生成了我们的`LabelledRagDataset`（顺便说一句，完全可以手动创建一个，使用人工生成的查询和参考答案！），我们将其存储到必要的json文件中。\n"]}, {"cell_type": "code", "execution_count": null, "id": "e34c2d0d-caf6-4960-bb37-6abd57b1ba4e", "metadata": {}, "outputs": [], "source": ["rag_dataset.save_json(\"rag_dataset.json\")"]}, {"cell_type": "markdown", "id": "e5088c85-6b56-4cf7-a93e-d0ba5880dfb3", "metadata": {}, "source": ["#### 生成基准结果\n", "\n", "除了添加一个`LlamaDataset`之外，我们还鼓励添加基准基准测试，供其他人用作衡量他们自己的RAG管道的参照。\n"]}, {"cell_type": "code", "execution_count": null, "id": "b366e286-39fb-487e-8ba4-1835352a0a94", "metadata": {}, "outputs": [], "source": ["from llama_index.core import VectorStoreIndex\n", "\n", "# 一个基本的RAG管道，使用默认设置\n", "index = VectorStoreIndex.from_documents(documents=documents)\n", "query_engine = index.as_query_engine()\n", "\n", "# 手动\n", "prediction_dataset = await rag_dataset.amake_predictions_with(\n", "    query_engine=query_engine, show_progress=True\n", ")"]}, {"cell_type": "markdown", "id": "db8640fc-9b94-4f22-b831-411b8f95d275", "metadata": {}, "source": ["## 提交拉取请求\n", "\n"]}, {"cell_type": "markdown", "id": "093e63cc-f244-42ec-bbc4-b67f104a2a51", "metadata": {}, "source": ["使用`rag_dataset.json`和源文件`paul_graham_essay.txt`（请注意，在这种情况下，只有一个源文件，但也可以有多个），我们可以执行两个步骤来将`LlamaDataset`贡献到`LlamaHub`中：\n", "\n", "1. 类似于为`loader`、`agent`和`pack`做出贡献的方式，为`llama_hub`存储库创建一个拉取请求，添加一个新的文件夹用于新的`LlamaDataset`。这一步将上传有关新`LlamaDataset`的信息，以便在`LlamaHub`用户界面中呈现。\n", "\n", "2. 创建一个拉取请求到`llama_datasets`存储库，实际上传数据文件。\n"]}, {"cell_type": "markdown", "id": "539c8f2f-bf6f-4a6d-b53f-0c8ca85fc891", "metadata": {}, "source": ["### 步骤 0（先决条件）\n", "\n", "首先，fork并克隆（到本地计算机）`llama_hub` Github仓库和`llama_datasets`仓库。您将从fork版本的新分支向这两个仓库提交pull请求。\n"]}, {"cell_type": "markdown", "id": "611a8a75-1aaf-479a-94d0-a9127f08fe12", "metadata": {}, "source": ["### 第1步\n", "\n", "在`llama_hub` Github仓库的`llama_datasets/`中创建一个新文件夹。例如，在这种情况下，我们将创建一个名为`llama_datasets/paul_graham_essay`的新文件夹。\n", "\n", "在该文件夹中，需要两个文件：\n", "- `card.json`\n", "- `README.md`\n", "\n", "特别是在您的本地机器上：\n", "\n", "```\n", "cd llama_datasets/\n", "mkdir paul_graham_essay\n", "touch card.json\n", "touch README.md\n", "```\n", "\n", "建议在此处查看先前提交的`LlamaDataset`，根据需要修改其相应文件以适应您的新数据集。\n"]}, {"cell_type": "markdown", "id": "3ee08d0e-2601-4978-bdb2-e28375454d7f", "metadata": {}, "source": ["在我们当前的示例中，我们需要`card.json`看起来如下所示\n", "\n", "```json\n", "{\n", "    \"name\": \"Paul Graham Essay\",\n", "    \"description\": \"一个基于Paul Graham的一篇文章的标记为RAG的数据集，包括查询、参考答案和参考上下文。\",\n", "    \"numberObservations\": 44,\n", "    \"containsExamplesByHumans\": false,\n", "    \"containsExamplesByAI\": true,\n", "    \"sourceUrls\": [\n", "        \"http://www.paulgraham.com/articles.html\"\n", "    ],\n", "    \"baselines\": [\n", "        {\n", "            \"name\": \"llamaindex\",\n", "            \"config\": {\n", "                \"chunkSize\": 1024,\n", "                \"llm\": \"gpt-3.5-turbo\",\n", "                \"similarityTopK\": 2,\n", "                \"embedModel\": \"text-embedding-ada-002\"\n", "            },\n", "            \"metrics\": {\n", "                \"contextSimilarity\": 0.934,\n", "                \"correctness\": 4.239,\n", "                \"faithfulness\": 0.977,\n", "                \"relevancy\": 0.977\n", "            },\n", "            \"codeUrl\": \"https://github.com/run-llama/llama_datasets/blob/main/baselines/paul_graham_essay/llamaindex_baseline.py\"\n", "        }\n", "    ]\n", "}\n", "```\n"]}, {"cell_type": "markdown", "id": "2c332954-560a-4769-be57-787089add4d5", "metadata": {}, "source": ["对于`README.md`，这些都是非常标准的，要求您在`download_llama_dataset()`函数调用中更改数据集参数的名称。\n", "\n", "```python\n", "from llama_index.llama_datasets import download_llama_datasets\n", "from llama_index.llama_pack import download_llama_pack\n", "from llama_index import VectorStoreIndex\n", "\n", "# 下载并安装rag评估器包的依赖项\n", "RagEvaluatorPack = download_llama_pack(\n", "  \"RagEvaluatorPack\", \"./rag_evaluator_pack\"\n", ")\n", "rag_evaluator_pack = RagEvaluatorPack()\n", "\n", "# 下载并安装基准数据集的依赖项\n", "rag_dataset, documents = download_llama_datasets(\n", "  \"PaulGrahamEssayTruncatedDataset\", \"./data\"\n", ")\n", "\n", "# 评估\n", "query_engine = VectorStoreIndex.as_query_engine()  # 先前定义，此处未显示\n", "rag_evaluate_pack.run(dataset=paul_graham_qa_data, query_engine=query_engine)\n", "```\n"]}, {"cell_type": "markdown", "id": "086f63ab-06f7-4a52-8271-9031530123e6", "metadata": {}, "source": ["最后，第一步的最后一项是创建一个条目到`llama_datasets/library.json`文件中。在这种情况下：\n", "\n", "```json\n", "    ...,\n", "    \"PaulGrahamEssayDataset\": {\n", "    \"id\": \"llama_datasets/paul_graham_essay\",\n", "    \"author\": \"andrei-fajardo\",\n", "    \"keywords\": [\"rag\"],\n", "    \"extra_files\": [\"paul_graham_essay.txt\"]\n", "  }\n", "```\n", "\n", "注意：`extra_files`字段是用于存储源文件的。\n"]}, {"cell_type": "markdown", "id": "0ec3d5a7-6ba8-40fa-bed6-a95d6c8813d6", "metadata": {}, "source": ["### 第2步 上传实际数据集\n", "\n", "在这一步中，由于我们在`llama_datasets`仓库中使用了Github LFS，因此进行贡献的方式与我们的其他开放Github仓库的贡献方式完全相同。也就是说，提交一个拉取请求。\n", "\n", "首先，fork `llama_datasets`仓库，并在`llama_datasets/`目录中创建一个新文件夹，该文件夹与在`library.json`文件中创建的条目的`id`字段相匹配。因此，对于这个示例，我们将创建一个名为`llama_datasets/paul_graham_essay/`的新文件夹。我们将在这里添加文档并创建拉取请求。\n", "\n", "在这个文件夹中，添加`rag_dataset.json`（必须命名为这个），以及其余的源文档，对于我们的情况来说是`paul_graham_essay.txt`文件。\n", "\n", "```sh\n", "llama_datasets/paul_graham_essay/\n", "├── paul_graham_essay.txt\n", "└── rag_dataset.json\n", "```\n", "\n", "现在，只需`git add`，`git commit`和`git push`您的分支，然后创建您的PR。\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}